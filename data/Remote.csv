,Job ID,Date,Company Name,Title,Location,Description,Level,Type,Functions,Industries,Solicitudes,Empleados,Quick Application,Emails,Visualizaciones,Recommended Flavor
0,2225762240,2020-10-21,Signifyd,Data Scientist,United States,"*This position requires you to be located in the US*Must be willing to work EST hours  The Data Science team at Signifyd builds the models that power our fraud detection engine. We make fraud prevention at scale possible. Our machine learning pipeline keeps us one step ahead of fraudsters and their constantly evolving tactics and our research and experiments develop into new products that improve the merchant payments experience. We expect our data scientists to be hands-on. We carry solutions from a brainstorm to experimentation and all the way to deployment. Some days you may spend doing research and designing experiments while others are spent using your analytical toolbox to surface insights into real-time fraud attacks. We’re a varied group with a diversity of strengths -- some team members came to us from academic backgrounds, others from engineering, some from big companies and some from small, but all of us are curious and collaborative. How you’ll have an impact:Building production machine learning models that identify fraudDesigning new algorithms that optimize all the key components of the Signifyd Commerce Protection PlatformWriting production and offline analytical code in Python and JavaResearching real-time emerging fraud patterns with the Risk Analysis teamWorking with distributed data pipelinesCommunicating complex ideas effectively to a variety of audiencesCollaborating with engineering teams to continuously strengthen our machine learning pipelineMentoring other members of the team Past experience you’ll need:An advanced degree (M.S. or Ph.D) in computer science, applied mathematics, or a comparable analytical fieldAt least 2-3 years of experience post M.S. requiredHands-on statistical analysis with a solid fundamental understandingDesigning experiments and collecting dataWriting code and reviewing others’ in a shared codebase, preferably in Python and JavaPractical SQL knowledgeFamiliarity with the Linux command lineMust be able to work EST hours Experience we love to see:Data analysis in a distributed environmentPassion for writing well-tested production-grade codeUsing visualizations to communicate analytical results to stakeholders outside your teamPrevious work in fraud, payments, or e-commerce",Algo de responsabilidad,Contrato por obra,"Ingeniería, Tecnología de la información","Internet, Software",74,None,False,,424,ACTIVELY_HIRING_COMPANY
1,2234272702,2020-11-03,TrueAccord,Data Scientist,United States,"Why TrueAccord?TrueAccord is a category-defining company. We combine machine learning with a human-based approach to transform debt resolution and to get people on the path towards financial health. Every year, more than 70 million Americans have negative experiences dealing with debt. We are changing this by providing personalized digital experiences that guide lenders and consumers through this challenging financial process.  With a world-class leadership team, passionate team members, and proprietary predictive models trained on years worth of transactional data, TrueAccord is well-positioned to deliver on a huge opportunity: helping millions of consumers to regain and keep their financial footing while lowering the cost of doing business for creditors across many industries. Team's Mission:TrueAccord has pioneered a new way of helping consumers deal with debt while safeguarding their credit scores. Using machine learning models to understand our consumers better, we remove the need for aggressive debt collectors completely, and work with consumers to cure their late debts with customized payment plans. TrueAccord has already helped over 11 million consumers deal with late debt, recovering higher amounts, and faster than traditional debt collectors. We do this by focusing on an automatically tailored repayment experience and carefully balancing the needs of creditors and debtors. Leading credit providers and debt aggregators, see recoveries in the 80% range vs. collections industry average of 60%.  Your Role:TrueAccord is looking for a data scientist to join its growing Data Science team.  You will join a team dedicated to creating a data driven culture and improving the efficiency and dependability of the way we make decisions. Our data scientists develop algorithms that enhance the collections process for our consumers, lead automation initiatives in the company and help create insights to better understand our product and performance. As a team member you will build machine learning models that optimize and elevate our automated debt collection strategy. You will work closely with engineers and product team partners to identify and prioritize machine learning-based projects destined to have the highest impact on external and internal customer experience. We’re looking for a driven, self-sufficient data scientist who can run with a project from conceptualization to production. You should have an excellent grasp on core machine learning techniques and a product focused mindset. You should be passionate about using data to create positive customer experiences and determined to have a huge impact at TrueAccord.  Key Responsibilities:Develop and maintain machine learning algorithmsApply data and algorithmic thinking to address business and domain problemsWork cross-functionally to identify high impact business needs and translate them into technical requirementsManipulate and curate data sets for analysis and model training You have:Advanced degree in statistics, applied mathematics, computer science or equivalent Minimum 1-3 years of data science experience, with focus in machine learningStrong foundational skills: Python, pandas, SQLHands on experience with machine learning tools, techniques, and frameworks (e.g. sklearn, Tensorflow, etc)Ability and desire to educate the rest of the company in data science concepts and techniques You might also have:Strong cross-functional communication skills with technical and non-technical partnersSolid understanding of experiment designExperience with natural language processing techniquesFinTech background What TrueAccord offers you + Culture & Benefits TrueAccord is a distributed company with a major presence in the San Francisco Bay area and Lenexa, KS. We offer a healthy work environment that continuously builds an inclusive and diverse culture where everyone is able to develop the best version of themselves. We are a dynamic group of people who are subject matter experts with a passion for change. We offer:*** Generous paid time off*** Paid training*** We promote work/life harmony*** Paid holidays*** Health, dental and vision benefits*** 401K with matching Our teams are crafting solutions to big problems every day. If you’re looking for an opportunity to do impactful work, join TrueAccord and make a difference. Our Dedication to Diversity & InclusionTrueAccord is an equal opportunity employer. We promote, value, and thrive with a diverse & inclusive team. Different perspectives contribute to better solutions and this makes us stronger every day. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",Algo de responsabilidad,Jornada completa,"Ingeniería, Análisis","Servicios financieros, Servicios y tecnologías de la información",160,None,False,,470,COMPANY_RECRUIT
2,2244976042,2020-10-27,Janes,Forward Deployed Data Scientist,"Coulsdon, England, United Kingdom","COMPANY With a legacy of more than 100 years, Janes provides the only single resource for comprehensive, unclassified and up-to-date intelligence on military equipment in production and use around the globe. By structuring and connecting this data to the inventories for more than 190 countries, Janes is uniquely positioned to provide our customers with timely, accurate, validated intelligence to support entity recognition, capability assessment and market analysis.Janes is a leading provider of timely and assured data, information, analysis and forecasts for Defence & National Security organisations globally. JOB PURPOSE You have a passion for finding insights in large datasets, developing novel and innovative solutions, having a positive attitude and taking pride in what you achieve on a daily basis. You enjoy working in a fast-paced environment where you engage with Defence & National Security subject matter experts on a weekly basis. You enjoy challenges and working on the most interesting data challenges in the industry. You challenge the status quo, supporting others in your team.The Forward Deployed Data Scientist will be a crucial member within a small innovation team, supporting the business by helping customers understand, integrate and use our content in ways that best supports their workflow and needs. Specifically, the role will support the development and delivery of custom solutions, using machine learning and statistical modeling.This is a new and exciting role, where the individual will play a key role in supporting the expansion of the services offered by Janes. The individual will be a core member of a small team, using novel technologies and systems to create and deliver new capabilities that adapt to and anticipate changing client requirements.  UK Security Clearance, SC minimum ROLE REQUIREMENTS Development of analytic (data science, machine learning, and data visualization) prototypes and capabilities to support our clients.Develop and implement novel analytic tools, work closely with software engineering team to deploy these tests to productProven ability to work independently with limited supervision, when required.Provide advisory support to customers on use of novel and new technologies to enhance data visualisation and consumption of complex data.Support the integration of our content within third-party systems and the optimisation of those systems to fulfil defined customer use cases.Support use case creation and refinement for demonstration and case studies and integrator support.Support the development of enhanced capabilities including content access and other enhanced search capabilities.Collaborate closely with cross-functional teams to identify gaps and structure problems.Provide feedback to the business on data, tools, technologies and workflow support required by the customer, to inform the development pipeline.Become a specialist in Jane’s content and its provision. THE IDEAL SKILLS AND EXPERIENCE FOR THIS ROLE ARE﻿3+ years of work experience involving quantitative data analysis to solve complex problems.Statistical modeling, supervised and unsupervised learning.Scripting languages e.g. PythonThorough understanding and experience of agile software development methodologies (e.g. SAFe, Scrum), values, and procedures.Strong analytical and problem-solving skills with a high attention to detail.UK Security Clearance, SC minimum.Databases SQL, graph database experience is a distinct advantage.Working with GIS Platforms, tableau, PowerBI.Degree (or equivalent) in Applied Math, Economics, Statistics, Engineering, Computer Science or other quantitative field. Relevant experience in applied areas of these fields will also be considered. Demonstrate a good understanding of Aerospace & Defence subject knowledge, although adjacent markets will also provide a degree of new approaches and learning to the team. For successful candidates, Janes provides a supportive, stretching and dynamic environment with the ability for you to grow rapidly both personally and professionally.   We value diversity at Janes and are committed to equal opportunities and creating an inclusive environment for all our colleagues. We welcome applicants regardless of ethnic origin, national origin, gender, race, colour, religious beliefs, disability, sexual orientation and age.",Intermedio,Jornada completa,"Desarrollo empresarial, Consultoría, Tecnología de la información",Servicio de información,90,None,True,,556,ACTIVELY_HIRING_COMPANY
3,2181308872,2020-10-13,Symphony AyasdiAI,Data Scientist,United Kingdom,"Ayasdi is breaking new ground in enterprise AI and is looking for data scientists to join our teams in London and New York. We have a unique approach combining best in class unsupervised and supervised techniques to solve hard problems in Anti Money Laundering, Fraud, Credit Risk and Liquidity. You will learn new techniques based on Ayasdi’s patented platform that combines Topology, Information Theory and Machine Learning to create the world’s most powerful global pattern discovery capability. As part of a growing team you will deploy our technology to help our customers solve their biggest and most impactful problems whether it be discovering the sinister Unknown Unknown’s evading their detection systems or re-balancing their Liquidity in the midst of a storm. We combine the rapid agility of a start up with the financial backing of the world’s largest private AI fund. At Ayasdi your contribution will make a difference to the world. Join us now!  Responsibilities:Directly interact with customers in the Financial Services industry to understand and help solve their business problems using the Ayasdi Enterprise AI platformBecome a master user and advocate of Ayasdi’s productServe as a technical and subject matter expert in Financial Services information technology, assisting sales during pre- and post- sales effortsMake research and development contributions to our core product offeringsInteract and collaborate with engineers and product managers, relaying feedback from customers to continually develop our product Minimum Requirements: MS or PhD in quantitative field5+ years hands on experience delivering machine learning applications in financial services with demonstrable results2+ years working within a financial institution or related organization 2+ years experience working with an Analytics software vendorDomain experience in Anti Money Laundering, Fraud, Credit Risk or LiquiditySolid understanding of existing statistical and machine learning techniques Ability to translate analytic ideas into code using Python and at least one other programming languageFamiliar with one or more data science toolkits such as Spark, Hadoop, Hive, scikit-learn and pandasAbility to travel 30% in the field as necessary",Intermedio,Jornada completa,"Tecnología de la información, Análisis, Ingeniería","Software, Servicios financieros",46,None,False,,603,ACTIVELY_HIRING_COMPANY
4,2155701772,2020-10-15,MBN Solutions,Data Scientist,"Edinburgh, Scotland, United Kingdom","Data Scientist – Edinburgh £45,000 - £60,000 + Comprehensive Benefits  MBN are partnering with a global leader in the development and delivery of software products to the Oil & Gas sector. The organization have an impressive array of international clients who they provide with state of the art engineering software products fueled by machine learning & AI. The business are looking to expand their data science team by appointing a Data Scientist with a keen interest in developing and deploying machine learning algorithms within an engineering & physical context. These models help optimise the management of oil & gas fields using real time data and predict failure across multiple engineering products contributing to positive environmental impacts. Key skills & experience required: Commercial experience creating and developing machine learning algorithms (use cases across Supervised & Unsupervised methods as well as Classification/Clustering techniques)Strong programming skills across Python, R or C++ as well as an understanding of opensource frameworksThe ability to manipulate large and deep data sets using SQL and create interactive dashboards using Tableau (or equivalent BI tool) highly advantageousEffective communicator, able to work alongside engineering teams as well as other stakeholders and explain the benefits of the models from a business and technical concept.MSc or PhD qualified preferentially across Computer Science, Engineering Physics or Mathematics Machine learning * Data Science * Python * Engineering * Deep Learning * Artificial Intelligence﻿For more information or to apply, please send your updated CV to Kris@mbnsolutions.com",Intermedio,Jornada completa,Tecnología de la información,Servicios y tecnologías de la información,381,None,True,Kris@mbnsolutions.com,1375,ACTIVELY_HIRING_COMPANY
5,2289225361,2020-11-08,None,Junior Data Scientist - Remote / London,"London, GB","Avanti Recruitment have partnered with a Global Data Analytics and Information provider to support them in growing their Data Science team in London.  Our client has a huge global presence with locations all over the world in over 50 locations and an annual revenue of c.£4bn per year. A lot of their business is done with companies within the Transport, Finance and Energy sectors and they are always looking to expand their offering, which is why they are building out their Data Science team in London to help support this.  They are looking for bright, hungry and dedicated junior Data Scientists to come in and work closely with the existing team. There is loads of training on offer that ranges from online courses, mentoring from senior members of the team, 'future leaders’ training as you develop your career and industry specific expert training from thought leaders within the sector. This is a great opportunity for someone to further develop their career, with clearly defined career progression available that will see you develop from junior level right through to senior, principal, Team Lead and management and Senior Leadership positions within the business.  Experience That Interests Them Includes  Python PySpark Machine Learning experience Experience with Data Visualisation Management of Big Data Exposure to AWS or other Cloud based technologies Experience in the areas above would be hugely beneficial, but they will consider candidates with similar experience in other areas providing they have an interest in learning and developing their knowledge in the areas mentioned.  Our client is offering a salary of £30k - £35k as well as a host of brilliant additional benefits that I am happy to share if you are interested in learning more.  If you are interested in the role or want further information, please get in touch or apply now for immediate consideration.",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Software, Dotación y selección de personal",30,None,False,,112,JOB_SEEKER_QUALIFIED
6,2218898134,2020-10-28,Current Health,Data Scientist,United Kingdom,"Who are Current Health?  Current Health is a global healthcare technology company, focused on predicting illness and delivering earlier intervention so that every human can live a healthier, longer life. In 2020, Current Health has grown 8500%, partnering with some of the world’s leading healthcare institutions and pharmaceutical organizations and improving health outcomes for patients across the world. What does a Data Scientist do here? We are looking for Data Scientists who are interested in the cross-section between acquisition of physiological signal from the human body and machine learning. You will work at the intersection between our wearable device and our data platform, Analyse and communicate current performance of algorithms to relevant internal stakeholders. You will create intelligent models to improve real world performance of mathematical based models and time series models to capture new and novel patient deterioration patterns You will be deeply involved in collating and providing diagnostic information to clinical staff to help them better understand their patients leading to the development of biomarkers for detecting patient disease. You will be expected to assist with the design of human studies to collect data. About you ﻿You will have proven experience with a common data science language (ideally python) and a query languageYou will have experience manipulating large and deep data sets (from 100s MB to 100s TB)You will have experience with feature extraction and feature selectionExperience in presenting data driven decisions to non-technical peopleExperience in extracting data from multiple sources such as S3, Hive, Athena, HDFSYou will have experience with time series modellingYou will have strong understanding of how to use statistics to evaluate modelsYou will have proven experience using both labelled and unlabelled data to build modelsExperience with digital signal processing would be a huge bonus i.e. FFTs, digital filtering, wavelet transformsFamiliarity with various data science pipelines and lifecycles for iterating models such as unix/liux pipelines would be idealExperience with source control preferably Git would be beneficialFamiliarity of clinical study protocol designExperience with distributed computing i.e. hadoop, spark, hive would be beneficial",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Atención sanitaria y hospitalaria,262,None,True,,763,ACTIVELY_HIRING_COMPANY
7,2271869059,2020-10-21,Bitso,Data Scientist,"Mexico City, MX","About The Company  Bitso is Latin America's leading cryptocurrency platform. Our goal is to evolve how we think about and use money. To achieve this, we provide individuals with fast, cheap, seamless and user-friendly financial services powered by blockchain technology. Cryptocurrency, or programmable money, does not rely on an intermediary to give it legitimacy or value. Instead, it is valuable because of the peer-to-peer technology that runs it. We think it's time for the world to have an alternative form of currency.  We believe that we should all have the opportunity to use our money whenever we want it, and how we want it, without boundaries or schedules: we believe that we all have the right to access and use safe, fast and efficient financial services that do not charge excessive fees and that suit the digital era we live in. We firmly believe in Blockchain technology and its use cases. We support financial innovation and everybody's right to access new and beneficial technologies. Visit us at https://bitso.com/  What we value:  Passion for Bitso's mission Entrepreneurial mindset, this is key! Be inspired and energized by our values: Drive change, Be human, Embrace your freedom Rolling up your sleeves and getting things done. No task is insignificant Raising the quality bar and challenging others  Seeing opportunities when others see problems Passion for working with a diverse group of people and different points of view A collaborative spirit who gives thoughtful and constructive feedback Making decisions guided by long-term company objectives Setting ambitious goals, taking risks, and empowering others   Responsibilities:  Develop metrics that can help us measure products performance. Carry out statistical analysis to understand user behavior. Carry out literature review to find the right modelling approach to each business problem. Develop machine learning models to predict user activity. Design, supervise and measure the impact of experiments.   To succeed in this role, you'll need:  Degree in: Computer Science, Statistics, Math, Economics, Finance, Actuarial Science or similar. Interest in building a career as a data scientist. Knowledge in manipulating databases. Experience in Causal Inference is a plus. Experience on the use of statistical methods to predict behaviors. Fluent in English and Spanish.   *These are the applicable requisites, although equivalent competencies in any of the above will also be considered.*  Additionally, it would be nice if you:  Have knowledge in how to program in:  SQL R Python   Compensation and Benefits:  Purpose: You'll be part of something bigger, working towards financial inclusion across Latin America Culture: You'll work in a thriving, friendly, and fun environment that promotes debates, jokes, discussions, video games, and occasional Catan matches. People: You'll work with some of the most driven and smart people in the crypto space in Latin America. Salary: We pay at the top of the market. Health Insurance: We offer one of the best medical plans. Performance Bonus: Your hard work will be rewarded with a juicy incentive-based bonus. Unlimited Free Days: We want our employees to recharge their batteries and explore who they are outside of the office.   *As you move on to the final stage of our talent attraction journey, we will ask you to please complete our background check process.*  *This role can be performed 100% remotely*",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Software, Servicios financieros",55,None,False,,217,None
8,1990927515,2020-11-04,BlackSwan Technologies,Data Scientist,Russia,"Who You Are:You are a full-stack data scientist, an experienced quantitative thinker who wants to develop further as both a data scientist and an engineer. You are skilled at finding the precise mathematical kernels of real-world problems and want to bring that talent to bear on the business questions facing the world’s leading companies. You are excited to apply your existing expertise in fields such as statistics and computer science on BlackSwan’s ELEMENT state-of-the-art infrastructure. You are excited to work at a startup where you will have a chance to expand your scientific and engineering skills to new areas.  You share BlackSwan’s commitment to winning Who We Are:BlackSwanTechnology.ai is a uniquely positioned data science and human Intelligence insights product company. In our primary application, we offer enterprise level AI empowered Business Applications to the data intensive organisations. We are currently building our next generation Enterprise AI Operating system which will be the world’s most advanced most comprehensive product for Digital Transformation. Our advantage is existing unbelievable human assets, science, engineering, and SaaS product capabilities that align very well with the technology needs.To help you succeed, we provide a supportive environment that fosters collaboration between teams and team members, where learning and professional growth is considered a key part of your success, and of ours. We offer a flexible work environment with a family-friendly work-life balance What A Great Candidate Looks Like:MS or higher in the following areas: Statistics and MathematicsAt least 3-5 years of professional industry experience, in addition to your academic experienceOutstanding quantitative analytical ability.Able to take less than precise business requirements and translate them into logic problems which you enjoy solvingIndependent and creative approach to problem solvingExcellent written and verbal communication skills, with prior experience explaining assumptions, conclusions and methodology to both internal and external customersIn-depth knowledge of Statistics/Probability/Machine LearningGeneral Statistical concepts such as hypothesis testing, estimation, inferenceSupervised and unsupervised statistical techniques such as regression (linear / logistic), time series analysis, clusteringMachine Learning foundations such as bias/variance trade-off, regularization, dimension reductionReal world experience with popular machine Learning algorithms such as Random Forest, Boosting, SVMsExperience with unstructured text data using NLP methods such as Latent Dirichlet Allocation (LDA), Latent Semantic Analysis (LSA), Sentiment Models, Word Embeddings, Text Similarity, Entity extraction is a strong plusStrong programming experience in Pyton and one of the following of the following: Scala/Java, RUnderstanding of algorithm complexity and performance implicationsKnowledge of data structures and algorithmsGood knowledge of Knowledge EngineeringGood knowledge of Graph technology, Knowledge Graphs, Graph Data bases and OntologiesExperience with SQLFamiliarity with R Shiny framework is a plus The Opportunity We Offer:BlackSwanTechnologies.ai is seeking to fill a Full-Stack Data Scientist position in on our Data Science team. We work closely with the Product Management team and Platform engineers to anticipate company needs and quickly put state-of-the-art mathematical tools into the hands of end users. Members of the Data Science team translate real world problems into quantitative language, find or create algorithms to solve those problems, and implement them in code. Our team values a creative and empathetic approach to problem solving and strives to maintain rigorous scientific and engineering standards. We will give you the opportunity to work on the full data science pipeline, bringing solutions from basic research all the way to production. We relentlessly solve problems. We win together.",Intermedio,Jornada completa,Tecnología de la información,Software,378,None,True,,1945,ACTIVELY_HIRING_COMPANY
9,2251938982,2020-10-29,Quora,Data Scientist - New Grad 2021,"Mountain View, CA, US","[As of June 2020, Quora has become a 'remote-first' company. This position can be performed remotely from anywhere in the world, regardless of any location that might be specified above.]  About Quora:  The vast majority of human knowledge is still not on the internet. Most of it is trapped in the form of experience in people's heads, or buried in books and papers that only experts can access. More than a billion people use the internet, yet only a tiny fraction contribute their knowledge to it. We want to democratize access to knowledge of all kinds — from politics to painting, cooking to coding, etymology to experiences — so if someone out there knows something, anyone else can learn it. Our mission is to share and grow the world's knowledge, and we're building a world-class team to help us achieve this mission.  About the Team:  Because Quora is such a data-driven company, our data scientists play a central role in the product development process by uncovering key insights from our data. As a data scientist, you'll work closely with engineers, product designers, and product managers to devise appropriate measurements and metrics, design randomized controlled experiments, build visualizations, and tackle hard, open-ended problems. You'll also develop tools and infrastructure to scale and automate the analyses that enable rapid product iteration. Quora has a wide range of rich data, giving you ample room for exploration and creativity. We use a variety of tools -- primarily Python and SQL — to analyze data and communicate results with the rest of the company.  While Quora's data scientists come from a variety of backgrounds, including statistics, computer science, economics, physics, mathematics, sociology, chemical engineering, and so on, we all share a love for data and continuous learning. Especially in your first role post-graduation, we realize that mentorship is important for professional growth and development. Every data scientist has a mentor and weekly 1:1s with their managers to get feedback and support for your career growth.  To give you a taste of what data scientists at Quora do, here are some example projects:   Analyze traffic patterns to similar questions and understand the metric implications of duplicate questions Forecast growth trajectory of Quora in different languages and identify growth bottlenecks and drivers Evaluate long term effects of a ranking algorithm change beyond short term metric gains as shown in experiments Devise metrics and build dashboards to measure the success of a new product feature or initiative Explain suspicious metric spikes as measured by dashboards and A/B tests Make trade-off and recommend product decisions when a key metric improves but another one drops in an A/B test  Responsibilities:   Extract actionable insights from broad, open-ended questions to influence product strategy and drive roadmap decisions Analyze data to understand the root causes of metric movements and uncover growth opportunities Design and evaluate A/B tests to make informed recommendations on product changes Develop metrics and create dashboards to orient the direction of product development and track the success of the product  Minimum Qualifications:   B.S., M.S., or Ph.D. in a scientific or quantitative field Proficiency in using SQL and procedural programming languages (e.g. Python, R) to manipulate and analyze data Rigorous coursework in statistical techniques (e.g. hypothesis testing, regression) Relevant past internship or research experience working with large data sets and experiments Demonstrated ability to exercise judgment and combine quantitative skills with product judgment to translate numbers into insights Demonstrated ability to clearly explain data results to cross-functional teams  Preferred Qualifications:   Experience in working with large data sets and distributed computing tools (Hive, Redshift) Experience pushing code and navigating a complex codebase Active Quora user with curiosity about the product  Further Reading:  Check out these resources (all on Quora!) to learn more.   Quora Data Science Team Session: https://www.quora.com/session/Data-Science/1 Quora data scientists answered a bunch of questions on Quora. Our Blog: Check out some of the things we've written up to share: https://www.quora.com/q/quoradata Machine Learning Engineer vs. Data Scientist: This is a commonly asked question. See https://www.quora.com/What-is-the-difference-between-a-machine-learning-engineer-and-a-data-scientist-at-Quora. If you are primarily interested in machine learning, please consider applying to our machine learning engineering opportunities instead of data science opportunities.   We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.  California Consumer Privacy Act (CCPA) disclosure",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Marketing y publicidad, Software, Internet",2077,None,False,,5359,COMPANY_RECRUIT
10,2148859560,2020-10-31,"Resolution Technologies, Inc.",Data Scientist - 100% Remote,Nashville Metropolitan Area,"DATA SCIENTIST - 100% Remote Data Scientist Responsibilities: Interpret and understand business needs/market opportunities, and translate those into production analytics.Select appropriate technologies and algorithms for given use cases.Work with other data scientists, product managers, and engineering teams to tightly integrate new analytic capabilities.Prepare reports, visualizations, and other documentation on the status, operation and maintenance of the analytics you create.Stay current on relevant machine learning and data science practices, and apply those to existing problem sets. Data Scientist Requirements: Bachelor’s in Math, Engineering, or Computer Science (or technical degree with commensurate industry experience).Understanding of machine learning algorithms, processes, tools, and platforms including: CNN, RNN, NLP, Tensorflow, PyTorch, etc.Proficient with the following (or comparable): Linux, Python, scikit-learn, NumPy, pandas, spaCyExperience with libraries like Tensorflow/PyTorch and with machine learning on large datasets/sparse data with structured and unstructured data.Great communication skills, ability to explain predictive analytics to non-technical audiences. Data Scientist Nice to Have: Familiarity with AWS services such as Lambda, S3, DynamoDBExperience with DockerExperience with CI/CD developmentExperience with speech-to-text or OCRPersonal projects using machine learningDemonstrated interest in audio, video, images, or text You Are Someone Who: Loves to solve difficult and interesting problems.Has a passion for code quality and craftsmanship but can balance that with shipping code.Views your profession as your craft and continuously pursues excellence in your work.Thrives in a fast-paced, high-growth startup environment.Collaborates effectively across various teams, coordinating regularly to set and manage expectations. You’ll Experience: Being a key part of a fast-growing software company where you can make a difference.Comprehensive insurance plans.Monthly wellness allowance.Flexible paid time off & paid volunteer time.Remote workLearning & development.Participating in team outings, events, and general fun! Helping to change an industry by serving the men and women that make our world turn.",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Servicios y tecnologías de la información,1852,None,True,,5184,ACTIVELY_HIRING_COMPANY
11,2176611462,2020-10-10,Accela,Data Engineer,"Dublin, IE","About Us  Accela is the industry pioneer in government licensing, permitting, service request, and inspection solutions, with more than 20 years of experience. We offer cloud based Civic Applications and a robust, scalable solutions platform informed by industry best practices. In short, Accela helps governments innovate, so they can improve the business and citizen experience, promoting community development and creating an environment where citizens and businesses thrive.  At Accela, employees enjoy a culture that emphasizes performance, productivity and collaboration. You can’t help but feel empowered and motivated when you work with like-minded individuals who are passionate about contributing to a market-leading, high-growth software organization with proven technology.  Accela Ireland  Accela has recently established a new development center in Dublin, Ireland. You will be joining this team developing GovTech solutions connecting people, things and businesses in Government.    Where You Fit  We are looking for a confident, self-motivated individual with a passion for technology and excellent communication skills who thrives in a collaborative team environment. You will be a part of an energetic team with a passion for building great software and a collaborative upbeat work ethic where you have ownership over a part of each release. You are a Data analyst, passionate about data integrity and smart reporting solutions. You are interested in working on market leading cloud-native product features and prototypes in a fast-paced software development team. Your strong analytical skills and diligent attention to detail will help us deliver on a progressive data roadmap which includes machine learning and AI initiatives. You are a highly organized, critical thinker with skills in statistical modelling.  Critically, you’re a collaborative team player with a fantastic work ethic.  Impact You Will Make In The Role  Identify & validate data sources, transformation rules and target data Document and describe semantic relationships between data Audit of important data elements to ensure data integrity Monitor and analyze new data to identify candidates for mapping Interfacing with product and business stakeholders to help support creation of highly effective data models Work closely with Engineering, data science, product and cloud operations to help solve problems at scale Cross validation skills and dataset evaluation Familiar with ETL and ELT processes Experience in data preparation, transform and warehousing     Technical Skills And Capabilities  Power BI skills Strong DB experience - SQL Server preferred Good understanding & working experience in the cloud - Azure Cloud is a plus Azure Analysis services or similar DAX skills   Nice to haves  Azure Synapse, Azure Data Factory Apache Spark, data bricks SQL Server Reporting Services (SSRS) Python   Qualifications And Experience  BA/BS computer science, data analytics, or relevant professional experience   Benefits And Perks  Beyond a stellar work environment, great people and inspiring, innovative work, we have some great benefits and perks:  Central Dublin Office Location 25 vacation days Ireland Standard Holidays Pension Contribution Supplemental Healthcare Package  Accela is an Equal Opportunity/Affirmative Action Employer  All qualified applicants will receive consideration for employment without regard to race, sex, color, religion, national origin, protected veteran status, or on the basis of disability, gender identity, and sexual orientation.",Sin experiencia,Jornada completa,Tecnología de la información,"Software, Servicios y tecnologías de la información, Internet",715,None,True,,2185,ACTIVELY_HIRING_COMPANY
12,2183079310,2020-10-14,Possible,Data Scientist,United States,"Do you desire to work with large amounts of data? Are you interested in building a data science function while doing meaningful work? Have you always wanted your work to have a positive societal mission to help underserved communities? As a Data Scientist at Possible, you will work on interesting, high impact and intellectually stimulating data science projects. Key responsibilities including: Life cycle credit policy management ranging from acquisition to collections, underwriting/machine learning models development, credit risk portfolio reporting, and monitoring, fraud management and prevention, new product analysis and definition, campaign management, and credit strategy testing. This role requires a high level of analytical problem solving and collaboration as you work cross-functionally to answer key strategic questions and drive decision making. This role reports directly to the Head of Data Science and ML. Roles & Responsibilities:Data AnalyticsDesigning, developing, and implementing machine learning models/algorithmsBuilds underwriting models to increase loan funding rates while lowering lossesDrives improvements in customer acquisition and fund recoveryIdentifies and evaluates new data sources to improve customer acquisition and fund recoveryWorks holistically across the entire risk management continuum including marketing channel evaluation and pre-approval criteria for existing customersContinue to test new strategies and models and work with the fund recovery team to improve cash collectionDrives analysis and ongoing improvements to the loss of performance of new markets.Working with other departments (including marketing, loan operations, finance, etc) evaluates new product opportunities and forecasts likely loss performance.Evolves strategies and pricing recommendations to improve performance as the new products scale.Work experience and education, knowledge, and skills. For this position we are looking for an experienced data scientist with:A bachelor's degree in statistics, data science, applied mathematics, computer science, or engineering is required. An advanced degree from a respected academic institution is preferred.2-3 years of hands-on experience using tools such as R, Python, SQL, SparkPrior experience using reporting tools such as Tableau, Looker, or equivalentSelf-starter with the ability to develop insightful financial models and quantitative analysis, paired with strong critical thinking and sound business judgmentExcellent organizational skills with the ability to set priorities and to work simultaneously on several projects.Excellent analytical and numerate skills. Attention to detail.Experience in analyzing large scale data in both structured and unstructured settingsKnowledge of cloud computing and AWS services is a plus About Possible FinancePossible Finance is a fast-growing Fin-tech startup, we believe financial health is something all everyone deserves, not just the affluent. We’re committed to empowering you with the tools to better your economic situation. We promise to be transparent, serve with kindness, be responsible, and hold ourselves accountable for creating positive change.",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información","Servicios financieros, Software",968,None,True,,2255,ACTIVELY_HIRING_COMPANY
13,2232853103,2020-11-02,Charlton Howard,Data Scientist,"London, England Metropolitan Area","In a few short years this business have already established themselves as a recognised Data Science consultancy, delivering huge insight in fraud detection, bitcoin transaction risk, real-time predictive analytics (to name a few) to some of the biggest FTSE businesses in London. We are beginning to grow our Data Science function, and with that are looking to bring on a Data Scientist to help deliver on projects as well as growing out our DS function As the Data Scientist, you will be working closely Lead Data Scientists and other Data Engineers, learning from both, furthering your skills in building data pipelines using a variety of different using a variety of tools, such as Apache Spark and Kafka, and improving your Python expertise, whilst honing you skills as Data Scientist with clear goals to move into a more leadership style role in the future.  So what do you need as a Data Scientist:Commercial experience of delivering Data Science projectsA Masters or PhD in a Mathathmatics, Statistics or Data Science related fieldStrong programming skills in Python, R or any other programming languageA good fundimental understanding of statistical models This is an amazing opportunity for a Data Scientist, not only to grow your career and move into a more senior or leadership position (which will accelerate your career massively), but also you will be having a massive impact on some of the biggest organisations globally Apply to this Data Scientist position now and we will be in touch to tell you more. Charlton Howard is a Trading Name of Talent Point Ltd. Talent Point Ltd and Charlton Howard are equal-opportunity employers and do not discriminate against these or any other class protected by applicable law. No terminology in this advert is designed to discriminate on grounds of gender, race, colour, religion, creed, disability, age, sex or sexual orientation.",Intermedio,Jornada completa,Tecnología de la información,Dotación y selección de personal,199,None,True,,561,JOB_SEEKER_QUALIFIED
14,2011663386,2020-10-13,Marketdata,Data Engineer,"São Paulo, Brasil","Desafios:Analisar e desenvolver soluções para ingestão e consumo de grandes volumes de dados estruturados ou não, em tempo real ou background, com alta performance e qualidade, garantindo a disponibilidade destas informações para a áreas clientes, principalmente CRM. Requisitos:Atuação com desenvolvimento de software.Foco em Spark e Hive.Desenvolvimento Orientado a teste.Padrões de Desenvolvimento.Geração de relatórios e documentação do projeto.Busca/Pesquisa e aplicação de novas tecnologias de mercado.Desenvolvimento de Aplicações orientadas a serviço.Tratamento de dados (engenharia de dados) para ingestão de dados em clusters, de forma a preparar os dados para análise.Considere também como requisitos conhecer estrutura de bancos relacionais. Experiência com SQL.Experiência e conhecimento em processo com ferramentas de ETL.Conhecimento e vivência em projetos com ecossistema Hadoop (Preferencialmente HDFS,Hive e Impala)Linguagens de Programação (Java e Python, principalmente)Graduação em: Análise de Sistemas, Ciência da Computação, Engenharia ou Matemática.Pós-Graduação em: Big Data, Analytics  ﻿Benefícios:Vale-Refeição, Assistência Médica, Assistência Odontológica, Seguro de Vida, Vale-Transporte, Auxílio Creche, Auxílio Educacional após 1 ano. Região: São Paulo/SP",Intermedio,Jornada completa,Análisis,Marketing y publicidad,241,None,True,,1404,ACTIVELY_HIRING_COMPANY
15,2243977889,2020-11-06,Acorns,Data Scientist,Los Angeles Metropolitan Area,"Data Scientist | Acorns At Acorns, we're building a financial wellness system that enables everyday Americans to save and invest every day. We are transforming the category and recruiting a team that is relentless at fulfilling our mission. The Acorns team comes together every day to deliver a revolutionary product to its customers, the up-and-coming. If you thrive in an environment where you can push yourself beyond all previous thresholds of possibility, come join us at Acorns. Acorns is actively seeking a motivated, detail-oriented, and solution-focused Data Scientist. This position will reside in the Data Science group, which serves as the central data science team for the company. The team is responsible for developing and using mathematical modeling, data mining, and machine learning techniques to be agents for good by helping look after the financial best interests of the up-and-coming. The Acorns Data Science group is focused on solving problems that directly affect customers, including recommendation engines, fraud prevention, and customer intention inference. But these aren’t Kaggle-type problems: we operate with urgency and often with imperfect data. We know that solving problems with data is an art and a science. Data Scientists at Acorns are as good at communicating and collaborating as they are at building models and writing code. At Acorns, Data Scientists have broad latitude around data and you will collaborate with groups including Analytics, Engineering, Product Management, Marketing, Operations, Risk, and Business Development. This role has the option to be remote or based in our Irvine or New York offices. You are not expected to have experience with all the listed requirements. If you feel passionately about Acorns' mission, vision and values, please apply.  Within 1 month, you will:Learn Acorns products, data warehouse, and how data fits into the products.Discover new opportunities to apply data science concepts to the portfolio of products.Present findings to the Data Science team members.Interact with multiple teams. Within 3 months, you will:Have established architecture and implementation for an intelligence-driven product feature in a data-rich environment.Made production quality code commits into the team’s repository.Contributed to the broader team’s success by offering ideas and constructive feedback to other team member’s projects.Proposed novel ML research directions that will eventually power new products. Within 6 months, you will:Collaborated with the Product Management team to plan projects and recommend areas for the next generation of Acorns products.Partnered with Engineering teams to deliver data science solutions into the product with proper API design.Be able to responsibly represent the Data Science team with other departments. What you will bring to Acorns:Empathy for our customers’ financial situations and the desire to help our customers in need of personalized products and services.The ability to uphold the values of transparency, honesty, and support for the team.An ability to explain complex problems in a simple way.Capability to build algorithms that touch statistics and machine learning.Knowledge of scalable and efficient methods for large scale data analysis and model development.Pride in your work Requirements:BS in Computer Science, Statistics, Mathematics, Economics, Physics, Engineering or a related field, or equivalent experience.3-4+ years of experience in working with noisy real-world structured and semi-structured data.Python or Scala, with related statistical and machine learning packages.Background in data mining, machine learning, statistical analysis, or mathematical modeling, with experience deploying models in a production environment.Experience with A/B testing methodologies and experiments.Hunger for impact, drive, and creativityStrong SQL abilities and experience with massive relational database systems.Able to take a complex, ambiguous topic and turn it into a defined problem that answers the business question we are trying to solve.Excellent communication skills  BonusMS or Ph.D. in Statistics, Mathematics, Computer Science, Economics, Physics, Engineering or another quantitative field. Experience writing production quality, version-controlled code.Knowledge of basic macroeconomic concepts.A belief that your work is tied to your life's mission.Optimistic about the potential of societal change. What we offer:Competitive salary and stock options.A comprehensive benefits package to meet the needs of you and your family.Flexible paid time off.Numerous career possibilities that allow you to grow with Acorns.Talented and motivated team members who care deeply about one another, our mission and our customers.The rare opportunity to create a new world. We inspire one another every day to do meaningful work that solves big societal challenges. About Acorns:Acorns is the leading micro-investing app in the U.S. It allows users to round up their daily purchases and automatically Invest the Change® into a low-cost, diversified portfolio of exchange-traded funds offered by some of the world's top asset managers (including Vanguard and BlackRock). Founded in Newport Beach, Calif., by father and son team Walter and Jeff Cruttenden, Acorns provides a simple entry-point using the Acorns app on iPhone or Android. Customers accumulate fractional shares in one of five portfolios constructed by world-renowned Nobel Laureate economist Dr. Harry Markowitz. Acorns' smart portfolio algorithms automatically work in the background of life, helping users build wealth naturally, pennies at a time. From Acorns mighty oaks do grow. Mission:With benevolence and courage, we look after the financial best interests of the up-and-coming: beginning with the empowering step of micro-investing.  Commitment to Diversity, Equity & Inclusion:Acorns believes diversity, equity and inclusion are fundamental obligations that strengthen our team. We need a diverse, multi-disciplinary team to build a meaningful company and culture.  Values:Lead with heartMake bold decisionsAlways build trustNever stop growingFind a way",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Servicios financieros,102,None,False,,546,COMPANY_RECRUIT
16,2011745415,2020-10-31,LifeBell AI,Data Scientist,United States,"The OpportunityAs a Data Scientist at LifeBell AI, you’ll be responsible for developing and validating novel machine learning approaches for early prediction of sepsis and other clinical conditions. You'll work closely with our CTO, CSO, data science core, and engineering teams. You’ll join a tight-knit group that values collaboration, continuous improvement, and solving challenging technical and product problems in an emerging space. Plus, we like to have fun along the way. About UsLifeBell AI creates intelligent software that saves lives by harnessing the latest advances in machine learning, analytics, and sensor technologies across healthcare. We’re a fast-growing, fully funded, Atlanta-based technology startup, with both local and remote employees. Join us as a data scientist in our mission to reduce morbidity and mortality from sepsis, a life-threatening condition that affects over 48 million people globally each year. Partners include top governmental, healthcare, and academic institutions. LeadershipLifeBell AI is founded and led by Erez Goren and Gari Clifford, PhD. Erez was previously the founder & CEO of Radiant Systems (NASDAQ: RADS, acquired by NCR for $1.2B), BlueCube Software (acquired by RedPrairie), and Hi-Rez Studios (70M+ players worldwide). Gari is the Chair and Professor of Biomedical Informatics at Emory University, and a Professor of Biomedical Engineering at Georgia Tech. Gari was previously an Associate Professor at the University of Oxford and a Principal Research Scientist at MIT where he commercialized multiple biomedical innovations, and managed a project to collect and analyse the world's largest public database of hospital data. What You’ll DoAsk questions, connect the dots, and uncover opportunities to improve healthcareWork on multiple initiatives to create and improve LifeBell AI’s models and analyticsWork across the entire machine learning pipeline, including data exploration, feature engineering, model training, deployment, monitoring, and calibration/retraining What We’re Looking For3+ years of professional experience applying machine learning to real-world problemsSomeone who has put models into production and monitored their effectivenessTeam player, who can work and communicate effectively with othersSelf-motivated, with a genuine interest in the problems you’ll be solving Nice to HaveMasters or PhD in Computer Science, Engineering, Statistics, or a related technical fieldDomain knowledge in biomedical informatics, healthcare, or a related fieldPrior publication of high quality peer-reviewed research articlesAbility to work in Atlanta, GA (however, remote-work from anywhere in US is OK)Ability to obtain a security clearance Benefits & PerksCompetitive salary with health, dental and vision insuranceGenerous vacation, sick day, holiday, and leave policiesEquity incentive plan and 401K matchingGreat office transit access, parking, and amenitiesGym membership, snacks & drinks, and a casual dress styleOpportunity for meaningful impact in a team-based environmentRemote-friendly culture with daily stand-ups, virtual lunches, and a video-first attitudeSelf-funded, stable technology startup with an approachable leadership teamWork-life balance and team-activities Core Values at LifeBell AISave Lives: Improving patient health outcomes is our north starInnovate: Our goal is to create industry defining moments, through technology & scienceBe Human: We treat ourselves, and each other, with respect & understandingAim for Excellence: We push ourselves, and each other, to improve every dayLess is Better: Focus and simplicity matter - we aim to do a few things exceptionally wellGet it Done: Actions speak louder than words, and execution is key Come As You Are: We aim to build an inclusive workforce. If you’re passionate about this role, but do not meet all of the qualifications listed above, we still encourage you to apply. We are an equal opportunity employer and celebrate diversity. We do not discriminate on the basis of age, ancestry, citizenship, color, ethnicity, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or invisible disability status, political affiliation, veteran status, race, religion, or sexual orientation. Remote Work: We are open to hiring remotely from anywhere in the United States. We know great talent is everywhere, and want to build the best team we can. You do not need to relocate to Atlanta GA for this role, although it’s our preference when possible. We do have periodic company retreats and team-events that include remote employees, which may involve occasional travel. These events are intended for your benefit, as an opportunity to connect more deeply with others. COVID-19: LifeBell AI is committed to hiring during the pandemic, with all interviewing and onboarding done virtually due to COVID-19. Everyone new to the team, along with our current staff, will temporarily work from home until it is safe to return to our office. In the meantime, we’ve implemented various practices to make remote working as enjoyable and practical as possible. Posting: If you are a recruiter or placement agency, please do not submit unsolicited resumes to our team unless we have a prior agreement. LifeBell is not liable for and will not pay for any placement fees associated with unsolicited resumes. Thank you.",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información",Software,434,None,False,,2811,JOB_SEEKER_QUALIFIED
17,2266794191,2020-10-08,Vesta,Data Scientist,"Remote, OR, US","To maintain our lead in using cutting-edge analytics to detect payments fraud, Vesta is expanding our Data Science team and we are looking for Data Scientists who will be responsible for developing high quality machine learning models to prevent payment fraud. As a Data Scientist, you will become part of the team to provide ideas, conduct proof of concepts, and develop production models to achieve Vesta strategic and operational objectives. As such, you will bring excellent analytic skills and a thorough knowledge of machine learning and help us solve toughest business problems.  Vesta is a SaaS-based, global leader in fraud detection and guaranteed e-commerce payment solutions. We are headquartered in Portland, Oregon with flagship offices in Atlanta, Ireland, Singapore and Mexico City and we are looking for energetic new talent to help us execute on our plans for innovation, growth and expansion.  Core Responsibilities:  Analyze large sets of transactional data to understand consumer behavior, explore and extract features and patterns to improve model performance.   Research state-of-the-art machine learning technologies to build world-class fraud detection models  Prototype modeling strategies to optimize model performance  Perform link analysis and fraud analytics in an enterprise environment.  Acquire and apply knowledge relevant to consumer behavior, risk management, and payment processing.  Work with interdepartmental teams to maintain and improve risk policies and procedures.  Identify possible problems with data or processes and takes action to resolve issues.   Education & Experience Required:  MS or PhD in Computer Science, Statistics, Applied Mathematics, or other quantitative fields.  Bilingual in Spanish/English 2+ years' working experience in machine learning.   Competencies Required:  Proficient in advanced machine learning algorithms  Solid knowledge on statistics and applied mathematics  Solid knowledge on both supervised learning and unsupervised learning. Experience in time series and adversarial modeling preferred   Fluency in Scikit-learn, PyTorch or similar machine learning frameworks  Expertise in SQL and Python and proven comfort and intellectual curiosity for working with large data sets  Experience in Hadoop/Spark or other distributed parallel computing paradigms is a plus  Experience with data visualization tools, such as Matplotlib/Seaborn, ggplot, D3.js, or Tableau is a plus.  Able to rapidly learn new subjects and process   Passionate about solving the toughest analytical problems  Have innovative mindset and take initiatives to work independently and collaboratively as needed to tackle projects  Organizational skills and ability to prioritize tasks and deliver on time  Can write clean and well documented code. Has good technical writing and verbal communication skills.  Strong communication skills and ability to articulate and share findings with the team   Other:  On occasion this role may require off-hours work in order to address escalations or urgent concerns.  Visa Sponsorship  Please note, this position is not eligible for visa sponsorship.  About Vesta  Vesta is a Software-as-a-Service (SaaS) company that specializes in managing payments in the 'card-not-present' (CNP) arena. We use next-level technologies and cutting-edge data science methodologies to bring unparalleled accuracy to fraud detection. Our zero liability solutions let merchants step fearlessly into the world of online commerce, so they can stop chargebacks—without stopping business.  We are a company reinventing ourselves for the future in an industry that is growing and changing at the same time. We are looking for talented people to join us who resonate with our Vesta Values: trust, partner, empower, passion and courage -- and who love to tackle new challenges every day.  We are also a casual, fun and flexible workplace that also offers highly competitive benefits including a selection of medical, dental and vision care options, paid parental leave, generous paid-time-off and a paid sabbatical program.  Vesta is an equal opportunity employer and considers qualified applicants for employment without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, ancestry, age, veteran status, or disability.  If you are an individual with a disability and require a reasonable accommodation to complete any part of the application process or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact Careers@trustvesta.com for assistance.",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Software, Servicios financieros",5,None,False,Careers@trustvesta.com,81,ACTIVELY_HIRING_COMPANY
18,2025503326,2020-11-02,Altana Trade,Data Scientist,New York City Metropolitan Area,"At Altana we are dedicated to improving global commerce. Our AI platform helps to fund and strengthen government institutions, disrupt transnational crime, and distribute the benefits of global commerce more broadly and inclusively. We employ and advance the latest machine learning and data engineering technologies to help tackle some of the central challenges of our time. We are building the Altana Atlas, which includes the world’s most comprehensive representation of global commerce activity. This data asset, composed of billions of records, covers more than 40% of cross-border transactions, corporate ownership registries in over 100 countries, the global movements of goods, illicit web activity, and more. Built on this foundation, our proprietary machine learning technologies and products are designed to help customers manage risk, automate otherwise labor-intensive investigations, and better manage cross-border flows. The technical team is looking for talented Data Scientists and Machine Learning Engineers to help build this vision. You’ll work closely with our engineers on projects to analyze and observe world-scale datasets and write code and models that can scale to produce never before seen insights. This position can be worked remotely, or from our headquarters location in NYC. ResponsibilitiesAnalyze global trade networks, using techniques from web/social/economic network analysisApply cutting edge classification, regression, and clustering techniques, including deep learning, to handle high dimensional feature and outcome distributionsTrain your models across hundreds of millions to billions of observationsWork with data in English, Spanish, Portuguese, Chinese, Russian, Arabic, and moreBuild performant models that deliver high quality results when applied to non-stationary and adversarial distributionsUse unsupervised and semi-supervised techniques in cases of low outcome-data availabilityWork with engineers to integrate your models into robust and performant data pipelinesOpportunity to work with the top technical and domain experts on our advisory board, including Matt Jackson, Stanford professor and leading expert on economic networksCollaborate with fellow engineers and data scientists across the organization RequirementsB.S., M.S., or Ph.D. in an engineering or quantitative discipline, or equivalent work experience3+ years industry experienceExpertise in machine learning and classical statistical analysisExperience with agile development practices and Git version controlAbility to evaluate solutions in terms of business impact in addition to traditional stats or ML criteriaYou have the ability to take ownership and iterate on a project through completionYou care deeply about machine-learning excellence, clean code, and knowledge-sharingYou have strong written and verbal communication skills Nice to have, but not requiredExpertise in one or more of the following: natural language processing, deep learning, computer vision, or network analysisExperience with relational and graph databasesExperience with docker and kubernetesExperience in machine learning model deploymentWorking knowledge of cloud services like AWS, Azure, or GCP Technologies we loveLanguages: Python, Go, JavaTools: Docker, Git, Airflow, Ansible, Swagger/OpenAPI, DaskDatastores: Postgres, Redshift, MySQL, Elasticsearch, Neo4j Why it’s great to work at AltanaWe love to collaborate, and we win as a team!We are committed to engineering excellenceWe value personal and professional developmentWe learn from diverse backgrounds and perspectivesWe impact the world, from enabling developing countries to identifying drug traffickers Altana is an equal opportunity employer with a commitment to inclusion across race and ethnicity, gender, sexual orientation, age, religion, physical ability, veteran status, and national origin. We offer a comprehensive healthcare package and paid parental leave of 2 months for the primary caregiver and 1 month for the secondary caregiver.",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información","Software, Logística y cadena de suministro",1279,None,True,,3410,ACTIVELY_HIRING_COMPANY
19,2285003808,2020-11-07,Monzo Bank,"Data Scientist, Financial Crime","London, GB","We're looking for a curious, adaptable Financial Crime Data Scientist to join our team at Monzo!  You'll be working in the intersection between data, engineering and our financial crime functions, forming part of a high performing cross disciplinary squad consisting of both data and engineering. You will be responsible for building downstream data models from backend services, identifying and driving process efficiency and ensuring timeliness and completeness of our financial crime data. You will be working in particular on important data assets within our financial crime regulatory and reporting space.  Data at Monzo  Our Data team's mission is to  Enable Monzo to Make Better Decisions, Faster  At the core of this mission sits our data platform. We're great believers in powerful, real-time analytics and empowerment of the wider business. Every engineer at Monzo is responsible for collection of relevant analytics events from their microservices. We optimise for simplicity and re-usability – all our data lives in one place and is made available via our data warehouse in Google BigQuery. 90% of day-to-day data-driven decisions are covered by self-serve analytics through Looker which gives data scientists the head space to focus on more impactful business questions and analyses.  Our technology stack  We rely heavily on the following tools and technologies (note we do not expect applicants to have prior experience of all them):   Google Cloud Platform for all of our analytics infrastructure dbt and BigQuery SQL for our data modelling and warehousing Python for data science Go to write our application code AWS for most of our backend infrastructure  The role  Working in a multi-disciplinary data and engineering squad, you will:   work closely with financial crime analysts, data scientists and engineers to understand the underlying business problem and propose an appropriate solution (whether involving purely engineering, purely data or both) translate regulatory reporting requirements into highly accurate data models and set the strategy for how we ensure the best possible data accuracy build robust data models, reports and visualisations downstream of backend services (mostly in BigQuery SQL) that support internal management information as well as governance and regulatory reporting investigate and effectively work with colleagues from other disciplines to address and improve data quality integrate new data sources into our data warehouse design, build and launch new data pipelines in production   You should apply if   you have strong SQL skills and are familiar with BigQuery and/or general data warehousing concepts you are comfortable exploring potentially ambiguous business problems and enjoy finding technical solutions to them you have experience building robust and reliable data sets requiring a high level of control you're keen to learn more about new technologies and their application in retail banking you strive for improvement, proactively identifying issues and opportunities and getting them prioritised  It would be a bonus if:   You have multiple years of analytics experience, preferably in a fast moving tech company or consultancy Experience working with governance reporting or financial crime  Logistics   We can help you relocate to London & we can sponsor visas. This role can be based in our London office or remotely within the UK We offer flexible working hours and trust you to work enough hours to do your job well, at times that suit you and your team. Diversity and inclusion is a priority for us – if we want to solve problems for people around the world, our team has to represent our customers. So we need to attract the best talent and create an environment that supports and includes them. You can read more about diversity and inclusion on our blog. If you prefer to work part-time, we'll make this happen whenever we can - whether this is to help you meet other commitments or strike a great work-life balance. The application process consists of a 30 min phone call with a recruiter, an initial call with someone from the team, followed by a practical written exercise and 2-3 video interviews. We promise not to ask you any brain teasers or trick questions.  Equal Opportunity Statement  At Monzo, embracing diversity in all of its forms and fostering an inclusive environment for all people to do the best work of their lives with us. This is integral to our mission of making money work for everyone.  We're an equal opportunity employer. All applicants will be considered for employment without attention to ethnicity, religion, sexual orientation, gender identity, family or parental status, national origin, veteran, neurodiversity status or disability status.",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Software, Internet, Servicios financieros",28,None,False,,266,ACTIVELY_HIRING_COMPANY
20,2279770170,2020-11-04,"Medable, Inc",Data Scientist - REMOTE,"London, GB","Company Description  Medable's mission is to get effective therapies to patients faster. We provide an end-to-end, cloud-based platform with a flexible suite of tools that allows patients, healthcare providers, clinical research organizations and pharmaceutical sponsors to work together as a team in clinical trials. Our solutions enable more efficient clinical research, more effective healthcare delivery, and more accurate precision and predictive medicine. Our target audiences are patients, providers, principal investigators, and innovators who work in healthcare and life sciences.  Our vision is to accelerate the path to human discovery and medical cures. We are passionate about driving innovation and empowering consumers. We are proactive, collaborative, self-motivated learners, committed, bold and tenacious. We are dedicated to making this world a healthier place.  Job Description Explore machine learning opportunitiesInvestigate and compile new sources of medical dataProvide clinical input to refine existing machine learning architectureDevelop and integrate machine learning algorithms for data processing and analysisBuilding models to address business problemsPresenting information using data visualization techniquesUndertake preprocessing of structured and unstructured dataAnalyze large amounts of information to discover trends and patternsBuild predictive models and machine-learning algorithmsPropose solutions and strategies to business challengesCollaborate with engineering and product development teamsOther duties as assigned Qualifications 0-3 years working in Computer Science or a combination of education and experience (3+ preferred)Bachelor’s degree in Computer Science, Artificial Intelligence, Engineering or relevant field Experiece with R programming language, C++, Python, Java, Node.JS  Additional Information Highly analytical with a knack for analysis, math and statisticsCritical thinking and problem-solving skillsPassion for machine-learning and researchExperience in data miningAnalytical mind and business acumenProblem-solving aptitudeExcellent communication and presentation skillsExperience working in machine learning (preferred) All information will be kept confidential according to EEO guidelines.",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Marketing y publicidad, Servicios y tecnologías de la información, Software",38,None,False,,186,ACTIVELY_HIRING_COMPANY
21,2205317367,2020-10-14,Acute Change,Data Scientist,United Kingdom,"DATA SCIENTIST | CHIEF DATA SCIENTIST | DATA SCIENCE MANAGER | SENIOR DATA SCIENTIST | LEAD DATA SCIENTIST  My client is looking for a Data Scientist to work in a small team of engineers, researchers and business stakeholders. They are in the energy space and are working with some of the most exciting technologies and forward-thinking people. They are looking for an independent character who will fit in well with the pro-active company culture. They are a well-funded start-up looking to grow out their team, looking for a Data Science expert with the following experience: ﻿Requirements An undergraduate degree in Computer Science, Machine Learning or related. Experience with Python and its libraries (TensorFlow, PyTorch etc.). A minimum of 3 years experience developing projects in Machine Learning and Data Science.Experience tackling business problems using datasets. Desired MS or PhD degree in Computer Science, Machine Learning, or relatedExperience working in the energy/enviroment sector Experience with a range of databases, including relational, non-relational database and time-series databases.Cloud experience: AWS/GCP",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información","Consultoría de estrategia y operaciones, Petróleo y energía",291,None,True,,858,JOB_SEEKER_QUALIFIED
22,2201862920,2020-10-22,Birch & James Associates,Data Scientist,"London, England, United Kingdom","Salary: £60,000 - £65,000 Seniority: Mid Level Experience Required: MSc Graduates must have 3+ years commercial experience, PhD Graduates must have 2+ years commercial experience  Our client's technology team is one of the best in the business and is the fuel behind the success of their platform. From patented machine learning methods to developing an award-winning application, the technology team is continuously innovating and enabling technology to solve real problems for their customers. We are looking for a proficient Data Scientist who is excited about working with some of the most talented data scientists in the industry to build amazing technologies and develop their career to be the best at what they do.  This role is up to 100% remote but will require 2 days' attendance in London per month. Travel and accommodation for required attendance are reimbursable.  Minimum Qualifications  Master's degree or PhD in Computer Science, Mathematics or another numerate discipline from a leading university Commercial hands-on data science experience developing statistical, machine learning and deep learning methods, such as search queries classification, named entity recognition and domain knowledge graphs, optimisation etc. Strong understanding of recent exciting advances in NLP such as pre-trained language models, contextualised word embeddings, attention and novel neural network architectures Confident writing production-quality code in Python and SQL Exceptional analytical, quantitative, problem-solving, critical thinking and communication skills Passion for Data Science, actively seeking out opportunities for learning and development. Preferred qualifications  Experience with PyTorch and related applications frameworks. Additional experience with high-performance cloud computing services (e.g. AWS, Azure) would be beneficial. Experience in computational advertising related tasks, such as ads response (click or conversion) prediction, bid-landscape forecasting, supply-demand forecasting, or advertising metrics and measurement Good knowledge using 3rd party data (e.g. Google Analytics, Google Adwords, Omniture Analytics, Adobe Campaign etc.) would be an advantage Able to present complicated data insights and strategic recommendations within a fast-paced Agile environment Responsibilities  Rapidly design, prototype and experiment possible machine learning and deep learning algorithms to solve real-world problems in a highly ambiguous environment of search advertising Maintain and enhance existing ML and AI models including resolution of client issues related to any model performance. Collaborate with Product and Engineering teams to integrate successful solutions into large-scale, highly complex production systems Facilitate thought leadership and best practices on data science across the business to continually improve the existed approaches and values Effectively communicate data findings and help team and business make data-driven decisions Take ownership and pride in the products we build and always make sure they are of the highest standard Be empathetic towards team members and customers Technologies we use across our Technology teams  Languages: Python, R, and SQLDS Toolkits: Pytorch, Tensorflow, Fastai, Flair, BigGraph, Optuna, Horovod, ONNX Visualizations: Flask, Shiny, Flexdashboard, Plotly, Highchart, Bokeh, Altair Databases: PostgreSQL, AWS(S3), Redshift, Redis, MongoDB, CassandraTechnologies: Luigi, RabbitMQ (messaging), Quartz scheduling, Docker and Kubernetes, MavenCI/CD: TeamCity, Jenkins Source Control: Git (GitHub) Other Tools: Pycharm, Sublime Text, Netron, Jira, Miro About the Data Science Team  Joining our client's award-winning Data Science team will give you the chance to work with the latest Machine Learning techniques using cutting edge frameworks such as Neural nets with PyTorch, NLP using Zero-shot learning and BERT, or Optimisation models that run on huge datasets with billions of data points.  The size of our datasets means that you will also be working with our experienced data team, led by published authors, to distribute and productionise your models. You will be part of a fast-paced agile team, ideating, researching, inventing, developing and maintaining all ML/DL models and artificial intelligence. With award-winning data scientists from multidisciplinary backgrounds, across Applied Mathematics, Statistics, Computer Science and Psychology, we are a friendly, passionate group of data scientists making a career out of building great products for our customers.  The data science team is revolutionising the search advertising industry, and its patented technology is a market leader in competitive intelligence. They are prototyping new learning algorithms that underpin the core product, used by some of the world’s biggest brands. The team focuses inventing new data-driven features and helping customers better understand their competitive search landscape (e.g. click-through rates, spend estimates, ad copy effectiveness.) These are challenging, unsolved data problems applicable to thousands of major enterprises globally.  Our data science culture is underpinned by sharing knowledge, coaching and growing together. You will have the opportunity to explore/innovate new technologies, mentor data scientists and lead R&D initiatives. You will enjoy this role if you love data, writing code, learning cutting edge new technologies, solving problems and winning as a team.",No corresponde,Jornada completa,None,None,107,None,True,,653,JOB_SEEKER_QUALIFIED
23,2197036822,2020-10-20,PRA Health Sciences,Central Data Scientist,United Kingdom,"OverviewAt PRA, we don’t make our 17000+ people great. It’s the other way around. As we have grown to a top-5 CRO, we have maintained the feel of a small company, dedicated to collaboration and passion for what we do. We always have a desire to keep seeking new and better ways to operate. We don’t settle for the same old ways. Our passion for improving patient lives worldwide permeates all that we do. Put simply, we care.ResponsibilitiesDue to growth we are currently seeking a Central Data Scientist, to work as part of an established global group that supports project teams in analyzing clinical data to identify risks and data issues, using advanced analytical techniques. Acting as a Key Functional Lead on projects: the Central Data Scientist will assess trial compliance, perform trending analysis, exploratory data reviews and report findings to internal and external stakeholders. Key responsibilities in this role include:Developing and maintaining study documents specifying strategy, approach and procedures on assigned protocols/projects.Providing input to applications, databases and systems used to assess study data quality.Reviewing clinical data at aggregate level regularly throughout assigned studies using analytical reporting tools to support the identification of risks and data patterns/trends.Creating analytical reports and presentations to facilitate review and data-driven decision making during team meetingsPerforms analytical reviews and collaborates with assigned project teamsto address data-related questions andrecommend potential solutions.Provides input during adaptive monitoring assessment process.Documents review findings utilizingapplicable systems, according to standard procedures.Develops analytical reports usingprogramming knowledge and data modeling techniques, e.g., SQL, SAS.Leads Analysis of Findings meetings on assigned projects.Escalates project concerns such as outof-scope tasks, at-risk project deliverables and project team relationship issues to functional and project managers in a timely fashion.QualificationsYou are...Analytically-minded, a problem-solverHere at PRA we want our employees to succeed and ensure that they are set up for this success through constant training, development and support. To enable success in this position you will have:Bachelor’s degree (or equivalent) in a Scientific or Healthcare disciplinePrevious experience, ideally in a similar role, but we are also open to considering people with other relevant clinical trials experience, including those working as Lead Data Managers, Programmers, Clinical Research Associates, Clinical Team Managers and Project Managers.Familiarity with risk-based monitoringTechnical ability: use of JReview specifically or other analytical/visualization tool (e.g Spotfire, SAS JMP Clinical, SAS, R) or at a very minimum significant experience in using excel (including pivot tables, graphics and data exploration).Analytical thinker: ability to break down issues into manageable componentsSQL experienceSkills in aggregating data review and interpretation using visualization/analysis software e.g. JReview, Tableau, SAS You will be frequently collaborating within multi-cultural global teams, so will need to demonstrate excellent written and oral communication skills, exhibit pro-active teamwork alongside a positive attitude, and maintain up-to-date industry awareness and understanding of regulation/standards. PRA is an EEO/AA employer and is committed to providing opportunities to minorities, women, veterans and individuals with disabilities.",Algo de responsabilidad,Jornada completa,Investigación,Investigación,86,None,True,,364,ACTIVELY_HIRING_COMPANY
24,2246172196,2020-10-27,DMW Group,Data Engineer,United Kingdom,"The Opportunity Would you like to help create a brand-new engineering organisation? Perhaps you know what great engineering culture looks like, or you have an entrepreneurial side as well as outstanding coding skills? Whatever your aspirations, we’re trying to create the best engineering consultancy in the UK and looking for brilliant engineers to be part of the journey. About DMW Engineering DMW helps organisations solve their biggest, most exciting engineering problems. We’ve created banks from scratch on Kubernetes and AWS, built streaming analytics solutions that protect the country and built platforms to enable whole organisations to move to AWS and Azure, and everything in between. We do all this in a work environment where regular social events, inclusivity and an ego-free culture mean we’ve been officially voted a “Great Place to Work” for five years in a row. We’re not interested in cutting corners and believe in helping our clients to make the right choice for the long-term. We draw on our reputation for outstanding delivery to allow our engineers to do the right thing for our clients, and not necessarily the easy thing. Innovation is in our DNA, and we encourage our engineers and consultants to work together to rethink conventional wisdom on how problems should be solved.  Here’s what you will do (Not all of it, but some of the important stuff!) Solve the problems others cannotSpend a day a week working on a combination of internal products and your own developmentCreate data platforms based around modern open source products and cloud-native technologies:AWS, Azure and Google CloudPythonKafka / NiFi / FlumeDB technologies: SQL Server / PostgreSQL / MySQLHive/Spark/ImpalaDataikuTerraformKubernetes The essentials?Experiece building data platforms using either cloud native products or commercial data analytics / data warehouse softwareWorking knowledge of data pipelines & data transformation processesExperience creating and/or maintaining production software delivery pipelines using common CI/CD tools (e.g. Jenkins, GoCD, CircleCI)Demonstrable experience in automating operations tasks with one or more scripting languagesExperience working with one or more of the main cloud providers (AWS, Azure or Google)Have a drive for self-improvement and learning, including learning new programming languagesApproach solving problems pragmaticallyExperience of Hadoop big data platforms (either Cloudera / Hortonworks or cloud native equivalents)Experience with data reporting and visualisation tools (PowerBI, Tableau, Qlik)Experience productionising machine learning algorithmsExperience with Infrastructure as Code (e.g. Terraform, Cloudformation)Experience supporting and operating production systemsFamiliarity with configuration management tooling (e.g. Ansible) It would be great if you had these desirable skills﻿Experience of Hadoop big data platforms (either Cloudera / Hortonworks or cloud native equivalents)Experience with data reporting and visualisation tools (PowerBI, Tableau, Qlik)Experience productionising machine learning algorithmsExperience with Infrastructure as Code (e.g. Terraform, Cloudformation)Experience supporting and operating production systemsFamiliarity with configuration management tooling (e.g. Ansible) This is what you get in return We’ve grown consistently over the years and offer an entrepreneurial environment within which to embark upon an exciting career path, where your contribution really counts, and we will recognise it. With personalised development opportunities, experienced colleagues and challenging client assignments, progression can be extremely rapid for high performers. We are a social bunch of people and go out as a team on a regular basis. You can also expect:A highly collaborative working environment and great rates of pay (including base salary and bonus potential).A range of flexible benefits consisting of well-being and lifestyle benefits.A commitment to your development & continuous growth of skills through one-to-one mentoring and wide-ranging hands-on experience.25 days’ holiday and the ability to flex this to 30 days if you chose to do so.2 day’s CSR volunteering days.Award-winning learning and development opportunities, including dedicated personal training budgets and time and a wide range of choice in training courses.A dedicated personal budget to choose the IT equipment of your choice. Here’s a little more about us and what we value Independent, award-winning and ambitious, DMW are a technology and management consulting firm that places a high value on people, which is why we have been recognised as a Great Place to Work™ consecutively for the last 5 years. We have a 30-year track-record of delivering complex, business-critical IT transformation projects moving seamlessly from strategy, design, delivery through to operations. We believe we offer a significantly better work-life balance than in other IT consultancies because you are involved every step of the way, making career decisions together.DMW is widely recognised as the place where smart, technically curious, ambitious people who value their integrity and independence want to work. We offer rewarding careers to people who are driven by the desire to do exciting work for ambitious clients.We have helped improve some of the biggest organisations in the UK and Europe across three core sectors: Finance and Insurance, Energy and Commercial and the Public Sector. Solving complex technology problems to create competitive advantage through the advanced application of Cloud, Digital and Data technologies: growing revenues, reducing costs, and improving efficiency and effectiveness for our clients. DMW Group is an equal opportunities employer and welcomes applications from all sections of society. We believe that diversity makes us a stronger team so seek to employ people with different ideas, styles and skill sets, each able to contribute in unique ways to our organisation’s growth and success.",Intermedio,Jornada completa,Tecnología de la información,Consultoría de estrategia y operaciones,41,None,True,,193,ACTIVELY_HIRING_COMPANY
25,1782530303,2020-10-19,B12,Data Engineer,United States,"Data Engineering at B12 B12's engineering team views software as a craft, but improving the world as the reason to practice it. Our engineers are responsible for prioritizing, conceptualizing, co-designing, building, testing, and engaging users for any concept we are building out. We’re generalists in encouraging each other to experience the full stack, but we’re also aware of each other’s preferences in the stack. We mentor and teach where we can, both inside and outside of the company. We value sharing our work with the outside world. Our team has published papers on forming expert flash teams and machine-mediated worker hierarchies. We’ve baked our research into Orchestra, the system that coordinates our expert and machine teams, and released Orchestra into open source to contribute our software back to the community.We’re looking for a Data Engineer to help us answer critical questions our business faces while improving our data systems and architecture to support greater variety, volume, and velocity of data and data sources. We hope our engineers have more longevity than any one tool we use, but here is a sampling of our current thoughts about technology:We build our product on Python/Django and JavaScript/React.We store blobs in Amazon’s S3, munch on them in Amazon’s EC2, develop in Docker, and deploy containers to Amazon’s Elastic Beanstalk.We believe Postgres should be the first system you consider when you think about persisting structured data.We religiously clean and centralize data in Amazon’s Redshift, and are able to answer most any question in SQL. We recently wrote our 1000th query in Metabase!Before building complex statistical machine learning models, we build simple ones we can understand. Rarely, we build complex models.We have near-full test coverage on the backend, and are making progress on our frontend and integration tests.We set up continuous integration and deployment because, while this model comes with its own pains, we’ve disliked being on fixed release schedules on previous projects.We like to move fast and support point-in-time recovery :). As a Data Engineer, you willCollaborate with operational teams including sales, marketing, and customer success.Contribute to infrastructure that enables and informs B12’s analytical efforts.Write SQL queries and reusable views that enable various analyses including funnel, retention, and performance reporting.Use Python to clean data, send it to various systems including our data warehouse and operational services, and perform feature engineering to power the creation of predictive models.Build rules-based models and statistical machine learning models in Python using packages like scikit-learn. You’d be a good fit ifYou are fluent in SQL and Python.You have experience building and using data infrastructure, including systems like Postgres and Redshift.You’ve used reporting tools like Metabase, Tableau, or Looker in the past.You know that no dataset is ever pristine, but love to interrogate, structure, and clean data.You’ve contributed to extract-transform-load pipelines to collect data from disparate sources and centralize them in a data warehouse. You feel comfortable managing your time and deciding amongst competing priorities.You have worked with non-engineering teams and are comfortable explaining technical solutions to them.You are passionate about the future of work.You enjoy learning and teaching.You have strong written and verbal communication skills in English. Don't fearWe don't have a minimum number of years of experience for this role. We highly favor talent and interest.Some candidates may see this list and feel discouraged because they don’t match all the items. Please apply anyway: there’s a good chance you’re more wonderful than you think you are. B12 is a safe place for human beings. We are dedicated to building a diverse and inclusive team with a wide range of backgrounds and experiences, each helping us understand our customers better, and strengthen our team. We particularly encourage you to apply if you identify as a woman, are a person of color or other underrepresented minority, or are a member of the LGBTQIA community.",Intermedio,Jornada completa,"Tecnología de la información, Ingeniería",Software,636,None,False,,2599,ACTIVELY_HIRING_COMPANY
26,2193844576,2020-10-19,Swoop,Data Engineer,United Kingdom,"Swoop is a marketplace platform connecting SMEs (small to medium enterprises) to funding solutions and financial savings. Swoop takes the pain out of raising finance and saving finance for business owners and financial advisors. No more painful blind research, no more arduous application forms and no more black holes of information. Swoop leverages an SMEs core data points and financial information to help business owners understand the funding landscape and discover the best funding and saving options for them. We design systems and journeys that are effortless and intuitive, so that our users can spend more time on what they want to do – managing their business. Some links to find out more about Swoop:Andrea’s (our CEO) recent interview for Capital Conversations: https://www.youtube.com/watch?v=21aGJB_gScQInformation behind our funding from the UK’s Banking Competition Remedies (BCR): https://swoopfunding.com/blog/swoop-receives-5-million-funding-from-bcr/An article about Andrea and Swoop in The Sunday Times:https://swoopfunding.com/wp-content/uploads/2019/08/10398-STim_SwoopFunding_25082019-A.pdf Requirements Swoop engineers get challenging problems to work on from day one. These include complex recommendation algorithms, transaction processing, creating scalable APIs to building new data services. We work with data and want to provide SMEs the best decisions and recommendations based on their profiles and specific details. You will make our processes data driven using the latest technologies and innovation in data processing, machine learning and AI. We are flexible and choose the best tools for the job. We have loads of exciting features in the pipeline and are looking for ambitious engineers to build the best marketplace platform in finance. A bit about you:You have 3+ years experience in backend development and keen to learn new techYou have 3+ years experience in data analytics / machine learning development You're passionate about user experience - empathy with customers drives your decisionsYou have good system design skills You have hands-on experience with C# and/or .NetYou hold yourself to high coding standards (TDD, Clean Code)You consider automated tests a mustYou have hands-on experience with SQL, PostgreSQL and no-SQL datastoresYou have hands-on experience with messaging and event driven infrastructure You understand and have experience using cloud infrastructureYou are self-motivated and able to work well as part of a distributed engineering team.You already have the right to work in the UK and/or Ireland  Bonus points:You have strong system design skills and experience building products with scale and performance in mindYou have working experience with natural language processing techniquesYou have working experience with building recommender systemsYou have working experience with building complex data sourcing systems and reconciliation enginesExperience with Azure, particularly BigQuery and Machine learning infrastructure and services Experience with GraphQL, gRPCExperience with reporting tools and BI systems (Tableau, Data Studio, …)Tools: Git, Docker, Kubernetes, Terraform, Airflow, ReToolFinancial services and/or Open banking API experienceKnowledge of SME funding options (loans, equity, grants)  BenefitsEnjoy a competitive salary25 days holiday per yearAll the latest tech you needPension planYoga ClassesFitness ClassesA lovely, spacious, natural light filled office in Fitzrovia or Dublin or BirminghamLearn how an exciting business that’s disrupting an industry is scaling upHave ownership of your work and enjoy the impact you createHave a say in how the business evolves and scales within a start-up environmentGet to work with some other excellent, like-minded expertsWork within a transparent, friendly and collaborative cultureLimitless challenge and scope for development. You are joining us at a very exciting time and have the opportunity to take this role in your preferred direction as we growFlexible and Remote working available.",Intermedio,Jornada completa,"Tecnología de la información, Ingeniería","Servicios financieros, Banca, Recaudación de fondos",56,None,True,,386,None
27,2243532150,2020-11-04,Nationwide Building Society,Data Engineer,"Swindon, England, United Kingdom","Nationwide has recently launched a new data strategy which will transform the way the organisation thinks about, values and manages its data. This new strategy includes areas such as reducing the number of legacy data stores that we have: simplifying our architectural landscape and ensuring that everyone throughout the business treats our data as a valued asset. Delivering on this strategy is one of the key responsibilities of the Data Solutions team, which is part of the wider Data & Analytics community. With that in mind, we are currently looking for experienced Microsoft Data Engineers who have experience of working on data warehousing and business intelligence projects using the Microsoft stack. The RoleThis role will focus on delivering data solutions onto our new Microsoft data platform. These solutions will encompass everything from smaller tactical fixes which help specific colleagues / small teams, to larger strategic designs aimed at solving complex business requirements for larger teams and departments.  Who we’re looking for:Our ideal candidate would be a strong communicator who is comfortable working on their own or as part of a wider team. Technically, they have been using the Microsoft development stack to deliver business intelligence / data warehousing solutions for a number of years.  As a minimum requirement you will have the following skills: Strong T-SQL scripting knowledgeSQL Server Integration Services (SSIS)Experience in designing & delivering solutions using Microsoft Visual Studio IDEConfiguration Management in GIT / TFSData Warehousing methodologiesExperience working in Agile methodologyGood stakeholder management skills It would be nice if you also had: Exposure to report writing platforms such as Qlik, PowerBI or SQL Server Reporting Services (SSRS)Experience using other ETL tools such as Informatica or TalendExposure to cloud technologies such as Microsoft Azure / Google Cloud / Amazon Web ServicesPython / C#Experience of DBA methodologies & processesHadoop / Teradata / Linux scripting What you’ll be doingYou will form a key part of a team of engineers responsible for the implementation of data solutions onto the new IM estate in support of our strategy objective of simplifying our data landscape and delivery of insight and innovation. Working directly with business and IT stakeholders you will help to deliver best practise, innovation and automation in the industrialisation of complex strategic IT initiatives alongside smaller user driven demand.",Algo de responsabilidad,Jornada completa,Tecnología de la información,Servicios financieros,47,None,True,,205,ACTIVELY_HIRING_COMPANY
28,2204952773,2020-10-23,Infogrid,Machine Learning Engineer,United Kingdom,"Machine Learning Engineer About InfogridInfogrid is making scalable IoT (Internet of Things) a reality. Our goal is to be the global go-to provider for connected devices in smart buildings, creating dynamic solutions for everyday challenges. Our mantra is 'innovation through simplicity' and this ethos drives our product development. We are a small, rapidly expanding team but already have a broad portfolio of blue-chip clients – a testament to the strength of our product market fit. We are supported by top-tier venture capital funds. Infogrid is an IoT platform (physical sensors + SaaS) capable of handling millions of data events from hundreds of thousands of sensors every day. With cutting-edge, low-cost micro sensors provided by several 3rd party partners we're able to turn any building into a ‘smart’ building at a fraction of the cost of existing providers. The simplicity of our solution enables clients to self-install thousands of sensors in a matter of hours, and receive immediate real-time data. With the analytics and reporting we generate, companies can run more efficiently, pre-empt failures, save money, meet regulatory requirements, provide better environments for their employees and customers, and be more sustainable. About the roleOur solutions are deployed to 100+ clients in a range of industries - healthcare, commercial property, retail - producing access to a large (1bn+ and counting) number of data points and a unique dataset for building a differentiated AI capability - and we’re just getting started. Through data science we are in the process of developing a platform that influences building owners, managers, and users towards a more sustainable future through transparency on otherwise hidden processes. We elucidate this through both direct sensor outputs (such as: current air temperature) and algorithmically-inferred outputs (such as: a temperature sensor placed in thermal contact with a water pipe can be used to infer water flow within the pipe). Synthesising all these outputs to build up a holistic picture of a building, with an understanding of the interrelationships of the sensors - we access an ability to offer insights (such as on underused spaces), recommended actions (such as how to improve energy efficiency), and predictive aids to planning (such as when to increase capacity), in a real-time fashion that has never previously been possible as this data was unavailable. We innovate at the edge of what can be done in the new era of IoT, and we are at an inflection point in the centrality of data science to our growth - we are currently led by a highly-qualified team that we seek to expand by several senior hires that have room to grow in responsibility as the company continues to grow further.  What you will be doing●     Design novel sensor-based applications to solve hard and impactful problems for our broad client base●     Experiment with new technologies to harness an unparalleled dataset●     Develop machine learning models from concept to production deployment●     Whilst largely working in a team with other data scientists, you will also interface with specialists in other areas such as DevOps and the wider front- and backend-development teams to find the most optimal product solutions●     Working directly under the Head of Data Science you will help to cultivate a team with huge growth potential and influence the trajectory of data science at InfogridWhat we are looking for●     3+ years experience in machine learning in a commercial environment●     Fluency in Python●     Experience with deployment of machine learning models (particularly AWS) is desired●     Experience with neural network architectures (particularly Tensorflow) is desired●     Experience with recommendation systems is desired●     A growth mindset, an interest in innovating new machine-learning products, and a willingness to work in a geographically-distributed team  Why we think you’ll love it here●     Fascinating challenges – no-one has a dataset quite like ours, which makes us uniquely placed to build AI products where solutions currently don’t exist.●     Creative freedom - you’ll be joining us early on in our journey, with plenty of autonomy and room to develop your role as we grow●     We have a lot of flexibility on working times and fully embrace remote working●     Data science is at the heart of the company - your work will reach our clients all over the globe and set the trajectory for future innovation●     Competitive salary, holiday, perks and equity options package",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Servicios y tecnologías de la información,211,None,True,,627,ACTIVELY_HIRING_COMPANY
29,2268204267,2020-11-02,Tata Steel in Europe,Data Scientist / Data Engineer,"Port Talbot, Wales, United Kingdom","Job Title:            Data Engineer/Data ScientistLocation:            FlexibleFunction:            Research & DevelopmentSalary Range:     £30,000 - £45,000 + BenefitsJob Type:           PermanentClosing Date:     11:00pm on Monday 16th November 2020 Are you looking for an exciting challenge within the field of Data Science? We are looking for talented individuals to join our expanding Research and Development team to support the company’s digital technology innovation strategy. Based at our site at the University of Warwick, the Data Science & Analytics group develops and implements technologies for the entire process chain of steel manufacture to ensure that Tata Steel in Europe can deliver products at top quality with world-class conversion costs. The Role Our Research and Development function is looking to strengthen its core team to provide company leadership in the field of data manipulation and advanced analytics. We are looking to enhance a multi-skilled team covering the field of data science, from data access and preparation to deployment of the results from analytical and data mining approaches. The core area of focus will be on optimisation of manufacturing and product quality but this also integrates business and supply chain data sources, extending into the realms of ‘Smart Manufacturing’. Who we’re looking for The successful candidate will hold a Masters or higher (or equivalent experience) in a mathematical, computer science or engineering discipline and be able to demonstrate a range of skills and experience including a selection of the following areas: Understanding of the principles of data governance and knowledge management.Data quality, ingestion, cleansing, manipulation and integration techniques.Programming languages (e.g. C#, Java, JavaScript) with emphasis on prototyping and implementation of results.Development of data models to enhance the capability of existing simulation and plant control models.Capabilities in database platforms (e.g. SQL/NoSQL, SQLServer/Postgres etc).Experience generating insights using Azure DataBricks for Data Analytics. Capabilities in operating system/platform system administration would also be an advantage as well as knowledge of, or a desire to develop expertise in, a range of commercial (e.g. Spotfire) and open source (e.g. R, KNIME, Python) data analysis tools. Candidates will be expected to know when and how to apply techniques such as these, but also able to explain their approach and results in ways that less ICT literate stakeholders can understand. They will also be able to identify and explain methods for implementation of findings. In terms of personal attributes you will be expected to be able to show:Experience in data project delivery.Ability to develop new ideas into structured, deliverable proposals and projects.Strong analytical and problem solving capabilities.Team working approach including collaboration with people and organisations with complimentary skills.Excellent presentation and report writing skills.Ability to work in a rapidly developing environment. The BusinessThis is an exciting opportunity to be part of a function that will shape the future of our industry!Tata Steel in Europe is one of the world’s top ten steel producers. The combined group has an aggregate crude steel capacity of more than 28 million tonnes and approximately 80,000 employees across four continents. We’re part of the Tata Group, one of the largest, most diverse conglomerates in the world with businesses in the UK including Tata Steel, Jaguar Land Rover and Tetley Tea. What we OfferTata Steel UK offers their employees significant benefits packages. For this role, you will benefit from: A market competitive salaryPrivate Healthcare Scheme (Individual cover)Annual Bonus Scheme – subject to business performanceOne of the UK’s leading defined contribution pension schemes (10% employer contribution / 6% employee contribution)Annual Pay ReviewEmployee discount scheme for companies including Vodafone, Nissan, Jaguar Land Rover and also various local services You may be also interested to know that we have an extensive list of lifestyle benefits including free onsite parking at all of our sites, an employee assistance programme as well as discounts with local and national retailers and services",Intermedio,Jornada completa,"Producción, Estrategia/planificación",Minería y metalurgia,35,None,False,,306,ACTIVELY_HIRING_COMPANY
30,1946811153,2020-10-02,Wikimedia Foundation,Research Scientist (Disinformation) - Remote,Germany,"Location: Remote, Global Summary We’re hiring a Research Scientist strongly committed to the principles of free knowledge, open source and open data, transparency, privacy, and collaboration to join the Research team to conduct applied research on the integrity of content and disinformation in Wikipedia and other Wikimedia projects. The surge of coordinated disinformation campaigns to infiltrate, disrupt, and co-opt movements, communities, and platforms is an important challenge for the integrity of the content in Wikimedia projects. At the same time, humans and machines rely on Wikipedia as a neutral arbiter of reliable information on the Web. Preserving the reliability of Wikipedia’s knowledge is therefore key in ensuring the integrity of the information propagating in the broader web. You’ll work remotely with a distributed team, with members spread between Europe and North America. Here are some things we’ve worked on recently that might give you a better sense of what you could be working on: Studying how content propagates across different Wikipedia languages, by predicting, given an article created in one language, what is the next language that will have the same article created.Modeling content inconsistencies between Wikimedia projects by aligning Wikidata statements to sentences in Wikipedia articles through natural language processing techniques.Designing algorithms to identify malicious actors such as sockpuppets, by detecting clusters of users behaving similarly.Building a model to detect unsourced content in Wikipedia using machine learning, through neural network classifiers that can detect sentences needing citations based on their content. (paper)Using qualitative methods to study Wikimedia communities and their patrolling techniques, to discover inner mechanisms of editor workflows to combat disinformation. You can learn more about what we have done in the past six month by reading our biannual report. You will be responsible for: Contributing to the three directions of the team: addressing knowledge gaps on the Wikimedia projects, supporting the Wikimedia volunteers in improving content integrity, and building a more global community of Wikimedia researchers with a particular focus on improving content integrity and disinformationCollaborating with other researchers, Wikimedia volunteers, and teams within the Wikimedia Foundation, including Legal, Trust and Safety, and Security teams to define disinformation and content integrity related research projectsDesigning and executing experiments to collect labeled data, large-scale data analysis and/or modeling and evaluation of machine learning methodsDiscussing, documenting and communicating the process and results of your research publicly Actively engaging in a collaborative, consensus-oriented environment and as part of a globally-distributed team and organizationElevating the importance of critical open research questions as well as nurturing and growing the global network of Wikimedia researchersProviding research consulting to the teams in the Wikimedia Foundation, affiliates, and the Wikimedia volunteers Skills and experience: PhD or MSc degree plus 1-2 years of related work experience in computer science, statistics, or related technical fields: PhD degree highly preferredStrong experience in Machine Learning and at least one of the following fields: Natural Language Processing, Algorithm Design, Social Network Analysis, HCI, Behavioral/ Experimental Economics, Computational Social Science: experience with disinformation research highly preferred.Programming experience in Python, Scala, or C++Experience with Hadoop and any of the following related technologies: HDFS, YARN, MapReduce, Hive, Spark, etc.Contributions to research communities and research initiatives including publishing in relevant conferences and journals, organizing academic workshopsStrong written and oral communication skills in English, including the ability to communicate complex technical issues to a cross-team and cross-functional audience  Qualities that are important to us: Commitment to the mission of the organization and our valuesCommitment to our guiding principlesAbility to disagree in a respectful manner and yet work towards a solution even when you disagreeGood at async communication Solutions-focused. The Wikimedia ecosystem is complex, resources are limited, and our guiding principles are ambitious. We want you to work to find solutions embracing these factors.Self motivated with an Ability to navigate through ambiguity and bring a project to completion with limited directionsCuriosity and commitment to learn Additionally, we’d love it if you have: Relevant work experience in the field of disinformation, in academia or industryExperience with large-scale experiments in online platformsExperience with mixed methods researchA strong record of scholarly publicationsExperience as a program committee member, senior program committee member, track chair, or editor in related conferences and journalsExperience with tools such as Spark, Flink, Hive, KafkaDeep knowledge of the Wikimedia ecosystem and the working of the projects and/or experience with volunteer or open source communities The Wikimedia Foundation is...  ...the nonprofit organization that hosts and operates Wikipedia and the other Wikimedia free knowledge projects. Our vision is a world in which every single human can freely share in the sum of all knowledge. We believe that everyone has the potential to contribute something to our shared knowledge, and that everyone should be able to access that knowledge, free of interference. We host the Wikimedia projects, build software experiences for reading, contributing, and sharing Wikimedia content, support the volunteer communities and partners who make Wikimedia possible, and advocate for policies that enable Wikimedia and free knowledge to thrive. The Wikimedia Foundation is a charitable, not-for-profit organization that relies on donations. We receive financial support from millions of individuals around the world, with an average donation of about $15. We also receive donations through institutional grants and gifts. The Wikimedia Foundation is a United States 501(c)(3) tax-exempt organization with offices in San Francisco, California, USA. As an equal opportunity employer, the Wikimedia Foundation values having a diverse workforce and continuously strives to maintain an inclusive and equitable workplace. We encourage people with a diverse range of backgrounds to apply. We do not discriminate against any person based upon their race, traits historically associated with race, religion, color, national origin, sex, pregnancy or related medical conditions, parental status, sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, genetic information, or any other legally protected characteristics. If you are a qualified applicant requiring assistance or an accommodation to complete any step of the application process due to a disability, you may contact us at recruiting@wikimedia.org or (415) 839-6885. U.S. Benefits & Perks* Fully paid medical, dental and vision coverage for employees and their eligible families (yes, fully paid premiums!)The Wellness Program provides reimbursement for mind, body and soul activities such as fitness memberships, baby sitting, continuing education and much moreThe 401(k) retirement plan offers matched contributions at 4% of annual salaryFlexible and generous time off - vacation, sick and volunteer days, plus 22 paid holidays - including the last week of the year.Family friendly! 100% paid new parent leave for seven weeks plus an additional five weeks for pregnancy, flexible options to phase back in after leave, fully equipped lactation room.For those emergency moments - long and short term disability, life insurance (2x salary) and an employee assistance programPre-tax savings plans for health care, child care, elder care, public transportation and parking expensesTelecommuting and flexible work schedules availableAppropriate fuel for thinking and coding (aka, a pantry full of treats) and monthly massages to help staff relaxGreat colleagues - diverse staff and contractors speaking dozens of languages from around the world, fantastic intellectual discourse, mission-driven and intensely passionate people ﻿*Please note that for remote roles located outside of the U.S., we defer to our PEO to ensure alignment with local labor laws.",Intermedio,Jornada completa,"Investigación, Ciencias",Internet,465,None,False,recruiting@wikimedia.org,5285,ACTIVELY_HIRING_COMPANY
31,2235702791,2020-11-01,Triplebyte,Data Scientist,"San Francisco, CA, US","As a data scientist at Triplebyte, you’ll have the opportunity to work on a variety of challenges to help us scale. You'll be part of a small team, who are leveraging data to fix technical hiring. Your day to day, will include a mix of dataset acquisition, statistical modeling, exploratory data analysis, and software engineering. You’ll report directly to Triplebytes' Head of Machine Learning and will work alongside a team of 6-8 machine learning engineers and data scientists.  Fields your work will touch on   Psychometrics Recommender systems Time series analysis Survival analysis Bayesian inference Probabilistic programming  This is an ideal role for a data scientist who wants the scope and responsibility to own features/products from the inception and research phase through to measuring real-world results.  The salary range for this position is $145,000 - $225,000",Algo de responsabilidad,Jornada completa,Ingeniería,Software,26,None,False,,115,ACTIVELY_HIRING_COMPANY
32,2189462468,2020-11-03,Provenir,Senior Data Scientist,"Leeds, England, United Kingdom","Who We AreProvenir is a global Fintech company with offices in London, Leeds, Singapore, Canada, New Jersey, Miami, San Francisco. We are passionate about technology and helping businesses become industry leaders. As a leading provider of decisioning and analytics products for financial services and other industries, we empower businesses to create innovative, digital-first financial decisioning solutions that drive business growth. At Provenir, you’ll be a member of a dynamic and growing team that prides itself in developing highly innovative, adaptable and configurable software solutions. You’ll enjoy a comfortable work space, competitive compensation and benefits package including: PMI, Pension Scheme, Life Assurance, Income Protection and Paid Company Holidays.  Who We Are Looking ForWe proactively enable our clients to get the best out of their data and to deploy advanced techniques within their decisioning processes. We are used across the globe for numerous use cases including onboarding, customer management, collections and recoveries for the insurance, credit and technology industries. All Provenir employees are currently working from home. What You’ll DoWe’re seeking an experienced data scientist to design solutions that can be used in many markets. Helping our clients identify the right data at the right time to make better decisions. Our ideal team member will have the mathematical, statistical and technology expertise you’d expect, but also a creative and curious mindset to think outside the box to help solve clients issues. Working closely with the engineering team and product leads you will develop general solutions to industry and geographic challenges that our clients face with the ultimate goal of enabling them fully leveraging available data sources and modelling techniques.  A key responsibility will be creating a better way for clients to navigate the data at their disposal and the techniques to get the most out of them. The role is global and covers all continents, so whilst some regulatory experience be advantageous you’ll be working with local teams that can support you. Objectives of this RoleEnable clients to develop smarter business processes and implement advanced analytics to improve business performanceCollaborate with product leads and engineering team to develop an understanding of needsResearch and devise methods and innovate around them to improve data analysisKeep current with technical and industry developmentsEnable clients to deploy advanced algorithms to identify opportunities to add, substitute or enhance data sources to improve performance Daily and Monthly ResponsibilitiesWork as the lead data scientist, identifying solutions and working with product and engineering teams to deploy in cloud environmentsWork closely with the engineering team to strategize and execute the development of data productsDevise analytical experiment methodology to help clients solve various problems and make a true impact across various domains and industriesIdentify relevant data sources and sets to mine for client business needs, and collect structured and unstructured datasets and variablesDevise and utilize algorithms and models to mine data, perform data and error analysis to improve models, and clean and validate data for uniformity and accuracyCommunicate analytic solutions to stakeholders, clients, and the industry What's RequiredEducation - Bachelor’s and Master’s degree in statistics, applied mathematics, or related disciplineExperience - 4+ years experience in data scienceProficiency with data mining, mathematics, and statistical analysisAdvanced pattern recognition and predictive modeling experienceExperience of Credit and/or Insurance decisioning/pricing processes and regulationsExperience of Model Monitoring methodologyProgramming languages (Python, R, Java, SAS)Experience with Excel, PowerPoint, Tableau, SQL, Cloud environments (AWS, Azure, Google)Comfort working in a dynamic, research-oriented group with several ongoing concurrent projectsPreferred QualificationsPhd in stats, applied math, data science, or related discipline a plus2+ years of project management experienceAdditional Languages a plus Our collaborative culture and strong technical environment make Provenir a great place to build your career. To learn more visit www.provenir.com. Provenir is an Equal Opportunity Employer",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Software, Servicios y tecnologías de la información, Servicios financieros",62,None,False,,565,ACTIVELY_HIRING_COMPANY
33,2149674733,2020-11-04,PlusUp,Data Engineer,Atlanta Metropolitan Area,"We are looking for a Data Engineer to join our growing team. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for our teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our team on advertising data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple projects, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s advertising data architecture to support our next generation of products and data initiatives.",Algo de responsabilidad,Jornada completa,Tecnología de la información,Marketing y publicidad,197,None,True,,1107,JOB_SEEKER_QUALIFIED
34,2252456514,2020-10-29,PolSource,Data Scientist,Poland,"For almost 15 years, PolSource has been specializing in delivering Salesforce solutions to the most recognizable brands from all over the world (Nike, Coca-Cola, Spotify, Volvo, Bank of America and much more). With over 200 employees on board from 7 location (PL – Krakow, Wroclaw, Lublin, Warsaw, Lodz, USA - Austin,  UK - London) and customers on each continent, PolSource has become a Platinum Consulting Partner of the Salesforce platform – the world’s strongest CRM solution platform. PolSource prides itself not only on prestige customers and attractive projects but also on the talent of its people. By working here you have a chance to be a part of highly experienced and talented team. Find more about PolSource on https://www.polsource.com/ Currently we are looking for: Data Scientist (location: Kraków, Łódź, Wrocław, Lublin, Warsaw or remote work) Key responsibilities Evaluating data sources and automate collection processesProcessing of structured and unstructured dataLooking for patterns and trends in analyzed datasetsBuilding predictive models and machine-learning algorithmsPresenting information using data visualization techniquesCollaborate with developers and product teamPresenting information using data visualization techniques   You are a perfect candidate if You Degree in Computer Science, Engineering or Applied MathProven experience as a Data Scientist or Data AnalystExcellent communication skills in EnglishExperience in data mining techniquesUnderstanding of machine-learningKnowledge of R, SQL, and Python: familiarity with Java or APEXKnowledge of commercial solvers (e.g. CPLEX, ALGLIB, Gurobi)Experience using business intelligence tools (e.g. Tableau) and data frameworks (e.g.Hadoop)Strong analytical skills and ability to work with large data setsKnowledge of consumer product goods (CPG) highly desirable We offer Flexible employment contract (B2B, regular employment contract, other)Competitive salaryOpportunity to take part in trainings and conferencesWorking with the most recognizable brands from all over the worldGood working atmosphere in a harmonious teamCofinancing of Multisport cardPrivate medical careTeam building / Integration meetings",Intermedio,Contrato por obra,"Ingeniería, Tecnología de la información",Servicios y tecnologías de la información,65,None,False,,462,ACTIVELY_HIRING_COMPANY
35,2227909374,2020-10-22,UST Global España,Data Scientist Junior (Python & GCP),"Madrid, Community of Madrid, Spain","¡Seguimos buscando talento…y nos encantaría que te unieras a nuestra familia!UST Global se preocupa por la seguridad de sus empleados y, ahora más que nunca dada la nueva situación, hemos reforzado nuestras operaciones. UST ofrece teletrabajo a los empleados y también otras modalidades de conciliación con las que podrás acumular suficiente tiempo para equilibrar tu vida personal y laboral. UST Global además, cree fuertemente en la Diversidad y la Inclusión como la forma de mejorar su fuerza de trabajo operacional, por lo que si tienes Certificado de Discapacidad, esta es tu empresa!Para que nos conozcas algo mejor, UST Global es una multinacional norteamericana certificada como Top Employer con más de 20.000 empleados a nivel global y con presencia en más de 25 países. Somos líderes en servicios de tecnología digital y proporcionamos soluciones tecnológicas de gran alcance a grandes compañías a través de proyectos end-to-end, consultoría y soluciones propias. ¿Qué buscamos?Para nuestro equipo de Big Data y Data Scientists estamos buscando incorporar un Data Scientist junior con experiencia con Python y Google Cloud Platform. Funciones-Desarrollar proyectos basados en datos utilizando tecnología Big Data y técnicas de ciencia de datos.-Selección, definición y ejecución de los entornos de programación adecuados, formatos de archivo, soluciones de almacenamiento de datos, flujos de datos automáticos.-Definir y seguir las mejores prácticas para los casos de uso de Big Data mientras extrae, transforma, almacena y alimenta datos a o desde diferentes fuentes de datos.-Conocer y mantenerse actualizado de las últimas técnicas, modelos, entornos de programación y enfoques técnicos para diferentes problemas de Data Science. Requisitos:-Mínimo 2 años de experiencia como Data Scientist con Python-Experiencia con Google Cloud Platform implementando servicios Big Data-Experiencia con tecnologías Data movement CDAP,Informatica,Talend, Nifi, Kafka y Google Data Fusion.-Grado en informática o disciplinas científicas/técnicas relacionadas-Inglés intermedio Deseable y valorable: Poseer Certificado de discapacidad, en grado igual o superior al 33%  ¿Qué te ofrecemos?Acceso gratuito a varias plataformas de formación para que tengas acceso a un amplio catálogo multidisciplinar.Estabilidad y carrera profesional dentro de nuestro Centro de Excelencia donde podrás participar dando cobertura a varios proyectos de la compañía.Entorno internacional y contacto directo con compañeros referentes en las tecnologías core de la compañía, con los que podrás compartir conocimientos.Tenemos implantado un plan de compensación de referencias internas del que podrás beneficiarte al referenciar profesionales que se incorporen a la compañía. Y además…23 días laborables de vacaciones y jornada intensiva en verano.Salario competitivo y beneficios sociales (tarjeta restaurante y seguro de accidentes).Programa de Retribución Flexible para que puedas adaptar tu retribución según tus intereses (cheques guardería, tarjeta transporte, clases de inglés online con profesores nativos, seguro médico…).Horario flexible y teletrabajo por proyecto, actualmente por la situación actual se ofrece jornada completa con teletrabajo y otras medidas de conciliación.Tarifa plana con los gimnasios que tú elijas, cerca de tu domicilio o de las oficinas.Fruta en la oficina.Te damos vacaciones los días de Nochebuena y Nochevieja. Si quieres conocer más, no dudes en inscribirte y nos pondremos en contacto contigo para ampliarte información de la posición, ¡te estamos esperando!",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información",Servicios y tecnologías de la información,589,None,True,,2082,ACTIVELY_HIRING_COMPANY
36,2243524834,2020-11-04,Volt - International,Data Scientist,"London, England Metropolitan Area","We are looking for talented Data Scientists with a background in statistical genetics, statistical bioinformatics, Biostatistics, or a related strongly quantitative discipline, with postdoctoral experience in fields related to statistical genetics or genomics. Role· Development of Bioinformatics datasets, resources, and scripts that will enable downstream analyses for users of the research environment · Carrying out complex custom computational analyses· Provide high quality consultancy services in a variety of projects· Continuously scan the scientific literature to identify new approaches to genome analysis that can be implemented to improve capabilitiesRequirements Postdoctoral level (or equivalent) in a strongly computational and statistical discipline such as statistical genetics, machine learning, computational biology.  · Strong statistical analysis skills and experience of bioinformatics research and analytics using large human genomic datasets alongside clinical data· Excellent communication skills, both written and verbal and excellent facilitation, influencing and presentation skills · Proven ability to communicate with key customer and internal stakeholders from diverse backgrounds (e.g. management, IT, R and D, biology, bioinformatics)· Excellent team working skills and comfortable working as part of matrix teams and as part of external teams to ensure delivery. · Experience with cloud-scale data processing and high-performance computing. HPC· Demonstrated knowledge and competence in relevant programming languages and applications (e.g. R, Python) and experience of using a suite of bioinformatics tools to problem solve and answer research questions.  If you have PostDoc industry, not academic, experience as a Bioinformatician or Data Scientist within a computational and statistical discipline such as statistical genetics, machine learning, computational biology please get in touch. (Ideally some technical writing experience with a strong publication record in a relevant field)Please do not apply if you do not have industry experience. (Life Sciences)",Intermedio,Jornada completa,"Tecnología de la información, Ciencias, Análisis","Investigación, Biotecnología, Industria farmacéutica",161,None,True,,586,ACTIVELY_HIRING_COMPANY
37,2243528871,2020-11-04,Cadent Gas Limited,Data Scientist,"Coventry, England, United Kingdom","Data ScientistBase Location – CoventryPermanentStarting salary - £29.187, plus a generous pension scheme and a range of company benefits Here at Cadent we’re at the start of an exciting journey of transformation, growth and evolution. We’re new but we’re 200 years old. (You might have known us as part of National Grid but now we’ve transformed ourselves to Cadent). We’re the UK’s largest gas network connecting and keeping energy flowing to our customer’s 12 million homes and businesses across the UK.  We’re proud of our story so far and we’re super powered up about what our future holds. That’s where you come in! Join us as a Data Scientist and start a transformation journey adding real purpose and direction to your career and feel genuinely proud about what you do.  About the Role Data has recently become a key focus area for improvement in Cadent and this role within a new Advanced Analytics Team will provide required skills and capability to identify insights and delivering value from Cadent’s data by developing predictive models for various areas within the business. This role will sit within the Analytics Team within the IS Data. The Data Scientist’s primary focus will be to apply data mining techniques, perform statistical analysis, and build high quality predictive models to be used at Cadent within business strategies and operations to unlock the value of Cadent’s data and support business in data driven decision making  Key Accountabilities: Development and collection of business requirements and data for analytic projectsPreparation of data for analytic investigation from both internal and external systemsDevelopment and validation of predictive models and applying business context to derived resultsDetermining correlation between external and internal factors and their effect on organisation’s KPIs.  About You You will possess the following skills, knowledge and qualifications:  Educated to degree level in computer science, physics, mathematics or similar, with a strong data science componentExperience of working with common data science toolkits to drive business growth with demonstrable positive resultsKnowledge of creating or supporting the creation of a business’ A/B testing framework and the subsequent testing of the model qualityDevelopment and execution of processes and tools to monitor existing models’ performance and accuracyExperience in collection, preparation and validation of data for statistical analysisExcellent understanding of machine learning techniques and algorithms (regression, simulation, scenario analysis, modelling, clustering, decision trees, neural networks etc.)Great communication skills and ability to present technical topics to non-technical audienceFamiliarity with Data visualisation tools, such as PowerBI, SAC, TableauProficiency in common query languages including SQLGood scripting and programming skills (R, Python, etc.)Basic knowledge of cloud computing services, such as AWS, and integrations with physical in-house IT infrastructuresExperience with big data technologies such as Hadoop/Mongo DB/Spark   Benefits  At Cadent we’ve got a whole host of standard and flexible benefits. You’ll get 25 days holiday + statutory days with the option to buy/sell also, a generous pension plan as well as the opportunity to earn bonus. Flexible benefits include: cycle to work scheme, salary sacrifice car, insurance and healthcare packages plus access to our Occupational Health services.  Diversity and Inclusion Cadent has a commitment to Diversity and Inclusion  - the more diverse our organisation is, the more  able we are to respond to and reflect our communities in all their diversity. We therefore encourage and welcome applications from people with a diverse variety of backgrounds: age, gender, ethnicity, disability, sexuality, social background, religion and/or belief.  We want our employees to achieve a work life balance and are happy to discuss flexible working options with you if the role can accommodate it. If you require any reasonable adjustments during the application process, please let us know. We’re committed to be Disability Confident in line with the Department For Work and Pensions scheme. Be part of something big. Help shape the future of gas for generations to come",No corresponde,Jornada completa,"Ingeniería, Tecnología de la información","Servicios públicos, Petróleo y energía",23,None,False,,253,ACTIVELY_HIRING_COMPANY
38,2289456997,2020-10-14,Lucidworks,Data Scientist (Remote - US),"Raleigh, NC, US","About The Team   The Data Science Team is responsible for research and development of end to end solutions for search related analytical problems. We collaborate with consultants and customers to learn user needs, gather data, design and prototype solutions, as well as validate preliminary results. We continuously explore new AI technologies, and join industry best practices with the latest ideas from academia to turn them into useful products. We work closely with engineering to put our algorithms into production and out into the world.  Our research areas include a variety of topics like, semantic search, relevance tuning/assessment, recommender systems, knowledge graphs, NLU and A/B testing.   About You   You understand common Machine Learning and Deep Learning algorithms, know when a certain algorithm is or is not the right tool for the job, and understand the impacts of different parameter settings.  You have strong experience with recommendation and relevance algorithms, NLP expertise with document classification/clustering techniques and summarization. You are able to code an algorithm from scratch based on paper or ideas, invent new or modify existing algorithms, and maybe have interetesting publications or patents.  Most importantly, you are able to work collaboratively with a diverse community of personalities spread across multiple time zones, leveraging your excellent communication skills to make sure everyone is on the same page   You Have  3+ years of professional R&D experienceStrong CS skills, ability to write efficient and easy to understand code in PythonGood knowledge of the common DS and NLP libraries such as pandas, numpy, scikit-learn, spacy, transformersExperience with the DL frameworks: PyTorch or Keras/TensorflowA mathematics based degree, advanced preferred, or equivalent experience   Bonus Points For  Publication record in NLP or IR fieldsFamiliarity with JavaFamiliarity with microservices and cloud technologies like Docker and KubernetesFamiliarity with search engines such as Lucene/Solr or ElasticsearcPlease note that at this time Lucidworks is unable to sponsor employment authorization (both new and transfer).   About Lucidworks   Lucidworks is leading digital transformation by fusing the power of search and artificial intelligence to create connected experiences for work, shopping, research and support.  Fusion is our cloud-native ML-powered search platform that integrates open-source projects Spark and Solr with our proprietary code for query intent prediction, low latency search, hyper-personalization and smart app creation. Our products include applications that run on the Fusion platform including Predictive Merchandiser, which helps ecommerce teams harness the power of ML to improve ecommerce conversion and Smart Answers, which enhances chatbots and virtual assistants with natural language processing and deep learning. We believe in building a team to deliver these products that make searching for insights a uniquely personal experience for a worldwide community of users.  Our roots are in Apache Solr, the global search standard used by 90 percent of U.S. Fortune 500 companies. Our team includes contributors and committers to Solr as well as some of the world's foremost machine learning innovators. We are trusted by the world's largest brands to deliver personalized digital experiences across many industries, including: insurance, banking, capital markets, manufacturing, media, oil & gas, retail, software, and telecommunications. Those customers include companies like: Aetna, Morgan Stanley, Reddit, Red Hat, Uber, Verizon, and Wells Fargo. We also serve government agencies in the civilian, defense and intelligence sectors, including the United States Federal Reserve and the U.S. Census Bureau.  Lucidworks believes in the power of diversity and inclusion to help us do our best work. We are an Equal Opportunity employer and welcome talent across a full range of backgrounds, orientation, origin, and identity in an inclusive and non-discriminatory way. Applicants receive consideration based on the relevant talents, skills, and experiences they offer to our company. Thank you for your interest and we look forward to learning more about you.",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Software, Internet",None,None,False,,13,ACTIVELY_HIRING_COMPANY
39,2200196618,2020-10-22,Chip,Data Engineer,United Kingdom,"Good data should be the heart of any business and here at Chip we're striving for excellent data to empower us to make excellent decisions. Working alongside our engineering team we are looking to find a Data Engineer to help us collect, transform and store and serve that data across all sectors of the business. We collect a lot of important data from all aspects of our business and we need engineers to help us write tools to ensure that data is accurate and consistent. Using any and all tools and languages necessary to give us the power to do everything from lending decisions to deciding which features we should develop. What you can expect to be doing:Develop robust ETL pipelines and automated processes for ingesting and processing dataDeveloping, managing and extending data warehouse and data models to provide a robust foundation for internal reporting.Ensure best practices are followed with regard to security and infrastructureCreating and maintaining relevant documentationSpot opportunities for improvement on data engineering and business intelligence best practicesAdvise on data modelling and reporting best practiceWorking with the engineering team to ensure application design accommodates reporting and analytics requirements What we’re really looking forAdvanced level knowledge of SQL and/or experience managing Data WarehousesKnowledge of AWS and GCP cloud platformsConfident getting hands-on with Python to process data and automate processesConfident interacting with Databases and web APIs and processing dataGood understanding of reporting and data modelling best practicesGood written and verbal communication skills and an ability to translate problems into technical requirements and implement a solution.Take requirements from someone non-technically minded, implement the solution and then explain your solution to a software engineerWork within the Data team reporting to the Head of Data Engineering What we’re really looking for: ✍️Although we’re in the financial space, and under the scrutiny that comes with it, the current engineering team works well together, and even sometimes with a smile. We’re sure you’ve got the technical skills, otherwise you would have stopped reading by now, so let us be clear in what will make us want to work with you.We want a real person, with interests outside of code, to join our work family. You could be a dancer, a gamer, a musician, a parent, a hockey fan, or even that one person that still writes Twilight fan-fiction. Doesn’t matter to us. At the interview stages will be looking for empathy, eq, fun stories, and ability to smile even when things are tough. Code monkeys need not apply. PERKS 🎁£45,000 - £50,000 per annum dependant on experienceDiscretionary share option bonus every 6 monthsWorkplace pension scheme (Employer: 3% / Employee: 4% / Tax Relief: 1% / Total: 8%)We are an equal opportunity employer and value diversityFlexible working arrangementsUnlimited holiday (28 days contracted but policy not to count) ✈️Free Classpass membership or gym membershipCompany laptopBased in the heart of Chancery LaneOpportunity to have a huge impact on our product while fast-tracking your knowledge, responsibility and skills in a high growth fintech startup 🚀 Our Interview process: 📖Phone Screen with someone from our Talent teamShort take home testVideo interview with the hiring managerFinal Interview with HR  ﻿Note to AgenciesChip does not accept unsolicited CVs from recruiters or employment agencies in response to any of our live roles on our career page. Chip will not consider or agree to payment of any referral compensation or recruiter fee relating to these unsolicited CVs. Chip explicitly reserves the right to hire those candidate(s) without any financial obligation to the recruiter or agency. Any unsolicited CVs, including those submitted to hiring managers, are deemed to be the property of Chip.",Intermedio,Jornada completa,Tecnología de la información,Servicios financieros,28,None,False,,279,ACTIVELY_HIRING_COMPANY
40,2289303063,2020-10-14,Deliverr Inc.,Jr. Data Scientist (New Graduates-2021),"San Francisco, CA, US","Large online marketplaces like Amazon have trained consumers to expect products to be delivered in two days at no extra cost. As a result, millions of sellers on other marketplaces are falling behind, unable to cost-effectively deliver products to their customers within two days. Deliverr enables any seller, regardless of size, to delight their customers with fast, cost-effective fulfillment.  If you get excited about joining a company on a mission to deliver products anywhere in the world within two days, we're looking for you.  What You'll Do  Forecast spatiotemporal demand and shipping times as a pioneering member of the Deliverr Prediction team  Inform and influence key Engineering/Growth/Ops decisions with insights from data Design, build, and maintain analytics to enable Engineering/Growth/Ops to track KPIs Design, build, and maintain large data collection engines   What We're Looking For  Academic background in mathematics, statistics, physics, computer science, or engineering Fluency in Python or similar language Proficiency with SQL Ability to visually express complex information to both technical and non-technical audiences Ability to work, prioritize, and adapt in a rapid-growth startup Knowing the difference between sophisticated and effective Must be based in North America.   Bonus points for:  Experience building experimentation platforms Experience working on growth initiatives",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Software, Internet, Servicios financieros",10,None,False,,43,ACTIVELY_HIRING_COMPANY
41,2235740885,2020-11-04,Stanton House,Data Engineer,"Edinburgh City, Scotland, United Kingdom","Permanent - Data Engineer- Scotland/Remote - c.£65k p/a Role:                                 Data EngineerStart Date:                       Starting ASAPJob Type:                          PermanentLocation:                           Scotland/Remote InitiallySalary: c.£65k per annum I am working with an innovative Data company who are looking to bring on a Data Engineer. This role will be responsible for actively writing code (Scala or Python) to support new products, processing massive amounts of data, and implementing new machine learning models, but also help own their overall data and processing infrastructure.  The Role:Innovate, implement, support, and iterate on their batch and streaming data-processing code, ETL pipelines, and systemsWork with data scientists and other engineers to implement and optimise machine learning algorithms, pipelines, and systemsParticipate in an on-call rota to support our systems in productionSupport, mentor, and pair with other members of the team to advance our team’s capabilities and capacity Required:5+ years direct experience solving complex, large-scale data challengesMastery of either Python or Scala for data-intensive use casesExperience with distributed processing using Spark, Hadoop, or similarFamiliarity with orchestration frameworks, like Luigi, Airflow, or OozieA full-stack understanding of production data analytics and ingestion engineeringHands-on implementation and architectural familiarity with streaming, relational, and non-relational databases and systemsAdvanced knowledge of cloud based services (AWS, GCP)Excellent working understanding of server-side LinuxKnowledge of general engineering principles and design patterns Desired:Practical experience optimising queries and code accessing relational row and/or column stores (e.g. PostgreSQL, BigQuery, RedShift) Please click 'apply' or email jessica.browne@stantonhouse.com for more information.",Intermedio,Jornada completa,"Tecnología de la información, Ingeniería","Marketing y publicidad, Servicios y tecnologías de la información",45,None,True,jessica.browne@stantonhouse.com,195,ACTIVELY_HIRING_COMPANY
42,2174481279,2020-11-05,Gazelle Global,Data Engineer (100% Remote),Poland,"I am currently hiring for multiple Data Engineers in Poland to join one of Europe’s fastest growing clients in a progressive and innovative international team on a 6 to 12 months contract. ﻿This is a fully remote position (even post Covid restrictions are lifted). You can be based anywhere in the EU/ UK . We are currently building a team of Data Engineers, some of the required skills are as follows: 4+ years of experience in Data EngineeringPython and/or any other languages used to move and transform dataSQL Server database developmentRelational databases like Oracle, PostgreSQL, MySQLETL processesData storage formatsAWS  To hear more about this opportunity, apply now or send me your updated CV on amita@gazellegc.com with a good time to discuss further. This is an urgent position and interviews are happening daily! Book your slot now!",Intermedio,Contrato por obra,Tecnología de la información,Servicios y tecnologías de la información,184,None,True,amita@gazellegc.com,981,ACTIVELY_HIRING_COMPANY
43,2155347875,2020-10-27,Hagerty,Data Engineer,United States,"Hagerty, an automotive lifestyle company and the world's pre-eminent membership, insurance and media organization for enthusiast vehicle owners, has an opportunity for a Data Engineer to work on our data science team. In this role you will be building and maintaining our data pipeline and scalable analytics platform. You will also be partnering with other technical and business stakeholders to develop and productionize data science models.This position can be based remotely, or located in our Traverse City, Ann Arbor, Michigan or Dublin, OH offices. What You’ll Do:Implement data engineering best practicesDevelop and implement robust and scalable data integration (ETL) pipelines using Python, SQL, Spark, and other AWS/Salesforce cloud solutions.Develop and implement data pipeline orchestration utilities using ApacheSupport AWS platform DevOps best practices throughout all data engineeringCreate and manage AWS resources using infrastructure-as-code bestpractices, specifically in terraform.Partner with internal and external stakeholders to collect requirements and recommend best practice solutions.Develop solutions to catalog and manage metadata to support data governance and data democratization.Develop and implement automated test cases and data reconciliation to validate ETL processes and data quality & integrity.Partner with Data Scientists to design, code, train, test, deploy and iterate machine learning algorithms and systems at scale. This Might Describe You:Associates degree, preferably in a technical/analytical field, or relevant workAdditional 3+ years working in another role within an IT delivery team, such as a developer, business systems analyst, data analyst, quality assurance analyst, ETL developer or DBAStrong problem-solving abilities and attention to detailAbility to authentically and effectively communicate (written and verbally) with various stakeholdersAbility to create technical artifacts and documentation to support development and maintenance of data productsExperience in successful delivery of data products as productionizable software solutionsExperience or willingness to learn open source data processing technologies such as Kafka, Hadoop, Hive, Presto, Spark, GraphXExperience ensuring rigorous code development, testing, automation, and other engineering best practices.Experience in imperative (e.g., Airflow) or declarative (e.g., Informatica/Talend/Pentaho) ETL design, implementation, and maintenance.Experience cataloging and processing non-relational data.Experience or willingness to learn one or multiple of the following languages Python, Scala, or SQLFunctional knowledge of relational databases and query authoring (SQL)Experience or willingness to learn productionizing data science models in frameworks such as numpy, ML Spark, pandas, scikit-learn, tensorflow, MOA, mlpack, etc.Preferred experience in machine learning techniques such as feature engineering, features selection, supervised and unsupervised algorithms, clustering, graph analytics, and time series analysis, K-means clustering, Gaussian distribution, decision tree, etc. We Offer:Competitive compensationInclusive benefits package allowing enrollment of dependents and partnersA flexible culture that understands the importance of quality of work over quantityAn opportunity to work with a diverse, global community of 1000+ Hagerty team members across multiple countries, united by our values of open, direct, and kindA culture of company-wide collaboration and shared successCompany supported and employee-driven resource groups that promote diversity, career development and empowermentCorporate social responsibility initiatives with global reachRegular recognition, feedback, and open communication across all levelsTeam building, bonding, mentorship and support to grow confidence, trust, and friendshipsAt Hagerty, we’re focused on building a world-class company and culture, and that starts with the people we hire. We take pride in being an equal opportunity, inclusive employer To apply for this position please visit our Career site at careers.hagerty.com If you like wild growth and working with happy, enthusiastic over-achievers, you'll enjoy your career with us!",Intermedio,Jornada completa,Tecnología de la información,Sector automovilístico,106,None,False,,543,ACTIVELY_HIRING_COMPANY
44,2191222242,2020-10-27,Envision,Data Engineer,Greater St. Louis,"Data Engineer, St. Louis, MO (remote possible*)No C2C or sponsorship, must be our W2 employee*Remote: For exceptional candidates who can show previous remote work on their resume, we will allow remote. You must be able to show where you worked remotely and outline the tools you used to work remotely.* Required experience:• At least 2 years experience with Go• Proven experience (2 years) building and maintaining data-intensive APIs using a RESTful approach• Experience with stream processing using Apache Kafka• A level of comfort with Unit Testing and Test Driven Development methodologies• Familiarity with creating and maintaining containerized application deployments with a platform like Docker• A proven ability to build and maintain cloud based infrastructure on a major cloud provider like AWS, Azure or Google Cloud Platform• Experience data modeling for large scale databases, either relational or NoSQLBonus points for:• Experience with protocol buffers and gRPC• Experience with: Google Cloud Platform, Apache Beam and or Google Cloud Dataflow, Google Kubernetes Engine or Kubernetes• Experience working with scientific datasets, or a background in the application of quantitative science to business problems• Bioinformatics experience, especially large scale storage and data mining of variant data, variant annotation, and genotype to phenotype correlationYou may apply on LinkedInor on our web site: http://www.envision.com/jobs/index.html#/jobs/71039",Intermedio,Contrato por obra,Tecnología de la información,Dotación y selección de personal,134,None,True,,722,ACTIVELY_HIRING_COMPANY
45,2242790761,2020-10-26,OutSystems,AI Research Scientist - Machine Learning,Portugal,"With the recently announced Project Turing, OutSystems is creating the future by leveraging cutting-edge AI to teach machines how to program, make our products smarter and enable anyone to create groundbreaking apps faster than ever, and with higher quality. We are embedding AI into the fabric of our organization and products. As a Research Scientist in our Artificial Intelligence Group, your main role will be to do applied research and development, in order to push the state-of-the-art and make our next generation products smarter and easier to use. The sky is the limit and you’ll help us get there. Key Responsibilities Push the state-of-the-art forward in Artificial Intelligence and Machine Learning, applied to smart App development.Design and build solutions for real-world problems, from idea, through research, prototyping, and into product solutions.Work together with data scientists, engineers, and product people to bring new developments to our products.Communicate research progress and milestones clearly and efficiently to internal and external audiences. Share your findings with the community, and be a thought leader in smart App development.Collaborate with other research institutions to openly advance research goals. Preferred QualificationsA Ph.D. degree in Computer Science, Artificial Intelligence, Machine Learning, or related technical fields is highly valued.M.Sc. with a strong focus on Computer Science and Statistical Learning components (e.g. Computer Science, Electrical Engineering).Deep expertise in one of the following: Deep Learning, Neural Networks, Sequence Models, Natural Language Processing, Image and Sound Processing, Classification.Hands-on experience with ML/Deep Learning platforms (e.g. Tensorflow, Keras, PyTorch, Scikit-Learn, Spark ML), and data processing platforms (e.g. Spark, Pandas).Proficiency in high-level problem solving and programming languages. Able to create end-to-end working prototypes - from planning, data engineering and analysis, and algorithm implementation. Experience in Python or R is valued.Be creative, ambitious, and curious. Be resourceful and innovative.  What you can expect from OutSystems: The possibility to create disruption in the software development market:A company that cares about employees wellbeing and provides a safe and comfortable work environment, even during adverse times:A world-class software engineering team with peers and leaders that are inspired to learn and share what they know:A fast-growing company that provides many opportunities for you to grow:Fun from day one: a relaxed work environment, colleagues from diverse backgrounds, and with a diverse range of interests, fun company events. Curious about OutSystems culture? Find out more in The Small Book of The Few Big Rules.",Intermedio,Jornada completa,Ingeniería,Software,69,None,False,,461,ACTIVELY_HIRING_COMPANY
46,2184079062,2020-10-15,Octopeek,Data Analyst / Scientist,"Paris, Île-de-France, France","Octopeek est une entreprise de services et d’édition logicielle spécialisée dans l'analyse et la science des données, créée en 2010.Nous développons des plateformes basées sur le Big Data et l’intelligence artificielle et permettant d’améliorer la performance business et la productivité des entreprises à améliorer leur productivité et leur performance grâce à l’AI. Cette Data Fabric est constituée de 3 briques :Big Data as a service (BDaaS) , Smart Data, AI as a service (AIaaS).  Cela permet de collecter, stocker, sécuriser les données, et en extraire toute la valeur grâce à des workflows Data Science (nettoyage, enrichissement, analyse, modeling, visualisation, traitements AI).Cette Data Fabric fonctionne en libre-service. Toutefois pour des besoins très spécifiques, Octopeek aide les entreprises en proposant ses services de consulting et de formations.Octopeek est agréée CIR et reconnue Organisme de Formation dans le cadre de vos financements OPCA.  Vous rejoignez une équipe d'experts afin d'intervenir sur des missions de Data Scientist. Votre mission: Au sein d’une équipe de data vous devrez accompagner les opérationnels et les experts métiers sur les démarches et sur les méthodes de modélisation.  - des cas d'usages internes, transverses et variés (technique, marketing grand public, commercial grand public, B2B, contrats opérateurs…) - Référent en interne et en externe sur les traitements analytiques avancées de données massives et variées (données techniques, clients, structurées et non structurées). ﻿Compétences et expérience souhaités : Data Analyst expérimenté dans les projets de traitements analytiques avancés de données volumineuses et variées. Maitrise ou bonne connaissance des différents types d'approches analytiques :Apprentissage supervisé dont différents types de régression, analyse en série temporelle…Apprentissage non superviséApprentissage avec renforcementApprentissage profondMaitrise de Python (R, JAVA et/ou Spark serait un plus)Librairies de machine learning (Scikit-learn…) et manipulation de données (Pandas…),Langage de calcul distribué (Spark, Hive…) en environnement Hadoop,Outils de DataViz.",Algo de responsabilidad,Jornada completa,"Ingeniería, Tecnología de la información",Software,809,None,True,,2876,ACTIVELY_HIRING_COMPANY
47,2008402131,2020-10-13,MAGO,Data Engineer,"Manchester, England, United Kingdom","Senior Sata Engineering role Work with an established but growing Data Science team Work from home or from offices at Manchester Airport above our Train/ Tram station Data Science is the driving force behind business decisions and strategy:– make a real difference and see your work turn into real world products and services!Strong Base salary + free parking and 25% off train travel to work + extensive other corporate benefits  Let us introduce ourselves and tell you why we’re a great place to work:https://youtu.be/ustPXwN12C8  The Company: MAG is the country’s largest airport group. We own Manchester, Stansted and East Midlands Airports as well as having MAG USA, a large Airport Services business based in Chicago. MAG-O is our digital business, driven by data and created to take the Group on the next leg of its digital journey. Utilising advanced MI, digital platforms, and new and emerging technologies, this is a fast-moving, agile engine house of ideas and innovation. We are a globally focused business, and pride ourselves on being the number one airport-centric travel company: defining how airports increase their non-aero revenues and delivering our class leading e-commerce services to airport clients across the world.  Do you want to see the office? Click the link below:https://www.youtube.com/watch?v=0pYS_ghtWSU&t=81s  The Role:  This Senior Data Engineer position is a key component in the growth of the Data Science team. Supporting the existing team of data scientists, and wider business with usable analytics. This role will help provide the glue that enables the team to capitalise on the data assets the business has, and drive value from the insight we extract. We develop advanced and actionable data-driven insight to increase the efficiency of our marketing and ecommerce, increase customer lifetime value, improve customer experience, and open new business opportunities.  This role offers an opportunity to work at scale with data from MAG’s 3 airports, marketing leading distribution companies (that we own) MAG USA and our numerous global clients. MAG’s customers alone number 60 million passengers per year, 70,000 car parking spaces, and digital properties attracting 30 million visitors per year. The projects supported are also varied, including forecasting, revenue management, support to the CRM team with optimization, customer experience, and recommender systems, with increasing interest in real-time solutions.   Typical duties will include:  To structure, develop, and support ETL tools for use by the Data Science teamAccountable for ensuring that data is made available when requiredDevelopment and maintenance of and MAG-O-specific data warehouseLeading the acquisition and extraction of relevant data setsResponsible for the development of production-level code to support active Insights products, such as API-driven interactions with CRMsCreation of adequate test harnessing and log capture to ensure we track the performance of the data science models implemented.Leading the team and the wider business on ensuring solutions are secure, reliable, fault-tolerant and efficient  You! As the successful individual, you will have experience working as a Data Engineer, ideally in the direct support of data science activities, be a genuine self-starter, and eager to support our business in tackling real world strategic business and customer problems. You will join our established Data Science team, working together to help increase productivity, push forward our tools and pipelines, and grow and help govern our data lake and warehouse.  You will have in-depth practical experience with AWS and will be comfortable leveraging services such as EC2, Redshift, Lambda, Kinesis, and Batch. Further, you’ll be able to help shape our evolving data science environment. You will have expert experience with Python, detailed SQL knowledge, and be used to dealing with API services to ingest and process data. Experience of supporting data users working with R is advantageous.  You must be naturally inquisitive and unafraid to offer solutions in a supportive and collaborative manner. You will need to be able to deal with multiple tasks simultaneously and be a supporting team player. As a growing team within MAG-O, you will have the opportunity to help shape how we operate, work with the latest technologies, and grow your skills, experience, and responsibilities.   What we Offer  MAG offers a very competitive base salary + free parking and 25% off train + 24 days annual leave. This is a growing start-up environment supported by one of the North West’s most iconic businesses. We can offer unparalleled career stability, and development opportunities and the opportunity to make a real difference as we continue to grow  Equal Opportunities MAG is a values led organisation and we are committed to providing equal opportunities in all areas of work and business. We want people to achieve their best, which will in turn positively impact on our customers and the communities in which we live and work. At MAG we empower people to be themselves within an inclusive and supportive environment, enabling everyone to achieve their full potential in line with their abilities and career aspirations.Reasonable Adjustments As an inclusive employer, MAG wants to see every candidate performing at their best throughout the job application process, interview process and whilst at work. We therefore encourage you to inform us of any reasonable adjustments you might need to enable this to happen.  Please apply today as interviews will commence immediately",Intermedio,Jornada completa,Tecnología de la información,Aeronáutica/Aviación,75,None,False,,1077,ACTIVELY_HIRING_COMPANY
48,2239706646,2020-11-03,Oliver Bernard,Data Scientist - £50K - £60K - FinTech,"London, England, United Kingdom","Data Scientist - £50K - £60K - FinTech Our client is an innovative FinTech. They build cutting edge software platforms (SaaS) for trading, Open Banking and market data and are used all over the world by banks, hedge funds and investment management firms.  They want to hire a Data Scientist to grow their Data Science and Machine Learning team. Working directly with Leads, Engineering teams and senior stakeholders you’ll be able to design and build the core Machine and Deep Learning infrastructure and develop innovative algorithms and data models - working with Python, Keras and TensorFlow amongst others. You’ll be key to growing their data science capabilities and, in a very agile environment, work closely with Big Data Engineers and Python / Scala Developers to create a world-leading data solution. The position is 100% remote / work from home, with their office in central London.  Requirements: - Excellent, quantitative, academic background- Experience building Data Science, Machine Learning, Deep Learning solutions and models- Experience in statistical methods- Good coding skills with Python and productionising code- Knowledge of Tensorflow, Keras etc- Excellent communication skills",Intermedio,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Servicios financieros",245,None,True,,521,ACTIVELY_HIRING_COMPANY
49,2166068655,2020-11-07,ASAPP,NLP Research Scientist / Research Engineer,United States,"At ASAPP, our mission is to solve complex and challenging problems by building transformative machine learning-powered products. We leverage artificial intelligence to address significant challenges that share three common characteristics: huge economic scale, systemic inefficiencies, and tremendous amounts of data. Our talented teams that drive our product innovation and development are located in New York City, San Francisco, Mountain View, and Buenos Aires. Researchers at ASAPP work to fundamentally advance the science of NLP and ML toward our goal of deploying domain specific real-world AI solutions, and to apply those advances to our products. They leverage the massive amounts of data generated by our products, and our ability to deploy AI features into real-world use to ask and address fundamental research questions in novel ways. We are expanding our research team and are looking for candidates with masters degrees, research experience in NLP or machine learning, outstanding communication skills, and strong software engineering skills. If you thrive in an environment of deep thinking, impactful research, and startup-paced execution, ASAPP is the ideal place for you. What you'll doDevelop and optimize NLP models for rapid iteration of our AI SaaS productsBuild and maintain toolkits or infrastructure to accelerate NLP/ML innovationFollow cutting-edge research in the field of natural language processing and machine learning What you'll needStrong software engineering skillsAt least three years of applied NLP or ML experience, ideally for a software companyFamiliar with at least one of the deep learning toolkits, such as PyTorch, Tensorflow and MxNetMaster or Phd in Computer Science, Natural Language Processing, or Machine LearningStrong communications and interpersonal skills What we'd like to seeAbility to work with a diverse team in a fast-paced environmentPeer reviewed publications in NLP, Speech or Machine LearningBonus - experience with large-scale production model training (Horovod, Ray, Parameter Server, etc.)Bonus - experience with production model optimization (model compression, TVM, torchscript, etc.)Bonus - experience with cloud computing infrastructure and software (AWS, Kubernetes, Docker, etc.) PerksCompetitive compensationFitness and wellness perksLearning and development opportunities ASAPP is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, disability, age, or veteran status. If you have a disability and need assistance with our employment application process, please email us at careers@asapp.com to obtain assistance.",Algo de responsabilidad,Jornada completa,Investigación,"Servicios y tecnologías de la información, Software, Internet",357,None,True,careers@asapp.com,1087,ACTIVELY_HIRING_COMPANY
50,2281966298,2020-10-22,Webflow,Data Scientist,"San Francisco, CA, US","Webflow is a visual web development platform that empowers non-coders to create incredible experiences for the web.  We're looking for a Data Scientist to inform the future of Webflow with data by building a deep understanding of how our customers create for the web with our product. You'll partner directly with key product stakeholders to identify interesting business questions and provide the data and quantitative analysis to answer them, leading the development of KPIs and helping teams understand how to improve our user experience.  As an early member of our data team, you'll also be working to improve our data warehouse by thoughtfully developing clean and reliable data pipelines for lasting impact. We're looking for an empathetic, humble, curious and collaborative team member who is excited to provide meaningful, actionable insight to teams at Webflow while helping to shape our foundational data capabilities.  About The Role  Location: SF or Remote (US timezone) Full time  As a Data Scientist you'll …  Enable our product teams with quantitative analysis to understand how customers engage with Webflow, diving deep into impactful questions alongside key stakeholders and delivering actionable insights. Lead the definition of product and business success metrics, building tools for monitoring and surfacing drivers of KPIs (Key Performance Indicators) . Partner with technical and non-technical team members to execute experiments, answer open ended business questions with data, and research levers for improving our product Develop our data foundation, building new pipelines and models that contribute to our connected, complete understanding of our customer journey. We currently use stitch, dbt, snowflake and Tableau!  That said, these responsibilities are just the start! At Webflow, we encourage you to contribute wherever your interests take you — and shape your role accordingly. And this isn't just a philosophical bent: we actually give you 4 hours a week (10% of the work week) to pursue passion projects outside of your role responsibilities.  About You  You'll thrive as (a) Data Scientist if you:  have prior experience working as a data scientist (or the equivalent in quantitative analysis), especially alongside product teams.  bring your knowledge of applied statistics (e.g. predictive modeling, hypothesis testing, regressions), segmentation or experimentation (e.g. A/B testing) in an industry setting have strong understanding of SQL, and experience with a programming language like Python or R thrive collaborating with product teams in a fast-paced and sometimes ambiguous environment engage both technical and nontechnical audiences with clear and compelling communication  If you don't meet 100% of the above qualifications, you should still seriously consider applying. Studies show that you can still be considered for a role if you meet just 50% of the role's requirements.  About Us  At Webflow, we believe that our success will be defined not only by what we do — but also by how and why we do it. So, here is the Webflow 'why' and our 'how':  Our dual missions — one for the world, one for us  For the world: To empower everyone to create for the web and spark an unprecedented wave of digital innovation. For ourselves: Lead fulfilling, impactful lives.   Our core behaviors (how we act)   Start with customers Practice extraordinary kindness Be radically candid Move intentionally fast Just fix it Lead by serving others Dream big  Our commitments to you  We'll pay you! This is a full-time, salaried position that includes equity We'll invest in your physical and mental well-being with health, dental, and vision benefits and a monthly stipend for health and wellness expenses  We'll pay you to take a vacation … seriously. We'll give you a $1,000 bonus for taking your first vacation with us that is more than 5 days  We offer flexible parental leave  We provide remote employees with the equipment they need to create a great remote work environment  We will offer you the support you need to help you grow as an impactful Data Scientist and a human being   Ready to apply?  If you share our values and enthusiasm for empowering the world, we'd love to review your application! We promise we do take the time and care to review every application we receive. However, as much as we wish we could interview everyone who submits an application, we cannot guarantee an interview or feedback due to the unprecedented volume of applications we are receiving today. We are rooting for you, and hope you do consider applying.  Note: You'll need valid U.S. work authorization to join us.",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Marketing y publicidad, Software, Internet",26,None,False,,129,ACTIVELY_HIRING_COMPANY
51,1881484391,2020-10-12,Empathy.co,Data Engineer,España,"Data Engineers influence how empathy.co does business, one data-driven decision at a time! In this role, you’ll develop software, data pipelines and applications to apply mathematical algorithms to data and perform large scale data reduction and analysis.Your work will inform, influence and support business decisions and product design. You’ll also be involved in the design, development, and implementation of high performance and easy-to-use data visualisations and automation scripts.  WHAT ARE WE LOOKING FOR?A committed, enthusiastic and open minded individual with the capacity to empathize with our customers. Someone who is not afraid to ask questions and always keen to learn and improve. A motivated self-starter who loves a challenge and is always pushing themselves, their ideas, and the norm.As a part of one of the market leaders and a fast-growing company, you will have the opportunity to direct and lead our path while reaching millions of users with your innovations.Position based out of Gijón / A Coruña / Remote.  KEY SKILLSDegree in Computer Science or related fields (i.e. Statistics, Mathematics, Physics, Computational Neuroscience).2+ years of experience designing and building backend systems (preferably oriented towards the processing of large volumes of data).Deep fluency in at least one backend programming language (Python 3+, Java 8, Scala, etc.).Analytical mindset to identify issues and opportunities.Excellent spoken and written english. BONUS POINTSAn advanced degree (MsC, PhD) in a specialisation is preferred.Machine learning and deep learning knowledge and experience.Hands-on experience developing microservices based architectures and the technologies that enable them (containers, REST APIs, messaging queues, etc.).Experience with distributed frameworks like Apache Spark or Apache Hadoop.Experience with the following technologies: MongoDB, Cassandra, ELK Solr, Redis…Experience with Team collaboration tools such as Git, Bitbucket, Jira, Confluence, etc.Experience with unit testing and continuous integration.Experience with Scrum/Agile development methodologies.Excellent verbal and written communication skills. BENEFITSOpportunity to attend tech courses, events and conferences worldwideFlexible working hours & Possibility to work from home.2.5K Training Budget per year.Reduced working hours on a Friday and during the summer monthsPrivate medical insuranceFree English lessons at the officeHigh-end gear: a 13-inch MacBook Pro with dual monitor setup and the IDE of your choiceWorking with cutting-edge technologiesUnlimited fruit, coffee and tea. And most importantly: an amazing working atmosphere and team culture",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Servicios y tecnologías de la información,540,None,True,,2887,ACTIVELY_HIRING_COMPANY
52,2218815252,2020-10-28,Veeva Systems,Data Scientist (Remote),"Toronto, CA","At Veeva, we build enterprise cloud technology that powers the biggest names in the pharmaceutical, biotech, consumer goods, chemical & cosmetics industries. Our customers make vaccines, life-saving medicines, and life-enhancing products that make a difference in everyday lives. Our technology has transformed these industries: enabling them to get critical products and services to market faster. Our core values, Do the Right Thing, Customer Success, Employee Success, and Speed, guide us as we make our customers more efficient and effective in everything they do.  The Role  As a Data Scientist for the Business Consulting team, you will work with Veeva engineers, consultants, and fellow data scientists to support analysis and analytical data deliverables.  Your role will be to generate and own the mathematical and behavioural models that will help drive the generation of impactful insights and suggestions for our clients. Our ideal candidate is multi-talented, with the capabilities to develop statistical, machine learning, and optimization models but they are also able to be client-facing, to understand the business needs of our clients (both within and outside of Veeva), and present complex statistical and machine learning models to the stakeholders.  This is a great opportunity for someone who is excited about using their deep Data Science expertise to help shape the Machine Learning offerings of Veeva business.  This is a remote position.  What You'll Do Develop advanced algorithms that solve problems of large dimensionality in a computationally efficient and statistically effective mannerDesign, develop and assess highly innovative models for clustering, anomaly detection, and moreBuild and run an analysis of models and algorithms in order to assess performance and identify the best algorithms to present to customersEnsure models and algorithms support our customers and help them drive towards more intelligent and effective engagement with their customersExecute statistical and data mining techniques (e.g. hypothesis testing, machine learning, and retrieval processes) on large data sets to identify trends and figuresWork closely with the data warehouse product team to ensure the architecture is effectively developed to support algorithms that are reproducible for many clients while being able to tailor said models for individual clients  Requirements M.S. or Ph.D. in Machine Learning, Applied Statistics, Mathematics, Computer Science, or other quantitative disciplines. Ph.D. with at least 2 years of relevant industry experience, M.S. with 3 years of relevant industry experience.Advanced in-depth specialization and experience in data analysis techniques such as: classification, pattern recognition, clustering, feature analysis, deep learning (NLP), fuzzy matching, sentiment analysis, A/B testing, active/adaptive learningExpertise in using R or Python to manipulate large data sets and develop statistical models, with the ability to accurately determine cause and effect relationshipsGood SQL skillsIntellectual curiosity, along with excellent problem-solving and quantitative skills, including the ability to disaggregate issues, identify root causes, and recommend solutions, even in situations with non-standard problemsExcellent oral and written communication skills with the ability to effectively explain complex problems and advocate technical solutions to other team members and clients  Nice to Have Experience with commercial aspects of the Life Sciences industryExperience working with Software as a Service and/or enterprise productsExperience with AWSHands-on experience building models with deep learning frameworks (Tensorflow or similar)  Veeva’s headquarters is located in the San Francisco Bay Area with offices in more than 15 countries around the world.  Veeva Systems is an equal opportunity employer. Accordingly, we are committed to fair and accessible employment practices. Veeva Systems welcomes and encourages applications from people with disabilities. Accommodations are available upon request for candidates taking part in all aspects of the selection process.",No corresponde,Jornada completa,"Formación, Consultoría","Software, Servicios y tecnologías de la información, Industria farmacéutica",247,None,False,,1143,COMPANY_RECRUIT
53,2239854452,2020-09-30,Phreesia,Data Scientist,"New York City, NY, US","Phreesia is looking for an experienced and hands-on Data Scientist to join our growing Data Science Team: someone with extraordinary analytical and technical skills who is familiar with the entire lifecycle of a data science project, from data exploration, modeling and analysis, to model selection, validation, evaluation, and deployment.  You will be joining a team of especially smart, humorous, quick-witted, and dedicated coworkers, all passionate about data and improving patient access to healthcare. You will be responsible for building data products for internal consumption, near real-time business intelligence tools, and predictive models. We are looking for someone experienced in partnering with business stakeholders, translating their needs into technical solutions and answers, and then building and delivering those solutions. This role will report directly to the Associate Director of Data Science.  What You'll Do:   Leverage Phreesia's massive and ever-growing dataset to build data products that provide actionable business insights  Optimize targeted engagement strategies through modeling, forecasting, and evaluation  Develop methods to efficiently classify and characterize patient populations  Navigate and use diverse machine learning stacks in Python and R  Use NLP techniques to parse, process, and structure textual data  Quickly prototype ideas and solve complex problems by adapting creative approaches  Build customized dashboards for internal and external clients  Take ownership of data products and ensure they are properly tracked throughout their lifecycle  Write clean, well-tested, code that will stand the test of time  Be an expert communicator: you could summarize your daily progress in a tweet   What You'll Bring:   2+ years of experience in an operational Data Science role.  Professional command of Data Science and Machine Learning toolsets such as Python (Numpy, Scipy, Pandas, Scikit-learn), R (dplyr, tidyverse, ggplot).  MS/MA in a quantitative field such as data science, computer science, engineering, mathematics, statistics, computational linguistics, physics, or relevant equivalent professional experience  Experience in using statistical principles to inform decision making (experimental design, significance tests, a/b testing)  Excellent interpersonal and communication skills, both written and verbal  Ability to organize, visualize, and present complex data in a way that tells a compelling story and drives decision making  Strong SQL skills  Experience contributing professional-level code using version control   Nice to Have:   Experience using web frameworks such as Python flask or R shiny  Experience in collaborating with Data Scientists and Data Engineers to propose, test, validate, evaluate, and deploy Machine Learning models  Experience using Apache Spark  Experience using Graph and/or search Databases (e.g. neo4j, elasticsearch)  Healthcare experience and a basic understanding of clinical terms   Who We Are:  At Phreesia, we're committed to helping healthcare organizations succeed in a fast-changing landscape—and we need smart, passionate people to help us do it. Our innovative SaaS platform offers our clients a suite of applications to manage the intake process, giving them the tools to engage patients, improve efficiency, optimize staffing and enhance clinical care.  Basically, what you do here matters, and hard work does not go unnoticed. Not only does Phreesia care about our clients, we also care about our employees. In fact, we're a three-time winner of Modern Healthcare magazine's Best Places to Work in Healthcare award. If you're interested in consistent feedback and recognition, defined career paths, and the opportunity to work with driven and engaged colleagues in a dynamic industry, this may be the right opportunity for you.  Benefits and Perks:   Variety of health plan options, dental/ vision coverage, and short/long-term and life insurance plans 401(k) savings plan Flexible working hours Unlimited vacation Home office set up  Mobile phone stipends and internet reimbursement Fitness reimbursement 100% paid maternity leave to our U.S. employees, as well as a generous maternity benefit to our employees in Canada. Tuition and certification reimbursement, as well as other professional development opportunities  We strive to provide a diverse and inclusive environment and are an equal opportunity employer.",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Software, Internet",67,None,False,,328,ACTIVELY_HIRING_COMPANY
54,2197375895,2020-10-30,Citymapper,Realtime Transport Data Engineer (Remote),"São Paulo, São Paulo, Brazil","DescriptionCitymapper makes cities usable, helping people move through urban spaces, getting people from A to B.We have launched in more than 60 cities so far. We've found that having a broad and deep set of data on the transportation options in that city is key to ensuring a great experience for our users.We are launching many new cities to bring Citymapper to users everywhere. We provide essential information for millions of users, letting them know when the next bus is arriving, which trains are disrupted, and what time they should leave to get home. We need engineers to help build and maintain the systems that do that.Good transport data, especially realtime information, is why our users love our app. What you’ll doAdd and maintain sources of realtime departure information in new and existing cities. Lots of feeds and cities require non-trivial and unique strategies in order to reliably show the correct departure times to the user. 'When does my bus arrive?'Find ways to turn disruption messages from agencies into useful notifications and re-routing for our users. Check out what we did in NYC. 'Is the metro blue line running?'Integrate private transport operators into our data streams. Public transport is being complemented by private transport operators in most of the cities we cover - bikes, moped, scooters, cars, etc... 'Where's the nearest electric bike to rent?'Improve the monitoring and operational systems necessary to keep these 100s of realtime data feeds working. 'Why are we not showing trains in Lyon?'Fun projects we recently took onDeployed a real time monitoring system to help commuters in Hong Kong navigate complex route diversionsBuilt a system to approximate TfL train predictions based on sparse dataAdded real time crowdedness information to help users decide which vehicle to use RequirementsUltimately we don’t have hard requirements beyond needing you to be smart, curious, and keen to get stuck in. However we are looking for candidates with at least 1 year of professional software engineering experience within a team. Attention to detail and experience wrangling data (especially transport data) is a plus. This is a remote contracting position for a 3-6 month full time contract positionOur stack for transport dataTech: main language Python 3Tooling: GitHub, AWS, SQL, LinuxBest practices: code reviews, tests, CI BenefitsContractor position in a remote-first teamWorking on something interesting and meaningful - help to make cities usableCompany provided Macbook & needed equipmentWorking with a not-too-big, diverse engineering teamArcane public transport knowledge with which to dazzle your friends",No corresponde,Contrato por obra,None,Internet,30,None,True,,724,JOB_SEEKER_QUALIFIED
55,2181302439,2020-10-13,Focus GTS,Data Scientist,"Miami, Florida, United States","Data Scientist shall provide the following functions and deliverables:  Research and develop statistical learning models for data analysis NLP experience with document classification and extractionImplement new statistical or other mathematical methodologies as needed for specific models or analysisSelect features, build and optimize classifiers using machine learning techniquesData collection and miningProcessing, cleansing, and verifying the integrity of data used for analysisPerform ad-hoc data analysis and present resultsMachine Learning The key difference between our ML Engineers and Data Scientists is that the former has more experience putting models into production and experience/familiarity with things like AWS Lambda, AWS Step Functions, CI/CD pipelines, using Git for version control, while the latter(Data Scientists) have more focus on model tuning, hyperparameter search, Python notebooks,etc.  Again, both types need to know all the above, but the relative focus and experience is the differentiator. This position is remote in the United States.",Director,Jornada completa,"Ingeniería, Tecnología de la información",Dotación y selección de personal,444,None,True,,1036,ACTIVELY_HIRING_COMPANY
56,2254593729,2020-11-03,Acxiom,Data Scientist,United States,"At Acxiom, our vision is to transform data into value for everyone. Our data products and analytical services enable marketers to recognize, better understand, and then deliver highly applicable messages to consumers across any available channel. The Audience Solutions division is responsible for enabling true people-based marketing with identity resolution and rich descriptive and predictive audience segmentation. We are seeking an experienced Data Scientist with a versatile skill set to undertake data science supporting the development of next-generation products for Acxiom’s business. As part of the Audience Solutions Analytic COE, the Data Scientist will work hands-on with Machine Learning and Big Data technologies and build scalable machine learning data products and solutions for our domestic and global businesses. The Data Scientist’s responsibilities include collaborating with internal and external stakeholders to identify insight requirements and applying creativity to test hypotheses, prepare data, build models, analyze and visualize results and integrate the solution into innovative data products. The Data Scientist will be a champion of the latest and greatest Machine Learning and Artificial Intelligence technologies. What You Will Do: Apply state-of-the-art algorithms relying on knowledge of statistical modeling, machine learning, and optimization to develop new data products or improve the performance/quality of existing productsBuild, evaluate and optimize models which incorporate machine learning and artificial intelligenceCollaborate with internal and external stakeholders to understand business and insight goals, define a learning agenda, and identify relevant KPIs and diagnostics to pursueCollaborate with other data scientists and team leads to define project requirements including data sources, algorithms, and implementationBuild expert knowledge of the various data sources brought together for audience segmentation solutions – survey/panel data, 3rd-party data (demographics, psychographics, lifestyle segments), media content activity (TV, Digital, Mobile), and product purchase or transaction dataWork with Product and Engineering teams to transition development projects to production systemsPrepare and present compelling analytical presentations and effectively communicate complex concepts to marketing and business audiencesProvide mentorship and guidance to data scientists where necessary What You Will Need: Bachelor's Degree in a quantitative field (Data Science, Statistics, Math) or related degree programs and 8+ years of relevant work experience OR Master's Degree in a quantitative field and 6+ years of relevant work experienceExperience with applying statistics and data science tools on large datasetsDeep knowledge of supervised vs. unsupervised learning algorithms, including neural networks/deep learning, SVM, decision trees (bagging, random forests, boosting), clustering, regression, and dimensionality reduction techniquesExpert at model training approaches, hyperparameter tuning, tuning learning rates, and model evaluation approachesExtensive experience with data preparation (normalization, scaling, etc.) for modelingExposure to Python or R libraries for machine learningExposure to Spark/ PySpark systems in a distributed computing environmentSQL mastery, including techniques for writing efficient code over large datasetsExperience using Hadoop stack, including Hive and Impala. Knowledge of Apache-based open source technologies such as Storm, Cassandra, Ruby, etc. a plusAbility to leverage critical data-driven thinking and enthusiasm for translating data into actionable insight to generate consistently accurate and useful analysis and modelsBalances desire for quantitative rigor with realities of inconsistent business dataAttention to detail and time management delivering high-quality work for multiple projects across several engagements while meeting deadlines",Algo de responsabilidad,Jornada completa,Tecnología de la información,Servicios y tecnologías de la información,109,None,False,,619,ACTIVELY_HIRING_COMPANY
57,2198827493,2020-10-21,ITR Partners,Data Engineer,United Kingdom,"Do you have a background in Data Engineering with experience developing software using Hadoop, Java or Python operating on Linux? Do you want to utilise these skills in the development of a ground-breaking, bespoke cyber security platform? Does the opportunity to work on complex Big Data sets both structured and unstructured sound exciting? This is an incredible opportunity to work with an innovative tech driven business configuring and implementing large Datasets using Hadoop, Java/Python, Spark all operating on Linux. What will I be doing? Configuring, implementing and utilising the bespoke platform to match client requirements Designing intelligent data solutions for clients and integrating data sources About your experience 4 years min in hands on software and data engineering Currently working with Large Datasets Ability to code and write high level programmes with any OO programming language, such as Java, Python, Scala In depth Hadoop/Spark experience to help the team compute and deal with massive amounts of data Using Linux systems Working in a DevOps environment In an ideal world you will have Elasticsearch/Kafka/MongoKubernetes/DockerData Science experienceLed engineering teams on projectsDevOps tech experience i.e. Ansible Why apply and perks: Great career progression potentialFully remote or in an office£55-65,000Modern tech stackBespoke innovative platformCloud based infrastructureFascinating industry of Cyber Security  If this sounds like the next step in your career or you want more information regarding the company and role, click apply!",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información","Software, Servicios y tecnologías de la información",77,None,True,,257,JOB_SEEKER_QUALIFIED
58,2211182624,2020-10-26,Curvestone,Machine Learning Researcher,Poland,"Who we areWe are an automation and machine learning consultancy operating from London and New York. We work with scale-ups and large corporations to launch solutions by validating problems, speccing ideas and building great products.  Our work is industry agnostic and we’re not limited to any particular digital approach. In fact, we pride ourselves in our ability to stay on top of the latest advancements in technology in order to solve an ever-increasing range of challenges. We are currently based in Paddington, London and we also have offices in Gdańsk, Poland. In 2020 we will open a physical office in New York, however 50% of our work is already based in New York. We are partnered with Google Cloud and recently graduated from Facebook’s Deep Tech Accelerator. Who we are looking forCurvestone is looking for a Machine Learning Researcher to help expand our AI innovation & delivery pipeline. Specifically, we need someone to help with the research and prototyping of machine learning algorithms to address real world client problems. This person will collaborate with consultants and engineers to take solutions from ideation to deployment! This opportunity is for a machine learning researcher who is happy to work remotely as part of a remote-first, highly collaborative, fast moving, tech start up. What it’s like to work with usAt Curvestone, we do things a bit differently. There’s no old-fashioned hierarchy, no hiding behind fancy job titles, no micromanagement and no moaning! Instead we work in autonomous cross-functional “pizza-teams” made up of consultants, designers, engineers, and domain experts. We join together and make ideas come to life, embracing Agile Sprint methodology.  Our team comes from a diverse range of backgrounds, with expertise spanning Machine Learning, Software Engineering, Product Management, Innovation Consulting, Automation, Data Analytics, Solution Architecture and Venture Building. What you’ll doResearch and prototype appropriate machine learning algorithms and tools to address real world client problemsWork with consultants to design machine learning systems that address business requirementsIdentify, source, and prepare appropriate datasetsDevelop machine learning applicationsIterate and optimise machine learning systems by designing & running experimentsWork with ML Ops specialists to design, deploy, and manage the ML lifecycleKeep on top of developments in the fieldIdentify & explore opportunities for applying ML both internally and on client projects Must HaveStrong communication skills in English, both written and verbal1-3 years of experience working with Machine Learning concepts and toolsProven success working on ambitious machine learning projectsDeep knowledge of math, probability, statistics and algorithmsAbility to write robust code in PythonFamiliarity with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn)Outstanding analytical and problem-solving skillsBSc/MSc in Computer Science, Physics, Mathematics or similar field Desirable Skills + ExperienceExperience of working in both start-up and corporate environmentsExperience using a wide range of third party MLaaS API’sExperience using Google Cloud and Microsoft AzurePh.D. in Computer Science, Physics, Mathematics or similar field MindsetHave the drive to continuously learn, and stay in the know with the latest ML news, advancements, and tools.Have a broad understanding of the concept of minimum viable product (MVP).Passionate about technology, product, user experience and building high quality solutions.An understanding that our work reaches beyond tech. You have the ability to work collaboratively with a multidisciplinary team of project managers, consultants, designers and developers.You get excited about solving head-scratching, life-affirming problems and a thrill out of change.You put the user at the heart of everything you do, and that empathy drives every decision you make. Tools UsedSlack: Internal and external communication on projectsNotion: Internal wikiGitHub: Code version managementComet ML: Experiment tracking & managementStreamlit: App UI prototypingMicrosoft Azure ML: Machine lifecycle managementJupyter notebooks: Prototyping and experimentationKeras/Tensorflow, Pytorch, Scikit-learn: ML frameworks PerksWe have mastered the art of working remotely, so we don’t consider this a perk, it’s part of our everyday!Flexible working hours. We have a daily stand up each day to check in with each other, apart from that, you can choose when you get your work done. Perfect for early birds, night owls, parents, gym goers.26 days holiday a year (+ bank holidays) and the flexibility to take unpaid time off for life adventures!",Algo de responsabilidad,Jornada completa,None,Software,112,None,True,,452,ACTIVELY_HIRING_COMPANY
59,2213582159,2020-10-26,DiDi,Data Scientist,China,工作职责:1.构建全面、客观反映区域/城市业务健康度的分析框架，定期对业务经营状况进行深度分析，识别风险点和机会点，提出优化建议。2.支持公司级重点项目推进过程中需要的行业信息收集、市场调查，并结合大数据分析，输出研究报告，产出洞察，为业务团队提供支持。 任职资格:1. 数学、计算机、经济管理本科以上学历，8年以上互联网/咨询相关工作经经验，对出行行业、共享经济有深刻理解。2. 有较强的商业洞察力、用户理解力、数据敏感度、框架型思维，善于结合外部行业资讯、内部数据从中发现、验证、提炼核心观点，发现机会并转化成相关策略。3. 具备大数据处理能力，熟悉掌握数据提取/分析工具，如SQL、Python、R、SPSS等，有丰富的数据挖掘和建模经验，能高效地与数据技术团队进行沟通。4. 有丰富的跨部门跨团队资源整合能力和项目管理/推动能力，落地性强。,Intermedio,Jornada completa,"Análisis, Consultoría, Otro",Internet,70,None,True,,575,COMPANY_RECRUIT
60,2245865971,2020-10-27,ShareChat,Data Scientist,"Bengaluru, Karnataka, India","AI @ ShareChatIndia’s active internet user population has crossed half a billion in 2019. If you look closely at thefirst 100 million Internet users and the rest of the users who came online in the last few years,you will notice stark differences in their needs and wants from the Internet. While the first-generation Internet users in India weren’t too different from Internet users in the rest of theworld, the next wave of users is truly unique in a number of ways. A huge chunk of the audience is a regional language first audience and therefore wants to consume content and services in their native language. Their taste in content also happens to be vastly different – we observe a longtail of content genres emerging that didn’t exist previously. Despite the internet growing soswiftly, many Indian Internet users are not comfortable with searching on the internet or findingwhom to follow in order to satisfy their information needs. A radically simplified paradigm forcontent delivery is needed for this audience – one that automatically learns the user’s taste andpushes the right content at the right time to them based on their interest. ShareChat harnessesAI in its quest towards this mission possible. Feed IntelligenceThe core product value of ShareChat revolves around its algorithmically generated contentfeeds. Our Feed Intelligence team is in charge of ensuring all feeds in the ShareChat appremain highly engaging for our users at all times, optimizing multiple objectives of relevance,freshness, diversity, and so on. The team is working to find answers to a number of interestingresearch questions. Examples include: How do we adapt the mix of content in feeds to optimizefor long term user engagement? How to effectively explore users’ preferences over a long tail ofcontent genres where their tastes are highly dynamic? Content IntelligenceOur Content Intelligence team is focused on developing models that can accurately make senseof posts so that they can be served to a relevant audience. We are investigating differentapproaches to create unified multimodal representations for a post that captures visual (fromimages or video), audio, and text data from the post. Such a representation for a post shouldprecisely predict how our users interpret the post and what they feel about it. Camera IntelligenceOur Camera Intelligence team builds unique capabilities in the ShareChat camera to help ourusers create engaging, original content on our platform. They focus on efficient implementationsof capabilities in Computer Vision (e.g., semantic segmentation, super-resolution) and SpeechProcessing so that they can run on mid to low-end smartphones. Our mission is to enable everycreator, across the long tail of content genres, to unleash the superpowers of AI and be able tocreate professional-grade content. We’re HIRING!! The AI team at ShareChat is growing. We are hiring talented individuals with expertise in theareas of Recommender Systems, Reinforcement Learning, Bayesian Optimisation, DeepLearning on Graphs, Computer Vision, Natural Language Processing, Speech Processing andso on. Our team of world-class scientists and engineers push the boundaries of state of the artin these areas and impact millions of people every single day. We have a strong focus onresearch and actively collaborate with academics on open-ended research problems. Responsibilities ●Apply state of the art in the relevant research domains to make significant contributionsto the feature roadmap of the ShareChat app in the aforementioned areas.●Apply expert coding skills to develop scalable product features in partnership with otherengineers on app and infrastructure teams●Apply best practices in big data processing to build feature stores, data pipelines, andmodel inference services that can deal with massive scale.●Adapt deep learning algorithms to best exploit modern parallel environments (e.g.distributed clusters, GPUs). In the case of on-device applications, tune network architecturesto efficiently run on low to medium end smartphones. Qualifications ●BTech, MS degree or Ph.D degree in Computer Science or a related discipline●Experience in deploying ML models with frameworks like Tensorflow, PyTorch, MXNet,Caffe, Torch, etc on Android and iOS devices●Excellent coding skills in C/C++ and Java●Knowledge of evolving and recent technologies in Android, IOS app development anddifferent mobile compute and memory resources and sensors●Ability to build basic Android/iOS apps using NDK for Audio-Video capture andprocessing pipeline with basic UI features is needed●Experience with multi-threaded implementations utilizing computer units like multicoreCPU, GPU, NPU, DSP, and media encode/decide accelerators is a huge plus",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información, Otro","Internet, Software, E-learning",1436,None,True,,3175,COMPANY_RECRUIT
61,2254334078,2020-10-04,SlashData,Data Storyteller (Remote - EMEA based),"Stirling, GB","SlashData is the leading research company in the developer economy We help the world understand developers and developers understand the world. We survey 40,000+ developers annually - across mobile, IoT, desktop, cloud, AR/VR, web, games, data science, and machine learning - to help clients such as Microsoft, Facebook, Google and Amazon understand who developers are, what tools they love or hate and where they are going next.  We’re now looking for a full-time, Data Storyteller to help drive insights out of a wealth of data points relating to developer activity. You’ll be working based in Europe or MEA, working from home or a co-working space to support our distributed team.  Who We’re Looking For  As a Data Storyteller, you will have 2-5 years working experience in data analysis, data visualisation, and data journalism. You will be fearless in data crunching and keen to unearth meaningful patterns, actionable insights and intriguing stories from the data.  You will have undertaken many data analysis projects where your novel insights and attention to detail would impress. You will have a proven record of communicating your findings to a non-technical audience, eloquently narrating the story behind the numbers. You might not have worked in the software industry before, but you have a passion for software, and wanting to figure out what makes the software economy tick - based on data.  If you’re that person, we’d love to talk.  Requirements  As a Data Storyteller you will be  Based in EMEA region (UK time ±4hrs) Performing data analysis using any scripting language (e.g. Python, R), and Excel. You‘ll be working on several data projects, extracting insights in the context of market trends, behavioural analysis, population forecasting, segmentation and profiling. Writing up your findings in short and long reports including visually appealing graphs and deep insights based on your analysis, answering the “why” behind the “what”. Tracking the latest trends in the software developer ecosystem. Helping shape our research agenda and asking developers and data scientists the right questions. Interacting with clients to provide insightful answers to tough data problems, and to support them in custom data insights projects. Helping clients identify key business questions and translate them into research questions and projects. Delivering briefings and webinars, and presenting our insights in conferences, meetups and events. Supporting the rest of the analyst team in their data and research quests as needed.   What Skills We Are Looking For  A data scientist who is also into data journalism, with a background in statistics, applied mathematics or computer science. An ability to tell signal from noise in the data, and answer the ‘so what?’ question behind the observed numbers and patterns. An ability to author data stories, comprehensively and in an unbiased way, with proven previous experience in authoring insights reports, blog posts or other published writing. Excellent writing skills (English), with the ability to communicate complex insights to non-technical audiences. Advanced Excel skills. At least basic programming skills, preferably in Python including Pandas. At least a basic grasp of clustering and classification methodologies and models. Ability to visualise data effectively, producing eye-catching and easy-to-understand graphs. Very good presentation skills. Comfortable working as part of a distributed team across four continents.  Bonus Points for  Having software development experience as a hobby or past work. Advanced Python skills. Advanced data modelling skills. Past experience of working with complex survey data. Past experience of consulting clients on data projects. A passion for technology, and thorough understanding of how it’s impacting people’s lives.  Key success metrics  You will be successful in the role if in the first 6 months you have  Actively contributed in shaping the research agenda and questionnaire of the upcoming Developer Economics survey. Authored at least two research reports, carrying out all data analysis and background research as needed. Authored at least one blog post based on our survey data, showcasing our research and/or promoting our surveys. Delivered at least one client briefing or webinar to our high standards. Actively supported the rest of the analysts team, by reviewing other authors’ reports. Supported our developer outreach and sales teams, promptly responding to any requests relevant to your work. Become a dependable team mate.   Benefits  What we offer  Opportunity to make a difference as part of the leading research company in the developer economy Part of an entrepreneurial company that's raising the bar, and calling the trends of the developer economy Opportunity to work with some of the biggest tech brands in the world International team, great work atmosphere & flexible working environment Competitive salary + bonus twice yearly based on performance Come to work in a t-shirt, shorts and flip flops, or tie and a suit - we don't mind! You will never work on your birthday - we automatically give you this day off Annual training budget to develop your skills and career Monthly book allowance from Amazon, on any book you like Spotify Premium subscription or Netflix vouchers",Sin experiencia,Jornada completa,Análisis,"Servicios y tecnologías de la información, Investigación de mercado, Software",18,None,False,,193,None
62,2213045057,2020-10-01,Weber Shandwick,Data Scientist (6 month FTC) - Remote,"London, GB","What’s Happening  Weber Shandwick is excited to be looking for a Data Scientist (6 month FTC) to join our analytics team. This is an opportunity to work remotely with the EMEA Insights team based in London.  With the agency shifting towards data-led insights and increased demand from our clients we are growing at pace and are looking to hire a Data Scientist (6 month FTC). There is a huge opportunity to grow professionally whilst learning from some brilliant thinkers in how to apply analytics in a business context. Working with various analytics tools and methodologies, the Data Scientist (6 month FTC) will get first-hand exposure to clients, their business problems and acquire useful transferable skills both in the application of your analytics abilities, and in presentation and people skills. The company also offers a plethora of training opportunities tailored to your career goals and interests.  You will be joining an eclectic bunch of people  In the analytics team, we have diverse backgrounds and expertise, speak many languages and bring this variety together in the work we do as a team. We both have, and get to have, experience with clients both in the UK and globally, championing insight and analysis in decision-making to enable real business performance.  Our work  It really is never boring in our team. The type of analytics work we do covers:  Conversation analysis Audience insights / profiling Campaign reports Influencer identification Multichannel reports Website analytics Modelling and data science  On a day-to-day basis, our main aim is to identify patterns in data which will provide useful insights to our clients. We channel our positive attitude, critical thinking and analytical mind-sets to solve our client’s problems, provide inputs into strategy and see opportunities not visible without data and insights. Depending on scope and requirements we work together or individually to identify insight from large (using NLP and/or machine learning) and small data (using research and panels).  What will you be doing?  As a Data Scientist (6 Month FTC) , You’ll Lay The Groundwork And Contribute To The Day-to-day Analytics Needs Of Our Clients And, Depending On Your Experience, Either Deliver Insights Independently Or In Tandem With The Analytics Manager Across The Following  Data wrangling and cleaning Analysing data sets to extract key findings Building visualisation dashboards tailored to client needs Building analytics products to streamline workload and bring innovation Audience segmentation and influencers identification Social and media listening analysis Campaign and monthly reporting Implementing measurement and evaluation frameworks   Who are you?  Skills Needed  We are looking for a Data Scientist (6 month FTC) with demonstrable experience, keen to work in the media, digital and or social domain.  Demonstrated experience in analytics, business intelligence or a similar role Solid knowledge of Python, SQL and Excel Experience with manipulating and auditing data to create insight Experience with data visualisation platforms like Tableau, Power BI, Looker, etc Familiarity with social media listening tools (e.g Brandwatch, Meltwater, Sprinklr) Strong communication skills, both verbal and written An appetite for challenge, innovation and learning new skills Ability to work both independently and within a team Someone who enjoys a fast-paced environment   Skills That Would Make You Stand Out  Experience with APIs / report automation / building custom dashboards Experience in writing production grade code, unit testing, using version control Working experience with predictive modelling, segmentation, NLP  Knowledge of cloud technologies such as GCP and AWS   Why would you join Weber Shandwick?  We will provide you with a fulfilling, collaborative, and friendly place to work in You will develop innovative solutions and add value driven, data driven decisions You will get to work across different teams, clients and industries offering you a unique insight on how different business work We have a culture of sharing best practice across our methodologies and products You’ll get to work with different tools and different methodologies, some you might know and some which will be new to you We have a bright open floor office with free fruit, coffee and refreshments You’ll get to join in with lots of social events with the teams and the our clients   Note From The Talent Team  We appreciate the time taken to apply for the role and your recent interest in Weber Shandwick. We will review all applications within five working days and be in touch with those who have been shortlisted to the next stage. Unfortunately down to volume we are not able to get back to everyone individually so if you have not heard back from us unfortunately you have not been successful on this occasion and wish you all the best in your search",Sin experiencia,Contrato por obra,"Investigación, Análisis",Relaciones públicas y comunicaciones,54,None,False,,374,COMPANY_RECRUIT
63,1988674149,2020-10-08,SalesLoft,Machine Learning Engineer,United States,"Job Title: Machine Learning EngineerLocation: Field (any major city)  WHY YOU’LL LOVE SALESLOFT:Put Customers First. Team Over Self. Focus on Results. Bias Towards Action. Glass Half Full.These are the values that define who we are, that have empowered our staggering growth, and could be instrumental to your career developmentHeadquartered in Atlanta, Georgia, with offices in San Francisco, New York, London, Indianapolis, and Guadalajara, SalesLoft is growing rapidly and is looking for future Lofters to join our team. As a testament to our Organizational Health, SalesLoft has been named by Forbes as one of America’s Best Startup Employers in 2020, twice by Deloitte as a ‘Fastest-Growing Technology Company in North America,’ featured by The New York Times as a start-up on a path to a $1B valuation, and has been recognized as a ‘#1 Best Place to Work in Atlanta’ three separate years. SalesLoft is ranked #1 in the emerging category of Sales Engagement software and is on a mission to equip companies to maximize revenue by creating a fantastic buying experience. We’re redefining an age-old industry! This is challenging work – but our team of brilliant creatives makes the journey thrilling. We’re fast-paced, innovative, and collaborative. We pursue excellence in everything and have a lot of fun along the way. Come join us! THE OPPORTUNITY:Although we’re proud of our history, we’re just as excited about the future. We want to create a world-class culture and company that attracts, develops, engages, and retains elite talent.  At SalesLoft, our Machine Learning Engineers are pivotal to our company’s success. You will be a key member of our fast-growing and high-performing engineering team working on new technologies in an environment that supports your technical and professional growth.  On a day-to-day basis, you will be responsible for serving as a liaison between the Data Science and Product Delivery teams to architect and deliver end-to-end data pipelines. Specifically, you will:Operationalize machine learning research at SalesLoft.Collaborate with Data Scientists on building and delivering models to production environments.Manage complete data lifecycles, including feature engineering, ETL workflows, iterating on deployed models, and monitor for model drift.Formalize the software development of machine learning in the platform by establishing standard frameworks and workflows.Build solutions at scale.Mentor peer Software Engineers who collaborate on development and seek to learn.In addition to working with amazing colleagues who exemplify our ‘team over self’ core value, you will also have the opportunity to create impactful and revolutionary software that is changing the way sellers sell. You will have an opportunity to make a difference.  WHAT WE’RE LOOKING FOR:We are seeking a bias-towards-action candidate who will help make machine learning a pervasive presence in the SalesLoft culture and platform. We are looking for someone who can establish the foundations for delivering novel research based on practical experience, at scale. Ideal candidates will be familiar with both structured and unstructured (natural language processing) data pipelines. They will advise the data research team on how to best architect, deploy, and maintain models in production environments, while also serving as a mentor to other engineers who are collaborating on software or express a passion for learning more about machine learning. We are looking for someone who can clearly communicate to less-technical audiences and participate in roadmap planning based on customer feedback.If you’re looking for an opportunity to learn more, do more, and become more than previously possible… if you’re passionate about innovation, growth and serving customers and thrive in a fast-paced, developmental environment, then becoming a Machine Learning Engineer is the career path for you! THE TEAM:Our SalesLoft’s Engineering team is comprised of seasoned and up-and-coming Data Scientists and Software Engineers who are all aligned on one vision and mission:Vision: Every seller is loved by the buyers they serve (#saleslove)Mission: Equip companies to maximize revenue by creating a fantastic buying experienceThe Engineering team consists of seasoned and up-and-coming Software Engineers who are all aligned on one mission: to redefine the Sales Engagement space and activate the authentic seller in all of us. They are also the epitome of our core values - Customers First. Team Over Self. Focus on Results. Bias Towards Action. Glass Half Full. THE SKILL SET:2+ years of proven experience in building machine learning applications at scalePython software developmentDeep learning tools: TensorFlow, KerasWord embeddings: Word2vec, GloVeStrong SQL skills across many data storesDiverse extract-transform-load (ETL) experienceStrong communication and collaboration skillsDesire to learn and continuously improveCloud-based environments: AWS, GCPContainerized workflows and deployment: Docker, KubernetesBachelor's degree preferred WITHIN ONE MONTH, YOU’LL:Attend SalesLoft’s New Hire Orientation, where you will learn our SalesLoft story and understand what makes our “Lofters” unique Learn how the SalesLoft platform works and helps customers winBegin 1:1’s with your manager, understand your 30-60-90 plan, meet & shadow current members of the SalesLoft team Set your OKRs (Objectives and Key Results) with your manager and develop an action plan to achieve themMeet key partners in Data Science and Product DeliveryBecome familiar with existing machine learning features and workflows in the productBe an active participant in team meetings and learn about ongoing research and development projectsWITHIN THREE MONTHS, YOU’LL:Be familiar with the platform and data science code in productionActively implementing data pipelinesPlanning incremental improvements towards better positioning the platform for data science applicationsCollaborating with internal and external stakeholders to establish clear objectives, acceptance criteria and timelines.Immerse yourself in the technical and sales contexts of the SalesLoft platform.Interact regularly with data infrastructure, engineering, and technical operations teams and start to establish monitoring metrics and processes.Implement the first of several large scale NLP models into production.Gain experience learning about and joint problem solving high-level business problemsProvide Internal expertise in data science and machine learning skill areas.WITHIN SIX MONTHS, YOU’LL:Implement model monitoring capabilities and processesBe responsible for custom ETL design, implementation, and maintenanceAdvise team members on improving model performance.Owning data science engineering projects and managing the data science software development lifecycle.Sharing knowledge, debating techniques, and conducting research to advance the collective knowledge and skills of our organization.Providing mentorship, guidance, and support to junior team members with a focus on developing scalable talent while amplifying individual expertise and contributions.WITHIN TWELVE MONTHS, YOU’LL:Pioneer initiatives around handling unstructured data, data quality, and performance.Interpreting data science challenges and opportunities into actionable engineering strategiesProactively identify forward-looking data engineering strategies, utilizing appropriate technologies, and implementing at scale.Recognized as a leader on the SalesLoft data team.  IS THIS ROLE NOT AN EXACT FIT? Keep an eye on our Careers Page for other positions!  WHY SHOULD YOU WORK AT SALESLOFT:You will become part of an amazing culture with a supportive CEO and smart teammates who actually careYou will work with an amazing team you can learn from and teachYou will experience joining a high-growth/high-traction organizationYou will hear “Yes, let’s do that!” and then have the opportunity to successfully execute on your ideasWe have a vibrant, open office that utilizes modern technologyYou will grow more here than you would anywhere else, that is a promise SalesLoft is proud to be an Equal Opportunity Employer and provides equal employment opportunities to all employees and applicants without regard to race, color, religion, sex, age, national origin, disability, veteran status, pregnancy, sexual orientation, or any other characteristic protected by law.",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Software,266,None,False,,1263,ACTIVELY_HIRING_COMPANY
64,2181308461,2020-10-13,Genuent,Data Scientist,United States,"**Remote****Not open to providing sponsorship at this time** We are looking for a Data Scientist to build econometric models and apply economic theory to solve business problems to support our enterprise strategic initiatives. Reporting to the Director of Data Science, this person will be the SME in developing complete analytical solutions, mining extensive data sets for insights, building scalable models, and enabling the overall Data Science capability. This person will also drive the optimization of how we predict market demand pricing, and marketing mix to support both the business lines of service. This person will help build a brand new data science organization. Responsibilities:Build long-term causal estimation models using a combination of econometrics, machine learning and predictive statistics to drive thought leadership around Real Estate, Merchandizing, Pricing, and Marketing, among others.Partner with our Data Engineering team to guide and build the data infrastructure needed to begin applying supervised and unsupervised modeling techniques to generate predictions and uncover patterns.Develop hypothesis statements and apply statistical testing to determine causality and generalize observationsModel Assessment & Validation: Identify the model evaluation metrics and apply best practice techniques for model testing and tuning to assess accuracy, fit, validity, and robustness for multi-stage models and model ensembles.Model Deployment & Scaling: Support efforts to ensure that analytical models and techniques used can be deployed into production. Support evaluation of the analytical model and the scalability and sustainability of analytical models.Code Development & Testing: Write code to develop the required solution and application features by using the recommended programming language and leveraging business, technical, and data requirements. Test the code using the recommended testing approach.Data Visualization: Generate appropriate graphical representations of data and model outcomes. Understand customer requirements to design appropriate data representation for multiple data sets.Support the leadership team in developing long-term goals and roadmaps. Technical Skills & Qualifications:Strong background in econometrics (e.g., program evaluation, forecasting, time series, panel data, and/or high dimensional problems), economic theory, and quantitative methods.Demonstrated understanding of financial levers related to merchandising, planning and allocation, marketing, pricing & promotions.6+ years of applied advanced analytics, statistics and/or data science experience, using R and/or Python, to solve business problems.Experience with price optimization and demand forecasting.Marketing industry knowledge and previous experience in working on marketing mix modelingCan effectively and succinctly decompose highly complex findings to non-technical audiences.Excellent data visualization skills, able to determine the appropriate visualization for a variety of data types and create compelling stories with data.A proven track record of leading successful projects and driving measurable, viable results using Data Science techniques. ﻿Education:Masters Degree or PhD. in a Data Science, Applied Mathematics, Computer Science or otherwise research-based field: 5-7 years of related experience and/or training: or equivalent combination of education and experience",Intermedio,Jornada completa,Tecnología de la información,Internet,413,None,True,,1486,ACTIVELY_HIRING_COMPANY
65,2174601500,2020-11-05,Virail,Data Engineer,Germany,"Are you a passionate engineer, fascinated by big data and love building from the ground up data pipelines? Do you enjoy collaborating and working across different teams to solve complex and challenging problems? Then this opening we are having in Virail for a Data Engineer might be the right role for you. Why do we need you at Virail?Being a metasearch, we compute billions of data every day which are waiting to be explored and analyzed. In this role you will:Design, implement, test, and optimize data pipelines in order to produce clean and unified data from multiple internal & external data sources.Make sure that any implemented solution follows good design patterns, architecture principles, is scalable, and accompanied by clear documentation.Identify technological solutions and build software that will support the work of our Marketing & Product team. What you will definitely need to bring in:At least 2 years' experience working as a Data Engineer.Outstanding data manipulation skills required including cleaning, optimizing and managing data (SQL, PostgreSQL, MongoDB)Rock-solid foundation in programming languages and system architecture (Python, Java, Elasticsearch).Strong quantitative and analytical skills.Ability to model complex data structures.Good understanding of APIs and ETL best practices.Familiarity with version control systems (Git). What can move the needle from the rest...Experience with Data Architecture.Expertise in testing methodologies is an advantage.Strong attention to detail, excellent organization skills, and ability to manage complex projects.Familiarity with some Elastic Stack components (Elasticsearch, Kibana, Logstash, Beats) Discover VirailWant to know more about us?We promote an entrepreneurial spirit, always thinking proactively and anticipating problems. We love to challenge the status quo and drive change when needed.We evolve in a friendly, respectful and collaborative work environment, where everyone's opinion is valued and where knowledge is sharedWe enjoy a playful and chill atmosphere, although when it comes to data, we are pretty serious.We love to learn as much as possible, not only in our field but especially from our peers. What we offer:Become a part of a unique startup environment, where tech, product, and marketing closely work together and learn from each other.Contribute from day one to the success and growth of the companyMentorship from experienced industry and marketing veterans.Fully remote working (within Germany), with the possibility to catch up with your colleagues in our co-working spaces throughout Berlin.Unrestricted freedom to apply your ideas to a fast-growing business. If this sounds like you, send us a line with your CV at jobs@virail.com",Sin experiencia,Jornada completa,Tecnología de la información,"Ocio, viajes y turismo, Internet",546,None,True,jobs@virail.com,2197,ACTIVELY_HIRING_COMPANY
66,2237190833,2020-11-03,European Recruitment,Data Scientist - FinTech,"London, England Metropolitan Area","Are you an experienced Data Scientist looking for a new role in the FinTech sector? The ideal candidate: • Has worked as a Data Scientist in a FinTech/Startup environment  • Has experience of implementing Machine learning frameworks  • Experience with at least one programming language ( Python or node is desirable)  • Has experience of working with SQL and NoSQL databases • Comfortable with researching and analysing data sources for accessibility and quality • Must be able to analyse data using models and algorithms  • Experience with data warehouses such as Redshift, BigQuery, or Snowflake • Hands on experience with Looker, Tableau, or Power BI • Has a passion for statistics and machine learning • Bachelor degree in STEM field, especially software engineering, computer science, machine learning, or statistics related  We have an expanding range of FinTech and Data Scientist openings, please do take a look at our Jobs page for more information.  Data Scientist- FinTech - Interviewing Soon",Intermedio,Jornada completa,"Tecnología de la información, Ingeniería","Mercados de capital, Servicios financieros",239,None,True,,576,JOB_SEEKER_QUALIFIED
67,2243519781,2020-11-04,Citizens Advice,Policy Researcher,United Kingdom,"Location: Flexible within England & WalesSalary: £28,967 plus £3,520 London Allowance (if applicable)Department: Policy Team Citizens Advice offers confidential advice online, over the phone, and in-person, for free. Through our national network of charities, we give people the knowledge and the confidence they need to find their way forward – whoever they are, and whatever their problem. We’re an organisation with a relentless focus on making society fairer. Each year we help millions of people to solve their problems across Great Britain. We have a unique insight into emerging trends and issues affecting those we help, and we use it to influence government, regulators, and industry to improve people's lives. Citizens Advice offers confidential advice online, over the phone, and in-person, for free. Through our national network of charities, we give people the knowledge and the confidence they need to find their way forward – whoever they are, and whatever their problem.  We particularly welcome applications from disabled and Black, Asian and Minority Ethnic (BAME) candidates as BAME and disabled people are currently under-represented throughout Citizens Advice. We are a member of the race equality campaign at Business in the Community, the Prince’s responsible business network and are committed to improving employment opportunities for ethnic minorities across the UK. We also welcome applications from, LGB and Trans and non-binary candidates. We have made a positive commitment to employing disabled people and guarantee to interview all disabled candidates who meet the minimum essential criteria for the role as set out in role profiles. Where the role will be placed The roles you’re applying for are in the Advocacy and Advice directorate and in the Post and Telecoms, Energy and Families, Welfare and Work policy teams.  The Post and Telecoms team is the statutory advocate for postal consumers. Our mission is to ensure that all consumers have access to secure, accessible and reliable postal services. We work to persuade the government, regulators and industry to take action where the market is failing to live up to these standards. A few topics we’ve worked on include providing safe and secure access to post for 7 million people, including homeless people and survivors of domestic abuse, improving treatment of disabled people getting deliveries and making the case for a telecoms advocate to give consumers a voice equal to industry. The Energy team is the statutory advocate for consumers and microbusiness customers in the energy market. We carry out research and follow market trends and policy developments to identify issues that are affecting consumers. Based on this evidence, we advocate for the best possible consumer outcomes to the government, the energy regulator and energy companies. A few topics we’ve worked on include improving customer service and consumer support in essential services such as energy, lessons for net zero from energy efficiency schemes, improving engagement for microbusiness consumers, and producing tools to help consumers engage with the energy market. The Families, Welfare and Work team works across a range of issues, including things such as the design and administration of Universal Credit, assessments for disability benefits, and rights and protections for people in work. We have seen a number of changes to improve people’s lives through our policy research, such as a reduction in the waiting time for somebody’s first Universal Credit payment, and a commitment from all major parties to form a single enforcement body for workers’ rights. The Policy Research role within this team will also work on research projects to improve the delivery of our Help to Claim service.    You’ll use a wide range of research methods and create outputs including blogs, reports, presentations, and events. The data and insight we gather helping millions of people across the UK and our strong brand will give you unique opportunities to engage with those who have the power to make a change. You will feed into our work influencing parliamentarians, the civil service, regulators and industry and you will work closely with our world-class news, campaigns, public affairs, and data teams.  We are looking for exceptional individuals with strong research, analytical and communication skills who have the curiosity and ambition to achieve real change on behalf of our clients and consumers. Our Policy Researchers will already be able to demonstrate experience of achieving an impact in a policy and/or research environment.",Algo de responsabilidad,Jornada completa,Otro,Gestión de organizaciones sin ánimo de lucro,134,None,True,,906,ACTIVELY_HIRING_COMPANY
68,2192934333,2020-11-06,Madison Logic,Data Engineer,United States,"As a Data Engineer, you will work closely with our data team to architect data generation infrastructures that improve data reliability and quality. Your work will enable our data scientists to do their jobs. You will ensure data delivery architecture is consistent throughout ongoing projects and combine raw information from different sources to create consistent and machine-readable formats.  What You'll Do:Organize and analyze large datasets using Structured Query language (SQL) and various python libraries like Tensorflow, Scikit, Pytorch and KerasDevelop and promote analytical reporting and business intelligence solutions using engineering and statistical methodsBack-test solutions and provide impact analysis by providing verifiable results in the form of dashboards and reportsBuild new datasets by combining/enriching/aggregating data from disparate sources based on Data warehousing principlesDevelop ETL (Extract, Transform and Load) Data pipelines in SQL or in any functional programming languageCreate scorecards and KPI indicators in the form of Business Intelligence dashboardsDevelop and test architectures that enable data extraction and transformation for predictive or prescriptive modeling What You Have:BS in computer science, engineering or other related field4+ years of Object Oriented/Functional Programming experience in languages such as Java, Scala, Node, Python.4+ years of experience working with cloud-based solutions providers like AWS and Azure3+ years of experience in SQL/WarehousingStrong analytical skills Excellent organizational and time management skills possessing the ability to prioritize work under pressure of time constraintsExcellent written and verbal communication skillsComfortable presenting to executives to achieve leadership buy-inHighly productive and resourceful with a “Can do” attitude  Perks & Benefits:Opportunities for Advancement – As We Grow, You Grow! Competitive Benefits including Medical, Dental, Vision, FSA plans, 401k with Company Match and employer-paid life insurance Commuter Benefits (Transit & Parking) Generous Paid Time Off including: 9 paid Holidays, 3 weeks' Vacation (to start!), 2 Volunteer Days, Sick Time, Summer Friday Program, and Parental Leave Development Opportunities including Global Mobility Program Company Outings, Social & Charity Events, Sponsored Healthy Hours & Happy Hours Discounted Gym Memberships and other wellness initiatives An innovative, energetic culture and a fantastic team Who We Are:Our Vision: We empower B2B organizations globally to convert their best accounts faster Our Values: #TEAM     #OWNIT    #RESPECT     #EXCEL     #EMPOWER Our Commitment to Diversity & Inclusion:Madison Logic is proud to be an equal opportunity employer. We are committed to equal employment opportunity regardless of sex, race, color, religion, national origin, sexual orientation, age, marital status, disability, gender identity or Veteran status. Privacy Disclosure:All of the information collected in this form and/or by your application by submission of your online profile is necessary and relevant to the performance of the job applied for. We will process the information provided by you in this form, your CV (including physical and online resume profiles), by the referees you have noted, and by the educational institutions with whom we may undertake to verify your qualifications with, in accordance with our privacy policy and for recruitment purposes only.  For more information on how we process the information you have provided including relevant lawful bases (where relevant) please see our privacy policy which is available on our website (https://www.madisonlogic.com/privacy/).",Intermedio,Jornada completa,Tecnología de la información,Marketing y publicidad,327,None,True,,814,ACTIVELY_HIRING_COMPANY
69,2176231126,2020-10-12,Rational,Data Engineer,United States,"Rational is growing, and we need amazing talent to join our team. If you have an entrepreneurial attitude with a deep spirit of service and killer subject expertise, we want to talk to you. We are always looking for the next great consultant to raise the bar and push Rational to be better than we were yesterday. Staying hungry, curious, and looking forward to what’s next is part of our DNA. This individual will be supporting several analytical project teams deliver solutions to their clients. We are looking for a candidate with a strong understanding of analytics solutions and infrastructure. This candidate will have experience building databases, data pipelines, and data models from a set of defined requirements. They will also have experience with scripting and programming languages, specifically for streamlining and automating ETL operations. This individual will need to have a grasp of the end-to-end analytical pipeline in order to enable teams to deliver timely and accurate insights to their clients. What you will do: Optimize and maintain data pipelines and architecture for the data analytics teamStandardize tools and automation for ETL across common data sources (Sprinklr, Adobe Analytics, Google Analytics, etc.)Work with project teams to assist with technical issues and support data infrastructureAssure compliance with data security and privacy guidelines across project teams What you will bring:Advanced professional experience with SQLExperience working with relational databases, query authoring (SQL), and working familiarity with a variety of databases.Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.Strong analytic skills related to working with unstructured datasets.Build processes supporting data transformation, data structures, metadata, dependency and workload management.A successful history of manipulating, processing and extracting value from large disconnected datasets.Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.Strong project management and organizational skills.Experience supporting and working with cross-functional teams in a dynamic environment. Who you are:Data Lover. You know your numbers and value the metrics behind the buyer story.Self Sufficient. Comfortable with ambiguity, you take initiative but know when to seek guidance. Proactive. You are always thinking ahead about what is best for the Client. Adaptable. Change happens at lightning speed: you are flexible, enjoy challenge, and get behind new ideas Visionary. Ability to see 'the whole picture' and simultaneously remain slightly obsessed with the details  Rational is a customer experience (CX) solutions firm that pairs the capabilities of a strategic consultancy with the creativity of a full-service digital agency. We design and activate compelling experiences that create strong connections between people and brands. We put humans at the center of business and partner with our clients to deliver meaningful experiences that help their customers while driving business success. Customer satisfaction at every level is our ultimate metric, and it's what drives our mindset, skillset, and company culture.  Incredible people are our non-negotiable. Our experienced team of consultants spans the globe. We love what we do, and who we do it with – let’s begin our next chapter together.  ﻿Rational is committed to ensuring all candidates have an equal opportunity to be considered for employment. Please let us know if you need any reasonable accommodation to participate in the job application or interview process.",Intermedio,Jornada completa,Ingeniería,Servicios y tecnologías de la información,82,None,False,,320,ACTIVELY_HIRING_COMPANY
70,2208474569,2020-10-23,LAC Group,Virtual Researcher,United States,"LAC Group is seeking a full-time, experienced Research Analyst to work virtually for our Library as a Service (LaaS) platform. The Research Analyst will join a team of researchers in staffing a busy and diverse virtual research desk, performing and managing requests for legal, corporate, business development, and other research from LaaS clients. All research and communication will be performed online and by phone, using both paid databases and open sources. The Research Analyst will report directly to the Director of Research Services and will work with other Analysts to complete research requests in a timely, professional, and cost-effective manner. Research will be delivered directly to clients using a virtual reference desk platform. This is a full-time virtual position. Successful candidates must be able to cover the shift : 9 AM – 6 PM PT/12 PM – 9 PM ET. RESPONSIBILITIESPerform legal, corporate, business development, and other research for LaaS clients using both paid databases (Westlaw, Lexis, etc.) and open sources (web searches, government databases, phone research, etc.)Communicate progress and research findings directly to client in a clear and concise mannerWork with clients to clarify research objectives when necessary and provide timely follow-up on pending requestsMaintain current understanding of research methods and tools, including database enhancements and updatesKeep Director apprised of research activities, client concerns, and issues that arise in the course of researchWork as a team with other Research Analysts to provide seamless service to clients, including but not limited to complex and long-term projectsProvide training and updates to research team regarding ongoing client projectsOn occasion, manage small research teams to accomplish more complex research objectivesManage database access and other resources used for researchOther duties as they arise according to client requests QUALIFICATIONS3-5 years experience as a researcher in a law firm library, preferably with some business development research experienceMLS or JD preferred, though work experience or a similar or related degree may take the place of MLS/JDSpecialization in California Law is required.Advanced legal research skills performed in a multi-practice environment, including but not limited to docket and case law research, secondary sources, and general practice guidanceExperience with corporate and business development research including gathering information from diverse sources (annual reports, SEC filings, Secretary of State records, case law, patent and trademark applications and records, lobbying activity, etc.)Extensive experience with Lexis and Westlaw and ability to quickly learn and navigate other databases, including but not limited to Monitor Suite, Bloomberg, Capital IQ, and IntelligizeExperience with open source research beyond search engine use, including government and non-profit databases, think tanks and academic sourcesExceptional client service skills, particularly via written communicationStrong interpersonal and communication skills, with the ability to effectively and efficiently interact with colleagues and clients alikeCurrent experience using Microsoft Office (Word, Excel, PowerPoint) as well as G-Suite applications (Drive, Sheets, Docs)",Algo de responsabilidad,Media jornada,"Otro, Investigación","Servicio de información, Bibliotecas",33,None,False,,1016,None
71,2261152715,2020-10-06,will bank,Remote Data Engineer Sênior,"São Paulo, BR","Sobre a área de Dados do will bank  A área de Dados do Pag é estratégica para o negócio, ligada diretamente ao CEO e atua como uma bastiã da nossa cultura data driven. A área é composta por Data Engineering, Data Science e Data Analytics. Hoje são mais de 20 excelentes pessoas e a equipe não para de crescer. A sinergia do time nos dá a possibilidade de ganharmos uma velocidade ímpar na construção e entrega de soluções baseadas em dados.  Os pilares da área são a excelência do time, liberdade pra inovar e construir a melhor solução para um problema e o excelente ambiente de trabalho que construímos.  Nosso Data Lake está 100% na nuvem da AWS e trabalhamos com uma stack de tecnologias de ponta pra fornecermos dados para todas as áreas da empresa. Centralizamos todas as nossas rotinas em Python e SQL de forma que sabendo as duas linguagens você consiga desde orquestrar uma DAG até construir e entregar um modelo em produção.  Responsabilidades e atribuições  Sobre Suas Atividades  O seu dia a dia vai ser dentro de um time multidisciplinar com um problema desafiador a ser resolvido. E esperado que já nos primeiros meses você tenha tido impacto na forma como conduzimos nossos negócios, de uma forma totalmente remota. Te daremos a liberdade, os desafios e o suporte para entregar o seu melhor! Seja melhorando nosso processo de onboarding, integrando uma nova fonte de dados que vai ser usada pra melhorar a vida dos nossos clientes, conseguindo conceder mais crédito com menos risco, etc Aqui vivenciamos o impacto que a autonomia e empoderamento de pessoas excelentes traz ao negocio No seu dia a dia, esperamos que seu tempo seja dividido entre as tarefas abaixo Administrar a infra de dados consumida pelos times de Analytics e Data Scientists. You build it you run it. Acreditamos nisso:Monitorar a saúde das aplicações que fazem Stream e Batch dos dados que são armazenados no Data Lake:Desenvolver e manter os fluxos de cargas:Documentar os dados armazenados processos:Desenvolver testes unitários e de integração. Qualidade de código e validação de dados importam!:Interagir com os times internos de negocio para polimento e solução de de problemas que possam envolver integração de novas fontes de dados ou alteração de fluxos existente.  Requisitos e qualificações  Para Isso, Você Vai Precisar De Graduação completa em Ciência da Computação, Engenharias ou áreas correlatas:Inglês (leitura fluente, no mínimo):Python:Spark:SQL:NOSQL:Streaming e Ingestão de Dados em bases não relacionaisGit para versionamento de código:Bash básico: Docker:Experiencia em ambientes Cloud (AWS é um diferencial):Facilidade em se relacionar com diferentes pessoas/times e boa comunicação. Ei, sabemos que você não é um robô e tem vida. Se não for expert em alguma das áreas, aplica e te ensinamos aquil Não dá pra ser expert em tudo, né?! :)  Informações adicionais  Gostou? Isso porque você ainda não viu os benefícios de ser um willer: will!up - o nosso cartão de benefícios flexível, no qual parte do saldo você usa para alimentação, e o restante fica livre para usar com educação, entretenimento e o que mais você preferir:Liberdade para escolher trabalhar 100% remoto ou nos nossos escritórios em São Paulo ou Vitória:Plano de saúde e odontológico:Exclusividades da Mastercard oferecidas aos cartões black:Invista - Aplicativo de investimento com taxa de rendimento especial para quem é willer: Seguro de vida:Parcerias (Netshoes, Zattini, Clube de Marcas):Programação especial para o período de quarentena: happy hours online, campeonato de e-games e muito mais!",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Internet",10,None,False,,79,None
72,2249320929,2020-11-05,ThinkOpen,Data Scientist - Full Remote,"Milano, Lombardia, Italia","ThinkOpen mette al centro le persone, dando valore a competenze e talento. Crescita professionale, mindset agile, predisposizione al lavoro di squadra, apprendimento e attività di training on the job: ecco gli ingredienti che ti offriamo per raggiungere il successo! Sei la persona che stiamo cercando?Unisciti al nostro team e dai una svolta alla tua carriera!Siamo alla ricerca di un Data Scientist per un importante cliente in ambito banking, una persona competente e preparata, desiderosa di mettersi alla prova e di far parte di una realtà d’eccellenza e in continua crescita! Cosa ti offriamo:Apprendimento: formazione hands-on guidata da professionisti IT certificati:Percorsi di carriera: crescita del know-how personale e percorsi lavorativi di successo:Team building: momenti di aggregazione, workshop e seminari per la condivisione delle conoscenze:Alloggi a costo agevolato: soluzioni abitative opzionabili su richiesta, dedicate a coloro che provengono da altre zone d’Italia e dall’estero.  Cosa cerchiamo: Un professionista che possieda le seguenti competenze:Esperienza in ambito Big Data - Data Lake:Ottima conoscenza di: Hadoop, Cloudera, R, Python:Nice to have: esperienza in ambito banking. Commitment e contratto:CCNL metalmeccanico con annesso piano welfare e assistenza sanitaria:Retribuzione da definire sulla base dell’esperienza e della seniority:Bonus legati al raggiungimento di obiettivi individuali e di team:  Benefit:Con noi può crescere rapidamente se fai un ottimo lavoro! Non è tutto: potrai usufruire di numerose agevolazioni e vantaggi, dal notebook aziendale al rimborso mezzi fino ai ticket restaurant.Candidati subito!  Sede di lavoro di riferimento: full remote",Intermedio,Jornada completa,"Tecnología de la información, Consultoría",Servicios y tecnologías de la información,114,None,True,,974,ACTIVELY_HIRING_COMPANY
73,2269889636,2020-10-26,Corvus Insurance,Data Scientist,"Boston, MA, US","Corvus is reimagining commercial insurance with data science and machine learning playing a critical role. Data Scientists at Corvus are a key component of our mission to find and use alternative sources of data that can help our clients mitigate risk and make the world a safer place.  We're looking for a full-stack data scientist who isn't intimidated by the prospect of working with large, messy data sets. You'll play a critical role in defining how data science can solve business problems, and will be responsible for the full data science life cycle, including defining the problem, prototyping data pipelines and building and implementing data science and machine learning products into client facing systems. Reporting to the Director of Data Science, this is a new and highly visible role in which you'll work closely with Product Managers, Software Engineers, and Underwriters to expand the reach and impact of our data products.  Responsibilities  Apply quantitative methods to solve complex data problems involving cyber risk modeling, natural language processing for industry classification, litigation risk measurement, etc… Translate product ideas into data science problems, and solve them Prototype tools and data pipelines to extract meaningful insight from innovative sources of data Clearly communicate analysis and train stakeholders to use our data products Work close with engineers to deploy and monitor Data Science Products Teach and mentor other Corvids to further our data driven culture   Qualifications  6+ years of experience as a Data Scientist A background working in cyber security or insurance is required Deep expertise in machine learning and statistical modeling Proven track record of rapid prototyping and development leveraging open source frameworks Experience with Python, R or other similar scripting languages",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Software, Seguros, Servicios financieros",5,None,False,,94,ACTIVELY_HIRING_COMPANY
74,2265045321,2020-10-17,Crowdskout,Behavioral Scientist,"Washington, D.C., DC, US","Crowdskout is a platform for advocates to create, power, and cultivate communities at local and national levels. We provide mobilization and data tools to non-profits, issue advocacy groups, electoral groups, and corporate social impact teams. We are building capabilities that live beyond a 4-year election cycle, and outside of a traditional 'Red/Blue' partisan paradigm.  We are looking for a Behavioral Scientist to join our growing Research Team. You will help Crowdskout to design, implement and analyze experiments and evidence-based interventions. As part of a cross-functional team, you will be involved in research collaborations within product, across client organizations and more broadly in society.  If you are highly motivated, super passionate about democracy, and want to join a close-knit team that is looking to build great things for regular people, Crowdskout may be for you. This is a full-time position in Durham, NC: Salt Lake City, UT: Austin TX: Washington, DC: New York City, NY, or fully remote.  Responsibilities:   Be an in-house expert in the principles and mechanisms of behavior change  Design, implement and analyze quantitative behavioral experiments (A/B tests, RCT, etc.) across Crowdskout. products and for client engagements. Work closely with User Researchers to understand user needs, goals, and experiences to create product features and content and Product Analysts to design and implement quantitative validation studies for new products and features.  Elucidate data-driven insights for product and content development for Crowdskout and clients and quickly learn from experiments to put forward new hypotheses, including identifying opportunities to improve the behavior change potential of products across the platform and organization. Conduct literature reviews and maintain up-to-date knowledge of academic research and market trends related to advocacy, civic engagement, voting, policy, campaigning, etc. Contribute to the development of quantitative survey instruments and user discussion guides  Develop behavioral and societal-level metrics and conduct appropriate statistical analysis of impact   Collaborate to develop and implement hands-on workshops, seminars, and other educational activities for Crowdskout focused on applied behavior analysis and design Improve data literacy across the organization and drive a culture of data-driven decision making   Must-haves   Deep experience in applied behavioral science: ideal candidate has a Master's Degree (or higher) in behavioral economics, experimental psychology, political science, applied behavior analysis, or closely related field 4+ years experience using evidence based behavior change interventions  Extensive training in statistical analysis and data management with demonstrated ability to use syntax-based statistical packages (e.g. R, SAS, Stata, MATLAB, etc.)  A love of experimentation and expertise with experimentation tools Excellent communication, collaboration, and interpersonal skills Strong project management skills  Nice-to-haves:    Understanding of political processes and campaign culture 2+ years proven experience working on product teams Exposure to the technical aspects of analytics, data science and data visualization software tools (Google Analytics, Mixpanel, SQL, Tableau etc.) Knowledge of technology and how to use technology and online tools in innovative ways    Crowdskout is an equal opportunity employer that encourages diversity across all spectrums in its hiring, without regard to race, gender, age, color, religion, national origin, marital status, disability, sexual orientation, or any other protected factor. With that being said, we wouldn't be able to accommodate candidates in need of work sponsorship at this time since we are a small company. If you find this role interesting and you hit on the elements above, please apply!",Algo de responsabilidad,Jornada completa,"Investigación, Análisis, Tecnología de la información","Servicios y tecnologías de la información, Software, Internet",4,None,False,,51,ACTIVELY_HIRING_COMPANY
75,2246235947,2020-10-27,Stone,Data Scientists (Conta Stone),Brazil,"# Sobre a vaga Estamos buscando Data Scientists (pleno e sênior) que tenham interesse em trabalhar com detecção de fraudes e queiram encarar conosco o desafio de construir a Conta Stone. Trabalhamos com Data Science e Machine Learning, atuando na criação de pipelines de processamento de dados, desenvolvimento de sistemas voltados para exploração e análise de dados em tempo real e somos a base de analytics da Conta Stone. Nossa stack é baseada em Python, Elixir e Scala no backend, tendo como fontes de informação dados estruturados e não-estruturados em Postgres, Kafka e buckets.  # Sobre a contratação A contração será em regime CLT, com possibilidade de trabalho presencial no Rio de Janeiro ou 100% remoto. # O que não pode faltar Experiência com Python e SQL:Experiência com a stack de Data Science para Python (pandas, scikit-learn, matplotlib, seaborn, plotly, jupyter)Experiência em exploração, extração e limpeza de dados de bancos relacionais:Experiência na criação de modelos preditivos com Machine Learning:Capacidade de produzir código limpo e de fácil manutenção:Experiência com ferramentas de versionamento de código:Nível avançado de leitura e escrita em inglês: Motivação por aprendizado e desenvolvimento contínuos:Capacidade de se comunicar de forma concisa, franca e clara (também por escrito). # O que aumentam suas chances Experiência em modelagem para sistemas de detecção de anomalias:Conhecimento sobre risco operacional em fintechs:Conhecimento sobre ferramentas de controle de workflow, como Airflow ou Luigi:Experiência com aplicação de Machine Learning em data streams via Kafka:",Intermedio,Jornada completa,"Tecnología de la información, Ingeniería",Servicios y tecnologías de la información,244,None,True,,1189,ACTIVELY_HIRING_COMPANY
76,2257168142,2020-10-30,Morson International,Computer Vision Researcher,"Greater Manchester, England, United Kingdom","Computer Vision Researcher  The UK’s most exciting Deep Learning and AI technology company are looking to bring on an established Computer Vision Researcher to join their collaborative and cutting-edge team with massive growth and investment plans for the future. The organisation is genuinely breaking new ground in the field of Deep Learning and Artificial Intelligence which is based on real-time machine decision making. We want to hear from you if:You enjoy working at the bleeding-edge of Machine Intelligence that can understand the world around and make rapid decisionsThrive on working in a fast-paced environment where you will have the chance to apply the product across various industries working with big house names and tech start-ups alikeYou want to make a difference Enjoy research and development, which a strong emphasis on your Python machine learning libraries Key requirementsKnowledge of Python machine learning libraries and strong coding abilityA commercial grounding in applying ML models and statistics anA solid understanding of the software development life cycle and take the product end-to-end, including deploymentA deep understanding of deep learning neural networks BenefitsRemote working available, with travel to the office once / twice every two weeksWork on truly ground-breaking Machine Intelligence research and development that will change the way we look at Artificial IntelligenceSalary up to £60,000 (based on skill) The Computer Vision Researcher will have come from a strong research or commercial background and understand how deployment in a commercial environment or a strong software developer with some knowledge of machine learning. Please apply directly or contact Chris Coyne on LinkedIn to learn more.",Intermedio,Jornada completa,"Educación, Finanzas, Investigación","Software, Banca, Servicios financieros",133,None,True,,401,ACTIVELY_HIRING_COMPANY
77,2225415171,2020-10-21,PrimeNeuro,Data Scientist,Raleigh-Durham-Chapel Hill Area,"PrimeNeuro is looking for a dynamic, self-motivated data scientist who is excited to apply their skill set to healthcare data to improve outcomes for families living with autism. This role will work on the research and development team to develop algorithms for classification and clustering in clinical data, including: outlier detection in image and feature data, classifier development and feature extraction from image data, regression analysis, and clustering based on features and supporting clinical data.  ResponsibilitiesDesign, develop, and test algorithms for data cleaning, clustering, and classification.Clean, manage, and provide analytics on clinical data.Research and development of new methods for analyzing clinical data. QualificationsPh.D. or Master’s in electrical or computer engineering, data science or a closely related field (e.g. physics), preferably with a focus on signal processing3-5 years of experience in applied machine learning working with healthcare dataSelf-starter with a passion for applied machine learning and a tolerance for ambiguity",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información",Software,441,None,True,,1687,JOB_SEEKER_QUALIFIED
78,2191222242,2020-10-27,Envision,Data Engineer,Greater St. Louis,"Data Engineer, St. Louis, MO (remote possible*)No C2C or sponsorship, must be our W2 employee*Remote: For exceptional candidates who can show previous remote work on their resume, we will allow remote. You must be able to show where you worked remotely and outline the tools you used to work remotely.* Required experience:• At least 2 years experience with Go• Proven experience (2 years) building and maintaining data-intensive APIs using a RESTful approach• Experience with stream processing using Apache Kafka• A level of comfort with Unit Testing and Test Driven Development methodologies• Familiarity with creating and maintaining containerized application deployments with a platform like Docker• A proven ability to build and maintain cloud based infrastructure on a major cloud provider like AWS, Azure or Google Cloud Platform• Experience data modeling for large scale databases, either relational or NoSQLBonus points for:• Experience with protocol buffers and gRPC• Experience with: Google Cloud Platform, Apache Beam and or Google Cloud Dataflow, Google Kubernetes Engine or Kubernetes• Experience working with scientific datasets, or a background in the application of quantitative science to business problems• Bioinformatics experience, especially large scale storage and data mining of variant data, variant annotation, and genotype to phenotype correlationYou may apply on LinkedInor on our web site: http://www.envision.com/jobs/index.html#/jobs/71039",Intermedio,Contrato por obra,Tecnología de la información,Dotación y selección de personal,134,None,True,,722,ACTIVELY_HIRING_COMPANY
79,2215517059,2020-10-28,ENGINE | Transformation,User Researcher,"London, England, United Kingdom","Who we are? Engine Transformation is part of Engine UK, a full-service agency group with expertise across creative and content, consumer and corporate PR, market research, data, analytics, CRM and consultancy services. At Engine Transformation we create, accelerate, design and build the future for our clients. We combine the creativity of an agency with the robustness of a consultancy and the technical agility of a start-up. Built on Research. Driven by Design. Fuelled by Data. Powered by Technology. We combine depth and breadth of experience, working across both public and private sector organisations to deliver tangible outcomes, built on a philosophy of transparency, collaboration and agility. We are proud to work for clients as diverse as Sky, Domino’s, Santander, Holland & Barrett, BMW, Ministry of Justice, Department of International Trade, DEFRA and Home Office. Engine are a global business and Engine Transformation have offices in London, Manchester, Sydney & Melbourne. User Research/UX Designer  We are looking for a design led user researcher to join us in a contract position, working on one of our large government digital transformation projects, where we are designing and building a leading digital citizen facing service. This is for an initial 6-month contract and we are looking for someone who can start immediately.  Duties/Experiences: Self-manage research activities from planning to delivery in partnership with your multidisciplinary team and stakeholdersHighly skilled in analysing, interpreting and shaping UX research findings in to meaningful and clear actionable insights at pace.Instinctively visualises your research findings (easy to understand, yet detailed user journey maps, user behaviours) - Whilst not a user interface designer, can mark-up or sketch-out user needs/feedback as simple wireframesFluent in turning user needs/insights into service processesExcellent communicator, both oral and written, with proven ability to influence broadly. Can connect stakeholders to fine details that can have a big impact on future service deliveryExperience of facilitating creative collaborative research and design working sessions (online - desirable).Ability to link customer/user insight with business opportunities.Proven experience in understanding digital analytics data.Proven capability in all phases of Usability Testing.Experience working in Government to GDS standardsExperience working in a central role as part of an agile delivery teamEvidence of a solid understanding of digital design. Ideally be multi-channel Key Skills: Propose, plan, facilitate, moderate and analyse results from 1-2-1 user research interviews, focus groups, usability testingFacilitation of collaborative research and design workshops (ideally online)Visually communicate research findings and make recommendations across UX and service/product teams to drive informed design decisions and functionality enhancements.Map out user journeys, highlighting key insights using tools like Miro, Photoshop, Mural, Sketch etcInterpret research findings to help a team prioritise workload and project roadmapStrong agile experience -ceremonies and ways of workingStrong previous public sector research and design project experience",Intermedio,Contrato por obra,"Tecnología de la información, Consultoría, Diseño",Consultoría de estrategia y operaciones,230,None,True,,813,ACTIVELY_HIRING_COMPANY
80,2231887377,2020-11-02,Michael Page,Data Scientist,"London, GB","My client is a Central Government organisation in the Public Sector and Government based in London who have embarked on a major transformation and as a result are looking for SC cleared Data Scientist (x2) to complete a 6 month remote contract to help complete a project ensuring the Product Strategy and Vision is delivered.   Client Details  My client is a Central Government organisation with its headquarters based in London.  Description  My client - A Central Government Body in the Public Sector based in London are looking for SC cleared Data Scientist (x2) to complete a 6 month remote contract. The responsibilities for this role are as follows -  * Switch on conditionally - Provide product support to enable operations to safely switch back on conditionally from July 1st .  * Segmentation - For who, and at what pace, protecting payment timelines. Help work coaches understand their caseload characteristics and needs to support labour market activation.  * Case-loading - How can we effectively support our work coaches' to manage, understand, and prioritise their caseload.  * Outcomes and use of data - Use our evolving segmentation and caseload understanding to drive providing MI. Build data tools to support work-coaches manage workloads and understand successful or unsuccessful interventions for claimants.  * Finding, referring, recording and tracking to provision (Kickstarter Find and refer).  * Provide discrete labour market tools in response to evolving priorities and providing data on outcomes from provision. For example matching vacancies to skills and goals (such as 'find my builders').  * Simplified view for work coaches to find information available across government that will help their claimants get new skills, training, in order to access the labour market.   1. Co-design a to-do to capture relevant and high quality data to develop a metric for measuring closeness to the labour market   2. Design options for a metric of labour market outcomes, and work with D&A colleagues to define the business case and source the data needed to create these metrics  3. Design data collection to establish an MVP measure of closeness to the labour market, how labour market outcomes depend on it, and the interaction with the intended labour market journeys (initially two distinct journeys)  4. Identify and source other relevant data assets to augment a labour market clustering  5. Deliver MVP recommendations on how to segment our caseload into journeys and carry out a first iteration labour-market clustering  In addition to the recommendations listed above, the successful candidate in role is expected to have identified and established close working relationships with other data-led Labour Market projects within Working Age, within the Department, and across wider government.     Profile  To be considered for the SC cleared Data Scientist (x2) to complete a 6 month remote contract the candidates must demonstrate the following -   * A track record of defining and delivering innovative, data-driven solutions on large or complex data sets including identifying and gathering disparate data, extensive data manipulation, iteration of analytical techniques and visualisation of the results  * Proven knowledge working collaboratively across an organisation on a transformational programme of data-led activity  - An understanding of UCFS datasets, and experience working in the area of Labour Market is beneficial but not essential.  * Proven capability of tackling challenging problems that are often unknown or very loosely defined, with a passion and curiosity to ask great questions to truly understand what's going on, and experience translating analysis into actionable recommendations when there are no precedents  * Proven stakeholder skills with a track record of working with stakeholders across all grades and working with internal / external stakeholders to deliver results  * Proven written and verbal communicator with the ability to present complex ideas in a compelling way to senior technical and non-technical audiences  * Capable of working within an Agile methodology and ability to manage diverse projects with changing user needs  Job Offer  Day rate is between £450 and £600 for this 6 month contract.",Intermedio,Contrato por obra,Tecnología de la información,Administración gubernamental,19,None,False,,258,COMPANY_RECRUIT
81,2184046836,2020-10-15,Exasol,Machine Learning Engineer (m/f/d),Germany,"We are looking for an experienced Machine Learning Engineer to strengthen the Product Integration team at Exasol in the area of Data Science and Machine Learning. Key Responsibilities:Develop and maintain integrations, as well as connectors of DS/ML libraries or products into EXASOLImplement ML algorithms within EXASOLAssist our customers and partners with your expertise in their data science projects, in order to solve their specific needs. As well as implementing custom algorithmsCreate and enhance documentation, showcases and examples that show and explain EXASOL‘s DS/ML capabilitiesSupport our Exasol Trainers by developing training materials for the connectors and integrationsUse your knowledge about DS/ML to further educate your colleagues Your Profile:You have at least 3 years’ experience with DS/ML for tabular and text dataYou are proficient in Python, scikit-learn, Tensorflow and JupyterYou are familiar with distributed machine learningYou are motivated and eager to broaden your knowledge within new areas, when necessary, e.g. R, PyTorchYou are proficient with relational databases and SQLYou have had touchpoints with Linux and have basic Linux based scripting knowledgeYou have experience working with Docker or other container technologiesYou have a customer-centric mindset and your goal is always to create an optimal user experienceYou have a good understanding of data structures, data modeling and software architectureYou have good knowledge of maths, probability, statistics and algorithms ﻿About Exasol:Exasol is one of the most exciting software companies in Europe and a global technology leader in the Big Data and Analytics market. Our high-performance, cloud-first analytics database gives companies the power to transform how their organization works with data – and turn it into value faster, easier and more cost effectively than ever before.With an ambitious international team, we help companies of all sizes achieve their goals with data support. Our team is characterized by inventiveness, enthusiasm and curiosity. In order to continue our worldwide expansion, we are looking for employees who want to make a difference and actively shape our dynamic growth.",Intermedio,Jornada completa,Tecnología de la información,Software,172,None,False,,990,ACTIVELY_HIRING_COMPANY
82,2276156902,2020-11-05,Splice,"Data Scientist, Product","New York City, NY, US","About The Role  We are looking for a Data Scientist to join our Data and Insights team. In this role, you will define metrics used to track engagement, feature usage, and user-centric outcomes. You will use data to uncover user preferences and quantify product experiences, all with an aim of guiding our Search and Recommendations team to build more relevant and impactful experiences for our users.  All of this means balancing ad hoc data exploration and longer-running analytical projects: designing and conducting experiments: bridging the gap between Product Managers and Data Engineers to assure that the necessary data is accessible and easy to use: regularly presenting findings to the Data and Insights team, Search and Recommendations team, as well as the company.  Skills We're Looking For  Data manipulation  In our opinion, things that can be reasonably expressed in SQL, ought to be. We expect our Data Scientists to have strong analytical SQL skills. This means a fluidity constructing statements that rely on a combination of joins, aggregate functions, subqueries, and window functions. This role will work with large-scale data, so this person must have experience writing efficient, performance-optimized queries.  Analysis  Right now, our bias is toward models that can be interpreted to drive human action. We're seeking an individual who enjoys experimentation and statistical analysis—someone who can translate what they see in the data into useful policy suggestions. A thorough understanding of statistical inference is required.  Modeling  You should have hands-on experience building machine learning models (supervised and unsupervised) and know how to incorporate your models into production workflows and product experiences. At the outset, this role will largely focus on experimentation and more foundational product analysis: however, some degree of specialization in either preference learning and recommendations or text processing and search is expected.  Tooling expectations  Regular usage of a programming language typically used for statistical analysis and machine learning (ideally Python).  Strong experience with analytical SQL (ideally BigQuery, Snowflake, or a similar MPP data-warehouse technology). Hands-on experience with self-service product-analytics tools (e.g., Looker, Mixpanel, Amplitude, Heap). Training in statistics, econometrics, or machine learning, with plenty of real-world experience applying these methodologies. Exposure to data sets used by Product teams. Chiefly, large-scale event data (e.g., Mixpanel, Segment, Snowplow, server logs) and normalized transactional databases (e.g., e-commerce and subscription datasets).   Additional Comments  There are no specific degree requirements for this role: we appreciate and seek out diverse backgrounds. Instead of any particular formal education requirement, we'll flesh out what you've built, what you know, and how you approach problem solving.  As a company that serves musicians and producers, some knowledge of the music-production process is an asset. If this topic is new to you, that's okay—you should be open to learning about it.  Equal Opportunity Employer:  Splice is an equal opportunity employer, committed to diversity and inclusion. We will consider all qualified applicants without regard to race, color, nationality, gender, gender identity or expression, sexual orientation, religion, disability or age.",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Marketing y publicidad, Software, Internet",257,None,False,,798,COMPANY_RECRUIT
83,2252759001,2020-10-16,Jefferson Frank,Data Engineer (AWS - Remote),"London, GB","Data Engineer - AWS  Central London  £60,000 per annum - Remote  My London based Client are a FinTech start-up who have created and launched a new innovative Open Banking platform based on AWS and ML/AI technologies.  They now have an immediate requirement to grow their Data Engineering team with this vacancy and are able to accommodate full remote working.  You will be part of an Agile team consisting of other Data professionals and Software professionals alike. There will be a genuine chance to touch on Machine Learning practices during your day to day work, regularly collaborating with the Data Scientists and continuously evolving your technical skill set beyond the capacity of a standard Data Engineer.  The Data you will be working on will be analysed in Real-time, so experience with cutting-edge streaming technologies will be hugely advantageous. As mentioned, they have incorporated modern-cutting edge cloud technologies offered by Amazon Web Services as part of the Data Analytics tech stack.  The platform itself has a wide range of functions and capabilities within the Financial Services market, so any prior experience within this sector would be highly beneficial, although not essential. To find out more about this product/service, please reach out to discuss in more detail.  Requirements  Data Engineering 2+ years within a commercial setting. Experience with AWS technologies, including Lambda, Kinesis (or Apache Kafka as an alternative) EC2, S3 etc. Experience with Scrum or Kanban methodologies. Python programming language Experience building and deploying ETL Pipelines NoSQL or PostgreSQL Databases Automation - CI/CD Experience Analysing Data sets and understanding of basic ML practices Benefits  Remote and Flexible working options Salary up to £60k Company benefits for travel and high street discounts Regular Learning and Development training Paid social and networking events throughout the year. Pension Scheme For more information, please contact ALEX from Jefferson Frank on 0191 814 7445 or a.todd@jeffersonfrank.com  LinkedIn - linkedin.com/in/alex-todd-25a072105/  Jefferson Frank is the Amazon Web Services (AWS) recruiter of choice. We work with organisations worldwide to find and deliver the best AWS professionals on the planet. We have a proven track record servicing the AWS permanent and contract recruitment market and, to date, have worked with over 30,000 organisations globally from our offices in North America, Europe, and Asia-Pacific.",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Dotación y selección de personal, Recursos humanos",None,None,False,a.todd@jeffersonfrank.com,30,ACTIVELY_HIRING_COMPANY
84,2269871281,2020-10-29,eyeo,"Data Scientist - Infrastructure and Compliance - Remote, Berlin or Cologne","Köln, DE","Get to know us  eyeo is an open-source software company that builds products like Adblock Plus, Adblock Browser, and Flattr. By leveraging distribution partnerships, we bring ad-blocking technology everywhere, giving users control over their online experience while offering creators, publishers and advertisers more ways to earn money for the free content they provide.  In combining our reach based on distribution partnerships and our own products, our technology runs on over 150 million devices.  At eyeo, we're passionate about user agency, personal privacy, sustainability, and keeping the web an open, fair resource for everyone.  How We Work  eyeo colleagues are based all over the world. We practice agile and work in distributed, cross-functional teams that span nearly every timezone. Many of our tech teams prefer to work asynchronously.  What You'll Do  Consult stakeholders in a wide range of data-related questions, supporting them on all stages from identifying which problems can be solved with data to training them on how to make the best use of the self-service platform for their business goals Work with fellow Data Scientists to ensure quality through code reviews and share knowledge Convey complex ideas in a simple way to enable stakeholders to make informed decisions Collaborate with Data Engineers and other parts of the company to bring solutions to production Further the company's ability to execute a data-driven strategy Perform analysis, create reports and visualizations   What You Bring To The Table...  An experienced data scientist with demonstrated success and a minimum of 4 years of experience with real-life data Background in statistics (mathematics, natural sciences, economics, psychology, ...) Fluent in programming with R or Python Good working knowledge of relational databases Experience with consulting stakeholders and/or driving projects Excellent communication skills in English, both written and verbal Experience with version control and reviews   It's Awesome, But Not Required, If You Know About...  Experience with GBQ, DataStudio, and related Google Cloud Platform services Experience with A/B testing Understanding of how the internet and web browsers work Interest in ML like NLP   What We Offer  Work from home, one of our offices, or a co-working space—we trust you to find what works best for you Stipend for one of the following: home office, co-working space, or relocation Flexible working hours 26 days paid vacation days Your choice of hardware and setup Personal and professional development budget Monthly child care stipend for children under 6 Offsite team days and annual summer company retreat in Cologne Company-sponsored hackathons  Privacy Notice  When you apply, you'll be automatically forwarded to our recruitment platform operated by an external service provider called Greenhouse (seated in the US). Greenhouse collects some information on its website, such as anonymous usage statistics, by using cookies, server logs, and other similar technology. For more information, please refer to Greenhouse's Privacy Policy. All documents and information provided by you are stored with Greenhouse. In order to ensure an adequate level of data protection, eyeo and Greenhouse have entered into the EU Standard Contractual Clauses ('processors') - Commission Decision C(2010)593. You can request a copy of this by contacting us at privacy[at]eyeo.com. If you don't want your data forwarded to Greenhouse, please do not apply. For detailed and further information, please refer to our Privacy Policy at https://eyeo.com/en/privacy.",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Software, Internet",27,None,False,,248,COMPANY_RECRUIT
85,2254463110,2020-10-29,Shift4 Payments,Data Engineer,United States,"Company Background:Shift4 Payments is the leader in secure payment processing solutions. The company’s groundbreaking technologies help power the top software providers in numerous verticals, including hospitality, retail, F&B, e-commerce, lodging, gaming, and many more. Shift4’s family of software brands includes Harbortouch, Restaurant Manager, POSitouch, and Future POS — with additional integrations to 300+ POS/PMS systems across every industry. With an expansive global footprint that includes eight offices across the U.S. and Europe and over 8,000 sales partners, the company securely processes more than a billion transactions annually for nearly 200,000 businesses, representing over $100 billion in payments each year. For additional information, visit www.shift4.com.  Job Summary:We are looking for a Data Engineer to join our Information Technology Group. This position will engage in an Agile-based SDLC to complete data layer requirements (includes but not limited to table creation, stored procedure creation and updates, ETL processes) as well as acquire a deep understanding of business processes and flows to assist with reporting / business intelligence tasks. The Data Engineer will work in a team comprised of front / backend developers, business analysts, QA engineers, and will follow the Project Manager’s lead for sprint goals and deliverables.  Responsibilities:Helping design, develop, debug and optimize stored procedures and views producing data suitable for reporting purposesEnsuring code standards are followed on all codeRefactoring existing code based on existing DBs and modifying it for newer modelsValidating data, performing cross reference checking between source data and outputsWorking with stakeholders and Technology Group to fine tune outputs to ensure all requirements are met for reportsWorking closely on related issues with internal business units Qualifications:Bachelor's degree in Computer Science or equivalent work experience5+ years of experience with SQL Server.Experience with SSIS and SSRS essential. SSAS preferred but not required.Thorough understanding of SDLC and how it pertains to the database.Experience with Jira and ConfluenceExcellent written communication skills, particularly in the realm of technical documentationBasic VB & C# experience a plus.Experience with an Agile SDLC a plus.Ability to communicate technical issues to all levels Education:Bachelor of Science degree and/or relevant work experience  We are looking for individuals that are extremely self-sufficient, available to work flexible hours, & hold themselves to the highest standards of professionalism. We will be evaluating candidates based on how they interview, prior experiences, functional knowledge, and references.  Shift4 Payments provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics.",Intermedio,Jornada completa,Tecnología de la información,"Servicios financieros, Software",21,None,False,,153,None
86,2233917626,2020-10-24,Holden Recruiting Talents,Data Scientist,"Rio de Janeiro, Brazil","Atividades:  Extrair insights dos dados da empresa , estruturados ou não de fontes variadas das áreas internas da empresa: Criar relatórios no conceito Self-Service BI : Participar das iniciativas de Infraestrutura de Dados (Data Lake, Data warehouse...): Desenvolver monitoria de aplicações ao longo do tempo com geração de alertas:  Desenvolver e manter modelos matemáticos para resolver problemas de negócio.  Requisitos:  Superior em Estatística, Engenharias, Física, Economia, Ciência da Computação ou cursos relacionados: Experiência em Análise Exploratória de Dados, Algorítimos de Aprendizado de Máquina, Séries Temporais: Conhecimento: cálculo, álgebra linear, estatística, banco de dados, plataformas cloud para ciência de dados: Stack Tecnológica: Python para ciência de dados, R, SQL, Power Bi, programação orientada à objeto (C# e Java)   Diferenciais  Conhecimento em metodologias ágeis: CRISP-DM: Experiência com Business Intelligence: Bibliotecas Python: Pandas, Numpy, Scikit-learn, Matplotlib: Conhecimento em Processamento de Linguagem Natural: Experiência com Web APIs: Conhecimento em versionamento de código (Git):  Contratação CLT + pacote completo de benefícios em empresa de grande porte, ampliando seu time interno de Data Science.  Atuação: Remoto  Contrato: CLT + pacote completo de benefícios",No corresponde,Jornada completa,None,None,76,None,True,,421,JOB_SEEKER_QUALIFIED
87,2269792147,2020-10-09,Mindstrong,Data Scientist,"San Francisco, CA, US","This role can be based out of Mountain View, CA or San Francisco, CA   Who is Mindstrong?  Mindstrong is a research-driven, consumer-focused mental healthcare company working to unlock a new virtual care model for delivering healthcare to people living with a serious mental illness (SMI) through innovations in measurement science, and care delivery. Our services are offered to people with an SMI through active partnerships with several nationwide health insurance payers.  As a Series C company, we have a blend of science, technology, and healthcare talent to help us unlock this paradigm-shifting approach, including the likes of National Institute for Mental Health, Stanford Center for Neurobiological Imaging, Uber, Facebook, Google, Apple, Oscar Health, and CMS.  We'd love to talk more!  What is the Data Scientist role?  We're looking for Data Scientists to join our growing team of people passionate about changing mental healthcare. In this role, you will work cross functionally and partner with engineers, product managers, data analysts, and the clinicians who directly deliver care to our Mindstrong members. You will lead projects that derive value from our extensive amount of data and will work on problems related to predicting and measuring mental health outcomes, optimizing our growth funnel, matching clinicians with patients, increasing the efficiency of clinical services, and making recommendations for impactful interventions. Our team works across the company to help influence decision-making, and your work will have a direct impact on our patient population.  What you'll be doing:    Become an expert in building healthcare critical deep-learning applications that re-map brain circuits from human-computer interaction patterns  Create highly scalable and adaptive online/streaming learning algorithms that impact the lives of millions of people daily  Work with a high-performance engineering team to deploy these applications in a highly scalable and distributed infrastructure   Who you are:    You feel good about your work knowing that what you do will affect the lives of millions of people around the world  Entrepreneurial and eager to thrive in a startup environment  Strong communicator (oral and written)   Your background and skills:    An amazing developer: technical challenges of all types excite you  Interested in contributing your opinions and perspective to help the team solve the challenges that our users face  Possess extensive end-to-end project experience using machine learning or deep learning to solve complex real-world problems. This includes feature selection, dimensionality reduction, algorithm development, cross-validation  Have a proven track record of delivering concrete implementations on tight schedules  Have extensive experience using Python/R, TensorFlow & Keras/Torch, Spark and the AWS stack (S3, SQL, Mongo, Redshift)  PhD (preferred) or MS in statistics, computer science or related mathematical disciplines with an emphasis on both theoretical analysis and algorithmic implementation, OR equivalent experience  Minimum 5 years of experience developing both statistical and machine learning models with at least 3 years in the industry, i.e. shipping product!   Competitive Benefits:    Medical, Dental, and Vision coverage  401k  10 paid holidays  Unlimited PTO  Fully stocked kitchen and catered lunches  Casual dress code  Telecommuting benefits   Join us in our journey to transform the future of brain health!    Mindstrong is proud to be an Equal Employment Opportunity employer that celebrates diversity. We are committed to providing equal employment opportunities to all employees and applicants. All individuals seeking employment at Mindstrong are considered without regard to race, color, religion, national origin, age, sex, marital status, ancestry, physical or mental disability, veteran status, gender identity, sexual orientation, or any other characteristic protected by federal, state, or local laws. This policy applies to all terms and conditions of employment. Mindstrong also strives for a safe and robust workplace and prohibits harassment of any kind. If you have a disability or special need that requires accommodation for interviewing, please let us know by emailing contact-recruiting@mindstronghealth.com",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Software, Internet, Atención sanitaria y hospitalaria",24,None,False,contact-recruiting@mindstronghealth.com,221,COMPANY_RECRUIT
88,2189656481,2020-10-22,Putnam Recruiting Group,Data Engineer,Los Angeles Metropolitan Area,"This company is a fitness tech company offering a streaming service through their online platform, which boasts thousands of professionally-filmed classes for a small monthly subscription. They are also expanding their fitness program portfolio and are completely self-funded!  The RoleBuild ETLs, data pipelines, data infrastructure, SQL queries and conduct some data analysis to support other teams You Have4+ years of relevant data engineering work experienceExperience with SQL, AWS Glue and AirflowProficiency with PythonWorked at small to medium sized companies and are accustomed to wearing many hatsIf you have subscription company or content company experience, that's a plus! This is an opportunity to join a talented team with a truly awesome, collaborative culture!",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Dotación y selección de personal,252,None,True,,673,JOB_SEEKER_QUALIFIED
89,2167633736,2020-10-29,Saturn Cloud,Senior Data Scientist,United States,"note: US-based applicants are welcome to apply, regardless of location -- we have always been remote-friendly MissionSaturn Cloud helps companies perform data science at a new level of scale, with one-click solutions, to solve the world’s hardest problems. Our product is a SaaS platform which equips data science teams with high-leverage automation tools, eliminating hours of traditional, manual work. The platform is user-friendly, scalable and secure. You will be a Data Scientist for Saturn Cloud. Data scientists here are similar to 'solutions architects' at other companies. As a data scientist at Saturn Cloud, you'll work hands-on with our customers to improve the runtime, scalability, and reproducibility of their data science work. ResponsibilitiesWork on high-visibility customer-facing projects (e.g. text and video tutorials, use-case examples, contributions to our engineering blog)Collaborate with customers to build proof-of-concept applications, data pipelines, or machine learning models using the PyData stack (e.g. Jupyter, pandas, numpy, dask)Use Saturn’s product to do data science work, and based on your experience, propose bug fixes, usability improvements, and new features to the engineering teamWork on public content like blog posts and tutorial videos, in which you use Saturn’s product, Python, other open-source software like Docker, and your own expertise to accomplish data science tasksOwn cross-functional interactions for your projects (across eng/marketing/field/sales) Preferred QualificationsExperience learning a new domain and using machine learning in a research setting in that domain. How you might demonstrate this:You hold a degree in Economics, Computer Science, Statistics, or another discipline.You have professional experience in a research setting like a corporate Research & Development team or in a center / lab at a university Excellent writer and communicator, proficient in generating engaging content. How you might demonstrate this:You have professional experience where you presented directly to customers or to executive audiences.You’ve spoken at conferences or meetups.You’ve taught a course or guest lectured in one. Experience working in an enterprise environment. How you might demonstrate this:You have relevant work experience where you did contract, consulting, or full-time work for a company. Foundational knowledge of AWS or a comparable public cloud, including some experience with object stores (e.g. AWS S3), machine learning services (e.g. SageMaker, EMR), and virtual machines (e.g. EC2). How you might demonstrate this:You have earned AWS certificates in the last 5 years, especially Solutions Architect, Big Data Specialty, or Machine Learning Specialty.You have relevant work experience where you used AWS or a comparable public cloud.You have used AWS as part of an open source project, personal side project, or class project. Proficient in Python, including the PyData ecosystem (at least two of dask, numpy, pandas, pyarrow, scikit-learn, scipy). How you might demonstrate this:You have professional experience where you wrote Python code to accomplish data engineering or machine learning tasks.You’ve made contributions to open source projects in the PyData ecosystem, including your own side projects.You’ve performed well in data science competitions such as Kaggle, or published Kaggle kernels.You’ve written blog posts which show an ability to use PyData tools to accomplish data engineering or machine learning tasks Comfortable reading and writing tabular data stored in files and  / or databases. How you might demonstrate this:wrote Python code to read / write one of these file formats: CSV, feather, parquet, JSON, fixed-width, TSVused SQL to access data in a relational databaseYou have professional experience, open source contributions, academic research, or side projects where you: Comfortable applying statistical techniques to business problems. How you might demonstrate this:You have professional experience where you used statistics to solve business problems by, for example, deploying machine learning models, writing data-drive reports, or publishing a dashboardYou’ve published an academic paper where you applied statistics to a research question. Strong interpersonal skills and ability to collaborate with others. How you might demonstrate this:You have professional experience where you worked on projects that required collaboration with coworkers.You’ve done academic research where you collaborated with co-authors to produce a paper.You’ve co-organized a conference, meetup, or other event.  BenefitsCompetitive salary commensurate with your growing experienceStock options in early-stage venture poised for scaleMedical, dental, vision coverage401k Retirement PlanUnlimited Paid Time Off (with enforced 3 week minimum)Awesome coworkersParental leave plans100% remoteOpen culture with a strong preference for asynchronous communication and respect for work / life boundaries. About UsOur mission is to transform the businesses of our customers by making data science faster. Founded by some of the creators of Anaconda and core authors of the PyData stack, Saturn provides a powerful data science platform for teams to build and manage data products. We make data scientists happier and their businesses more successful. For more information, visit www.saturncloud.io.",Director,Jornada completa,"Consultoría, Ingeniería, Gestión de proyectos",Software,155,None,False,,658,ACTIVELY_HIRING_COMPANY
90,2207197379,2020-10-23,CircleUp,Senior Quantitative Researcher,"San Francisco, California, United States","CircleUp is a technology company on a mission to help entrepreneurs thrive by giving them the capital and resources they need. We have built Helio, our machine learning and predictive analytics platform to discover the fastest-growing companies in the consumer products sector. Helio allows us to uncover data and insights that enable faster, smarter decisions for our capital offerings by investing in a “systematic” fashion. We’re now scaling these capabilities beyond our existing discretionary private venture fund. We are looking for a Quantitative Research expert to lead our mission to create a fully systematic investment solution for the private venture markets. The Senior Quantitative Researcher will be responsible for identifying winning portfolio brands that CircleUp’s private equity business will invest in for a new fund raise. This person will lead the design, discovery, and delivery of portfolio companies that represent high growth and successful outcomes for CircleUp and it’s Limited Partners. To do this, the Quantitative Research leader will leverage our comprehensive knowledge graph of data and insights that harnesses the power of machine learning. This individual will also play a very visible part in driving confidence and conviction in Limited Partners who seek to invest in our fund through data science, backtesting analysis and strong communication skills. You will be working closely with data scientists, the GM of Equity, product managers, and investors. Prior experience with financial investment research is critical. This role will report to the Chief Product Officer.   CircleUp was recently honored as one of Fast Company's Top 10 Most Innovative Companies in Data Science and has been named a CB Insights FinTech 250, a Top 5 Most Disruptive Company in Finance by CNBC, and to the Forbes FinTech 50. Founded in 2012, CircleUp is headquartered in San Francisco and backed by Union Square Ventures, GV, Canaan Partners, QED Advisors, and others. Responsibilities:Lead the R&D for quantitative analytics that inform portfolio selection of winning CPG brandsBe able to evaluate new and existing data pipelines to develop, design and deliver analysis that drives conviction in systematic investment portfolio decisions Build end to end algorithms for assessing early stage consumer companies for growth equity investmentsBuild causal and interpretable modelsBuild reproducible backtests for proposed models / algorithmsWork cross functionally with data science, engineering, product, and business development to help decide & prioritize building systematic data pipelines and insightsDevelop innovation to find and use data that significantly delivers impact against our key business metricsRepresent CircleUp as subject matter expert leading systematic investment strategy in fundraising activities Requirements:Prior experience as a quantitative researcher at a quantitative investment firm/hedge fund is a big plusPhD preferably in statistics, computer science, engineering, physical sciences, economics or related technical fieldExtensive background in finance or investment research Excellent communication skills – Must be able to articulate their analysis and methodologies clearly and communicate insights in an easily accessible way to the teamMust be excited about working in a fast and changing environment where solutions have not been already definedPassionate about disrupting an entire industry within the private investment marketsAbility to write code in at least one scripting language, preferably PythonExperience with machine learningExperience putting models into production systems is a huge plusOperates with unassailable integrityStrong work ethic and courage to overcome meaningful obstacles If you got to this point, we hope you’re feeling excited about the job description you just read! Even if you feel that you don't meet all of the requirements and qualifications, we still encourage you to apply. We’re eager to speak with those who share our passion to help entrepreneurs thrive - not just those who match every bullet point in our job descriptions.  CircleUp is an equal opportunity employer. We do not discriminate based upon race, religious creed, color, national origin, ancestry, physical or mental disability, medical condition, genetic information, marital status (including registered domestic partnership status), sex and gender (including pregnancy, childbirth, lactation and related medical conditions), gender identity and gender expression (including transgender individuals who are transitioning, have transitioned, or are perceived to be transitioning to the gender with which they identify), age, sexual orientation, Civil Air Patrol status, military and veteran status and any other consideration protected by federal, state or local law. We encourage those who really want to make an impact to apply for our open positions.",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Servicios financieros,159,None,True,,716,ACTIVELY_HIRING_COMPANY
91,2018791010,2020-10-30,SDL plc,Research Scientist - Machine Translation,"Seattle, Washington, United States","Research ScientistLos, Angeles, CA Must have at least 2 years experience with Research or software engineering skills directly related to Machine Translation. Who are we?At SDL Research, we have over a decade of experience in designing, building and deploying large-scale cutting-edge software applications. We offer the opportunity of research and software development in a dynamic setting where you can have an enormous impact.As a Research Scientist at SDL, you will discover, design and implement solutions to interesting problems at the intersection of Artificial Intelligence and Software Engineering. You will use your strong knowledge of machine learning, and natural language processing to build SDL Research next-generation products and platforms. What is this role?The role will entail working alongside a friendly team of experienced researchers to develop Machine Translation and Artificial Intelligence products and services. We have our own mature state-of-the-art R&D environment and are looking for able researchers to extend it. Basic Qualifications:PhD or equivalent experience in computer science, engineering, statistics, machine learning, mathematics, or in another highly quantitative fieldDepth and breadth in state-of-the-art approaches in natural language processing2+ years of relevant academic research or industry experienceScientific mindset and the ability to inventExcellent creative problem solving skillsAbility to design and develop system prototypes in simulationSuperior communication and data presentation skillsEffective working in a team environment Preferred Qualifications: Superior communication and data presentation skillsDemonstrated ability to lead research projects and identify fruitful research directionsDemonstrated ability to work on cross-functional teamsExperience with applying scientific principles Benefits:Amazing benefits. (Seriously!)Infinite training, professional development and personal growth opportunities.The rare opportunity to impact how organizations communicate globally. There’s a reason we work with 90 of the top 100 brands.Smart, engaged co-workers, a culture of diversity, innovation and opportunity.Relaxed, fun environment with a game room, in house happy hours and many great office events throughout the year.Great work life balance! SDL is an Equal Opportunity / Affirmative Action Employer. Qualified applicants will be evaluated for employment without regard to race, color, religion, sex, national origin, veteran, and disability status. For more information about EEO/AAP legislation please visit http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf.",Algo de responsabilidad,Jornada completa,"Ingeniería, Investigación, Ciencias",Software,180,None,True,,980,COMPANY_RECRUIT
92,2244791809,2020-10-08,Augury,Data Scientist,"Haifa, IL","Machines Talk, We Listen. We are all surrounded by machines and rely on them in everything we do - from the buildings in which we live and work, the goods that we consume, to the power and running water that we use. We are on a mission to make machines more reliable and reduce their impact on the environment. Our Machine Health platform combines Artificial Intelligence and IoT, to generate insights that help customers lower costs, reduce downtime, and increase supply chain resilience.  Augury is looking for a Data Scientist to join our advanced Algorithm team. You will solve real-world problems and have a direct impact on innovating Augury's core technology. You will be at the forefront of technology for diagnostics of electro-mechanical equipment, using advanced machine learning approaches and the latest big-data technologies with a unique data set.  A Day In Your Life  You will research, develop, and deploy solutions for the multifaceted automatic machine health diagnostics problem.  Completely own the entire algorithmic life-cycle including problem learning, discovery, data analytics, prototyping of new ideas , and implementing algorithms in a production environment. You will be a technology point of contact for Machine Learning Algorithm in the group and the company.  You will apply your scientific knowledge and creativity to solve complex problems. You will use industry-leading cloud technologies in big data storage, distributed processing, stream processing, and time series analysis (such as Apache Spark, Cassandra, Apache Beam). You will improve Augury's capabilities in detecting and classifying changes to machine health by applying your knowledge in data analysis, signal processing, supervised and unsupervised machine learning and deep learning methods, and time-series anomaly detection. You will work with unique big data. You will apply research to achieve impact - improvements to machine health, industrial process performance, customer insights, and efficiency improvement suggestions. You will work on patented state-of-the-art technology, while contributing to new and ongoing patent applications.   What You Bring  Education: M.Sc./Ph.D. degree in electrical engineering, computer science, physics, mathematics, statistics or relevant engineering discipline.  Your playground: You design algorithms, train predictive models, deploy them (Python is preferred), and track their performance. You research and implement machine learning methods - clustering, dimensionality reduction, classification, anomaly detection. You are familiar with signal processing methods and challenges. You understand the impact that software plays in the world of data science. You are familiar with Agile, constantly seeking challenges while enjoying the fast feedback loop. Own it: You are passionate about creating an impactful and innovative environment. You like to share your experience and coach other team members to have a direct impact on the team and the core technology of the product.   About Us  We love creating stuff. We are passionate about building meaningful products that can change the world. Our team is a diverse group of people that breed creative thinking and are not ashamed of having fun. We are only as good as the relationships we build - we treat each other with respect, dignity, and humility. We don't pursue the mythical work-life balance - there is only life, and Augury is a part of it.  Perks  Stock options Paid parental leave Flex PTO",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Software, Internet",27,None,False,,219,ACTIVELY_HIRING_COMPANY
93,2251964028,2020-10-05,"Fetch Rewards, Inc.",Data Scientist,"Chicago, IL, US","Who We Are:  We reward shoppers for digitizing their shopping experience. Our mission is to delight the world's shoppers with a free smartphone app that is easy, smart and fun.  Why Join the Fetch Family?  We make it better for users even when that's difficult for us We empower people with information and trust We challenge ideas, not people We think bigger and keep building We find ways to bring the fun to Fetch!  We're committed to building an empowered and inclusive community of innovative and passionate people. As a growing organization, we need team players who can go above and beyond their individual responsibilities to help our company build towards its vision. If you are a creative, hard-working, and fun-seeking person interested in working with a close-knit group of highly talented people, this is the right place for you.  Fetch Rewards is an equal employment opportunity employer.  The Role!  The Data Science & Analytics team embodies these values and works with a laser focused objective to enable data driven decision making for both internal stakeholders and external partners. We are looking for a Data Scientist to contribute to this vision and reap the rewards of joining an exciting company in the high growth phase.  You will create analytical solutions and machine learning models that help Fetch teams leverage and monetize actionable insights from our unique data. This is a challenging and high visibility position, responsible for creating these solutions as well as guiding technical direction. Success in this role requires the ability to take on challenging problems and design & develop an amazing solution with little to no assistance.  You possess:   Hands-on experience in developing / deploying machine learning models that are tied to business value. At bare minimum, a good grasp of machine learning techniques, and their application in the real world. Ability to create SQL/Python programming modules for custom insights required by our clients. Leverage statistical analysis to understand what is 'acceptable' versus 'outliers'. Ability to successfully collaborate with both business users and engineers for effective analytical solution development and deployment Passion to drive actionable insights from data and present them to external and internal clients through Tableau / Powerpoint / Excel in a compelling manner. Knack for conducting the apt Data Exploration needed to enhance the cleanliness and effectiveness of our data sources. Discipline to create well documented coding and analytics packets to ensure reusability as the team expands. Master's or PhD in Statistics, Mathematics, Computer Science or any other Quantitative field 2+ years of experience in data science workstream  Bonus points for:   Experience in CPG/Retail domain and/or analytics at app-based B2C companies Familiarity with Big Data frameworks like Snowflake, Spark and AWS services Familiarity with Tableau or any other visualization tools Effective communication, ability to translate and explain technical issues to non-technical team members Love of Dogs! . . . Or just tolerance. We're a very canine-friendly workplace",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Software, Internet",30,None,False,,144,ACTIVELY_HIRING_COMPANY
94,2194396012,2020-10-20,Eurostaff - Connecting Europe™,Big Data Engineer,United Kingdom,"The logistics industry has seen a significant improvement in infrastructure and technology in recent years and ever more services are being brought online, raising the hopes of a step change in the way businesses and consumers move goods around the world. However, it significantly lags behind all other major industries in one key area: continually optimising the use of assets and operations. As a result, logistics costs are needlessly high and the customer experience poor. The vast majority of businesses have wasteful and expensive logistics operations. My client's mission is to optimise logistics for everyone, making more efficient use of resources and improving the service that our customers receive. This can only be achieved through the combination of machine learning or artificial intelligence and far reaching automation of the industry. We’re looking for engineers who want to join us on the journey from our (already successful) proof of concept technology to a fully distributed, scaleable, highly available microservice SaaS platform.   Required skills:3+ years data engineering or related experience in a commercial environment and have an MS or PhD in subjects ranging from computer science, electrical engineering, mathematics or similar. Ideally you must be experienced in some or all of these technologies: Python 3PostgresqlRedisAWSGraphqlDjango 1.11 / 2Django grapheneDjango REST frameworkCeleryPandasPytestSplinter/Selenium Main responsibilities: Design and build quality code to current style guides for release to production.Envision, design, build and support services and tools for data scientists where 'self-service' is the goal.Identify and maintain the integrity of mission-critical data.Design reliable distributed systems that handle high volumes of data with low latency.Take pride in communicating, documenting, and otherwise understanding scientists when needs arise and the world changes. Why we think you’ll love it here…You’ll work alongside amazing, high-performing colleaguesWe offer a competitive salary and equity options with every role, as well as annual salary reviewsYou’ll work in a private, high-spec, comfortable, spacious, non-open-plan (engineering and non-engineering will have private quarters) office in Soho in central LondonEveryone gets unlimited days of paid annual leave (a minimum 15 days must be taken to encourage a healthy work-life balance)Free gym membershipA generous private health insurance planYou’ll get a high-spec tech kit to work onFlexible morning start-times on the engineering teamsOne week of remote working from abroad per yearWe have regular communal company lunches, team socials and activitiesFully stocked kitchen with plenty of office snacks including fruit, nuts, bread, cereals, and amazing coffeeWe will offer a cycle to work scheme, eye-care vouchers and childcare vouchersParents and carers are guaranteed one day per week of work-from-home, and we'll give you an extra day of annual leave to take your child to their first day of nursery and primary school",Intermedio,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Servicio de información",42,None,True,,213,ACTIVELY_HIRING_COMPANY
95,2222658083,2020-11-05,SearchDATA Group,Data Engineer (Snowflake),"London, England Metropolitan Area","Data Engineer (Snowflake)  Do you have experience of Snowflake and are now looking to specialise in that area? Do you want to work for a solutions provider with a range of exciting greenfield projects? Are you looking for a role with genuine scope for progression and a great work-life balance? An analytics house based in central London is actively seeking a Data Engineer with experience of working with Snowflake to join a team responsible for a number of business-critical projects dealing with a range of technical solutions. Our client is a dynamic technology company that is focused on business analytics and planning. They take an innovative approach to making complex solutions simple so their clients can focus on running their businesses. Their services and applications enable clients to gain the benefits of world-class analytics and planning capability without the headaches. What we can offer﻿A competitive basic salary(£80-105k)A bonus scheme paying 10% of basic salary depending on individual performanceFlexible working hoursThe option of homeworkingPensionPrivate healthcareIndustry specific training Role Summary: As a Data Engineer, you will: Experience on client-facing projects, including working in close-knit teamsDesign, Build, and maintain production-grade pipelines into the data warehousePlay a key role on projects from a data engineering perspective, working with Architects and clients to model the data landscape, obtain data extracts and define secure data exchange approachesPlan and execute secure, good practice data integration strategies and approachesWork with Data Analysts, Data Scientists, and Product Engineers to build APIs and pipelines that serve up real-time analytics and predictive models to the Snowflake service.Help define best practices for data movement which Engineers will use when designing and implementing pipelines. Our Ideal Candidate will have:Experience of working with SnowflakeExperience building pipelines to move large-scale data.Fluidity with at least one modern scripting language (Python being the preference)Experience with a compiled programming language, preferably something that runs on the JVM (Scala being a preference).Experience working with SQL and relational data. Specifically, an ability to identify and tune problematic queries.Hands-on experience with MPP databases such as Snowflake, Redshift, BigQuery, Vertica, etc.Hands-on experience with tools used for low-latency event-based pipelines, such as Kafka, Flume, Kinesis, Fluentd, etc.Familiarity with orchestration frameworks (Preference for Airflow).Familiarity with streaming/micro-batch compute frameworks (we use Spark and are interested in Storm).A solid understanding of AWS Roles and Policies, as well as secret managementAbove all else, you thrive in a dynamic environment. That means being flexible and willing to jump in and do whatever it takes to be successful. Additional nice to haves:A familiarity with business intelligence tools such as Power BI, Tableau and QlikViewSome other technologies we use that we’d expect this person to be familiar with (or willing to learn): Git, SVN, Docker, AWS EMR, and AWS Lambda.",Intermedio,Jornada completa,"Análisis, Tecnología de la información",Dotación y selección de personal,52,None,True,,223,JOB_SEEKER_QUALIFIED
96,2194380913,2020-10-20,TRINITY,Junior Data Engineer,"Gurgaon, Haryana, India","We are looking for a savvy Junior Data Engineer to join our growing team of claims data analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing our systems that run and support those pipelines. The ideal candidate has experience in working with Patient and Claims data sets. The Junior Data Engineer will support our existing team and analysts on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the opportunity to design our company’s claims data architecture to support our next generation of products and data initiatives. Responsibilities:Assist in product development using cloud platforms for ELTUse claims/patient data business rules to build out data flows to meet analysis objectivesBuild the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL, Matillion, Snowflake, and PythonBuild analytics tools using Power BI and Tableau that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs. Use GitHub SCM for version and release managementPerform test and QC on all development work Work with data and analytics experts to strive for greater functionality in our data systems.  Qualifications:Experience working with US closed and open claims datasets (e.g. Marketscan, Pharmetrics, IQUVIA)Experience working with longitudinal patient dataExperience with epidemiological terms and applications to patient data setsExperience with cloud data platforms, preferably Snowflake and Matillion ELTExperience working with large datasets (Billions of rows)Experience with cloud data management tools: Azure Storage Explorer, FTP, Azure BLOB Storage, S3 BucketsExperience with Python and Powershell Strong SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. Snowflake  or other cloud database experience preferredExperience building and optimizing claims data pipelines, architectures/data models and data sets. Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. Experience with the Agile workflow, Test Driven Development, and continuous improvement/continuous deployment. Strong analytic skills related to working with structured and unstructured datasets. Build processes supporting data transformation, data structures, metadata, dependency and workload management using Azure Automation, Azure Function Apps, and Azure Data Factory. Strong self-organizational skills. We are looking for a candidate with 1+ years of experience in a Data Engineer or Software Engineer role, who has attained a Graduate degree in Software Engineering, Computer Science, or another quantitative field. They should also have experience using the following software/tools: Experience with big data tools: Matillion or other ETL/ELT tools Experience with building relational SQL databases Experience with data pipeline and workflow management tools: Azure Data Factory, SSIS,  PythonExperience with Git/GitHub and automating builds.  TRINITY is a trusted strategic partner, providing evidence-based solutions for the life sciences. With over 20 years of experience, we are committed to solving our clients’ most challenging problems through exceptional levels of service, powerful tools, and data-driven insights. TRINITY’s range of products and services includes industry-leading benchmarking solutions, powered by TGaS. To learn more about how we are elevating life sciences and driving from evidence to action, visit trinitylifesciences.com.",Sin experiencia,Jornada completa,"Tecnología de la información, Ingeniería",Consultoría de estrategia y operaciones,477,None,True,,1668,ACTIVELY_HIRING_COMPANY
97,2184373913,2020-11-05,QUOR,Data Scientist,India,"A full-time long-term project with an exciting venture-funded startup out of the US (Silicon Valley, NYC, Tel Aviv, and India) and a giant media/tech Partner building a new type of solution that has the potential of changing the way we search and consume content online. The project was initially tested successfully in Wall Street and now we are taking it mainstream. Roles and Responsibilities: As a Data Science Manager, you will apply your passion and expertise for data, machine learning, predictive analytics, and entrepreneurship to create data-powered products that enrich company’s culture of innovation. You will be responsible for building intelligent systems using techniques in machine learning, optimization, data analysis, and statistics that enhances the overall customers’ experiences. We are soon going to have an incredible amount of data that will capture a comprehensive view, requirements, and experience of our customers with respect to one or more types of digital content items that are out there on the World Wide Web. Very few companies in the world have this diversity and scale of data, and we are stepping into the same world. Hence the breadth of problems available to solve in a data-driven fashion is going to be immense. With millions of customer interactions every day, you will eventually be tapping the industry’s best data to develop new algorithms and extract useful and valuable infights to figure out how those customers navigate their content finding journey and what else we can do to deliver a richer experience to our customers. Qualifications and Requirements:Masters or PhD in quantitative discipline (Statistics, Math, Data Science, Engineering) is preferred3+ years of experience in the following areas: Java, Python, Scala, or other languages appropriate for large scale analysis of numerical and textual dataData mining, machine learning, statistical modelling, and underlying algorithmsRecommender Systems, Search Algorithms, or Operationalizing performant algorithms for website integration is a plus",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información",Internet,762,None,True,,2092,JOB_SEEKER_QUALIFIED
98,2282972620,2020-11-06,KDR Recruitment Ltd,Data Scientist,United Kingdom,"I am working with an industry leading, innovative & growing FinTech organisation based in the heart of Manchester, who are looking for an experienced Quantitative Data Scientist to help them to support other analysts to build tools, models & applications to make them more efficient.  Working in a fairly smaller sized team, you’ll need to really hold your own and come from a background of mentoring/coaching others so you can really throw yourself in at the deep end. Data & Analytics is the heart of what they do, so they will look someone to have the same outlook & attitude as them.  It’s an exciting time to join my client, not only have they put more bums on seats over the last few months, but they have also integrated clear progression plans for their staff to get stuck in to.  Skills required:Python You will ideally have the knowledge/experience of working with FinTech/Investment Banking organisationsYou’ll have a degree in the following: Computer Science, Mathematics, Statistics etc This role will focus on building models & tools specific to the organisation: using your background knowledge & experience, as well as using Python on the daily!   You’ll take some of the work from the Investment Analysts, who are doing it all at the moment – they are spending too much time building software & models to get their own analysis, as opposed to having someone to deep dive into the technical part of the role, to pass the analysis onto them… You’ll manage the application of Decision Science techniques: you’ll create and maintain models and above all you’ll get excited about the investments you make. You will be joining a new kid on the block in the FinTech space, they are heavily backed, and they are going places. A small headcount, a lot of ownership, autonomy, and freedom to play with modern tech to solve problems. These folks will invest in you, the team, and the tech: and they are completely open to hearing your ideas. In return, you will receive the following: Competitive based salary between £50,000 to £60,000BonusPension schemeCity centre location with flexible working days/hours",Intermedio,Jornada completa,"Tecnología de la información, Finanzas","Banca, Servicios financieros, Servicios y tecnologías de la información",96,None,True,,274,ACTIVELY_HIRING_COMPANY
99,2187596848,2020-10-16,ALTEN Calsoft Labs,Data Scientist,United States,"Data Scientist Long Term Contract - On W2 Only As a fully functioning analytics team member, applies best practices to analytics solutions and contributes to the development of improved best practices.   Below are the MUST HAVES:At least 3-4 years of experience as Data Scientist.Must come from a IT Product, Media, eCommerce Company.Data analysis experience working with large-scale data.Strong experience using Python & SQL for analysis, modeling, and data visualization.Advanced statistics, data mining and modeling knowledge. Description:Partner with product, technology, and ops leaders to turn business problems into data problems and demonstrate creativity by using existing data to solve those problems.Years of experience in applied data science and analytics, including hands-on development and deployment of predictive modeling/machine learning models.Collaborate with business partners to identify opportunities, understand objectives, and rationalize efforts to support strategic business objectives with both short-term and long-term deliveries in an environment with high SLA expectations.Machine-learning engineer or applied data scientist who wants to work on exciting algorithmic and deep infrastructure issues. Knowledgeable in one or more of the following: machine learning, information retrieval, recommendation systems, social network analysis.Number of years of experience in applied data science and analytics, including hands-on development and deployment of predictive modeling/machine learning models. Requirements:Advanced Python for Data Science (descriptive / predictive models) + Strong Stats background Own the end to end data science process, from initiation to deployment, and through ongoing communication and collaboration, sharing of results to partners and leadership.Drive personalization, real-time decision-making, causal inference, and predictive analytics capabilities through the application of Machine Learning, Deep Learning, NLP, and Simulation in an agile development framework.Conduct quantitative analysis of experimental, and textual data to generate insights and drive decision making (ANOVA, Regression, Chi-Sq, AB, pre-post etc..) Working knowledge of SQL, Tableau, Hadoop, BigQuery, Presto, Vertica Write well documented code that can be shared and used across teams, and can scale to be used in existing products",Intermedio,Contrato por obra,Tecnología de la información,Servicios y tecnologías de la información,135,None,True,,444,COMPANY_RECRUIT
100,2149991410,2020-10-19,MCG Health,Staff Data Scientist,"Seattle, Washington, United States","We are a company of passionate individuals striving to improve healthcare and patient experiences. Our evidence-based medical content and software tools empower both payers and providers to make the best decisions for patients. Our work makes a difference in the quality of care that hundreds of thousands of patients receive each day and we’re proud of our positive impact.  MCG Health’s Data Science Solutions Team is responsible for building, delivering, evolving and operating the company’s Data Science Solutions. These solutions empower doctors, nurses and patients to make the best decisions for health outcomes and quality of life factors valued by patients. The primary purpose of the Senior Data Scientist is to provide thought leadership and pragmatic technical leadership to the Data Science Solutions group and their use of AI, Data Science, Machine Learning and Natural Language Processing Technologies. In this role you will:Collaborate with business, product, technical stakeholders and team members to deliver innovative solutions that improve the efficiency and effectiveness of healthcare deliveryBe an expert on problems that matter to MCG’s markets / clients, and propose approaches to leverage data, AI / ML / NLP / DS technologies and MCG’s assets to address these problemsContribute to establishing a team environment of collaboration, excellence and innovationProvide thought leadership regarding the continually advancing state of the art of readily available AI technologies and cloud-based services that are relevant to MCG products and solutionsContribute to establishment and evolution of methodologies for development and maintenance of data science models, to ensure effective usage and rapid, continuous improvementContribute to technology choices (build, buy, use open source) to support rapid experimentation and development of data models that can be readily transitioned to productionCollaborate with DSS and/or MCG software engineering leadership to deploy platforms to support data ingestion from internal and external sources, and to deploy platforms to support continuous transformation of successful models into production usagePartner with MCG technical leadership team to ensure compliance with security, privacy (HIPAA), regulatory and other obligationsRepresent MCG’s Data Science Solutions group, products and technologies to business and technical stakeholders at client companies and industry groups / associations We’d love to hear from you if: You have a minimum 5 years experience working with AI technologies You have demonstrated experience building one or both of: Predictive / classification models using Machine Learning techniques, NLP systems using Deep Learning, or other techniquesYou have demonstrated experience delivering successful ML and/or NLP solutions to the marketplace is required.You have demonstrated experience working with software engineers to design and deliver Data Science platforms and tooling for use by a Data Science team is required: this may include creating such a platform from the ground up or successful configuration / deployment / usage of third-party platforms augmented by internally built tooling as neededYou have demonstrated experience with cloud-based data science services You have demonstrated experience mentoring and providing technical leadership for data science model experimentation, and ongoing enhancement / evolution of solutions You have demonstrated the ability to think “outside the box” and identify business problems appropriate to usage of AI / ML / NLP / DS techniques is requiredYou have demonstrated proficiency with lean system development practices successfully applied to deliver business value at sustainable velocity We embrace diversity and equal opportunity, and are committed to building a team that represents a variety of backgrounds, perspectives, and skills. It is only with diverse thoughts and ideas that we'll be able to create the change we want in healthcare. The more inclusive we are, the better our work will be for it.",Intermedio,Jornada completa,Tecnología de la información,Atención sanitaria y hospitalaria,104,None,False,,739,ACTIVELY_HIRING_COMPANY
101,2157919944,2020-10-27,Loadsmart,Senior Data Science Engineer,Brazil,"Who we areLoadsmart aims to move more with less. We combine great people and innovative technology to more efficiently move freight throughout North America. Our focus is on designing and building the best tools for our team and our customers, using machine learning models to connect freight with trucks. We automate with algorithms and scale with integrations to better match supply and demand. In doing this we reduce wasted fuel and lost time, cutting out empty miles for motor carriers and providing cost savings and instant booking for shippers. Who you areWho you are: You believe in game-changing innovations and are excited about reimaging a 700 billion dollar industry. You know how to take ideas, optimize them, and push it into production code using Python. The RoleWe are looking for a Sr. Data Science Engineer to work remotely in Brazil with experience in Software Development to join us in the Sourcing Automation group in order to analyse, design and implement machine learning algorithms for systems that provide recommendations to source carriers, and that optimize margins of carrier prices. Key ResponsibilitiesModel predictive techniques to a variety of logistic problemsDevelop new (and improve existing) machine learning algorithmsImplement, release, and then maintain the algorithms running in productionAnalyse metrics and look for sourcing improvement opportunities QualificationsExperience in modeling and implementing predictive algorithms(either from scratch or by having used libraries / frameworks) Software development skills in Python, databases (such as PostgreSQL, Redis) and REST APIs (other programming languages, a plus)Software Design / Object-Oriented Programming / SOLID PrinciplesExperience implementing automated tests - unit and integration tests(test-driven development, a plus)2+ years of experience as a data scientist/machine learning engineer 3+ years of experience as a software developer5+ years of experience totalYou’re very comfortable communicating in English (both written and spoken) - you will work in an international team with native and non native english speakersNative proficiency in Portuguese languageCuriosity. You're keen on learning new technologies and tools as well as evaluating their pros and cons. You ask questions and are hungry to learn moreMS or PhD in a technical discipline would be cool, but it is not mandatory. We are an international company, so will only accept resumes in English. At Loadsmart, we believe our biggest asset is our people. We are proud to be an equal opportunity employer, hiring and developing individuals from diverse backgrounds and experiences to add to our collaborative culture. Loadsmart treats all candidates and employees with respect and does not discriminate in our recruiting, hiring, and promoting processes, including on the basis of race, color, religion, sex, age, sexual orientation, gender identity and/or expression, national origin, veteran status, or disability.",Intermedio,Jornada completa,Ingeniería,"Software, Internet",25,None,False,,370,None
102,2193255240,2020-11-04,AIM Consulting Group,Data Engineer,"Houston, Texas, United States","Let AIM Consulting guide you to success today! Our IT Placement Specialists are dedicated to placing qualified professionals, like you, in exciting opportunities with leading companies across the nation.  We are currently seeking a Cloud Data Engineer for a 100% remote eligible position with a great company! Unfortunately, no corp-to-corp candidates for this position. You can email Madison Nichols to apply directly at mnichols@aimconsulting.com.  Responsibilities:Create and maintain optimal data pipeline architecture, assemble large, complex data sets that meet functional and non-functional business requirements.Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.Build the infrastructure required for optimal extraction, transformation, and loading of data from a variety of data sources using ‘big data’ technologies.Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.  Qualifications:5+ years' experience in data engineering using Python 5+ years' of working within Azure including Data Bricks and Data Factory1+ year of experience using Snowflake  Preferred:Bachelor’s Degree in Computer Science, MIS, Math, Engineering or equivalent technical experience Benefits:Comprehensive Medical PlanPrescription ProgramDental PlanVision ProgramTerm Life Insurance Plans401(k) Retirement Savings Plan",Intermedio,Jornada completa,Tecnología de la información,"Software, Servicios y tecnologías de la información",108,None,True,mnichols@aimconsulting.com.,444,ACTIVELY_HIRING_COMPANY
103,2246968191,2020-10-27,ettain group,Data Scientist,"Charlotte, North Carolina, United States","Do you have two years of professional Data Science experience and a PhD?! Join a Fortune 40 retailer in Charlotte, NC to develop unique retail solutions! Requirements: 2 Years of experience as a Data Scientist within an enterprise environment PhDNatural Language Processing Experience (NLP)TensorFlow (Tool)Hands on development experience Python preferred  About the Role: The primary purpose of this role is to provide advanced analytical capabilities to support data science initiatives. This position gains experience in various areas including, but not limited to:Predictive modelingPersonalization and recommendation algorithmsNatural language processing and text miningSearch recall, precision, ranking, and related problemsOptimization and mathematical programming with applications in labor scheduling, inventory and capacity planning, network flows, and supply chain optimization *******No sponsorship available for this role********",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Venta al por menor,243,None,True,,760,ACTIVELY_HIRING_COMPANY
104,2273357936,2020-10-14,BitGo,Data Engineer,"Palo Alto, CA, US","BitGo is the leader in digital asset financial services, providing institutional investors with liquidity, custody, and security solutions. In 2020, BitGo launched Prime Trading and Lending, as well as BitGo Portfolio and Tax, providing clients with a full-stack solution for digital assets. In 2018, it launched BitGo Trust Company, the first qualified custodian purpose-built for storing digital assets. BitGo processes over 20% of all global Bitcoin transactions, and supports over 250 coins and tokens. BitGo's customer base includes the world's largest cryptocurrency exchanges and institutional investors and spans more than 50 countries. BitGo is backed by Goldman Sachs, Craft Ventures, Digital Currency Group, DRW, Galaxy Digital Ventures, Redpoint Ventures, and Valor Equity Partners.  The Custody Platform team is looking for a Data Engineer to work on new and existing projects. BitGo processes a significant amount of cryptocurrency transactions so our applications need to be fast, accurate, scalable and secure. Our integrated platforms interact with a number of exchanges, agencies, and governments around the world, and we use the best technology the industry offers to build them.  Responsibilities:   Develop tools endpoints to assist the customer success team with managing customers and identifying common customer support trends Create and manage both standardized and custom reports via company CRM and BI tools Construct and maintain CRM workflows and validation rules to ensure data integrity Provide reliable metrics and reports concerning customer billing and ensure our customers are properly billed on a regular basis Troubleshoot data issues quickly and communicate the resolutions in clear user-friendly language Investigate and resolve data quality, data loading failures and develop data cleansing routines Participate in regular revenue cycle projects such as audits analysis and compliance initiatives Administer tools APIs to extract and parse data from SQL and NoSQL data stores for the purpose of both external and internal reporting  Requirements:   Minimum 5 years of related experience building and managing ETL processes Expert in scripting, regular expressions and task automation Advanced experience with scriptwriting, database architecture and platform/system administration process knowledge Advanced knowledge of database solution languages Experience in creating and maintaining optimal data pipeline architectures, emphasizing performance, resiliency, and high-volume processing Excellent verbal and written communication skills BS or MS in Computer Science or equivalent experience  Nice to have:   Knowledge of/or experience with blockchain technology Knowledge of/or experience with fintech Knowledge of data visualization tools such as Tableau or similar Past experience with accounting tools Experience with writing analytics tools to provide actionable insights into operational efficiency, financial reports, and other key business performance metrics (KPIs)  Experience with JavaScript   Why Join BitGo?  Disrupting an industry takes vision, innovation, passion, technical chops, drive to deliver, collaboration, and execution. Join a team of great people who strive for excellence and personify our corporate values of ownership, craftsmanship, and open communication. We are looking for new colleagues who bring innovative ways of thinking and problem solving, and who want risks to be part of the team that changes the world's financial markets.  Here are some of the benefits of working at BitGo:   Competitive base salary, bonus and stock options 100% company paid health insurance for employee, spouse/partner and children (medical, vision, dental, life, FSA, HSA) 401k company match up to 5% Paid parental leave Catered custom lunches, fresh snacks and gourmet coffee at the office Computer equipment and workplace furniture to suit your needs Paid vacation time  Great colleagues and inspiring startup environment  Cryptocurrencies are the most disruptive change the financial services industry has seen in years. Join us and you'll be able to look back and say you were part of the team that transformed investing.",Sin experiencia,Jornada completa,Tecnología de la información,"Software, Internet, Servicios financieros",10,None,False,,73,ACTIVELY_HIRING_COMPANY
105,2251564975,2020-11-06,Advantage Resourcing UK Ltd,Data Scientist,"Somerset, England, United Kingdom","SC Cleared - Data ScientistInitial 3 month contract inside IR35. Based in Taunton, Somerset - predominantly remote working at the moment but you should be able to come to the office if needed.  Advantage Resourcing are recruiting on behalf of a well established public sector organisation who provide critical geospatial data services to organisations. They seek a Data Scientist with significant experience with Deep Learning/MLOps approaches.  You must be capable of confidently programming in one or more of the following: R, Python, Matlab, Scala, and able to pick up other programming languages quickly. You must be able to offer production experience of data analytics, data processing, data visualisation, scientific research methods and machine learning. Excellent communication and team working skills are important.  Desirables:Experience of processing geospatial, marine or oceanographic data – particularly 3D point clouds – bathymetry or lidar data.Production experience of deep learning, Python, Cloud and geospatial datal.Experience with bathymetric data, lidar data or some other form of 3D point cloud data. Submit your CV now via the link to be considered. Job Ref# 836254",Intermedio,Contrato por obra,"Tecnología de la información, Ingeniería","Administración gubernamental, Servicio de información, Servicios y tecnologías de la información",45,None,True,,156,ACTIVELY_HIRING_COMPANY
106,2259618180,2020-10-31,Civis Analytics,"Applied Data Scientist, Government","Washington, D.C., DC, US","What We Do  At Civis, we take a science-first approach to solving problems. With a blend of proprietary technology and statistical advisory services, we help public and private sector organizations find, understand and connect with the people they care about, so they can stop guessing and start using mathematical proof to guide decisions. We know others use 'data science' and 'analytics' as buzzwords, but at Civis we don't stand for fluff, and we will always deliver scalable products and technologies — not PowerPoints — to drive your business forward. Learn more about Civis at www.civisanalytics.com.  Our mission  Our mission is to bring objective, data-driven truth to organizational decision-making – all the way from the boardroom to the world's largest social causes.  What We Are Looking For  Are you interested in using data science to solve new and challenging problems in innovative ways — like helping cities, states, and the federal government use data to improve citizen services and outcomes? Civis Analytics is looking for an Applied Data Scientist to join our government Applied Data Science practice and help us solve some of the most challenging and interesting questions facing businesses today.  The Applied Data Science (ADS) team is the solutions and advisory arm of Civis Analytics and works closely with organizations to help solve their toughest challenges with data science. This role of Applied Data Scientist will support clients in our government verticals specifically and report to an Applied Data Science Manager.  Due to the uncertainty of COVID-19, all Civis offices are closed and all employees are remote for the foreseeable future. This is being closely monitored as things change and it's likely our offices will reopen. Because of this uncertainty, we want to ensure candidates are open to relocating to one of our offices in the future, but other locations may be negotiable.  Responsibilities  An Applied Data Scientist is responsible for the end-to-end execution of client engagements utilizing data science, which includes: Unifying large 1st- and 3rd-party datasets and building predictive models Deriving clear, actionable, and timely insights from analyses Creating client-ready materials and solutions for stakeholders of varying technical experience or familiarity with methods Working with cross-functional teams of data scientists and software engineers where necessary to create and implement solutions  Other job responsibilities of an Applied Data Scientist include: Creatively identifying opportunities in the solution delivery process for scalable applications, and collaborating with other teams to further construct these tools Maintaining a continuous and independent education of cutting-edge statistical techniques and programming languages  Travel requirements: < 5%   Minimum Qualifications  Bachelor's degree in an analytical subject (statistics, math, economics, physics, engineering, business, political or social science, computer science, etc.) Proven affinity for and experience working with large or messy data sets SQL experience a plus  Experience with statistical programming languages (R, Python, etc.) and proven ability to work pragmatically with statistical concepts Experience with presentation or data visualization software, such as Microsoft PPT, Tableau, Shiny, etc. Excellent interpersonal and communication skills US work authorization   Preferred Qualifications  Practical understanding of and experience with predictive analytics, machine learning, and/or causal inference Familiarity with software development tools and practices (Git, code review, etc.)   Who We Are  At Civis, we have opportunities for applicants who are newcomers, seasoned professionals, and anywhere in between. Our teams are energized by complex challenges and value diversity of thought. Opportunities to stand out and inspire happen daily and we trust and encourage you to act on your ideas – no matter how big they are. We offer you the tools and community you need to do your best work. Each of us is committed to holding ourselves accountable for results, challenging the status quo and finding new ways to grow our company and each other.  Why join our team?  The opportunity to be part of a growing tech startup focused on solving interesting and meaningful problems, invested in internal promotion, and committed to fostering a diverse, equal and inclusive workplace.  Competitive benefits, including unlimited PTO, 401K match with immediate vesting, health, dental, and vision benefits, fully paid parental leave, breastfeeding support including breastmilk shipping services for traveling moms, commuter benefits, wellness initiatives including weekly group meditations, monthly on-site massage therapy, and pet insurance.  To support employees in our now fully remote work environment, we also have expanded our virtual journal and book clubs, Donut Pals (organized virtual coffee meet-ups), Lightning Talks (5-minute presentations on anything you'd like), Lunch-and-Learns, and HR Open Discussions (bi-weekly meet-up where we discuss ideas and topics of the day in a casual format). We are also able to support and accommodate flexible work from home schedules to help employees juggle responsibilities at home.  Civis Analytics embraces the individuality of our employees and we celebrate each other's differences. Our products, services, and culture benefit from and thrive on the unique perspectives brought by each person in our community. We're proud to be an equal opportunity workplace, and we are committed to equal employment opportunity regardless of race, age, sex, color, ancestry, religion, national origin, sexual orientation, gender identity, citizenship, marital status, disability, or Veteran status. If you have a disability or special need that requires accommodation, please contact internalrecruiting@civisanalytics.com  In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States.  EEO IS THE LAW  EEO Supplement  Pay Transparency",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Marketing y publicidad, Software, Internet",99,None,False,internalrecruiting@civisanalytics.com,466,ACTIVELY_HIRING_COMPANY
107,2273321878,2020-10-10,LAAgencia,Data Scientist (Remote),"Mexico City, MX","Hello!  ¡We are looking for a Data Scientist to work remotely in Mexico City!  Our team:  Our expectations are pretty high for Data Scientist positions. The Data Science team plays a leading role in solving our most challenging problems and guiding the decisions that we take around product.  Impact:  Build, implement, and maintain machine learning systems in technology products. Lead engineering best practices for scaling ML and designing/building software that is reliable, scalable, and secure  Be responsible for the implementation, testing, and release of a range of models, both for existing and “to-be-invented” use cases  Work closely with Machine Learning scientists to design, code, train, test, deploy, iterate and own state-of-the-art systems for executing ML models  Building end-to-end data pipelines to train, maintain, and track performance of our Machine Learning and Operations Research products  Requerements:  2+ years as Data ScientistAdvanced englishPython, R, SQL Benefits:  Negotiable salary100% remote  Powered by JazzHR  iKQUZ10Umx",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Software, Servicios financieros",12,None,False,,55,JOB_SEEKER_QUALIFIED
108,2268965111,2020-10-13,REED,Data Engineer (Part remote),"South Glamorgan, GB","I’m recruiting a mid to senior level Data Engineer for a permanent role in Cardiff. The salary is circa £45,000 - £52,000pa + benefits and the role is fully remote initially, with part-remote working available afterwards.  Reporting in to the Data & Analytics Manager you'll be responsible for the design and maintenance of autonomous data pipelines and solutions. My client have recently built an Enterprise Data Platform and are looking for a Data Engineer / BI Developer with strong ETL experience to join the team and contribute towards the changing data landscape within the business. In this role you’ll gain exposure to Cloud technologies and Big Data architectures.  Requirements: -  1+ year experience in a BI / Data Engineering role SQL & Python programming experience Solid understanding of data processing and ELT / ETL  If you’re interested please apply ASAP or email Alistair.Cooke@reed.com for further information.",Sin experiencia,Jornada completa,Tecnología de la información,"Construcción, Dotación y selección de personal, Servicios financieros",None,None,False,Alistair.Cooke@reed.com,15,ACTIVELY_HIRING_COMPANY
109,2227530931,2020-10-22,Charles Levick Limited,Quantitative Researcher,"London, England, United Kingdom","Charles Levick is partnered with an international investment manager specialised in deploying systematic, computational trading strategies across multiple asset classes (equities, fixed income and FX). As part of the Quantitative Research team you will work alongside traders, researchers, software engineers to develop and evaluate automated trading strategies.  Main responsibilities:﻿End-to-end strategy development, involving alpha concept generation, data processing, back-testing and implementationWork closely with software engineers to develop and enhance core models and trading algorithmsIdentify and analyse new data-sets to discover and capture trading opportunitiesPerforming detailed assessments of model subcomponents to understand model risk Requirements: PhD or Msc in a quantitative field with a strong foundation in statisticsDemonstrated proficiency in Python or C++Familiarly with data science toolkits, such as scikit-learn, Pandas, keras, tensorflowAbility to scrub, format, and manipulate large, raw data sourcesExperience in systematic alpha research and creating intraday alpha signalsCooperative mindset with great independent research capabilities Applicants may reach-out directly to mathew.abbott@charleslevick.co.uk",Intermedio,Jornada completa,Análisis,Gestión de inversiones,294,None,True,mathew.abbott@charleslevick.co.uk,1030,ACTIVELY_HIRING_COMPANY
110,2231284866,2020-11-02,Pactera EDGE,Data Scientist,India,"Role: Data ScientistSkill: Deeplearning, NLP,AI,MLExperience:1.5yrs to 3.6yrsLocation: Anywhere India Note: Candidates form Premier colleges like IIT,NIT,BITS and IIIT can apply Job Description:Responsibilities for Data ScientistWork with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.Mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies.Assess the effectiveness and accuracy of new data sources and data gathering techniques.Develop custom data models and algorithms to apply to data sets.Develop company A/B testing framework and test model quality.Coordinate with different functional teams to implement models and monitor outcomes.Develop processes and tools to monitor and analyze model performance and data accuracy.Qualifications for Data ScientistStrong problem solving skillsExperience using statistical computer languages (R, Python, Google Big Query, Cloud AutoML) to manipulate data and draw insights from large data sets.Experience working with data architectures.Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.Excellent written and verbal communication skills for coordinating across teams.A drive to learn and master new technologies and techniques.We’re looking for someone with 2-3 years of experience manipulating data sets and building statistical models, is a Engineering graduate from Tier 1 and Tier 2 schools in India and is familiar with the following software/tools:Coding knowledge and experience with several languages: PythonKnowledge and experience in statistical and data mining techniques: Facebook Prophet, GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, etc.Experience querying databases and using statistical computer languages: R, Python, Google Cloud Big Query, Auto ML and other Google products.Experience using web services: Redshift, S3, Spark, DigitalOcean, etc.Experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc.Experience visualizing/presenting data for stakeholders.",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Servicios y tecnologías de la información,407,None,True,,908,ACTIVELY_HIRING_COMPANY
111,1998179199,2020-10-30,Skyrocket Ventures,Computer Vision Research Scientist / Researcher - Augmented Reality Startup,San Francisco Bay Area,"Computer Vision Research Scientist / Researcher - Augmented Reality Startup(Multiple openings from Jr. to Lead level)Location: Redwood City, CA (you can work remotely as much as you'd like, even after the pandemic)  Note: To be qualified for this position, you must have authored at least one computer vision publication (preferably several to many) in top conferences such as CVPR, ICCV, ICLR, ECCV, NIPS, or PAMI).  The company's product is in the realms of augmented reality, computer vision, deep learning, navigation, machine learning, and edge processing. The product has similarities to autonomous vehicle technology but is not for autonomous vehicles and will be available on the market in the near future. The company has about 10 employees and 9 engineers and is about to raise series A funding. In this position, you would be doing about 90% research and 10% coding. The company will pay competitive salary (up to $200k or more depending on experience), plus equity which could be very lucrative.  Qualifications: - Authored at least one computer vision publication (preferably several to many) in top conferences such as CVPR, ICCV, ICLR, ECCV, NIPS, or PAMI). - Expertise in both classical and deep learning computer vision techniques for object recognition, semantic segmentation, or 3D geometry. - A Master's Degree or PhD (strongly preferred) in Computer Science or similar, with a focus on Computer Vision. - Familiartity with OpenCV, and ability to write clean code in Python and/or C/C++. - Experience with deep learning frameworks such as Torch, PyTorch, Keras, Caffe/Caffe2, Tensorflow, etc.  Nice to have: - Sampling methods, optimization, graphical models, and statistical machine learning - Experience with CUDA, OpenGL, and/or OpenCL. - Object detection and localization. - Object tracking. - Semantic segmentation and image segmentation. - SVM, random forests, ensemble models, clustering, boosting, and other non-deep learning ML methods.",Intermedio,Jornada completa,"Investigación, Ingeniería","Software, Internet",454,None,True,,1703,ACTIVELY_HIRING_COMPANY
112,1917866327,2020-10-08,Megaphone,Data Engineer,United States,"About the RoleMegaphone is looking for a Data Engineer to help develop and own data solutions at our fast-paced podcast technology and ad services company. The Data Engineer role is an excellent opportunity for someone who wants to join a close-knit and smart team at a rapidly growing business. If you are a highly independent worker and have excellent organizational and problem-solving skills, this is the job for you. Working at Megaphone also means full benefits, competitive salary, and a friendly work environment. This role is open to fully remote candidates, as well as candidates near our Reston, VA office. This role will report to the VP of Engineering. Key ResponsibilitiesDevelop and maintain ETL/ELT processes at scale, handling hundreds of millions of records per dayWrite advanced SQL for data wrangling, as well as scheduled reporting and automated queriesPerform data exploration and analytics with the goal of developing new insights and business valueHelp develop APIs and dashboards to surface data insightsMaintain awareness and knowledge of industry best practices to ensure Megaphone is able to take advantage of new tools and techniques Requirements and Attributes of the Ideal Candidate3+ years of experienceHands-on implementation and maintenance of a large-scale, high-volume data pipelineKnowledge of programming language(s) for data processing, such as Python, Scala, R, and libraries and tools, such as DataflowExperience with Ruby and/or Go is preferredIn-depth knowledge of relational databases (e.g. PostgreSQL, MySQL) and NoSQL databases (e.g. Druid, Cassandra), as well as analytics using BigQueryFamiliarity with containers and related technologies, such as Docker and Kubernetes, and working with public cloud (e.g. AWS or Google Cloud Platform)Knowledge of machine learning and time-series forecasting methodologiesAnalytical mind with problem-solving aptitudeAbility to work independently Application RequirementsTo apply, please send a resume to dataengineers@megaphone.fm  Megaphone is committed to excellence through diversity, which involves attracting talented people from diverse backgrounds and traditions. We encourage everyone to apply.",Algo de responsabilidad,Jornada completa,Ingeniería,Medios de comunicación en línea,347,None,False,dataengineers@megaphone.fm,1955,None
113,2222455820,2020-10-29,C2FO,Data Engineer,"Leawood, KS, US","C2FO is working to deliver a future where every company in the world has the capital it needs to grow. Our technology provides an easy, low-cost way for businesses of all sizes to increase cash flow by receiving early invoice payments. Since 2008, C2FO’s online marketplace and innovative financial products have accelerated payments by more than one billion days for companies in over 180 countries.  Named one of Forbes’ “Fintech 50,” C2FO provides more than $1 billion in working capital each week for hundreds of thousands of businesses. C2FO has more than 400 employees worldwide, with headquarters in Kansas City and locations throughout Europe, Asia Pacific and Australia. For more information, visit www.C2FO.com.  Commitment to Diversity and Inclusion   Pollen, Inc. (C2FO) believes that unique backgrounds and individual voices strengthen our team, leading to the best ideas and discoveries for our innovative and growing company. At C2FO, we seek, encourage, and nurture diverse perspectives, and we welcome those of all backgrounds to help us change the way global businesses of all sizes gain access to working capital.   As an organization, we not only value diversity and equality, we cultivate teams that feel empowered to bring their authentic selves to work every day. We strive to create a workplace that reflects the communities we serve and our global, multicultural clients. We recognize the power of inclusion, emphasizing that each team member was chosen for their unique ability to contribute to the overall success of our mission.   Data is the lifeblood of any technology company. At C2FO, we know the best way to ensure our success is to provide our decision-makers with the most accurate, most relevant data possible.  Our Data Engineers use cutting-edge, open-source technologies to collect, process, and store the company’s data.   They also work closely with talented scientists, engineers, and data experts to solve complicated long-term financial and working capital problems for clients in different industries, including Retail, Technology, and Health Care.  Responsibilities  Work closely with Software Engineers, Data Scientists, and Business Analysts to meet the company’s data storage, access, and analysis needs. Collaborate with the Development and Operations teams to deploy and maintain clustered computing across multi-cloud environments. Monitor, maintain, and enhance existing data structures to ensure reliability and data integrity. Design and build large-scale, automated ingestions pipelines that integrate across multi-cloud platform and disparate data sources. Evaluate cutting-edge technologies for integration into existing technology stack.  Aptitudes y experiencia deseadas   Requirements  Bachelor’s degree in Computer Science or a related field. 3 years of experience in the job offered or in a related position. Demonstrated proficiency in data analysis and pattern identification. Advanced proficiency with Big Data streaming and processing technologies. Experience using technologies in the Hadoop Ecosystem and Linux/Unix operating systems. Proficiency with a JVM language or experience coding within a functional programming paradigm. Experience with cloud-hosted computing. Experience using a version control system. Strong demonstrated SQL and data modeling skills or experience. Familiarity with Distributed Computing and Parallel Processing frameworks. Familiarity with data science and machine learning concepts or methodologies. Applicants must have the legal authority to work in the United States.   C2FO is an Equal Opportunity and Affirmative Action Employer. We welcome all veterans and disabled applicants.",Algo de responsabilidad,Jornada completa,Ingeniería,Servicios financieros,42,None,False,,285,ACTIVELY_HIRING_COMPANY
114,2246968191,2020-10-27,ettain group,Data Scientist,"Charlotte, North Carolina, United States","Do you have two years of professional Data Science experience and a PhD?! Join a Fortune 40 retailer in Charlotte, NC to develop unique retail solutions! Requirements: 2 Years of experience as a Data Scientist within an enterprise environment PhDNatural Language Processing Experience (NLP)TensorFlow (Tool)Hands on development experience Python preferred  About the Role: The primary purpose of this role is to provide advanced analytical capabilities to support data science initiatives. This position gains experience in various areas including, but not limited to:Predictive modelingPersonalization and recommendation algorithmsNatural language processing and text miningSearch recall, precision, ranking, and related problemsOptimization and mathematical programming with applications in labor scheduling, inventory and capacity planning, network flows, and supply chain optimization *******No sponsorship available for this role********",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Venta al por menor,243,None,True,,760,ACTIVELY_HIRING_COMPANY
115,2224720447,2020-10-29,Prospect 33,Data Scientist (Bootcamp 33 REQUIRED),New York City Metropolitan Area,"Are you seeking to advance your Data Science career in the Financial Services industry? Eager to consult with some of the top players in the industry? If so, look no further! We are seeking eager Data Scientists who are looking to enter the Financial Services field and impact real change in the industry. To qualify for these opportunities, you must first attend Bootcamp 33- please follow the link to be taken to our webiste, simply click 'Apply Now' and be directed to our Qualifying Quiz.  The ideal candidate's favorite words are learning, data, scale, and agility. You will leverage your strong collaboration skills and ability to extract valuable insights from highly complex data sets to ask the right questions and find the right answers.  ResponsibilitiesAnalyze raw data: assessing quality, cleansing, structuring for downstream processingDesign accurate and scalable prediction algorithmsCollaborate with engineering team to bring analytical prototypes to productionGenerate actionable insights for business improvements QualificationsMaster's degree or equivalent experience in quantative field (Statistics, Mathematics, Computer Science, Engineering, etc.)At least 1 - 2 years' of experience in quantitative analytics or data modelingDeep understanding of predictive modeling, machine-learning, clustering and classification techniques, and algorithmsFluency in a programming language (Python, C,C++, Java, SQL)Familiarity with Big Data frameworks and visualization tools (Cassandra, Hadoop, Spark, Tableau)A desire to work in the financial services industry",Algo de responsabilidad,Jornada completa,"Análisis, Finanzas, Consultoría","Servicios financieros, Banca, Banca de inversiones",133,None,False,,624,ACTIVELY_HIRING_COMPANY
116,2220551736,2020-10-28,Primer.ai,"Senior Machine Learning Engineer, Platform",San Francisco Bay Area,"As a Senior Machine Learning Engineer, you will have the opportunity to make a wide impact on our machine learning processes, tooling, coding standards, and codebase. Primer believes in creating an environment that encourages and creates opportunities for growth. Whether it’s helping create and contribute to a set of architectural principles, or pushing us to adopt high-impact OSS, we need engineers to help us make those decisions. About Primer: The world is changing at an accelerating rate and understanding the shifting landscapes has never been more critical. Primer is the premier artificial-intelligence powered platform that allows humans to get information that they need, instantly, in ways that until now have not been possible. We believe that truth is knowable: our mission is to free the curious to be their most human. We are building machines that can read natural language text documents, understand them, correlate them into events, and share what they learn by writing their own natural language text documents.  At Primer, we use machine learning and natural language processing to automate the exploration of very large corpora of unstructured text. We build systems that read documents, extract insights, and write reports comparable to those of a human analyst. Our objective is to help our customers understand the world around them –– from geopolitical events and scientific research to changes in the risk profiles of companies. Our clients include some of the world’s largest corporations, financial institutions, and government agencies. You can learn more about Primer's technology and the sort of problems we solve at our blog, as well as recent media coverage of our work. From your first day, you’ll drive the technical implementation of a major feature. You might... ... design and build a pipeline to train models for NLP problems like Classification, Question Answering, Summarization... scale our ability to run models to process millions of documents... develop APIs that showcase our models’ capabilities and enable third-party integrations... collaborate with the research team to train and ship state of the art models... evaluate, adopt, and contribute back to open-source software to build out the Primer technology stack We Like:Curiosity and enthusiasm, and a love for teaching and learningExpertise in PythonExperience applying machine learning algorithms to real data sets, preferably including text analysis and NLP5+ years of shipping commercial software (SaaS, or PaaS) to third parties outside your company. Bonus Points: Experience building human-in-the-loop ML pipelineExperience in GoLangExperience with Language models like BERT, XLNet, GPT What we offer: Health, Dental, Vision BenefitsUnlimited Paid Time OffSmart, engaged co-workers who are at the top of their gameHonest and open environment for exchange of ideasReal customers with global name recognition + healthy sales pipelineProactive learning and teaching opportunities via individual book allowances, tech talks, and brown bag lunchesTeam outings and bi-weekly company happy hoursFun, puzzle-loving office in the SF Financial District  Primer is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. Please see the United States Department of Labor's EEO poster and EEO poster supplement for additional information. If you need assistance or an accommodation due to a disability, you may contact us at info@primer.com. Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.",Intermedio,Jornada completa,Ingeniería,Internet,75,None,True,info@primer.com.,297,JOB_SEEKER_QUALIFIED
117,2211188476,2020-10-26,Resolute Asset Management,Junior Machine Learning Engineer,Ukraine,"About the Team Science and Data sits at the heart of Resolute Asset Management and plays a uniquely crucial role in what we do. With data we build intelligent Real-Estate Asset Management capabilities that helps our Clients and Analysts to understand and maximise the return of their granular portfolios. Fundamentally, data underpins the innovation and scaling of our current and future business at Resolute Asset Management and being part of the team gives you the chance to have a major impact across the company – apply today to join our world class data science team.   About The Role The driving force of managing Real-Estate assets is to build a complete 360 digital identity of each asset and provide the users with the intelligence to make decisions on the liquidity, value and segmentation to maximise the revenue from their assets. You will be in the centre of this product – as a Machine Learning Engineer you will work in the Data Science team, the Back-end and Front-End Engineers as well with client teams to create a set of Products to help lead the market in Real-Estate Asset Management using a range of technologies such as NLP, Data extraction and remediation, Image recognition, financial modelling, Proprietary models for Asset value, Liquidity and target Audience, GIS and local information driven insights. What Skills You'll Need 1 years proven experience as a Machine Learning Engineer or similar rolePython for data modelling, advanced analytics, automated pipelines and software developmentAble to come up with new data ideas as well as focus on the internal business to drive efficiencies and innovationKnowledge of ML and AI algorithms and the theoretical/practical/statistical reasoning behind themFamiliarity with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn)SQL for working with database (PostGIS knowledge is desired)Experience of cloud technologies like google cloud platform (BigQuery, Google Storage etc.) and distributed data computingWorked with data visualisation techniques from simple charts to maps within custom reports or interactive dashboards (with Javascript, Qliksense, PowerBI etc.)Used data scraping techniques to extract information from various websitesInterest in Real Estate and Property MarketCommercial and business development knowledgeFollow methodologies for existing projects and research/develop new technologies and solutionsHave communication skills, good at data storytelling and confident to present products and service offeringsDesign proof of concepts and deliver minimum viable products to internal stakeholders and external clients Fluent in EnglishExperience in geospatial domain, GIS applications and expertise in spatial data engineering is desirable A Bit About Us Resolute Data Science believes that enabling our clients and analyst with impactful data and intelligent technology will enable the growth of projects with our existing clients and to acquirenew clients. Resolute Asset Management started in 2010 and Resolute’s combination of real estate, banking and finance capabilities allows us to deliver tangible, measurable benefits to our Financial Institution clients throughout the business cycle. Our ability to understand not just asset specific and real estate sector issues, but also regulatory, accounting and general banking frameworks ensures we deliver practical solutions to real estate related banking challenges. What We Are Looking For You will be self-motivated and yearn for making an impact through your skills and determination.You look for solutions to overcome problems and lead by example even if in a junior position. You can work autonomously and take ownership. We thrive with the space and responsibility to solve problems. You operate best without lots of bureaucracy. We don’t hide behind fancy job titles or clunkyprocesses ‘because that’s how things are done’. You approach work in a logical way. We are not afraid to make mistakes, but we use scienceand data and logic to backup decisions and improve understanding.  The Benefits Competative Salary - up to €20,000 per annumInclusion in company annual bonus schemeAll the latest tech you needWork Anywhere - working from home and flexible hoursPension planRest up with 25 days’ holiday per year",Algo de responsabilidad,Jornada completa,"Ingeniería, Tecnología de la información","Servicios financieros, Bienes inmobiliarios, Bienes inmobiliarios comerciales",211,None,True,,618,ACTIVELY_HIRING_COMPANY
118,2218881874,2020-10-28,IQVIA,Data Scientist,"Warsaw, PL","Data Science & Advanced Analytics  Data Science & Advanced Analytics - with departments in Frankfurt, Philadelphia, Beijing and Warsaw as well as a network of over 150 team members worldwide - is the global competence centre for data science at IQVIA. Complex advanced analysis at the highest level are conceptualized and implemented to support international customers in the pharmaceutical industry - often within multinational projects. As a member of our team you can expect exciting international projects with interesting development perspectives.  Data Scientist, Data Science & Advanced Analytics – the role Collaboration in projects of the European Data Science & Advanced Analytics TeamSupport in development and execution of complex statistical, econometric, and machine learning analysis (Advanced Analytics, Predictive Analytics), especially in the area of Commercial Effectiveness (e.g., Next Best Customer, Profiling, Segmentation and Targeting, Brand Performance drivers and optimisation, etc) and Real World Evidence (e.g., risk of disease progression, treatment compliance, etc) in collaboration with European local officesSupport in development of innovative methodologies to deliver custom solutions to our clients as well as execution and implementation of concept studies using advanced statistical methodsApplication of modern data mining and machine learning techniques in connection with Healthcare Big Data to identify complex relationships, to derive business-relevant findings, and develop new offerings Support in the implementation of new statistical and machine learning technologiesWorking with technology teams to support machine-learning algorithms in big data platforms  Our Ideal Candidate Will Have Master degree in Mathematics/Statistics, Economics/Econometrics, Computer Science or related fieldAt least 2 years of professional experience in quantitative data analysis or PhD with at least 1 year of relevant professional experience with research in machine learning algorithmsGood knowledge and understanding of Machine Learning methodsExperience applying Machine Learning methods to business questionsGood knowledge of the higher statistical and econometric methods in theory and practiceExperience with handling Big DataSkilled in Python/R and SQLFluent in EnglishKnowledge of German and/or Polish language would be an assetStrong analytic mindset and logical thinking capability, strong QC mindsetDemonstrates consulting, creativity, critical thinking, project planning, and attention to detail capabilitiesKnowledge of pharmaceutical market and experience with pharmaceutical data (medical, hospital, pharmacy, claims data) would be a plus, but not a must  We know that meaningful results require not only the right approach but also the right people. Regardless of your role, we invite you to reimagine healthcare with us. You will have the opportunity to play an important part in helping our clients drive healthcare forward and  Whatever your career goals, we are here to ensure you get there!  We invite you to join IQVIA™.  At IQVIA, we believe in pushing the boundaries of human science and data science to make the biggest impact possible – to help our customers create a healthier world. The advanced analytics, technology solutions and contract research services we provide to the life sciences industry are made possible by our 67,000+ employees around the world who apply their insight, curiosity and intellectual courage every step of the way. Learn more at jobs.iqvia.com.",No corresponde,Jornada completa,"Ingeniería, Tecnología de la información",Industria farmacéutica,157,None,True,,577,COMPANY_RECRUIT
119,2243956329,2020-11-06,IOV Labs,Researcher Developer,"Berlin, Germany","The internet has democratized Information but billions of people still dream of financial equality. At IOV Labs we are planting the seeds for a new global economy. Our low-cost, highly secure, easy to use platforms harness and extend the power of Bitcoin giving everyone the tools to create and protect wealth on an international scale. With our platforms RSK, RIF and Taringa people everywhere will have the power to create and manage digital identity, build reputations, enforce agreements and engage in commercial transactions without intermediaries.We dream of a world in which individuals control their data and privacy, participate in a sharing economy and thrive.Join our team to be part of the next technological revolution and help us build the Internet of the Future.We are looking for open-minded, passionate, analytical, and hard-working developers with interest in cryptocurrencies and the blockchain ecosystem to join a highly qualified team of technical excellence for one of the most challenging projects in the Bitcoin and FinTech industry worldwide. Our Innovation/Applied Research Team seeks to incorporate experienced developers who:Want to put their theoretical computer knowledge into practice, from writing complex data structures to designing critical algorithms for network performance.Enjoy writing code but also and formally analyzing algorithms and protocols. As part of the Innovation/Applied Research Team you may have the following responsibilities:Analyze blockchain designs and code from the security perspective and find design vulnerabilitiesDesign, evaluate, use, and produce PoC implementations for blockchain technologiesMake sound recommendations based on research findings and product performanceWrite research reports, blog posts and scientific papersGive oral presentations on key blockchain technologies in fluent English Experience & Skills RequiredRequires bachelor’s degree in area of specialty, such as math or computer scienceSenior-level programming skills in one procedural languageFluent written and oral EnglishWilling to work in a fast paced and highly agile environmentExcellent interpersonal and communication skills. Other Desired SkillsSubject matter expertise in blockchain and related technologies (computer privacy, computer security, cryptography, number theory, distributed systems, algorithm complexity, data structures, game theory, statistics, economics)Superior analytical skills, applying conceptual models, recognizing patterns while drawing and defending conclusions.Strong knowledge and passion for FinTech and financial services, Bitcoin, RSK & Ethereum, willing to work in this fast-moving environment. TypeFull time LocationThe location is not an issue, since we are hiring globally.",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Servicios y tecnologías de la información,22,None,True,,219,ACTIVELY_HIRING_COMPANY
120,2203382157,2020-10-23,Canva,Machine Learning Engineer (Python),"Auckland, New Zealand","Designing with Canva involves making many choices, out of our incredibly large content pool of over 75M+ templates, photos, videos and elements. The Content Recommendations team is building machine learning-driven recommendations and a personalised content experience, helping to narrow down these choices, and make design easier, smarter, and more magical.  We're looking to grow the team to continue to scale the impact of recommendations across Canva. You'll be joining a fast moving team, rapidly building and shipping machine learning-driven recommendations to users, and making it effortless for users to discover the most relevant content for them. ResponsibilitiesHypothesis-driven development of recommendation features across Canva.Engineering implementation: developing and implementing ML models and features, as well as using third party APIs and pre-trained models when appropriate.Running offline and online recommendations experiments.Investigating and spiking applications of recommendations across the Canva product, considering tradeoffs between different approaches and rapidly shipping.Contributing to the full life cycle of ML/data models: data analysis, data preprocessing and pipeline, modelling, tuning and productization.Improving the scalability, speed and performance of existing models.Working alongside data specialists, software engineers and product owners to identify business and growth opportunities.Designing and creating new data workflows and deploying these workflows to users. Sharing and articulating statistical analysis, modelling, experiment and results to technical and non-technical audiences. RequirementsPrevious experience in the machine learning / data science domain.Experience building and deploying machine learning models, ideally recommendations models. Strong understanding of end-to-end machine learning pipelines and components.Coding proficiency in Python, interviews will be in Python. Experience in Scala is preferred. Strong understanding of Computer Science/Engineering fundamentals and first principles covering system design, data structures, architecture, and design patterns.Familiarity with big data tools: Apache Spark, Hadoop, MapReduce. SQL experience preferred.Strong research skills: the ability to dig through deep learning literature and translate this into product and value for users.Bachelor's degree in Computer Engineering / Science or Mathematics.Excellent collaboration and communication skills. Perks and BenefitsFlexible daily working hours, we value work-life balanceBreakfast and lunch prepared by our wonderful Vibe teamOnsite-Gym and Yoga MembershipEnd-of-Trip Facilities: Bicycle parking and showersGenerous parental (including secondary) leave policyPet-friendly officesSponsored social clubs, team events and celebrationsRelocation budget for interstate or overseas individuals (see below for visa information) Want to experience Canva for yourself?Check out what life is like at Canva on Instagram.Check out what our users are saying about us on Twitter.Learn how we work from Dave, our CTOGet to know our Chef, ChrisMeet our CEO, MelanieFinally, give Canva a go! If you're seeking professional growth and enjoy working on large, distributed, cloud-based applications that delight our millions of individual and business users alike - then apply now to be considered for the position! If you require visa sponsorship, you must ensure you have at least two (2) years of post-University commercial experience as a Software Engineer and meet the mandatory sponsorship requirements laid out by Department of Home Affairs. We will not accept or review any CVs from external recruitment agencies.",Intermedio,Jornada completa,"Tecnología de la información, Investigación","Servicios y tecnologías de la información, Software",205,None,True,,1122,COMPANY_RECRUIT
121,2218962133,2020-11-02,Cloud Theory,Data Scientist,United States,"Summary/ Objective:A CRM services company is looking for a Data Specialist with extensive working knowledge of SQL and other data management utilities. The Role is responsible for managing data processes to ensure data is properly transformed and loaded into CRM: projects present a variety of data science related problems, from data cleansing to complex manipulations of unstructured data to comply with business logic, with the purpose of pushing more client actionable data into Salesforce.com.  Essential Functions:- Working knowledge of data migration processes- Know-how in data cleansing and comparison efforts- Proactively identify and implement operational improvements and enhancements to meet data quality goals- Perform data entry and data management functions- Familiar with Data Mapping: migration and integration+ Python data manipulation is a plus+ Knowledge of salesforce data loader and CLI is a plus Competencies:Must be very proficient with SQLThorough knowledge of Salesforce.comCommunication ProficiencyTime Management Experience:~1-3 years experience in a similar role  Work Environment: This can be partially onsite, partially remote About Cloud Theory:    Cloud Theory is a NYC-based technology firm specializing in cloud-based client-facing solutions. Although we work across all industries, our expertise is financial services. We provide firms with the knowledge and tools needed to compete in the 21st century economy.    Our consulting practice provides teams that create strategic roadmaps, optimize business processes, engineer custom Salesforce-based solutions and provide ongoing managed services to support the full lifecycle of a firm’s interaction with its clients.",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Servicios financieros",404,None,True,,1074,ACTIVELY_HIRING_COMPANY
122,2215509247,2020-10-27,Ascendeum,Data Scientist,"Gurgaon, Haryana, India","Ascendeum is looking for mathematicians, with extensive hands-on experience in the field of data science, who can analyze large data sets efficiently to generate actionable business intelligence that drives peak performance for our clients. About Us: We provide AdTech strategy consulting to leading internet websites and apps globally hosting over 200 million monthly worldwide audience. Since 2015, our team of consultants and engineers have been consistently delivering intelligent solutions that enable enterprise-level websites and apps to maximize their digital advertising returns. Our Team Structure: Our teams are small-unit (<9), autonomous, and multi-disciplinary. At Ascendeum, we are continuously researching, innovating and developing solutions – pushing every contributing member to learn new languages, frameworks, ideas, and concepts. Job Responsibilities:Identify valuable data sources and automate collection processesUndertake preprocessing of structured and unstructured dataAnalyze large amounts of information to discover trends and patternsBuild predictive models and machine-learning algorithmsCombine models through ensemble modelingPresent information using data visualization techniquesPropose solutions and strategies to business challengesCollaborate with engineering and product development teams Desired Skills and Experience:2+ years of overall industry experience as a Data Scientist (mandatory)Solid understanding of Operations Research, Data Modelling, ML, and AI conceptsKnowledge of R, SQL, and Python: familiarity with Scala, Java or C++ is an assetExperience using visualization tools (e.g. Jupyter Notebook) and data frameworks (e.g. Hadoop)Analytical mind and business acumenStrong math skills (e.g. statistics, algebra)Problem-solving aptitudeExcellent communication and presentation skillsMaster's degree in Engineering, Data Science or other quantitative field is mandatory Thank you for your interest in joining Ascendeum.",Algo de responsabilidad,Jornada completa,Tecnología de la información,Marketing y publicidad,553,None,True,,1282,JOB_SEEKER_QUALIFIED
123,2231246190,2020-11-01,Branch International,Machine Learning Engineer,"San Francisco, CA, US","Branch's Engineering Team builds products for customers in 4 markets and is distributed across 3 continents. Our team in the US works closely with teams in Africa and India on our existing products as well as new product initiatives. In the long term, we envision the US team as the team responsible for some of the most important foundational building blocks that enable us to rapidly build and improve products across multiple markets.  You will work closely with other Engineers, Product Managers, and Data Scientists to develop, improve, and deploy machine learning models and to solve other optimization problems. We make extensive use of machine learning in our credit product, where it is used (among other things) for underwriting and loan servicing decisions. We are also actively exploring other applications of Machine Learning in some of our newer products, with the ultimate goal of improving the user experience.  Machine Learning sits at the intersection of a number of different disciplines: Computer Science, Statistics, Operations Research, Data Science, and others. At Branch, we fundamentally believe that in order for Machine Learning to be impactful, it needs to be closely embedded into the rest of the product development and software engineering process, which is why we emphasize the importance of software engineering skills and experience for this role.  Qualifications  You excel at software engineering and programming in Python and SQL. You have 5+ years of experience working on Machine Learning systems in a production setting. You have a diverse range of data skills including experimentation, statistics, and machine learning, and have used these skills to inform business decisions. You have a keen eye for detail and a healthy skepticism for data before relying upon it. You are highly entrepreneurial. You teach yourself new skills. You take the initiative to solve problems before they arise. You know that startups are a team sport. You listen to others, speak your mind, and ask the right questions. You are a great collaborator and teacher. You are driven by making an impact on customers’ lives.  Project Examples  Credit Decisions - Core to our business is understanding and building signals from unstructured and structured data to identify good borrowers  Customer Service - Using machine learning, automate customer service interactions and provide context to our customer service team  Fraud Prevention - Identify patterns of fraudulent behavior and build models to detect and prevent these behaviors  Product Growth - Understand user experiences, test ideas, and improve conversion rates through experimentation  Paid Growth / Marketing - Use external and internal data sources to measure and optimize marketing spend  Benefits of Joining  Mission-driven and fast-paced, entrepreneurial environment  Competitive salary and equity package  99% coverage of insurance costs (health, dental, vision) Unlimited PTO Flexible working hours Discretionary trips to our offices around the globe (when it's safe to travel!) Pre-tax commuter and 401(k) programs Weekly team meals and quarterly team building events (virtual for now!) Generous child bonding leave policy  Location  We are primarily looking for candidates located (or willing to relocate to) the United States, ideally in the Pacific Time zone.  Branch International is an Equal Opportunity Employer. The company does not and will not discriminate in employment on any basis prohibited by applicable law. We’re looking for more than just qualifications -- so if you’re unsure that you meet the criteria, please do not hesitate to apply!  The salary range for this position is $190,000 - $250,000",Algo de responsabilidad,Jornada completa,Ingeniería,Software,62,None,False,,417,COMPANY_RECRUIT
124,2234500570,2020-11-03,QoreFi,Data Scientist,India,"3+ exp in core Predictive Modeling, Deep Learning & NLP Python Ninja  Background in Fintech/Credit Risk is a plus.",No corresponde,Media jornada,None,None,111,None,True,,449,JOB_SEEKER_QUALIFIED
125,2011304511,2020-11-05,Bold.co,Data Engineer,Colombia,"BoldNuestra compañía fue fundada en Mayo de 2019 por un equipo de personas increíbles y con una experiencia única, el grupo de fundadores está conformado por los creadores de PayU Latam y otras empresas expertas en tecnología financiera. Estamos creando soluciones de pago para pequeñas y medianas empresas. Nuestro primer producto es un datáfono móvil que le permite a nuestros clientes recibir pagos con tarjetas crédito y débito.AndroidiOS Nuestra plataforma cumple con estándares de seguridad como PCI-DSS, está construida bajo una arquitectura Serverless y seguimos un enfoque ágil y DevSecOps. Para más información de la compañía por favor visita: https://bold.co El rolComo Data Engineer estarás a cargo de la construcción de fuentes de datos para toda la organización, estos datos deben ser limpios, confiables y consistentes.Trabajarás muy de cerca con otros Ingenieros de Software, Ingenieros DevSecOps e Ingenieros de Pruebas para garantizar que se cumplan los estándares bajo un entorno ágil y Lean. Adicionalmente, tendrás acercamiento a diferentes áreas de la organización para entender las diferentes necesidades en cuanto a datos que se requieren, especialmente para permitir un crecimiento acelerado del negocio. DeberásDiseñar, construir y mantener el data warehouse de la organizaciónDiseñar, construir y mantener soluciones ETLAportar en decisiones de arquitectura y selección de herramientas y procesosDar puntos de vista y generar crítica constructivaColaborar con los demás Ingenieros, especialmente con DevSecOpsColaborar con diferentes personas del negocio para entender los requerimientos de datos BeneficiosMedicina prepagadaAcciones de la compañía (ESOP)Contrato a término indefinidoSalario competitivoTrabajo remoto de tiempo completo RequisitosExperiencia de más de 3 años en desarrollo de plataformas BI y de análisis de datosExperiencia en todo el ciclo de desarrollo de data warehouse, ETLs y plataformas BIDeseable experiencia con PythonExperiencia con alguna de las siguientes plataformas: AWS Redshift, Snowflake, BigQuery, Metabase, AWS QuickSight, Tableau",Intermedio,Jornada completa,Tecnología de la información,Servicios financieros,63,None,False,,474,None
126,2204941045,2020-10-23,Codex Recruitment - Data Analytics and EPM Recruitment,Data Scientist,Atlanta Metropolitan Area,"Data Scientist – Atlanta (Initially Remote)  A leading manufacturing client is looking for a hardworking Data Scientist to join their growing Data Science Centre of Excellence. Tapping into massive product usage data sets, you will be a key driver on using data to better process and kick off business-wide initiatives. Data is at the core of decision making. The Data Science team works in collaboration with all different parts of the business, from sales, finance, analytics etc. to ensure efficiency of data flow is running through the centre of the enterprise.  You will be brought in for a specific project geared around Supply Chain. This body of work is looking to run until the end of March and thus it would initially be a contract engagement until then. Most likely it will be extended beyond this to work across the business before being made into a permanent hire.  You’ll dive deeply into the data to uncover insights, design experiments and measure the impact of certain decisions. You will report directly into the Lead Data Scientist .   They will be looking at you to build cutting edge, front-end dashboards (Flask or Django preferred).  They will want someone who has experience connecting to SAP using Python. The successful candidate will come from a strong Software Development background.  You will need to be someone who is hungry to get heavily involved and get your hands dirty on some of the most exciting projects.  You will engage with users, discuss their behaviour and patterns and help drive new initiatives to engage the business in key data driven initiatives and utilise machine learning techniques where possible.  Experience -Relevant degree (Advanced Degrees are preferred): Quantitative field-2+ Years: of industry experience in a Data Science, Data Analyst or similar role-Strong proficiency in SQL-Programming experience – Python & R heavily preferred-Machine Learning experience a big plus-Other’s of interest: Django, Flask, Azure -Strong written and oral written skills with ability to engage and persuade senior audience",Intermedio,Jornada completa,Tecnología de la información,Dotación y selección de personal,355,None,True,,912,JOB_SEEKER_QUALIFIED
127,2243544255,2020-11-04,Tria Recruitment,User Experience Researcher,United Kingdom,"UX Researcher / User Researcher – UK Remote£45,000 - £55,000 + Benefits My client is an industry leading technology company based in Birmingham who are looking for an outstanding UX Researcher to join their business as they modernise their technology and design function.  You will be responsible for leading and advising on research methods & approach for products and be responsible for planning, designing, organising, recruiting and conduction research activities. You’ll be utilising several research techniques and tools both remote and in-person, moderated and unmoderated research. You will be representing the customer with stakeholders across the business ensuring that their voice is heard across the design and product teams.   What we are looking forAt least 3 years working as a UX Researcher or User Researcher in a fast-paced digital first environment.You will have worked in an applied research role, not a purely academic background.You’ll be a research evangelist and be confident working with UX & UI Designers and educating them on research best practice.You’ll have experience utilising a multitude of research methods: usability testing, interviews, workshops, tree testing, card sorting, competitor analysis, ethnography and A/B testing or MVT.You will have worked in agile teams working closely with designers.You will have an excellent background of conducting quantitative and qualitative research.",Intermedio,Jornada completa,"Tecnología de la información, Investigación",Servicios y tecnologías de la información,65,None,True,,286,ACTIVELY_HIRING_COMPANY
128,2203729754,2020-10-23,dutchie,User Experience Researcher,United States,"About dutchie Dutchie is a technology company that connects consumers with their favorite dispensaries. Our mission is to create easy and safe access to cannabis for everyone. We are the leading and fastest-growing e-commerce provider in cannabis, facilitating $2.4B in sales, powering online ordering for the top dispensaries throughout the United States and Canada. We deliver insights to our dispensary partners that grow their business and ensure they are compliant with ever-changing rules and regulations.  Dutchie has raised $53M in funding to date, backed by Howard Schultz (Former CEO of Starbucks), Thrive Capital (Investor in Instagram, Stripe, Spotify, and Slack), Snoop Dogg’s Casa Verde Capital, one of the leading cannabis-focused VC’s, Gron Ventures, members of the founding team at DoorDash, Kevin Durant’s Thirty Five Ventures, and other notable angel investors. About the Role Dutchie is seeking a UX Researcher to work alongside product managers and designers, uncovering meaningful human-centered insights to drive great design and innovative product development. We feel strongly that research should inform all aspects of the product lifecycle, from product strategy and problem definition to iteration and evaluation.  As our first UX Researcher, your work will not only influence the products we build but will also establish the UXR discipline at dutchie. You’ll get to shape the research culture and processes from the ground up and have direct input on big and meaningful product decisions. If you're comfortable in a fast-moving organization and excited about the high potential for growth and ability to make an impact, this role is a great fit for you.  The ideal candidate will be comfortable operating at highly strategic and tactical levels, switching between them effortlessly. You will have a track record of leveraging insights to build consensus with large cross-functional teams and of building trusted relationships with senior product leaders. What You’ll Do… Partner with product managers, product designers, and other stakeholders to understand dutchie’s research needs and create a research roadmapPartner closely with product marketing and our analytics team to develop a deeper understanding of our customers and surface opportunities to product leadership to inform the roadmapGenerate insights through qualitative and quantitative studies that shape how product teams think, ranging from short-term to long-term product strategyCreate and own a variety of research studies, including field studies, usability tests, concept tests, group discussions, etc.Perform research projects independently, from defining research questions, research project management and implementation to presentationSynthesize findings into meaningful themes, making them actionableAct as a research thought leader and advocate for our customers What You Bring… MA/MS or PhD in Human Computer Interaction (HCI), Cognitive or Experimental Psychology, Sociology or a related field preferred, not required5+ years of experience in user research related to software and digital experiences2+ years of experience of driving research and product roadmapsFamiliarity with a wide variety of qualitative research methods such as: usability, 1:1 interviews, concept testing, ethnographic-style fieldwork, group discussions, card sorting, workshops, remote studies, etc.Experience designing and summarizing surveysExcellent communication, presentation, and writing skillsA proven track record of successful partnership with product managers, product designers, analysts, engineers, and other business partnersAbility to work independently and take initiative to solve problems You’ll Get... Competitive SalaryFully paid medical, dental, and vision insuranceEquity401(k)Flexible vacation days, sick days, and work from home days Technology (hardware, software, reading materials, etc..) allowanceThe opportunity to shape an entire industry and create a product that touches millions of people  At dutchie, we’re committed to providing an environment of mutual respect where equal employment opportunities are available to all applicants and teammates without regard to race, color, religion, sex, sexual orientation, gender identity or expression, pregnancy, age, national origin, disability status, genetic information, protected veteran status, or any other characteristic protected by law. Dutchie believes that diversity and inclusion among our teammates is critical to our success, and we seek to recruit, develop and retain the most talented people from a diverse candidate pool.",Intermedio,Jornada completa,"Tecnología de la información, Investigación, Gestión de productos","Software, Servicio al consumidor",122,None,False,,1294,None
129,2194842280,2020-10-20,WhyLabs,Machine Learning Engineer,"Seattle, Washington, United States","WhyLabs is on a mission to build an interface between AI applications and human operators. As a member of our early team you will be responsible for building core customer-facing components of the WhyLabs Platform. Your work will help customers across AI organizations monitor the health and performance of their AI models at enterprise scale. In this capacity you will build and invent approaches for monitoring and understanding data quality, data/concept drifts, as well as ongoing model performance. You will contribute to open source libraries (https://github.com/whylabs) as well as develop key components of the enterprise platform that enables robust operations of AI applications.   WhyLabs is a fast-growing early stage startup. There will be many opportunities for growth and ownership as we move fast to build solutions for customers who deploy and operate AI. As a Machine Learning Engineer and an early member of this team, you will: Have the unique opportunity to help build the Why Labs Research & Development team, you will play a big role in establishing the engineering and data science culture, process, as well as best practices Work closely with the CEO to help define the technical roadmap of the platform Play a key role in developing open source libraries that establish the standard of data logging/profiling for unstructured dataPlay a critical role in architecting, developing, and scaling the data profiling, monitoring and anomaly detection components of the core productParticipate in customer development meetings to build a deep understanding of customer needs and requirementsParticipate in the team building process by helping source, interview and mentor new members of the team Introduce new technologies and internal tools to help us build features faster About you:4+ years of engineering experience building machine learning based applications and large scale data pipelinesExperience with OSS Python frameworks (MLFlow, Airflow, Dask, Ray)Strong knowledge of Python and experience with C/C++Experience building enterprise applications on top of cloud services (AWS, GCP or Azure)Experience with ML deployment technologies (SageMaker, MLFlow, Airflow)Understands data structures and algorithms at a level sufficient to write performant code when working with large datasets or large incoming data streams.Passion for writing clean, concise, well-organized codeHands-on experience in Computer Vision, Perception or Computer Graphics projects.Experience with unit testing and integration testing for deploying production software Bonus points:You worked on machine learning applications or machine learning tools in a commercial setting.You led development or actively contributed to a major open source project. You have experience working at a startup and thrive in a fast-paced environment.You have experience in Java, Kotlin, Scala, GoLang, or Rust WhyLabs is committed to a diverse and inclusive workplace. WhyLabs is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status.  About WhyLabs:  At WhyLabs, we have our eyes set on an ambitious goal: to build the interface between humans and AI applications. As teams across industries adopt AI, WhyLabs enables them to operate with certainty by streamlining model monitoring, preventing costly model failures, and facilitating cross-functional collaboration. Incubated at the Allen Institute for AI, WhyLabs is a privately-held, venture-funded company based in Seattle. The company was founded by Amazon Machine Learning and Cloudflare alums. We realize people do not fit into neat boxes. We are looking for curious and empathetic individuals who are committed to developing themselves and learning new skills, and we are ready to help you do that. We cannot complete our mission without building a diverse and inclusive team. Learn more about WhyLabs at www.whylabs.ai.",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información",Software,525,None,True,,1768,ACTIVELY_HIRING_COMPANY
130,2186317142,2020-10-15,Harnham,Data Scientist,New York City Metropolitan Area,"Data Scientist - Fintech Are you passionate about strategizing machine learning approach? Do you enjoy building predictive models that lead to growth? Are you interested in fintech? The CompanyAs a Data Scientist, you’ll be working for a fintech company looking to bring on a data scientist eager to contribute to their increasing growth. The RoleYou will be part of a growing team of data scientists - your work will assist stakeholders in making decisions surrounding the strategic direction crucial to US growth. You can expect to:Collaborate with your team of Data Scientists to build and guide industry-leading forecasting models to be used within the companyBuild machine learning models through all phases of development, from design to implementationWork with internal stakeholders and executive leadership team to inform company strategy Your Skills and ExperienceMaster's and/or PhD degree in a quantitative field requiredTeam player, ability to work with a diverse set of professionals6+ years commercial machine learning experience and technical expertise of PythonKnowledge of statistical methodologies Salary and BenefitsThe successful candidate will secure a salary of $140,000 - $160,000 commensurate to experience How to ApplyPlease click 'Apply Now' Keywordswashington dc, district of columbia, machine learning engineer, machine learning, machine learning project manager, data science, ai, artificial intelligence, data scientist",Algo de responsabilidad,Jornada completa,"Ingeniería, Tecnología de la información",Servicios financieros,335,None,True,,1075,ACTIVELY_HIRING_COMPANY
131,2203344570,2020-10-22,Shelf Engine,Head of Data Science,"Seattle, Washington, United States","At Shelf Engine, we’re harnessing the power of AI to provide real-time, intelligent forecasting for food retailers like grocery stores, restaurants, and cafes across the United States. We’re able to drastically reduce the amount of shrink (food waste) which in turn drives profit for retailers, lowers costs for consumers, and reduces the ecological and social impacts of waste. We’re using technology to solve a globally-relevant problem that both creates a positive environmental impact and an exciting (and potentially massive) commercial opportunity. We are hiring a Head of Data Science to join our growing technical team. You will work alongside our co-founders and lead our data science team, to develop continued excellence in our business. Your deep background in mathematics, statistics or econometrics, combined with your experience solving real world business problems, will directly impact the accuracy of our forecasting - reducing food waste and avoiding understocking situations. Help us solve critical problems in the food industry in the following areas: time-series demand forecasting, optimization, and feature/trend analysis. As a Head of Data Science at Shelf Engine you will:Lead a team of Data Scientists to build a live forecasting system that accurately determines how much food to order at thousands of grocery stores across the country, drastically reducing food waste.Build organizational capability in time series forecasting, optimization, and other disciplines relevant to solving Shelf Engine's business needs.Work to deeply understand customer needs across the business, and build the infrastructure necessary to measure their performance, detecting anomalous forecasting situations and building plans to address them. Work cross-functionally (e.g. Engineering, Operations, Customer Success, Sales, etc) to champion a strategy to frame problems, both mathematically and within the business context.Design, analyze, and run both simulated and live experiments (A/B and multivariate tests) to drive KPI improvement.Work hands on with the team, building mathematical and ML models, writing and reviewing production code, and using analysis and reporting to gain actionable insights in the business. And our ideal Head of Data Science will have:﻿Have a Masters or higher degree in a related quantitative field (Applied Math, Statistics, Econometrics, etc). Bring 8+ years of relevant working experience in data science, preferably with specific experience in the domain of time series forecasting and/or optimization.Display strong leadership skills, with 3+ years of team management experience, and a strong ability to mentor and guide a small team of Data Scientists.Have experience building and operating a live forecasting or other machine learning system in production.Have production-level experience with data querying languages (e.g. SQL), scripting languages (e.g. Python).Have expertise with statistical analysis, applying various machine learning techniques, especially predictive modeling, to solve business problems Bring a proven ability to think creatively, solve problems, learn quickly, work independently, handle ambiguity, and adapt to change in a fast-paced environment Possess excellent written, verbal, and interpersonal communication and presentation skills  About Us:At Shelf Engine, you will join a small, powerful, customer-centric team that’s hungry for change in an untapped industry. Our founders are well versed in the food industry and have successfully built product and engineering teams. We’re not only solving complex technical problems at scale but tackling key initiatives with large environmental impacts as well. We're a tight-knit and passionate team that is determined to disrupt a massive industry and leave behind a positive legacy for generations to come.  Shelf Engine is an equal opportunity employer and does not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",Director,Jornada completa,"Tecnología de la información, Ingeniería",Software,44,None,False,,398,JOB_SEEKER_QUALIFIED
132,2004841046,2020-10-12,Prospa.,Lead Data Engineer,Australia,"Prospa has established itself as a clear #1 online lender to small businesses in Australia and current growth trajectories see the business continuing to invest in its rapidly growing team, currently over 200 strong. This represents a unique opportunity to join us, one of Australia's most exciting and fastest-growing Fintech businesses with an awesome culture. We are driven by our people. Their diversity, skills and passion are the foundation of what we deliver to our customers - where employees are dedicated to achieving stellar results and exceeding customer expectations. Our values: obsess about customers: deliver value fast: day 1: simplicity: be bold, open and real: and one team, inform how we think and act every day. We are also recognised as an AON Hewitt Best Employer in 2017 and 2018 FINNIES Best Fintech Place to Work and a Great Place to Work in 2019! The role As a Lead Data Engineer, you will be part of our Data Engineering team. You will be responsible for extending and optimizing our data platform and architecture to provide a reliable and trustworthy data as a service offering. Your work will ensure our data pipelines are running efficiently, our enterprise data lakes and data warehouses are up to date and operating reliably, and data is presented to our analysts, scientists, and stakeholders in an easy-to-use, trustworthy, and self-serviceable manner. Key responsibilities include Extend and optimize our information models to meet BI and Data Science needs. In addition, our data pipelines, data lake, and data warehouse. Cater to our ever-growing set of data sources, with streaming and batch processing needs.Build reusable tools in Python/Javascript/etc that will allow the wider team to deliver value fast with precision.Drive the adoption of leading practices and suitable technologies in developing end-to-end data solutions within Prospa’s cloud environment.Partner closely with a diverse set of stakeholders to solve data and business problems with self-service and re-usability in mind.Be accountable for the availability, reliability and data quality of our data platforms end-to-end.Drive the quality, surfacing data and metrics to guide development, quality and availability.Mentor Prospa Data Engineers, Data Scientists and Data Analyst through peer programming, effective code reviews, and delivering feedback.Engage closely with engineering, product and business partners to prioritise technical tasks alongside business objectives. What you'll need to succeed 8+ years Data Engineering experience.Extensive experience in working with MSSQL, Databricks, Snowflakes, Airflow, Spark, Kafka and accompanying ecosystems (or similar).Extensive knowledge in building enterprise data warehousing and data lakes.Extensive knowledge in data modelling techniques and data workflow management.Extensive knowledge of Object Oriented Programming and Test Driven Development in Python and JavaScript.Experience in working with Linux-based systems, NoSQL databases and data structures.Passion and leadership in data engineering, cloud, software development and security practices.Experienced with cloud platforms, preferably Azure, in an enterprise environment. Come and Join Our Team If you can see yourself at Prospa and feel you can contribute to the ongoing success of our company, please hit ‘apply’. We embrace diversity in our people and our thinking and provide a collaborative, inclusive, innovative and respectful environment. We celebrate who you are, recognise & reward great achievements, and actively provide our people the same great experience we provide our customers. We are committed to being an equal opportunities employer and we never discriminate on the basis of race, religion, gender identity or expression, sexual orientation, age, marital or disability status. With the greatest respect CVs will not be accepted from recruitment agencies at this time.",Intermedio,Jornada completa,Tecnología de la información,"Servicios financieros, Servicios y tecnologías de la información, Banca",24,None,False,,392,ACTIVELY_HIRING_COMPANY
133,2198866063,2020-10-21,Student Beans,UX Researcher,United Kingdom,"About Student BeansStudent Beans is the world's leading student loyalty network. We produce our award-winning technology for the biggest retailers on the planet, connecting them with the youth market. Featuring in The Sunday Times Tech Track 100 2020, a list of the fastest-growing private tech companies in Britain, Student Beans consistently innovate to offer new solutions that satisfy our consumers, drive ROI for our clients and create an empowering workplace for our employees. In the last two years alone, Student Beans has tripled the size of its teams in London, Manchester, Birmingham and New York and opened a brand new office in Melbourne. But we’re not stopping there! Student Beans has an incredibly exciting journey ahead, with ambitious goals and endless possibilities. Our success is due to our brilliant people and we are looking for more talented individuals to join us on our journey. As a result of our incredible success and growth, we are looking for a User Researcher to join us.  Responsibilities include:Develop an overall research strategy for the product function SBCoordinate user research across multiple product value streamsUse both qual and quant techniques to identify and prove/disprove hypothesesEnsure scientific approach to testingRecruitment of users for research purposesRecruiting and maintaining a panel of customers for research purposesEnsure that learnings from research are communicated and usedBe the voice of the user(s) within the product teamInterviewing users and customers RequirementsWe’d really like to hear from you, if you have...3+ years experience managing multiple UX research streams within an organisation or agencyUsed to working in tech focused companies, with product/tech teams working agileExperience developing research plansExperience with both qual and quant researchExperience using analytics, user behaviour tools (eg google analytics, tableau, hotjar, clicktale etc)Understanding of product design principles BenefitsLife at Student BeansWe are passionate about our mission to empower students to thrive and believe our success is only due to our fantastic team, their different backgrounds, experiences and beliefs. At Student Beans our culture is welcoming and empowering, everyone has a voice and direct impact on our journey.Here are just a few things that make Student Beans an awesome place to work:Competitive salary.Fully remote workingMental health first aiderFlexi-time.Vibrant, purposeful and social environment - famous winter parties and summer getaways, regular socials and adventurous activities.Focus on wellbeing - gym membership, wellness challengesIncredible partnership discounts for the biggest brands in the world: Google, Apple, TopShop, Ted Baker, GymShark, Domino's, Uber … to name a few!Check out our Careers site to see for yourself! https://about.studentbeans.com/careers Due to the high volume of applicants we can only respond to shortlisted applicants. By submitting your application, you agree that Student Beans may collect your personal data for recruiting, global organization planning, and related purposes. Our Applicant Privacy Notice explains what personal information and where we may process, our purposes for processing, and the rights you can exercise over Student Beans' use of your personal information.",Intermedio,Jornada completa,Tecnología de la información,Medios de comunicación en línea,154,None,True,,692,ACTIVELY_HIRING_COMPANY
134,2261173226,2020-10-31,Toptal,"Data Scientist – Remote, Full-time","Mobile, AL, US","Design your lifestyle as a top freelance data scientist, with the freedom to work however, wherever, on your terms.  Freelance work is defining the careers of today's data scientists in exciting new ways. If you're passionate about working flexibly with leading Fortune 500 brands and innovative Silicon Valley startups, Toptal could be a great fit for your next career shift.  Toptal is an elite talent network for the world's top 3% of developers, connecting the best and brightest freelancers with top organizations. Unlike a 9-to-5 job, you'll choose your own schedule and work from anywhere. Jobs come to you, so you won't bid for projects against other data scientists in a race to the bottom. Plus, Toptal takes care of all the overhead, empowering you to focus on successful engagements while getting paid on time, at the rate you decide, every time.  As a freelance data scientist, you could join an ever-expanding community of experts in over 120 countries, working remotely on the projects that meet your career ambitions.  That's why the world's top 3% of developers choose Toptal. Data Scientists in our elite network share:  At least 3 years of professional experience in Data Science Project management skills A keen attention to detail Full-time availability is a strong advantage  If you're ready for a career shift to impactful freelance work, take the next step by clicking apply and filling out the short form. #RemoteJobsDataScience",Intermedio,Contrato por obra,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Software, Dotación y selección de personal",9,None,False,,71,ACTIVELY_HIRING_COMPANY
135,2149520548,2020-11-02,Leap,Data Engineer,Netherlands,"About Us Leap’s mission is to stop climate change by creating the demand flexibility required to have a reliable electric grid that runs on clean energy. The electric grid is transforming from a model based on dirty (but largely predictable) fossil fuel generation to one that relies on clean (but often less predictable) renewable generation. As the grid absorbs all of this new variable energy, it will need need more flexible demand and supply to help maintain stability and reliability. Leap’s marketplace unlocks access to the wholesale energy markets for IoT-connected distributed energy resources, enabling our partners to get paid for providing flexibility to the grid. Our platform connects market-pricing signals with the end-customers’ ability to shift load. We act as an aggregator of aggregators and partner with some of the best-known and most innovative players in clean energy and IoT. Working with these partners, we’ve helped a variety of new resources (think batteries and electric vehicles, but also irrigation pumps, smart thermostats, food processing centers and commercial refrigeration, to name a few) earn revenue by helping to balance the grid, smoothing the path for more renewable energy to come online. Founded by Dutch entrepreneurs with experience in technology and energy, we are based in San Francisco with an engineering office in Utrecht (NL). Leap is a privately-held tech company with funding from well-known energy entrepreneurs and VCs. Who are we looking for? We’re seeking a creative and driven individual who will be responsible for designing, implementing, and maintaining data pipelines and our data lake infrastructure. This medior/senior position is essential for helping Leap to grow our business in existing and new markets.  Required:Have 3+ years of experience working with PySpark Or have 3+ years of experience designing and maintaining a data lakeYou may be a fit for this role if you:Love to design and build data pipelines, using the most pragmatic tools that fit with our current infrastructure and data science goals  Are proactive in anticipating future needs based on the current workflows Enjoy working with data scientists, developers and other stakeholders in bringing pipelines to production -- whether they’re machine learning based or simple analysis pipelinesHaving experience is definitely a plus, but willingness to learn and innovate is a mustWhat will you be working on?Building data pipelines of e.g. electric meter data, from ingestion to storage to displaying real-time metricsDesigning and implementing infrastructure to support our data lake  Work with back-end and front-end developers to ensure that the pipelines can scale with our businessClosely collaborate with data scientists to develop a workflow where machine learning and analytics can be performed seamlessly on the most up-to-date data Work with the team to productionize modeling efforts and deliver the analyses to the relevant stakeholders  What’s it like to work at Leap? Product: At our core we are a tech company. We love technical challenges and build things that we are proud of and would like to use ourselves. Everyone is highly involved in building and designing our products, making them extremely valuable and a pleasure to use. Purpose: Some of us worked in energy before, some of us haven’t. All of us would like to make a difference and do our part in helping the world move towards a more resilient grid run on renewable energy. Fun: We work hard, but enjoy our time at work as well as outside of work. With the team spread out over multiple time zones we also embraced flexibility early on, and are focused on results instead of time spent in the office. We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.",Intermedio,Jornada completa,Tecnología de la información,Servicios públicos,91,None,False,,1033,JOB_SEEKER_QUALIFIED
136,2202564868,2020-10-12,DigniFi,Data Engineer,United States,"DigniFi is a platform company that connects consumers with lenders for car repairs, tires, accessories, and other auto-related needs. The automated, contactless process serves up financial products through the point of sale at car dealerships and independent repair shops. DigniFi provides consumers with access to fixed payment plans from 12 to 36 months. The loans are originated through WebBank, an FDIC-regulated bank. To date, DigniFi has provided access to over $120 million in loans in partnership with more than 5,000 auto service centers. For more information, please visit www.dignifi.com. We are currently searching for a Data Engineer to join the Dignifi team. As a Data Engineer, you will partner with stakeholders including the engineering, business intelligence, product, sales, and marketing teams to assist with data-related technical issues and support their data infrastructure needs. We are seeking someone who has a deep understanding of end-to-end data interactions and dependencies across complex data pipelines and data transformations to enable the Company to extract insights and value from data. In this position, you will help develop the vision and map strategy to provide proactive solutions to create and maintain optimal data pipeline architecture through exploring new tech, creating your own tools, and discovering new ways to constantly optimize and improve the data infrastructure. Additionally, you will design and implement best practices for data processing, data modeling, and data warehouse development throughout the organization to enable for greater scalability as we build and develop a best in class data landscape. What we’re looking for:Passion for turning data into data models that help others unlock insightsThe ability to identify unreasonable results and a well-tuned sense of skepticismAttention to detail and commitment to high-quality results-oriented outputStrong problem-solving skills, comfortable with ambiguity and imperfect dataAbility to adapt to rapidly changing priorities and work independently in fast-paced environmentSelf-motivated with a high degree of intellectual curiosity and a positive attitudeExcellent written, verbal, and interpersonal communication skills Key Responsibilities:Build the infrastructure required for optimal data ingestion (ETL/ELT) into data lakes and data warehouses from a wide variety of data sourcesDesign and deploy data models, complex data sets, and views with large datasets that meet business requirements using data warehouse standard methodologiesDeliver test plans, monitor, debug, and create technical documents as a part of development cycleCollaborate with partners to understand needs and define business requirementsIdentify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.Create data tools to translate data questions into flexible methodologies that scale to improve operational efficiency and other key business performance metrics Essential Experience:Bachelor’s degree in Information Technology or Computer Science or equivalent5-7 years of professional experience working in a building a data warehouse and data pipelines or data intensive engineering rolesProficient in programming languages (e.g. Python, Java, etc.)Experience with big data architectures and data modeling to efficiently process large volumes of dataAdvanced working SQL knowledge (PostgresSQL, MySQL, MS SQL, etc.) and experience working with relational databases and data warehouses, query authoring (SQL) as well as working familiarity with a variety of databasesProficiency in understanding and designing complex ETL processesExperience supporting and working with cross-functional teams in a dynamic environmentFamiliarity with cloud data warehouse solutions (e.g. Snowflake, Redshift, BiqQuery, etc.)Familiarity with ETL/ELT tech (e.g. Stitch, FiveTran, Matillion, etc.) Desired Experience:Experience working with Business Intelligence and Data Science teams to manage risk.",Intermedio,Jornada completa,"Análisis, Ingeniería","Internet, Servicios financieros",181,None,True,,570,ACTIVELY_HIRING_COMPANY
137,1987018055,2020-11-06,"TrueCar, Inc.",Senior Data Engineer and/or Data Engineer,"Santa Monica, CA, US","Job Description: TrueCar envisions a world where car shopping is an uplifting experience. Our shopping experience helps buyers consider choices from every angle, builds confidence in their decisions, and enables every step of the process with tools and information that make car buying easy. Ultimately, TrueCar is helping people in the second largest purchase they will make in their lives. We're removing the complexity out of buying a car, using technology and personalization, to create a one-of-a-kind experience that transforms car buying and ultimately people’s lives.  Come join the team and help us accomplish our mission. TrueCar maintains a Dynamic Workplace, allowing employees to have their primary workstations at home, with office space in Santa Monica, CA and Austin, TX to be made available to individuals and teams to use as needed. Employees enjoy excellent benefits (health/vision/dental coverage, 401k with contribution matching, equity, etc.) as well as perks like monthly credits for at-home food delivery, internet/mobile phone service coverage, fitness expenses, and Caregiver support.  About the Team:  TrueCar is seeking to add a Senior Data Engineer and a Data Engineer to the team.  The Data Engineering team applies subject matter expertise to ingest, analyze, and validate the automotive data required from internal and 3rd party sources. Data engineers are responsible for building and maintaining highly scalable data pipelines to power the website while also providing data for our analytical engine to derive insights in a meaningful fashion.  About the Job:   Design and develop efficient and scalable data processing pipelines using big data technologies ( Hadoop, Spark, HBase, Kinesis, MapReduce, etc.) on large scale structured/unstructured data sets for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL/NoSQL.  Build complex workflows and orchestrate data dependencies.  Monitor and support data pipelines to honor internal and external SLA’s.  Work within standard engineering practices (i.e. SCRUM, unit/integration testing, design review, code reviews, continuous integration, etc.) to deliver product features with optimal efficiency for TrueCar customers and clients.  Closely work with product owners & analysts to understand business and functional requirements and contribute to the design and prioritization discussions.  Working with a team of engineers where mentorship is valued.  Ability to learn and adapt to continually evolving technologies in the big data ecosystem.   What Youll Need:  Senior Data Engineers Require:   5+ years of experience programming in Java.  2+ years of experience in Big Data technologies.  Experience in any of big data technologies: MapReduce, Spark, HBase,  Proficient in SQL and experience with RDBMS/NoSQL databases.  Experience working with Cloudera/Hortonworks/EMR distribution in AWS.  Ability to self-manage tasks and be proactive in working with other teams to accomplish them while taking pride and ownership in their work.  Team-player with strong collaboration and communication skills, who is able to respond positively to feedback.  Bachelor degree (or Master) in Computer Science or related engineering field  Data Engineers Require:   3+ years of experience programming in Java.  1+ years of experience in Big Data technologies.  Experience in any of big data technologies: MapReduce, Spark, HBase,  Proficient in SQL and experience with RDBMS/NoSQL databases.  Experience working with Cloudera/Hortonworks/EMR distribution in AWS.  Ability to self-manage tasks and be proactive in working with other teams to accomplish them while taking pride and ownership in their work.  Team-player with strong collaboration and communication skills, who is able to respond positively to feedback.  Bachelor degree (or Master) in Computer Science or related engineering field   About TrueCar:   TrueCar is a leading automotive digital marketplace that enables car buyers to connect to our nationwide network of Certified Dealers. We are building the industry's most personalized and efficient car buying experience as we seek to bring more of the purchasing process online. Consumers who visit our marketplace will find a suite of vehicle discovery tools, price ratings, and market context on new and used cars -- all with a clear view of what's a great deal. When they are ready, TrueCar will enable them to connect with a local Certified Dealer who shares in our belief that truth, transparency, and fairness are the foundation of a great car buying experience. As part of our marketplace, TrueCar powers car-buying programs for over 250 leading brands, including AARP, Sam’s Club, and American Express. Nearly half of all new-car buyers engage with TrueCar powered sites, where they buy smarter and drive happier.  TrueCar is headquartered in Santa Monica, California, with an office in Austin, Texas.   Location(s):Santa Monica, CA",No corresponde,Jornada completa,Tecnología de la información,"Marketing y publicidad, Software, Internet",83,None,False,,675,ACTIVELY_HIRING_COMPANY
138,1887470953,2020-10-26,Personal Capital,Senior Data Engineer,United States,"The Company:Personal Capital is a leading digital wealth management company, founded in 2009. We’re on a mission to transform financial lives through technology and people, providing both insight-driven advice with free financial tools and personalized wealth management from 200+ registered financial advisors across the country. Personal Capital has raised $315 million in capital from accomplished financial and strategic investors (IVP, Venrock, Crosslink, Corsair, Blackrock, BBVA, USAA, IGM/Power) to disrupt the traditional $30 trillion U.S. wealth management market. Our free personal finance app is utilized by over two million users, helping them track over $840 billion of their personal finances, all in one place. Our award-winning apps paved the way for our advisory firm, which now manages over $12 billion in personalized investment portfolios for American families. Personal Capital is headquartered in Redwood Shores with offices in San Francisco, Denver, Dallas and Atlanta. The Opportunity:You will play a critical role on the Data and Analytics team, responsible for transforming data from disparate systems to provide insights and analytics for business stakeholders. You’ll leverage cloud-based infrastructure to implement technology solutions that are scalable, resilient, and efficient. You will collaborate with Data Engineers, Data Analysts, Data Scientists, DBAs, cross-functional teams, and business partners. You will architect, design, implement and operate data engineering solutions, using Agile methodology, that empower users to make informed business decisions. The Candidate:You are self-motivated, self-directed, and have hands-on experience with all aspects of the software development lifecycle, from design to deployment. You have a deep understanding of the full life data lifecycle and the role that high-quality data plays across applications, machine learning, business analytics, and reporting. Strong candidates will exhibit solid critical thinking skills, the ability to synthesize complex problems, and a talent for transforming data to create solutions that add value to a myriad of business requirements. You have the demonstrated ability to facilitate and take ownership of assigned technical projects in a fast-paced environment. Excellent written and speaking communication skills are required as we work together in a collaborative cross-functional environment and interact with the full spectrum of business divisions. Qualifications:Bachelor of Science degree in Computer Science or equivalent.At least 7 years of post-degree professional experience, including:4+ years development experience building and maintaining ETL pipelines3+ years of Python development experienceExperience with AWS integrations such as Kinesis, Firehose, Aurora Unload, Redshift, Spectrum, Elastic Mapreduce, SageMaker and LambdaExperience in mentoring junior team members through code reviews and recommending adherence to best practicesDeep understanding of writing test cases to ensure data quality, reliability and high level of confidenceTrack record of advancing new technologies to improve data quality and reliabilityContinuously improve quality, efficiency, and scalability of data pipelines Expert skills working with SQL queries, including performance tuning, utilizing indexes, and materialized views to improve query performanceAdvanced knowledge of both OLTP and OLAP environments with successful implementation of efficient design conceptsProficiency with the design and execution of NoSQL database to optimize BigData storage and retrieval Experience with API code integrations with external vendors to push/pull data between organizations Familiarity with data orchestration pipeline using Argo or AirflowKnowledge of analytic tools such as R, Tableau, Plotly, Python PandasFinancial services industry experience is a plus Personal Capital is proud to be an equal opportunity workplace dedicated to pursuing and hiring a diverse workforce.",Intermedio,Jornada completa,"Tecnología de la información, Ingeniería","Servicios financieros, Internet, Servicios y tecnologías de la información",239,None,False,,1056,ACTIVELY_HIRING_COMPANY
139,2255794481,2020-10-30,Goodway Group,Data Scientist - Marketing Technology,New York City Metropolitan Area,"Goodway Group is a fully remote, digital marketing, and advertising firm. We sit at the intersection of top talent, amazing technical partnerships, and game-changing analytics within the ad technology and marketing technology space. We're well-established with the pace of a start-up. This position is work from home (or anywhere else you have reliable internet) and can be located anywhere within the United States.    Doing This Involves  Goodway Group aims to be the beacon of honesty and intelligence in the programmatic marketplace. We deliver authentic results for our clients by running smart advertising campaigns. Data Science & Analytics at Goodway Group develops data products that ensure the company's media campaigns are running efficiently.  showing feasibility through data analysis, designing and producing prototypes deploying models to production.  Who You Are  A Data Scientist is a key member of the Data Science and Analytics team at Goodway. This team utilizes advanced tools and innovative techniques to maximize advertising results for our clients, as well as demonstrates thought leadership within the digital advertising industry.  You will be at the center of data analysis, modeling, machine learning, and data engineering and on the bleeding-edge in the ad-tech space.  The ideal candidate will have hands-on experience working on a wide range of optimization and analytics problems in ad-tech including fraud detection/mitigation, price prediction, conversion attribution, and modeling, as well as experience with the tools of the trade including SQL, Python, Hive, R, Athena, and others.  What You Will Do  Design, build, and deploy algorithms to optimize the performance of advertising campaigns. Define data requirements and gather/validate information, applying judgment and statistical tests. Apply various models and methods to test, learn, and improve the manner in which data is being evaluated and algorithms are being built. Construct data narratives to convey complex ideas to non-technical stakeholders. Be constantly learning the latest technologies and trends. Work with analysts and stakeholders to gather, understand, and develop business initiatives and specifications. Provide expertise and leadership on making technical decisions, thus delivering a platform that provides business value and meets end-user goals.  What We Offer  Goodway Group is a wholly remote organization, so no commute to consider! We offer unlimited PTO (MyTime) because we know you're at your best when your life has balance. We have the usual steak and potatoes array of benefits, as well as some great wellness programs that are available to both you and your family. While we work remotely, we foster an environment that promotes connectedness and community.  For a lot more detail, make sure to check us out on Glassdoor!  You’ll Be Successful Because You Are  Knowledgeable: B.S., M.S. or Ph.D. in computer science, math, statistics or a strong quantitative educational background Adept with Python and exposure to modern software development practices including GitHub Excellent at communicating complex ideas and are able to convey ideas accurately and concisely to both technical and non-technical stakeholders Results-Oriented: we call this grit. You can be counted on to exceed goals, and you’re known to push yourself and others across the finish line Able to learn new paradigms, tools, and processes quickly and thrive in a fast-paced, rapidly changing, exciting work environment Work from Home: we all work from our home offices throughout the United States  Things You Should Know Twice per year, we gather together to work and play for a week. Both retreats are “can’t miss” events (like seriously…they are mandatory). There may also be other opportunities to travel depending on your specific role and business needs.  Goodway embraces a culture of equality and wants applications from everyone, regardless of race, creed, color, religion, sex, sexual orientation, gender identity, national origin, marital status, citizen status, age, disability, military or protected veteran status, genetic predisposition or carrier status or any other legally protected status.",Intermedio,Jornada completa,"Tecnología de la información, Marketing, Publicidad","Marketing y publicidad, Producción multimedia, Servicios y tecnologías de la información",70,None,False,,273,None
140,2167600550,2020-11-05,Trissential,UX Researcher,"Rochester, Minnesota, United States","OverviewTrissential is a trusted partner for end-to-end quality services and management consulting. As a part of our parent company Expleo, we have a footprint in 30+ countries. Our Mission is to have a positive impact on every person who interacts with Trissential. Clients love us because we are service focused. Employees love us because they are valued and cared for. Come join a team where benefits start the first day of employment and compensation plans are designed to meet a flexible life style. We are looking for a UX Researcher to join a new product team providing digital patient services. ResponsibilitiesConduct product user research through interviews, contextual inquiry, work groups, surveys, and analyticsDefine usability goals and evaluate usability solutions, including baseline testing and iterative prototype testingDefine Accessibility requirements based on product features and intended audienceDefine and execute prototypes and test approaches for research and assumption validationDevelop user persona's, journey maps, storyboardsPlan and carry out interviews and surveys to inform future product work.Build relationships with key stakeholders and clients to gain deeper insights.Establish and manage relationships with research-related vendors.Collaborate with other researchers, product managers, and UX designers to ensure research translates into business impact.Create a test plan, write a screener, recruit users, schedule users, moderate test, create video clip highlights, compile top-line results, create a findings summary, author durable reports, and effectively present and share results. QualificationsBachelor’s or master’s degree in Interaction Design, Graphic Design, Human-Computer Interaction, Industrial Design, or related field SkillsA mixture of creative and technical skillsCreativity and innovation, to come up with new ideasEnthusiasm for design and technologyEmpathize with users and uncover latent needsSynthesize and simplify data for sharingCo-create innovative solutions to problemsCollaborate in a team environmentQuickly develop user-testable prototypesExcellent verbal and written communication skills.  Listen activelyAble to collaborate effectively with stakeholders and act as a strategic partner in product decisions. Experience3+ years conducting user research for software/web-based productsExperience of using prototyping software tools, for example Axure Pro and OmnigraffleAbility to use Adobe Creative Cloud, including Photoshop.Previous experience working on product teams in an Agile environmentDemonstrated experience with various audiences and levelsAble to perform all research-related tasks in the research project lifecycle",Intermedio,Contrato por obra,"Tecnología de la información, Diseño","Servicios y tecnologías de la información, Atención sanitaria y hospitalaria",70,None,False,,465,ACTIVELY_HIRING_COMPANY
141,2004865326,2020-10-02,ADVANTIS Global Inc.,User Experience Researcher,"Seattle, Washington, United States","ABOUT THIS FEATURED OPPORTUNITY We are looking for a motivated mixed-methods (qual + quant) UX researcher with excellent communication and people skills. Strong candidates will demonstrate a rigorous approach to UX research methods as well as have experience developing solution concepts and shipping consumer products.  ﻿THE OPPORTUNITY FOR YOU  You will work with other UX researchers as well as multi-disciplinary hardware and software teams to push the boundaries of what is possible in the AR/VR product and research science spaces. Ultimately, your expertise and ingenuity in research must do more than just contribute to knowledge - you must also be skilled at driving measurable positive impact on the product and user experience. KEY SUCCESS FACTORS5+ years of experience in product UX researchKnowledge of qualitative and quantitative research methods Experience with survey design and response effects Experience in one or more phases of the product lifecycle, from early generative research, to concept evaluation, to ship, to in-market UX research Passion for consumer technology Experience shipping consumer hardware and wearable technologies Experience working with design teams Work experience in the AR/VR space or other emerging technologies Strong skills in qualitative research and analysis Experience with Matlab, Python, R is a plusAble to drive impact through a range of research approaches and tools, including literature review, qualitative methods (observation, contextual inquiry, interview), usability, experimentation, & survey research.Experience leveraging hardware prototypes and sensors to collect user data related to human perception, human performance etc.Able to work closely with other UX researchers to help design research plans and specific studies, as well as communicate findings with stakeholders and drive impact of the work.Able to work independently executing research, including data collection, data analysis, reporting, shareouts, and knowledge consolidation.Able to coordinate with teammates and run multiple studies in parallel Able to work effectively with cross-functional partners (e.g., industrial design, UX design, hardware & software engineering, PM) to ensure our research accounts for their needs and creates a complete picture of the user experience. #LI-WC1",Intermedio,Contrato por obra,"Tecnología de la información, Investigación","Dotación y selección de personal, Electrónica de consumo, Software",330,None,True,,1522,ACTIVELY_HIRING_COMPANY
142,2231896204,2020-11-02,EXTIA Romania,Data Engineer - REMOTE,Romania,"This position is for one of our clients, specialised in Microsoft solutions. What skills you should have? • Good working knowledge of Azure data services e.g.:  Azure SQL Database options, Azure Cosmos DB, Data Lake, Azure Storage,  Data Factory, Databricks:• Working knowledge of Azure Databricks or Databricks platform:• Good knowledge of Apache Spark framework (SPARK 2.3x):• Databricks Delta Lake – ACID transactions, metadata handling:• Programming skills in Python:• Proficient with both Python (in a Spark environment) and SQL  (PySpark & Spark SQL)• Experience with Power BI Highly desirable• Agile methodolgy experience• CI/CD, Azure DevOps experience, highly desirable Apply and let's talk more!",Intermedio,Jornada completa,Consultoría,Servicios y tecnologías de la información,31,None,True,,236,ACTIVELY_HIRING_COMPANY
143,1961916425,2020-10-09,Global Touchpoints Inc.,Data Engineer,San Francisco Bay Area,"One of our Hi-tech 'social media' client is looking for Data Engineer's who has solid background in building ETL pipelines and building data products with expertise working in Python and SQL. We see a potential opportunity for all Data Enthusiats out there who would love to play around with multiple large scale data-sets.  Position : Data EngineerEmployment Type : Open for both FTE/Contractors Location : Remote (client location is in San Francisco, Bay area) Your Role:Individual contributor to help build data products and ETL pipelines.  Minimum Qualifications:Python development experience. Experience with more than 1 language is preferred.SQL (Oracle, Vertica, Hive, etc.) experience.Data Modeling, Data warehousing and pipelines.Ability to analyze data to identify deliverables, gaps and inconsistencies.Experience in custom or structured (i.e. Informatica/Ab Initio/Talend/Pentaho) ETL design, implementation and maintenance.Experience working with either a MapReduce or a MPP system on any size/scale.Communication skills including the ability to identify and communicate data driven insights. Responsibilities:Build data expertise and own data quality for the pipelines you build.Architect, build and launch new data models that provide intuitive analytics to your customers.Design, build and launch extremely efficient & reliable data pipelines to move data (both large and small amounts) to our Data Warehouse.Design and develop new systems and tools to enable folks to consume and understand data faster.Use your expert coding skills across a number of languages from Python, Java and PHP.Build framework for auditing, error logging & master data management for your pipelines.Work across multiple teams in high visibility roles and own the solution end-to-end.",Intermedio,Jornada completa,"Tecnología de la información, Ingeniería, Análisis","Software, Servicios y tecnologías de la información, Medios de comunicación en línea",476,None,True,,1322,ACTIVELY_HIRING_COMPANY
144,2269868653,2020-10-09,ClassDojo,Data Scientist / Product Analyst,"San Francisco, CA, US","ClassDojo's ultimate goal is to create an education system that gives every child on Earth an education they love. We are doing this by bringing together communities of teachers, children and families, and then helping them get learning experiences their children love. Last school year, we served over 40 million children—with a team of just 45.  Data is core to how ClassDojo makes decisions. As our third Data Scientist / Product Analyst, you'll help build a global consumer education business reaching tens of millions of parents, teachers, and children by creating, monetizing and analyzing products,. You'll grow ClassDojo to our next major milestone: reach 100 million+ active families, and 100 million+ in revenue, while deepening our brand love.  As a data science team, we work closely with partners across product, engineering, design, research and marketing to develop business insights and inform product and company strategy. We're looking for high-performing generalist data scientists, with experience in product and/or business analytics, to come work alongside us to take on some of the most interesting and impactful problems in education.  You'll shape direction as part of a high context, cross-functional team, where we value learning quickly to build a modern education system for hundreds of millions of teachers, children and families. You'll pursue a variety of problems ranging from understanding our users, to ensuring we invest in the right growth strategies in each of the 180+ countries we operate in, to growing our community, to empowering teams to find their own answers. You'll work with colleagues across the business to uncover insights, design experiments and measure the impact, and ultimately help influence decision-making across the entire company.  What you'll do:  Partner with product managers, engineers, marketers, designers, and operators to define product strategy and direction Develop analytical frameworks to monitor business and product performance, including growth and engagement Identify opportunities for growth by designing and analyzing product experiments, working with cross-functional teams to translate insights into action Empower teammates with the skills and tools to make data-driven decisions.   Relevant Skills / Experience  3+ years of industry experience in a data science or analytics role Ability to write structured and efficient SQL queries on large data sets Experience designing AB/multivariate tests and drawing actionable conclusions Ability to visualize and communicate insights to stakeholders Bonus: Experience with data pipelines: transforming raw production and external data into user-friendly tables. Americas timezones   About ClassDojo  ClassDojo's mission is to bring communities together, and help them create an education experience their children love. Founded in 2011 (ImagineK12 / Y Combinator) and based in San Francisco, California, ClassDojo started as a communication app: a simple way for teachers, families, and children to share the magic of the school day through photos, videos, and messages. It creates a close-knit classroom community, and exciting, inspiring and creative classrooms and homes for kids. We're one of the fastest growing education companies of all time, used and loved by tens of millions of teachers, families and children in 90% of K-8 schools in the US, and 180 other countries.  You can read more about our vision to change education from the ground up here: https://medium.com/@samchaudhary/https-medium-com-samchaudhary-how-to-change-education-from-the-ground-up-f82b8f3e4b95.  The Team  We believe focused, talented, non-hierarchical teams can achieve a surprising amount: https://blog.ycombinator.com/its-surprising-how-much-small-teams-can-get-done-sam-chaudhary-of-classdojo/. Our team is made up of engineers, designers, and educators from around the world, with deep backgrounds in education, as well as from leading consumer internet organizations like Instagram, Netflix, Dropbox, Uber, Y Combinator and more. We're building a company that will transform education, and one that is the kind of place we've all always wanted to work. We believe you'll do the best work of your life here.  Diversity  ClassDojo's vision is to give every child on Earth an education they love. We strongly feel the best way to do this is to work with people from diverse backgrounds that truly reflect the world. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. In accordance with the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records. We are happy to accommodate any disabilities or special needs. We hire both locally in San Francisco, and distributed teammates around the world.  If you're excited about having an impact in education at massive scale, we'd love to hear from you.",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Software, Internet",21,None,False,,122,COMPANY_RECRUIT
145,1974064488,2020-11-08,BedRock Systems,"Security Researcher, Threat Intel Lead","San Mateo, California, United States","Full timeSan Mateo, CA – DC Metro AreaThe Current StateBusinesses should be built on a rock-solid foundation. However, the current edge and cloud computing infrastructures are built on a foundation of sand. None of its components should be considered “trusted.” Design and implementation defects in these components give rise to vulnerabilities that can become critical security flaws. And security flaws become safety issues and can severely impact governments and entire industries.BedRock’s MissionOur Mission is to BedRock the world’s critical systems from Edge to Cloud, implementing the most secure and Trusted Compute.THE FUTURE IS BUILT ON BEDROCK – An Unbreakable Foundation for Formally Secured Computing. BedRock Systems is on a mission to deliver a trusted computing base from edge to cloud, where safety and security isn’t just a perception, it’s a formally proven reality. Our foundation does not require painful up-stack changes: it embraces existing hardware, operating systems, and application ecosystems. When systems are BedRocked, the operation is secured, innovation is unlocked, new services are launched, trust is re-established, and revenue can grow. Governments and businesses gain back velocity and can securely evolve at the speed of software.Our Team Is Growing!BedRock Systems is a stealth startup with a global team. Our platform is based upon cutting-edge technology and leverages the latest development methodologies and tools. We were founded by industry veterans who built large successful companies from scratch. Our top-notch team is a mixture of the best from industry and academia. Come transform the computing landscape. Join the BedRock Systems team!As a BedRock Security Researcher, Threat Intel Lead you will:Establish the cyber threat intelligence (CTI) program for BedRock’s customersGuide development of products to maximize the security impact for our customersEstablish the process for acquiring threat intelligence data in customer sectors through our products and servicesPublish research in blogs and at conferencesYou could be a great fit for this role if you: Must Haves:Experience working in a threat intelligence or incident response roleAbility to lead and grow a CTI programAbility to set up and write your own automation tools and workflowsCan set up and write your own tools and your own analysis workflowsMust be able to clearly communicateAbility to work independentlyNice to Have:Reverse engineering experienceExperience interacting directly with customersOpen-source contributions/projects in the domainActive US Security ClearanceWhy BedRock?We were founded by industry veterans who built large successful companies from scratch. Our top-notch team is a mixture of the best from industry and academia. Come transform the computing landscape.BedRock is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Software, Seguridad del ordenador y de las redes",164,None,True,,941,JOB_SEEKER_QUALIFIED
146,2218910922,2020-10-19,Ualá,Data Engineer,Argentina,"#Somos﻿Ualá, una fintech que nació de la convicción de trabajar por la inclusión financiera con un producto digital basado en las últimas tecnologías. Queremos que más gente tenga acceso al sistema financiero, que puedan realizar sus transacciones personales de manera más fácil, transparente, cuándo quieran y dónde quieran! Queremos sumar a nuestro equipo un/a Data Engineer para el equipo de Data & Business Intelligence. Su objetivo será construir, mejorar y mantener la plataforma de datos que se encarga de procesar y disponibilizar toda la data (a nivel infraestructura y código) para la extracción, transformación y carga de datos de los distintos orígenes a nuestra plataforma de datos. Tendrás el desafío de...Construir y mantener los pipelines que ingestan, procesan y transforman los datos en la plataforma.Ayudar y contribuir con nuestra 'infraestructura como código': Utilizando Terraform y Github Actions para soportar nuestro flujo CI-CD.Proponer, evaluar y contribuir en la definición de la arquitectura planteada para la plataforma de datos (respecto a los servicios elegidos y el diseño planteado).Colaborar con los distintos desarrollos del equipo utilizando mayormente Python, SQL y todo el stack de AWS (orientado principalmente a Big Data con EMR (Sqoop/Spark), Glue, Lambdas entre otros .Trabajar codo a codo con los equipos de negocio, BI y ML para generar soluciones de reporting y modelos de machine learning que contribuyan con la toma de decisiones.Investigar, probar y proponer nuevas ideas y tecnologías que permitan llevar al próximo nivel nuestra plataforma de datos.Monitorear, controlar y velar por el cumplimiento de estándares, políticas y buenas prácticas de desarrollo dentro del equipo. Para tomar este desafío necesitamos principalmente que cuentes con...Estudiante o Graduado/a en carreras de Ingeniería/Licenciatura en sistemas y/o informática, o carreras afines.Experiencia manejando grandes volúmenes de datos.Excelentes habilidades de comunicación y presentación.Modelado de DatosIngles Avanzado (deseable)Habilidades de programación ETL utilizando herramientas como Python, Spark, PySpark, Hadoop, MapReduce o Kafka.Experiencia trabajando con infraestructura en la nube.Experiencia trabajando con servicios de AWS orientados a datos (Glue, EMR, Redshift, Firehose, etc). Todos los niveles de experiencia.Experiencia en ingesta de datos a partir de APIConocimientos en Data Catalog, Data Governance, Data Lineage (no excluyente).Conocimientos de herramientas de ETL (Pentaho, Talend, Informática Power Center) (no excluyente).  ﻿Queremos compartir con vosEl desarrollo conjunto de soluciones innovadoras con impacto social, en un ambiente laboral flexible, en crecimiento y de enorme potencial de desarrollo profesional.Te ofrecemos descuentos en capacitación y en entidades educativas de primer nivel.Apostamos al balance entre la vida profesional y personal: contamos con tres semanas de vacaciones, licencias extendidas por maternidad y paternidad, día libre de cumpleaños, política de home office, y más.Además te ofrecemos: cobertura de medicina prepaga para grupo familiar, descuento en gimnasio, reintegro por almuerzo, bono por referidos, entre otros beneficios. ¡Sumate a Ualá!",Algo de responsabilidad,Jornada completa,Tecnología de la información,Servicios financieros,99,None,True,,906,ACTIVELY_HIRING_COMPANY
147,2218879495,2020-10-28,Burns Sheehan,Contract Data Engineer,United Kingdom,"Contract Data Engineer / Python / AWS / Spark - £450 - £550 - 6 months Our client, a start-up in a disruptive field are looking for a Data Engineer to join on contract for a 6 month initial engagement. They are very early on in their journey and this Data Engineer will be responsible for building out their Data pipelines via ETL to ensure that the Data they are getting is structured & effective. For this Data Engineer role, this will primarily be done in Python but there will be additional responsibilities, primarily around cloud technologies, database work & big data pipelining. As a start-up things are very fast paced and as a Data Engineer you will need to be a self-starter and work on your own 2 feet, especially as this is a remote role. So, if you're a Contract Data Engineer looking for your next role, we need to see the following:Excellent Python skillsCloud experience (AWS/GCP)Any other programming (Scala or Java)SQL (multiple flavours)Extensive ETL experienceSpark & other big data toolsAnd for the most part with this Contract Data Engineer, that is it! So don't hesitate & apply now for immediate consideration! Contract Data Engineer / Python / AWS / Spark - £450 - £550 - 6 months",Intermedio,Jornada completa,"Tecnología de la información, Análisis, Gestión de productos",Dotación y selección de personal,64,None,True,,221,JOB_SEEKER_QUALIFIED
148,2185172784,2020-11-06,RomAnalytics,"Data Engineer, Artificial Intelligence",New York City Metropolitan Area,"Live and breath AI??? Join a team that is living and breathing AI into the Life Science Industry!  RomAnalytics is recruiting this exciting REMOTE position on behalf of an AI-driven pharmaceutical omni-channel marketing solution company. The company combines real-world claims data with advanced AI. The company is uniquely positioned to find, engage, and convert a pharmaceutical brand’s Ideal Patient Population and their associated healthcare providers, offering a unique omni-channel solution to life sciences organizations. The Position:Optimize code to run efficiently in a distributed data environmentSupport creation of architecture and manipulation of health data assets into a distributed data environment and develop utilities to support data extraction and analysisIndependently research and procure core knowledge of diagnoses and treatment in specific therapeutic areas to drive internal business decisions for the design of user-defined functionsAnalyze secondary data and research to identify key findings and trendsGenerate cohesive outputs in summary outputs (R, Scala, Python) tying project objectives and goals to data outputAssist in drafting quantitative or qualitative analysis to support client deliverables and issuesAssist in the management of projects and workstreams and help with shifting prioritiesAssist in drafting and updating internal tools with supportive documentation for projects and process flows for evolving standard operations and proceduresDevelop broad knowledge of the healthcare market and monitor market changes and events within the industry Skills & ExperienceKnowledge and a basic understanding of the fundamental processes of pharmaceutical and medical device industriesAn avid interest in healthcare analytics, technology, and clinical dataStrong attention to detailStrong capabilities in multi-tasking and flexibility for a dynamic working environmentBusiness acumen and a fundamental understanding of the sales processStrong interpersonal and communication skillsAbility to think creativelyPrior working experience in any of the following forecasting, statistics, predictive modeling, primary/secondary market research, technology & applications, healthcare IT, managed markets, management consulting, sales force effectiveness, sales operations, business intelligence, epidemiology, HEOR, or data miningAdvanced experience coding SQL or Scala in a distributed database environment required Compensation Package:Generous Salary & Performance-based commission commensurate with experience",Intermedio,Jornada completa,"Tecnología de la información, Ingeniería, Análisis","Industria farmacéutica, Biotecnología, Consultoría de estrategia y operaciones",524,None,True,,1438,ACTIVELY_HIRING_COMPANY
149,2201835553,2020-10-22,Showpad,Data Engineer,"Ghent, Flemish Region, Belgium","About Showpad Showpad is the leading sales enablement platform for the modern seller. Showpad’s all-in-one platform empowers sales and marketing teams to engage buyers through industry-leading training and coaching software and innovative sales content and engagement solutions.  At Showpad, personalities and cultures connect across oceans to create something extraordinary. As a top 10 software company in the Inc. 5,000 Europe list, Showpad is changing the game when it comes to sales enablement. Our employees create the engagement and impact that drives our success as we expand globally. In the morning, we’re drinking San Francisco cold brew coffee with a side of Portland doughnuts – English scones for afternoon tea, and in the evening we’re toasting success with Belgian tripel Westmalle to a Chicago house tune.  About the position As a Data Engineer, you will shape the future of the Showpad product by developing its data intelligence platform. Showpad is a data-centric company and you will help to develop an ecosystem of services that retrieve, process, enrich, and serve that data. Your decisions will help make Showpad the ultimate intelligent sales platform.  Key responsibilities as a Data Engineer at Showpad Apply data-driven product development techniques to improve Showpad’s search and intelligence productsWork in software teams where code reviews and pair programming are part of our strong engineering cultureTake a security-first approach to implement features and changesWork together with Product Management and other stakeholders (Frontend, UX, etc.) to iterate on new features within the Showpad platformHave a passion for bringing a smile to the face of our customersHave a keen eye on the bigger picture because everything you do will have an impact on more than 100,000 global users Skills we are looking for Experience with scalable, production-ready, backend code using JVM-based languages and frameworksExperience with a modern server framework such as Vert.x, Micronaut or Spring BootExperience with building data products based on Kafka and ElasticsearchExperience working in a cloud environment. Knowledge of AWS core services is a plusExperience containerizing and deploying cloud-native applications and services. Kubernetes experience is a plusFamiliarity with data analysis tools like Jupyter notebooksAbility to model data and queries around feature requirements.Experience with Kotlin (or strong desire to learn)Understands the importance of strong software testing at every stageContinuous integration and delivery mindsetExperience designing and implementing APIs for, and collaborating with, internal and/or public data consumersTeam player mentality, committed to the whole software development life cycle in an agile team  What you can expect from Showpad Focus on Impact and Growth We are building the future in sales and marketing where every sales person is successful. As an international scale-up, we aim for yearly double digit growth that opens many opportunities. We want people who thrive in a fast-paced, performance-driven company, who are not afraid to stretch themselves in a fun environment, and focus on impact and growth.",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información","Software, Servicio de información, Servicios y tecnologías de la información",15,None,False,,212,ACTIVELY_HIRING_COMPANY
150,2020174048,2020-11-05,Pluralsight,Senior Data Scientist,"Draper, UT, US","This position is available for remote employment in these areas:Boston MA, Draper UTJob Description: The Opportunity  Pluralsight Iris is the learning intelligence platform built within Pluralsight. It helps technologists worldwide discover the learning they need to achieve their personal and career goals in technology.  As a data scientist on our core team, you will help us solve novel statistical, machine learning, and data science problems by building and improving on the intelligence of Iris. We are looking for an experienced data scientist who loves tackling ambiguous problems, finding creative and practical solutions, and producing concrete prototypes that will become a key part of Pluralsight’s user experience. You’ll work closely with an established team of top-notch, collaborative data scientists and you will collaborate with a cross-functional product team that is responsible for one of Pluralsight’s key differentiators.  Who You Are  You are intellectually curious, collaborative, and highly driven with an entrepreneurial mindset. You have excellent critical thinking, problem solving, and analytical skills.  You can guide complex projects from ideation and planning to model design to deployment and independently make decisions about the technical approach  You have a solid data science toolkit that you can leverage, with knowledge of and understanding of how and when to apply different algorithms and technical approaches.  You have a strong foundation in Machine Learning, Computer Science, and Statistics.  You have mastery of either Python or R. Regardless of your favorite scientific computing environment, you can flex between the two languages.  You know your way around SQL-like databases (e.g. PostGres, Impala, Hive) and even better if you have experience with Spark and other big data platforms.  You are able to perform rapid prototyping of experimental solutions, writing readable, scalable, and reproducible code.  You can describe and speak in an approachable way about complex analyses and concepts within a cross-functional team. You are a great “analytic translator”.   What You’ll Do  You will collaborate with product teams to understand and solve complex problems: envisioning and creating data science solutions needed to drive our user experience outcomes.  You will create, iterate, and innovate on models and algorithms and collaborate with team members to implement them on the Pluralsight platform.  You will evaluate and introduce new technology by developing proof-of-concepts and prototypes and effectively communicating highly complex information to Experience team partners and leaders  You will propose and design experiments to test new product features and analyze their results.  You will also serve as a data science expert and consultant to Pluralsight’s product teams, leveraging your statistical and analytical skills to answer ad hoc questions.   Experience You’ll Need  M.S. or Ph.D in Computer Science, Statistics, Mathematics, Data Science, or related quantitative discipline  Minimum 5 years in a non-academic data science role, conducting analysis, developing algorithms and building prototypes  Experience working with product development teams and/or with developers",Algo de responsabilidad,Jornada completa,Otro,"Marketing y publicidad, Servicios y tecnologías de la información, Software",148,None,False,,1187,ACTIVELY_HIRING_COMPANY
151,2150932034,2020-10-29,Square,"Data Engineer, Marketing","San Francisco, CA, US","Company Description  Square builds common business tools in unconventional ways so more people can start, run, and grow their businesses. When Square started, it was difficult and expensive (or just plain impossible) for some businesses to take credit cards. Square made credit card payments possible for all by turning a mobile phone into a credit card reader. Since then Square has been building an entire business toolkit of both hardware and software products including Square Capital, Square Terminal, Square Payroll, and more. We’re working to find new and better ways to help businesses succeed on their own terms—and we’re looking for people like you to help shape tomorrow at Square.  Job Description  As a Data Engineer on the Marketing team, you will join an organization whose mandate is to develop foundational data and reporting infrastructure to driving Square's revenue growth and accelerating seller acquisition. You will collaborate and work with teams across Square to build outstanding data pipelines, dashboards and processes that stitch together complex sets of data stores and guide large investment decisions. Your work will have an impact on hundreds of partners at Square.  You Will Develop data foundation and architecture, data pipelines and dashboards to ensure accurate and reliable business reportingPartner with business leads to understand their data and reporting requirements and translate them into Product Requirement Definitions and technical specificationsBe the expert on end-to-end data flow for MarketingBridge the gap between business requirements and technical implementation by troubleshooting data discrepancies and implementing scalable solutions, and communicate with high-level stakeholders in formatsMonitor daily execution, diagnose and log issues, and fix business pipelines to ensure SLAs are met with internal stakeholdersMake data model and ETL code improvements to improve pipeline efficiency and data qualityMentor Data Engineers and Data Analysts, and promote data engineering best practices  You Have  Qualifications 6 years experience in Data Engineering or similar role6 years experience in writing complex SQL and ETL development with experience processing extremely large datasets within cloud-based data warehouses like Snowflake, Google BigQuery, and Amazon RedshiftExpert knowledge in data warehousing architecture and concepts, and dimensional data modelingExperience in PythonExperience working with business teams on complex problems and translating them to efficient, scalable and easy to maintain data engineering solutionsBS degree in Engineering, Computer Science, Math or a related technical field  Technologies We Use And Teach SQL and PythonLooker, or other data visualizations technologiesETL scheduling technologies with dependency checking such as AirflowLinux/OSX command line, version control software (git)  Additional Information  At Square, we value diversity and always treat all employees and job applicants based on merit, qualifications, competence, and talent. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. We will consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the San Francisco Fair Chance Ordinance. Applicants in need of special assistance or accommodation during the interview process or in accessing our website may contact us by sending an email to assistance(at)squareup.com. We will treat your request as confidentially as possible. In your email, please include your name and preferred method of contact, and we will respond as soon as possible.  Perks  At Square, we want you to be well and thrive. Our global benefits package includes: Healthcare coverageRetirement PlansEmployee Stock Purchase ProgramWellness perksPaid parental leavePaid time offLearning and Development resources",Sin experiencia,Jornada completa,Tecnología de la información,"Software, Internet, Servicios financieros",290,None,False,,1874,COMPANY_RECRUIT
152,2213581476,2020-10-26,Sperax,Researcher -Blockchain Technology,United States,"About Us Sperax (https://sperax.io/) is a Silicon Valley-based blockchain platform that builds trusted infrastructure for decentralized economy to connect the physical world with decentralized ecosystems.  With its innovative BDLS protocol, Sperax offers a high performance consensus module that is more secure for decentralized applications than other BFT consensus. On top of it, Sperax is building an embedded financial layer, with its native multi-currency stablecoin, to connect the crypto world with real-world financial services through partnerships with regulated financial service operators and payment integrators.  Believer of technology innovations, we mission to build a blockchain-enabled society that is equal and inclusive society. Our team consists of purpose-driven engineers, mathematicians, marketing specialists and designers that have faith in our value and culture.  Sperax envisions to be global from day one. We currently have offices in San Francisco, Singapore, New York, Beijing, and are expanding in Europe. You will:●     Conduct research on blockchain projects including analyzing their technology white paper, reading their GitHub codes, and writing analysis reports or introductory articles on them●     Track current trends in blockchain industry including watching blockchain-related news, keeping track on interesting projects, and writing introductory or analytic articles on them●     Research on top DeFi projects including reading their documents, experimenting on their functionalities, and write introductory articles or analytic reports●     Interact with blockchain KOLs on social medias and forums and promote Sperax blockchain project You have:●     A strong passion for our mission●     Enthusiasm to work in a startup environment●     A bachelor’s degree in computer science or in related fields, familiarity with cryptography preferred●     Basic knowledge on blockchain technology like Bitcoin, Ethereum, smart contract, Proof of Stake consensus, Byzantine Fault Tolerance, etc.●     Strong writing abilities●     Strong communication skills●     Proficiency in English●     Bonus: experience in smart contract development, e.g. Solidity codes on Ethereum●     Bonus: knowledge on DeFi, stable coin, cross-chain technology, side chain, ZK Rollup  What we offer:●     Competitive salary and token plan●     Medical, dental, and vision insurance●     401k plan●     Work visa (H1B etc.) applications●     Multicultural work environment●     Beautiful office space",Algo de responsabilidad,Jornada completa,"Investigación, Análisis, Tecnología de la información","Servicios y tecnologías de la información, Servicios financieros",123,None,True,,428,ACTIVELY_HIRING_COMPANY
153,2239751251,2020-11-03,Sharecare,Data Scientist,"New York, United States","Sharecare is the digital health company that helps people manage all their health in one place. The Sharecare platform provides each person -- no matter where they are in their health journey -- with a comprehensive and personalized health profile, where they can dynamically and easily connect to the information, evidence-based programs and health professionals they need to live their healthiest, happiest and most productive life. With award-winning and innovative frictionless technologies, scientifically validated clinical protocols and best-in-class coaching tools, Sharecare helps providers, employers and health plans effectively scale outcomes-based health and wellness solutions across their entire populations. We are always looking for people that value the opportunity to work hard, have fun on the job, and make a difference in the lives of others through their work every day! Job Summary: Sharecare is searching for a Data Scientist/Statistician who will support our product, delivery, sales, leadership and marketing teams with insights gained from analyzing company data. The ideal candidate is adept at using large data sets to find opportunities for product and media delivery process optimization and using models to identify target audiences. The Sharecare Data Scientist must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. He/she must have a proven ability to drive business results with their data-based insights. He/she must be comfortable working with a wide range of stakeholders and functional teams. The right candidate will have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes. Essential Functions:Formulates and leads guided, multifaceted analytic studies against large volumes of data.Interprets and analyzes data using exploratory mathematic and statistical techniques based on the scientific method.Coordinates research and analytic activities utilizing various data points (unstructured and structured) and employ programming to clean, massage, and organize the data.Experiments against data points, provide information based on experiment results and provide previously undiscovered solutions to command data challenges.Coordinates with Data Engineers to establish requirements for and/or build data environments for modelingWorks closely with all business units and engineering teams to develop strategy for long term data platform architecture.Mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and media optimization strategies.Develop custom data models and algorithms to apply to data sets.Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.Develop company A/B testing framework and test model quality.Coordinate with different functional teams to implement models and monitor outcomes.Develop processes and tools to monitor and analyze model performance and data accuracy. Qualifications:Master's degree in Operations Research, Industrial Engineering, Applied Mathematics, Statistics, Physics, Computer Science, or related fieldsFluency in statistics/statistical methods2-4 years of professional experienceProficient with one or more programming languages (Java, C++, Python, R, SPSS etc.)Demonstrated experience applying data science methods to real-world data problemsExperience utilizing visualization tools to take advantage of the growing volume of available informationAbility to multitask, manage tight deadlines, and work effectively with cross-functional teams in an ever-changing and exciting environmentStrong communication skills (written and verbal) with a results-oriented mindset",Algo de responsabilidad,Jornada completa,"Ingeniería, Tecnología de la información","Sanidad, bienestar y ejercicio",133,None,False,,469,None
154,2193858856,2020-10-30,Compri Consulting,Data Scientist,Denver Metropolitan Area,"Denver, Colorado or REMOTEDuration: thru 3/31/21 with possible extension/conversion The role will be a member of our Machine Learning Operations Team (ML Ops), working on all aspects of platform development for data science work. Qualified candidates will have demonstrated success in data engineering, software engineering, and advanced experience developing machine learning models through experimentation. DaVita aims to transform dialysis care and clinical operations through the use of artificial intelligence. You will join a large data science team with access to large data sets, an incredibly robust AI platform, and be surrounded by top talent.Skills: •   Building production-grade models on large-scale datasets to identify new insights by utilizing advanced statistical modeling, machine learning, or data mining techniques •   Deploying model training and inference •   Developing and maintaining machine learning infrastructure that powers clinical and operations decision-making •   Conducting Proofs of Concepts relating to AI pipeline development, rapid ML modeling, and improving the data science experience from model ideation to post-deployment maintenance and support. Education and Experience: •   Bachelor of Science (Com Sci, Engineering, Mathematics, Statistics) Mandatory Master's preferred Demonstrable experience in software development including testing (unit tests, integration tests), advanced programming concepts (types, OOP, FP) You have worked with Docker extensively and container centric frameworks (Kubernetes, Helm) •   You have coding experience, specifically wrangling (such as with Python, SQL, Java, and/or Scala) and analyzing (such as with Pandas or R) large datasets •   You have worked extensively with machine learning (such as Tensorflow, PyTorch, or Ray), natural language processing, and advanced analytics (e.g. time series, regression, neural networks, mathematical optimization) You have experience with workflow orchestration tools such as Airflow, Kubeflow, MLFlow, CI/CD",Algo de responsabilidad,Contrato por obra,Tecnología de la información,Servicios y tecnologías de la información,445,None,True,,1060,ACTIVELY_HIRING_COMPANY
155,2273298193,2020-11-04,MCS Group | Your Specialist Recruitment Consultancy,Big Data Engineer Contract - Remote working,"Belfast, GB","Big Data Engineer Remote Working   MCS Group are delighted to be working along side a global powerhouse at the forefront of technology in their industry who have a requirement for two data Engineers to join the team for a remote working contract. You will play a key role for leading the technical delivery of systems that must achieve a unique blend of low latency performance, big data scalability, and rock-solid reliability and integrity, all while undergoing rapid release cycles.  You will sit in the Data flow team, helping to populate into the Data Lakes for downstream into applications. Working with big data critical to the current integration and continuous work at this organisation.   Excellent Date rate Contract    The Role   Working with technologies like Map Reduce / Spark, python Java, AWS  You will be working in an agile environment with CI/CD  Assists with system design, working with the various teams to build fit for purpose platforms.  Works ahead - ensuring the architecture is responsive to evolving needs  As this is a remote role communication is key, you need to be a team player. Assisting the teams as required to achieve delivery milestones.  Utilises the expertise of the team to develop architecture through consensus and team approach.  Hands on with detailed design and architecture plans for complex, large scale efforts within a multi-cloud environment.    The Candidate   Experience in python, Java, Linux, AWS  Experience architecting enterprise software applications  Previous banking / fintech experience  Developing and automating solutions directly related to Continuous Integration/ Continuous Delivery and infrastructure automation  Experience coding in a story-driven, agile environment  Experience working in the Big Data space handling both real time and batch  Experience in the Hadoop ecosystem using EMR, Map Reduce and/or Spark    To speak in absolute confidence about this opportunity please contact Jennifer  Curran  , IT Contracts at  MCS  Group on click apply or send an up to date CV via the link provided.   If you are considering a move to contracting roles but would like more information before committing, please get in touch. We run late night appointments on a Monday evening for discussions around the market, setting up and active roles. Please visit us at . mcsgroup .jobs to view a wide selection of our current jobs or call us on click apply.",Algo de responsabilidad,Contrato por obra,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Dotación y selección de personal, Servicios financieros",8,None,False,,63,ACTIVELY_HIRING_COMPANY
156,2261179401,2020-10-31,VIQU Recruitment,Data Engineer - Remote - 3 months contract,"Nottingham, GB","Data Engineer – Remote - 3 months contract. A SQL BI Developer / Data Engineer – Data SME is required by a Global Organisation based in Nottingham for an initial 3 month contract role. My client is in the mid to end stages of migration from SQL Server 2008 on prem to an Azure solution and require a SQL Developer to join this team to support this migration, whilst taking on other projects which come in. Ideal Skills:. Microsoft SQL Server 2008/2012/2014/2016. Migration experience using SQL Server Integration Services / SSIS. MS Azure / Azure Analysis Service. Strong demonstrable T-SQL experience. Good knowledge of ETL. Ability to analyse data to create new reports for operational use. Proficiency with Microsoft SSRS Tool (SQL Server Reporting Services). Knowledge of SSAS (SQL Server Analysis Services). Experience of working in Qlikview and Power BI will be advantageous. This is an initial 6 months contract and they are looking to bring this person in ASAP. To discuss this exciting opportunity in more detail, please APPLY NOW for a no obligation chat with your VIQU Consultant. Additionally, you can contact Matt Hudson, by exploring the VIQU IT Recruitment website. If you know someone who would be ideal for this role, by way of showing our appreciation, VIQU is offering an introduction fee up to £1,000 once your referral has successfully started work with our client (terms apply). To be the first to hear about other exciting opportunities, technology and recruitment news, please also follow us at ‘VIQU IT Recruitment’ on LinkedIn, and Twitter: @VIQU_UK.",Algo de responsabilidad,Contrato por obra,Tecnología de la información,"Servicios y tecnologías de la información, Software, Dotación y selección de personal",27,None,False,,152,None
157,2268620116,2020-11-02,Prognos Health,Associate Data Scientist,New York City Metropolitan Area,"Prognos’ is a NYC-based healthcare startup whose mission is to improve health by driving the best actions learned from the world's data. In order to achieve this goal we have curated the world’s largest clinical lab dataset, covering over 350M patients in the US, and are currently deploying cutting-edge technology for predicting disease at the earliest possible time. The Mission of the Data Science team at Prognos is to develop, deploy and maintain analytic and machine learning pipelines within Prognos’ products, addressing business-relevant problems in close collaboration with our Engineering, Clinical and Product teams. Candidate Profile and Responsibilities We are looking for an associate Data Scientist to join the team, and help us move this mission-critical task forward. This position will be focused on helping us analyze and evaluate healthcare data from our partners (laboratories, pharmaceuticals, etc..).You have a strong bias for action in a collaborative environment with a demonstrated track record of communicating clear insights from complex data (some relational, flat files and unstructured)You will analyze and extract preliminary insights from these datasets before anyone elseYou will work with the clinical team to define quantitative metrics that characterize the (multidimensional) utility of the data assets from potential partnersYou will evaluate disparate healthcare assets from potential data partnersYou will ll need to partner with stakeholders to quickly think through complex problems, determine effective analytical approaches, and clearly communicate results in a fast-paced setting. Candidates must have at least one year of prior professional experience working with large datasets. A bachelor’s degree or higher in Business Analytics, Computer Science, Engineering or a similar quantitative field is preferred but not strictly necessary, depending on industry experience. Growth with Us This position is highly visible and will provide you with a lot of opportunities to demonstrate your technical abilities. For the ideal candidate, this will be a springboard to grow into a full-fledged data scientist building predictive models within 18 to 24 months. We have a lot of resources that you can leverage to drive/build a successful career in data science and machine learning. From our weekly theory sessions, where we discuss research papers and the maths behind learning algorithms, to our research tracks where clinical and data scientists alike collaborate for a better understanding of conditions, testing. And we have a sizable ego-free team of fellow data scientists at all levels that you can lean on for growth. Required Skills and Experience At least one year of professional experience in a data engineering/data analysis /data science context.Professional experience wrangling large, complicated datasets from different sources and formatsBasic knowledge of sampling and inferential statistics (hypothesis testing, familiar probability distributions, confidence intervals, regression analysis, comparison of means, etc.)Experience with Python data analysis and plotting ecosystem (pandas, matplotlib and derivatives)Experience with SQL, regular expressions, string similarity and hashing algorithmsExperience with data manipulation in Spark/Dask/Python.Accustomed to working with git and shared codebases. Preferred Skills and Experience Experience with common AWS products and tools (EC2, S3, Athena).Experience with healthcare data and/or insurance data a plus. About Prognos Health Prognos is a leading clinically-focused healthcare analytics company with a platform that can query patient-centric data to answer key healthcare questions in minutes not months. The prognosFACTOR™ platform addresses payer, life sciences and provider needs, enabling clients to securely, efficiently and cost effectively analyze billions of lab and health records on more than 325 million de-identified patients. prognosFACTOR is HIPAA compliant and harmonizes and integrates lab data with other healthcare data assets from a trusted and diverse data ecosystem. For more information, visit prognoshealth.com. Values & Culture We are collaborative. We put team trust and energy ahead of individual stardom. We are humble and willing to admit when wrong.We go above and beyond. We exceed the needs of our partners and are not limited by our job descriptions. We are accountable for our actions, work, decisions, and results.We are purposeful in all that we do. We focus on what matters and prioritize. We think in perspective and see the full picture.We are curious. We learn from solving big problems. We are never satisfied and always strive for a better way. We aim to continually develop ourselves.We are courageous and honest. We are not afraid to speak out. We challenge the process. We deal with conflict head on.We are enthusiastic. We are optimistic for change and a better future. We believe in the greater good. We celebrate accomplishments and have fun. Our Mission To improve health by driving the best actions learned from the world’s data Our Vision To prevail over disease and empower people everywhere to live life to the fullest Selected Perks﻿Flexible work arrangements (e.g. no set hours), fully remote work, and unlimited PTOHealth InsuranceLife InsuranceShort Term and Long Term DisabilityDentalVision401(k)HSAFSADependent Care Flexible SpendingCommuter benefitsFree access to One Medical GroupGym discountsFlexible work hours and locationsHealth AdvocateEmployee Stock Option Plan",Sin experiencia,Jornada completa,"Tecnología de la información, Gestión de proyectos",Atención sanitaria y hospitalaria,1178,None,True,,2482,ACTIVELY_HIRING_COMPANY
158,2226349758,2020-10-31,Scorpion,Senior Machine Learning Engineer,United States,"About Scorpion:Scorpion is a full-service digital marketing & technology company that works hard to help our clients realize their goals and accomplish their vision. We partner with law firms, home services businesses, franchises, and healthcare organizations to deliver an experience unlike any other. Our services include website design, search engine optimization (SEO), pay-per-click (PPC) advertising, video advertising, online reputation management, social media marketing services, and branding/UX services. As of 2020, we have the honor of being named to the Inc. 5,000 list of fastest-growing private companies in America for the 10th year in a row.  About the Senior Machine Learning Engineer role:As a Senior Machine Learning Engineer at Scorpion, you’ll work with our growing data science team to develop data products for Scorpion and its clients. We’re looking for a highly skilled mathematician and python developer who will be excited to build new models and iterate on our existing suite of machine learning models.  Responsibilities:Bring extensive modeling expertise to the table when new projects are being prototyped and designedImprove the accuracy and scalability of existing models by using advanced feature engineering and modeling methodsSupport model monitoring efforts to any model degradation or application errorsContinue development of existing feature storesMentor junior members of the team to improve their modeling abilitiesValidate production models and analyze the performance of existing modelsAssessing the usefulness of new data sources, transformations, and modeling techniques Requirements:Extensive industry modeling experience (Masters/Ph.D. in Statistics/Data Science/Machine Learning/etc. and one prior role as a machine learning engineer OR 5+ years applied modeling experience)5+ years of Python development experienceExperience with machine learning cloud deployment (AWS/Azure/etc.)Python Expertise (including extensive experience with pandas/numpy/scikit-learn/xgboost/etc. - Bonus if applied experience with PyMC3)Statistics expertise (A/B Testing, experiment design, Bayesian methods, etc.)A deep understanding of common machine learning algorithms (RF, SVM, LR, GBDT, GLMs, etc.) as well as probabilistic modeling. (Bonus if the experience with NLP and/or NNs) ﻿Perks & benefits:Competitive pay100% remote-based100% of medical, dental, and vision coveredCommunity service opportunitiesTraditional and Roth 401(k)Paid-time offThe icing on the cake: an amazingly friendly and family-oriented culture",Intermedio,Jornada completa,"Ingeniería, Análisis, Investigación","Marketing y publicidad, Software, Atención sanitaria y hospitalaria",94,None,True,,336,None
159,2239883949,2020-10-25,EPAM Systems,Big Data Engineer,Romania,"EPAM is committed to providing our global team of 36,700+ EPAMers with inspiring careers from day one. EPAMers lead with passion and honesty and think creatively. Our people are the source of our success and we value collaboration, try to always understand our customers’ business, and strive for the highest standards of excellence. In today’s new market conditions we continue to support operations for hundreds of clients around the world remotely, with the vast majority of our teams working from home. No matter where you are located, you’ll join a dedicated, diverse community that will help you discover your fullest potential. DESCRIPTION: Currently, we are looking for a Big Data Engineer for our Romania office to make the team even stronger. EPAM invites talented and ambitious engineers to become part of our Big Data Solution Practice. We are looking for people with strive for self-development who are keen on data science and eager to work with Big Data tools and frameworks, NoSQL databases and cutting-edge technologies. RESPONSIBILITIES: Work on high-quality architecture and implementation design, collaborating with thecustomer, system/business analysts and onshore architects  REQUIREMENTS: 3+ years' experience in Java or ScalaExperience with Big Data (Hadoop, Spark, Kafka, etc.)Extensive experience building scalable, high-performance distributed systems, systems that deal with large data volumes, n-tier, client/server, cluster and load balanced architectures, web applicationsExperience working in agile continuous integration/DevOps paradigm and toolset (JIRA, Git, TDD, Test Automation, Jenkins)Solid technical EnglishLinux experience NICE TO HAVE: Knowledge of AWS, AzureWorking experience with scripting languages – Bash, Python, GroovyMachine learning experience  WE OFFER: Competitive compensation depending on experience and skills:Work in enterprise-level projects long-term:Full-time remote work (you can work from anywhere you are):Unlimited access to learning courses (LinkedIn learning, EPAM training courses, English regular classes, Internal Library):A community of 30,100+ industry’s top professionals.",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Servicios y tecnologías de la información,28,None,True,,174,ACTIVELY_HIRING_COMPANY
160,2191770075,2020-11-08,"RediMinds, Inc",Entrepreneurial Health Tech Researcher,"Southfield, Michigan, United States","Deep learning and medical imaging researcher Looking for an entrepreneurial health tech researcher to join a cutting-edge and mission-driven research team working at the intersection of artificial intelligence and medicine.At RediMinds you will join a supportive and fast-paced team environment. Here you will create state-of-the-art deep learning and computer vision systems that will make a meaningful difference in healthcare.In this role you will push the boundaries of what is possible, working with clinicians, leadership, engineers, and developers to imagine the next generation of medical technologies and make them real. We are looking for a creative spatial problem solver who will stay engaged with developments in AI/ML. They are well plugged into emerging techniques with a goal to help the team conceive new possibilities.Clinical and medical needs will drive each project. You will analyze technical requirements working with fellow engineers and developers, plan and organize data engineering and preparation efforts, and follow up on progress. Qualifications, Skills, and ExperienceBachelor’s Degree in quantitative fieldStrong communication skills and the ability to work as part of a teamAn openness and willingness to try new things and failExperience working in a research environmentExperience with scripting in at least one programming languageExperience programming robust pieces of softwareComfortable working with Git and the Linux terminalStrong understanding of geometry and applied mathematics with experience executing coordinate transformsAbility to maintain a flexible schedule to coordinate with team members in multiple time zones Preferred:Experience developing 3-dimensional games using game engines like Unity or UnrealExposure to Simultaneous Localization and Mapping (SLAM)Knowledge of basic segmentation techniquesExperience with Python, C, C++, and Cuda or OpenCL",Algo de responsabilidad,Jornada completa,"Investigación, Análisis, Tecnología de la información",Servicio de información,66,None,True,,402,JOB_SEEKER_QUALIFIED
161,2281682861,2020-11-05,ample,Data Scientist - (remote),"New York City, NY, US",Job Description  We are looking for Data Scientists who are passionate about analytics and using data to help drive business decisions. You enjoy doing data science projects with structured and/or unstructured data and are motivated to produce highly actionable results. Critical thinking and problem-solving skills are essential for this role.,Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información",Energía renovable y medio ambiente,58,None,False,,223,JOB_SEEKER_QUALIFIED
162,2247735516,2020-10-26,TipTopJob,User Researcher : Remote (UX/Agile),"London, GB","User Researcher : Remote (UX/Agile) : London GBP 50k My client, an award:winning Media House is looking for a creative and driven User Researcher to join their friendly team. This role is based predominantly at home for now and some travel to London is needed once they return to a new normal What will the role involve? Planning and executing user research studies throughout the design and development lifecycle, from early strategic direction through post:release validation. Employing a wide range of research methods, including generative design research and contextual inquiry, participatory design workshops, interviews, formative and summative usability studies, and quantitative methods, such as surveys and data analytics. Developing and using relationships across the company to understand existing research and insights and identify impactful research questions, and collaborate on end:to:end research that looks across the customer journey. Leading workshops with cross:functional teams to ensure that findings and insights are translated into actionable product goals and direction. Sharing customer insights with the broader organisation in creative ways to increase customer empathy, including posters, immersion rooms, blog posts, and workshops. Iterating and improving the processes within the user research community at Reach. Who are we looking for? Experience in research You will have a strong track record of qualitative research leading to results impacting product/UX strategy and development. You will have worked closely with quantitative experts and knows how to blend this with qualitative research to synthesise actionable insights. You will possess an up:to:date toolkit of research methods and the experience and savvy to know when to be lean and scrappy and when to be rigorous. The ability to collaborate with a wide set of stakeholders including UX and UI designers, product managers, and software developers. It would be great if you had the following, although not essential: Familiarity with the news and media industries. Experience researching multichannel experiences. Familiarity with Lean UX and Lean Research methodologies. Experience with agile software development. Experience identifying and implementing process improvements for research teams. A passion for Accessibility and Inclusive Design Important Information: We endeavour to process your personal data in a fair and transparent manner. In applying for this role, Additional Resources will be acting in your best interest and may contact you in relation to the role, either by email, phone or text message. For more information see our Privacy Policy on our website. It is important you are aware of your individual rights and the provisions the company has put in place to protect your data. If you would like further information on the policy or GDPR us. Additional Resources Ltd is an Employment Business and an Employment Agency as defined within The Conduct of Employment Agencies and Employment Businesses Regulations 2003 :",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Construcción, Dotación y selección de personal, Servicios financieros",18,None,False,,108,None
163,2198723047,2020-10-21,Teikametrics,Machine Learning Engineer,"Boston, Massachusetts, United States","Machine Learning Engineer, Boston - Remote About the Role: Teikametrics is looking for a Machine Learning Engineer to join a team under the Data Science directorate tasked with building a platform that supports the rapid construction and deployment of prediction and control services in the domain of E-commerce. Candidates should have an understanding of machine learning and statistical modeling concepts paired with strong software engineering fundamentals. The Data Science team's predictive services are developed in Python on top of AWS Sagemaker, orchestrated by Airflow and backed by a data warehouse in Snowflake. Our back-end code emphasizes a ‘functional-first’ Scala stack with cats and fs2. The team's mandate is to design and build infrastructure that enables us to safely deploy solutions to the multi-agent, game-theoretic problems at the heart of decision-making in E-commerce. This entails model train/evaluate/serve lifecycle management, ML metadata storage and visibility, provisioning of separate environments for staging and integration testing, and task orchestration. The team will be adopting existing solutions, like Kubeflow or AWS Sagemaker, where appropriate and fill in the rest. Qualified candidates should have: 1+ years of experience working as a professional software developer.Proficiency in Python with exposure to some subset of the Python ML ecosystem (numpy/scipy/pandas, Tensorflow, etc.).Exposure to machine-learning model lifecycle: training, evaluation, serving.Interest in deploying machine-learning models as scalable services.Interest in 'tool-making': building features for developers that empower them and make them faster.Passion for learning and growing as a developer.Desire to work in a collaborative environment focusing on continuous learning: participating in tech talks, code review, and pair programming. It's a bonus to have:﻿Experience with any of: AWS, Airflow, Kubernetes, Terraform, Spark, Snowflake.Experience writing, testing, and interpreting numerical, scientific code.Experience with functional programming.Proficiency in SQL. ABOUT TEIKAMETRICS There has never been a more exciting time to join Teikametrics, the leading Retail Optimization Platform (ROP). We’re building an operating system to optimize every aspect of a retailer's business -- from advertising to inventory to pricing. We optimize billions of transactions for thousands of entrepreneurs and brands around the world selling on Amazon and other marketplaces. The Teikametrics ROP uses proprietary econometrics and machine-learning data models packaged in a simple SaaS interface. We combine our best in class technology with coaching and support from our world-class teams based in Boston, MA, Seattle, WA, and Bengaluru, India. We are looking for people who can excel, add value to our mission, and thrive in a demanding start-up environment.",Algo de responsabilidad,Jornada completa,"Ingeniería, Tecnología de la información","Internet, Software",185,None,False,,612,ACTIVELY_HIRING_COMPANY
164,2220590240,2020-10-28,Bookbyte,"Data Engineer, Pipeline","Salem, Oregon, United States","Summary This is a fully remote position. Bookbyte is the largest 3rd party provider of product rentals on Amazon. Our remote-first organization is focused on real-time analysis of available market data to perform tens of thousands of pricing operations each minute.  Bookbyte is looking for a Pipeline Data Engineer to help architect and develop our evolving data platform. The Pipeline Data Engineer role will be part of our growing data team, interfacing closely with software engineering. If you are a highly independent worker and have excellent organizational and problem-solving skills, this is the job for you. Working at Bookbyte also means full benefits, a competitive salary, and a friendly work environment. While Bookbyte is based out of Oregon, we are a remote-first company. As a member of a small but growing data team, you will be working closely with business partners, and software engineering teams playing a vital role in the design, build, and maintenance of data pipelines: providing timely, accurate, and reliable information to all aspects of the business. As we incrementally improve and expand our company, you will be building new systems from the ground up or replacing legacy systems outright, free from supporting legacy code bases.  U.S. Citizens and those authorized to work in the US are encouraged to apply. We are unable to sponsor at this time. Duties and Responsibilities ·        Develop, construct, and maintain core transactional datasets (NoSQL, RDMA, Graph)·        Expose data sources via API and other standards, maintain exposure tools·        Development and support of orchestration layers (airflow)·        Develop and maintain ETL between core services (ERP, data lake, etc.)·        Development and support of streaming data solutions·        Translate business requirements into technical specifications·        Participate in all design reviews and requirement sessions, as required·        Understand database design, programming concepts, cloud architecture patterns, and data modeling·        Communicate ideas to both technical and non-technical people at all levels of the organization·        Create or update technical documentation for transition to support teams, including data flows and transformations·        Develop automated data audit, testing, and validation processes·        Stay up to date on ever-evolving technologies Minimum Job Requirements ·        3+ years of data and/or software engineering experience·        Experienced developing testable ETL solutions in python·        Experienced pulling and manipulating data from multiple data sources using Python·        Intermediate SQL skills·        Experience deploying to a public cloud solution (i.e., AWS (preferred), Azure, GCP) Preferred Qualifications ·        Experience in delivering solutions based on Agile principles·        Experience architecting cloud data solutions·        Experience with AWS Lambda and Dynamodb·        Developing streaming data flows (i.e., w/ Kafka, AWS Kinesis, AWS SQS, Spark Streaming)·        Experience with Kubernetes / containers·        BS in Computer Science, Engineering, or related field, or equivalent job experience",Intermedio,Jornada completa,Tecnología de la información,"Internet, Servicios y tecnologías de la información, Software",115,None,True,,371,JOB_SEEKER_QUALIFIED
165,2195989462,2020-11-05,Elizabeth Norman International,Qualitative Researcher,"New York, United States","We're still looking for candidates for this role - advert reposted 5th November.  Are you looking to join a fast-growing cultural insights agency? They partner with the World's best-known brands in entertainment, eCommerce, FMCG, social media, finance and travel. They have influenced the strategic vision of the World’s most popular social media platform to the narrative of the world’s most sought-after computer game. Their approaches range from 360 immersion programmes, brand strategy and digital research. They are a creative agency looking for qualitative researchers who relish the challenge of getting to the heart of research by pioneering approaches. They do a lot of ethnography projects so experience with this is a big bonus. They have a team based in London and are now hiring in the US. They are looking to bring on a mid-level (3-8 years experience) qualitative researcher who has qualitative research experience, brand strategy and/or planning experience from a market research or advertising agency. The office is based in New York. They are currently remote working so this person can be based anywhere in the US. Future travel to NY and elsewhere in the US will be expected in 2021. They have been nominated for an MRS Culture Award and are having their best ever year, winning contracts with the likes of Amazon, TikTok, Spotify, PlayStation and other big names. They offer competitive salaries and benefits including healthcare and holiday allowance (between 20-25 days), a wellness budget and more. An incredible opportunity for a seasoned qualitative researcher who is keen to join the early journey of the NY office and help grow their offering further globally. (Plus an opportunity to work with the nicest and most talented researchers we know)! Apply below. Please note that all applicants must have Right to Work status for the US.",Intermedio,Jornada completa,"Investigación, Marketing, Publicidad","Investigación de mercado, Investigación, Marketing y publicidad",357,None,True,,1503,ACTIVELY_HIRING_COMPANY
166,2277633047,2020-10-17,Uptake,Data Scientist,"Chicago, IL, US","What we do:  Uptake is the premier Industrial AI company, providing a predictive analytics SaaS platform that empowers major industry leaders to optimize performance, reduce asset failures, and enhance safety. At Uptake, we combine our strengths — machine learning, analytics, data visualization, and software development — to deliver actionable insights that make industry more reliable, productive, safe and secure.  What Data Scientists Do Here:   Data science is at the core of what we do at Uptake. We collaborate with engineering, product, and other teams to contribute insights and data science best practices to all parts of the business.  Typical day to day tasks for a data scientist might include:   Collaborating with teams to analyze problems. Learning a new programming language or data science technique - we continually build our skills and explore new things. Building, testing, and deploying supervised or unsupervised learning models. Writing data analysis reports for internal use. Building tools to enable other data scientists to scale their knowledge and increase impact. Working with customers to develop analyses that help them solve business problems and drive value.  What We Are Looking For:   Bachelor's degree or higher in a relevant field Passion for data science! We want candidates who love data science and are excited about what they do.  Some ways previous successful candidates have demonstrated this are by:  Writing relevant blog posts and/or articles. Participating in relevant online communities. Expressing detailed knowledge of and genuine interest in Uptake's unique methods, products, data, and technology within a cover letter.     Ability to write sophisticated machine learning and data analysis code in Python or R  Some ways previous successful candidates have demonstrated this are by:  Contributing to influential Open Source Projects like sklearn, XGBoost, tidyverse, Tensorflow, pytorch, Kafka, Spark, Elasticsearch etc. Describing a data science model they developed that is deployed in a live setting within a resume or cover letter. Making a high quality data science project available in a public forum like GitHub or Kaggle. Publishing work in Data Science related journals or conferences such as ICML, NIPS, JML, KDD, and INFORMS.     Experience communicating effectively with people at all levels of an organization. Our data scientists regularly share complex insights with all kinds of people.  Some ways previous successful candidates have demonstrated this are by:  Teaching data science to non-data scientists in an academic or professional setting. Elaborating in a cover letter or resume ways that they have professionally collaborated with others in the organization and the impact that collaboration had on the organization's KPIs.      Nice to Have:   2+ years professional experience working in an analytics focused role Experience working with IoT systems, ranging from DIY home projects to industrial IoT deployment Substantive contributions to open source projects in the areas of data science or machine learning Experience developing software projects with large teams using collaboration tools like git and Jira Experience with CI/CD tools like Docker and Jenkins Master's degree or PhD in a relevant field Experience working in one of the following industry areas:  Industrial technology Agriculture Mining Energy Transportation    Applicants must be authorized to work in the U.S.  Uptake welcomes and encourages applications from all individuals, without regard to any prohibited ground of discrimination, including from people with disabilities. Accommodations are available upon request for candidates taking part in all aspects of the selection process.",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Software, Internet",13,None,False,,94,ACTIVELY_HIRING_COMPANY
167,2239754129,2020-11-03,Sentient Science,Machine Learning Engineer,United States,"Here is an opportunity to join Sentient Science, a company whose solutions lie at the convergence of many exponentially accelerating innovative technologies: Cloud, edge computing and the Industrial Internet of Things (IoT): AI, machine learning and deep learning: Big Data and analytics: and 3D printing (additive manufacturing). Sentient Science helps customers lower the costs of designing, operating, and sustaining their high value mechanical assets by providing digital twin technology that predicts the life of mechanical systems. Sentient's DigitalClone® SaaS solutions use proprietary algorithms derived from physics-based modeling and machine learning. Help us achieve our vision of a world where rotorcraft manufacturers, wind energy operators and railroads rely on Sentient DigitalClone for a digital implementation of their O&M cost reduction strategy. And a high concentration of PhDs will keep you intellectually stimulated and challenged. Position Summary: The Machine Learning Engineer will occupy a strategic role with an unwavering focus on production deployment of current and future machine learning models as well as reduced-order physics models. Individual in this position will have a strong background in computer science and software engineering as well as demonstrable experience exhibiting strong commitment to software engineering best practices in building machine learning systems. The candidate needs to have a broad exposure to a wide variety of machine learning techniques including but not limited to damage-anomaly detection, natural language processing, explainability-driven deep learning and time-series forecasting. Being able to a) work in an ego-less capacity with a diverse team, b) communicate complex concepts in simple language to diverse stakeholders and, c) display unwavering commitment to empathy and customer obsession is highly valued. The title and associated responsibility for the position can be modified for the right candidate – if our mission inspires you, please send resume and cover letter to  careers@sentientscience.com.  Responsibilities: Lead efforts to develop/integrate automated software solutions for understanding model performance,  workflow tracking, logging and validation, as well as prediction explainabilityInfluence and communicate at a variety of levels across a diverse set of stakeholders, including team members, product leadership and software engg leadersLead initiative to develop / integrate leading edge tools and frameworks to build scalable and efficient machine learning solutionsFocus on building best practices within and across your global teams to drive effective outcome and a progressive mindsetWork with a team of Data Scientists, SMEs, Data Engineers and Software Engineers to architect, develop and deploy scaleable end-to-end model workflow systems (for both machine learning and reduced order models)Act as knowledge leader by staying updated on emerging trends in the fast-moving AI/ML domain and introducing well-researched concepts and frameworks into our software architecture and solutions.Own current roadmap items specific to design and development of scalable machine learning services and data platforms.Utilize benchmarks, metrics, and monitoring to measure and improve data-driven services. Experience & Qualifications: Bachelors (Bonus points for grad school!) in Computer Science, Software Engineering or other relevant disciplinesStrong DevOps, Data Engineering and ML-focused software engineering background3-5 years of experience with machine learning systems – progressive experience showing transition from a standard software engineering role to ML/AI software design/deployment systems is desirableExperience with frameworks and packages such as TensorFlow, PyTorch, Sagemaker, scikit-learn or similarExperience with one of more of MLOps tools: ModelDB, MLFlow, Pachyderm, Data Version Control (DVC) etc.Demonstrable exposure and experience to building and deploying end-to-end systems using either in-house infrastructure or cloud ML environments e.g. SageMakerStrong understanding and demonstrable experience of software testing, benchmarking, and continuous integrationComfortable working with AWS CLI, bash, regex and Linus SysAdminExposure or experience to data serving tools and products such as AWS S3, AWS Lambda, ELasticSearch, Spark etc.Solid experience setting up and optimizing DBs for production usage for ML systemsSolid experience in one or many of the following: Docker, Kubernetes, Jenkins, Spark, Kafka, HDFS, CassandraSolid experience with data storage formats such as Parquet, Arrow, HDF5, NetCDF as well as with relational databasesAdept with current-generation tools-of-the-trade such as Python, SQL, git, bash, Jira and keen to learn and use new ones as neededDemonstrated experience working with modeling solutions/platforms using large (TB+) repositories of structured and unstructured data spanning forms such as numeric, text, images/rastersPossess a curious mind, insatiable drive to learn proactively and profound humility and empathy for your colleagues as well the customerWhile we encourage candidates to apply regardless of immigration status, preference will be given to candidates who are US citizens.  Benefits: Unlimited paid time-offFlexible working hours and fully remote option availableEmployer-sponsored health insuranceOur commitment to inclusion across race, gender, age, religion, identity, and experience drives us forward every day",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información",Software,287,None,True,careers@sentientscience.com.,1068,ACTIVELY_HIRING_COMPANY
168,2278245779,2020-11-05,Dell,Junior Data Engineer,"Hopkinton, MA, US","Junior Data Engineer  Remote Role in Massachusetts USA  Dell provides the technology that transforms the way we all work and live. But we are more than a technology company — we are a people company. We inspire, challenge and respect every one of our over 100,000 employees. We also provide them with unparalleled growth and development opportunities. We can’t wait for you to discover this for yourself as a Junior Data Engineer on our global Decision Sciences team.  The desired candidate will work to enable Dell's Global Business Operations organization with data-driven insights that support our quota planning and business transformation efforts. The ideal candidate will work with a variety of stakeholders including ML engineers, data scientists, software engineers, and peer data engineers to align and execute end-to-end solutions which start with data collection and management, extend through machine learning methodologies, and end with governance of machine learning model performance. As a Junior Data Engineer on our team, it will be your responsibility to ensure your fellow team members have clean, reliable data that can be easily consumed into our data science and machine learning procedures.  Key Responsibilities Deep dive into business problems relating to our quota planning and sales compensation effortsDeign and maintain optimal data architecture for our data science products: partner with your peer data engineers to build reliable systems that scaleBuild, clean, and maintain data sets that feed our machine learning algorithms and discovery processes (based in PostgreSQL database)Identify opportunities for process improvements (may results in automating, optimizing, or fully rebuilding workflows)Work with the greater Decision Sciences team to help with data related issues and analysis needs  Essential Requirements Self-learner who is driven to learn new methods and techniques to fulfill business needsDetail-oriented with the ability to effectively prioritize tasksKnowledge of PostgreSQL (this is a strict requirement for the role)Knowledge of Python, Java, or a similar object-oriented languageKnowledge of optimization techniques for data workflowsKnowledge of data pipeline architecturesWillingness to participate in root cause analysisWillingness to learn!Good project management and organizational skills1+ year(s) of experience (preferred) in a data engineering capacity, preferably on a data science or advanced analytics team: will consider recent graduates if other requirements are metBachelors (or Certification) in Computer Science/Engineering or related field  Benefits  We offer highly competitive salaries, bonus programs, world-class benefits, and unparalleled growth and development opportunities — all to create a compelling and rewarding work environment. If you share our passion for data and you’re keen to play a key role in driving progress, this is your opportunity to develop with Dell. Dell is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at Dell are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV Status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. Dell will not tolerate discrimination or harassment based on any of these characteristics. Learn more about Diversity and Inclusion at Dell here.  Job Id: R075809",No corresponde,Jornada completa,Tecnología de la información,"Equipos informáticos, Software, Servicios y tecnologías de la información",211,None,False,,799,COMPANY_RECRUIT
169,2022504435,2020-11-08,BetterUp,Machine Learning Engineer,"San Francisco, CA, US","BetterUp is a mobile-based coaching platform that brings personalized professional coaching to employees at all levels. We help managers lead better, teams perform better, and employees thrive personally and inspire professionally. Our mission is to help professionals everywhere pursue their lives with greater clarity, purpose, and passion. Our product was developed by a team of leading behavioral scientists, researchers, and technologists to bring evidence-based learning to professionals everywhere. We’re already transforming the way companies approach talent development at high-performing organizations like Genentech, Mars, LinkedIn, and Workday. Let’s build together!  Responsibilities  Data product engineer: Build and deploy machine learning models into production designed for operational excellence and rapid iteration/optimization. Data storyteller: Effectively deliver analysis, insights, and recommendations to answer cross-functional business questions with clearly communicated artifacts using statistical analysis, ad-hoc reporting, etc. Applied behavioral scientist: Advance the understanding of behavior change and interventions by measuring quantitative and qualitative signals across a breadth of psychographic signals.   Key Behaviors  Act as an owner: It’s not done until it’s in production. Adept at moving projects forward and able to unblock projects regardless of the role on the project. Do less, deliver more: Familiar with the terms YAGNI and yak shaving? Focus your efforts on high impact initiatives that really move the needle. Impress yourself: We hold ourselves to quality above and beyond something that “just gets it done”. Each line of code is an opportunity to blend craftsmanship with playfulness. Collaborate without ego: Willing to take on roles small or large in order to further the mission at hand. Stay on your edge: Continuously learning and applying emerging technologies. Pushing yourself and your team to new heights. Practice imagination: Hypothesize meaningful questions and dive into data to uncover insights.  If you have some or all of the following please apply:  5+ years of relevant experience, at least part of which in a startup environment. Alignment with BetterUp mission of enabling behavior change. Succeeded in a remote work environment. Strong verbal and written communication. Impressive portfolio (patents, publications, Kaggle profile, etc). Advanced Python expertise with data analysis and machine learning libraries (e.g. Numpy, tensorflow, etc). Experience with advanced machine learning architectures and models (e.g. NLP, Deep learning, etc). Effective analytical presentation skills using Jupyter notebooks and static presentation formats. Efficient database modeling and cleaning techniques (SQL). Experience with cloud computing techniques (AWS, GCP or Azure).   Benefits  At BetterUp, we are committed to living out our mission every day and that starts with providing benefits that allow our employees to care for themselves, support their families, and give back to their community.  Access to BetterUp coaching: one for you and one for a friend or family member  A competitive compensation plan with opportunity for advancement Full coverage for medical, dental and vision insurance Employer Paid Life, AD&D, STD and LTD insurance Flexible paid time off Per year:  13 paid holidays  4 BetterUp Inner Work days (https://www.betterup.co/inner-work) 5 Volunteer Days to give back Learning and Development stipend  Holiday charitable contribution of your choice on behalf of BetterUp 401(k) self contribution  BetterUp Inc. provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, disability, genetics, gender, sexual orientation, age, marital status, veteran status. In addition to federal law requirements, BetterUp Inc. complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.",Intermedio,Jornada completa,Ingeniería,Formación profesional y capacitación,242,None,False,,1567,ACTIVELY_HIRING_COMPANY
170,2192238629,2020-10-19,TechNET Digital,Data Engineer,Sweden,"I am currently seeking a Data Engineer for a remote contract opportunity. This organisation is a leading ecommerce business who are working on a vast digitalisation programme. They are currently working with data gathered from an array of sources and working towards building automated solutions and ML pipelines Key Responsibilities Work with a cross-functional agile team consisting of Data Scientists / Analysts, ML, DevOps and Software Engineers.Contribute to DevOps efforts / setup (CI/DI) on Google Cloud Platform (GCP)ETL / Pipeline Development to facilitate analysis and reporting activityDeveloping ML pipelines on GCPWork with Product Owners and tech / non-tech stakeholders Key Requirements Experience in the following…Google Cloud Platform (GCP)Data Engineering / ETL DevelopmentBigQuery, SQLApache / DataflowPythonDevOps Engineering, CI/CD on GCP",Intermedio,Contrato por obra,"Análisis, Ingeniería, Tecnología de la información","Dotación y selección de personal, Aeronáutica/Aviación",131,None,True,,518,JOB_SEEKER_QUALIFIED
171,2239710615,2020-11-03,Cognizant,Data Engineer,México,"We are looking for Senior Data Engineer: Bachelor’s Degree in MIS, Statistics, Business or related fieldExperience with: ·      Hadoop or other Big Data platform and building solutions that deliver value through leveraging data as an asset.·      Proficiency in AWS, Drone and GitHub.  Advanced Spanish and English level Challenge:This position will be responsible for designing the technical solution and leading the development team to deliverdata/analytics products for client data platform program.This role will be working very closely with Product owners and Data Architect to understand the product backlog and overall. We offer:Salary 100% payrollOpportunity to earn extra income through incentive bonuses and potential for overtime10 vacation daysInsurance for major medical expenses (coverage for couple and children) without costDental and optical insurance (coverage for couple and children) without costLife insurance for the employeePantry vouchers for $ 2641 net pesosBonus for referring candidatesCertifications and online coursesIntegration events",Intermedio,Jornada completa,Tecnología de la información,Servicios y tecnologías de la información,24,None,True,,185,COMPANY_RECRUIT
172,2248343732,2020-10-03,Good Money,Analytics Engineer,"San Francisco, CA, US","About Good Money  Good Money is the world's first digital banking platform that will make every customer an owner and allocate 50% of our profits to social and environmental impact. We're building a conscious banking platform providing best-in-class mobile banking and financial services while democratizing ownership to its customers for the first time in history.  About The Data Team  We're a small analytics team, which means that you have a ton of opportunity to learn and grow along with the team! There are two of us right now but we have plans to scale the team and analytics at Good Money significantly over the next 18 months - so join us on the learning curve.  We utilize modern tools and embrace the vision of the full-stack data scientist. We've built a stack with Snowflake, Segment and DBT to empower data analysts to go all the way from raw data to modeling to analysis without waiting for external dependencies. Own the entire problem! We also have the ability to provide you with the tools and training you need to continue to grow in your analytics career.  The analytics engineer at Good Money plays a critical role in maintaining and improving our data pipelines, ml models, databases and data visualization tools. Success in the roles means being flexible and fast moving in adapting to change and staying up to date with the ever shifting world of data engineering. Constant focus on gaps and issues in our data stack, our product and our overall analytics efficiency as an organization is must.  Exceptional candidates will have:  Build and maintain the analytics layer of our team's data environment to make data standardized and easily accessible Maintain/build derived marketing/sales schemas on our Snowflake cluster and investigate and refactor any expensive queries Integrate third party data sources as we add channels, data partners and other vendors Working closely with Product and Engineering to ensure upstream product model changes integrate well with our data model: and when it doesn't build the necessary capabilities to adjust Define user roles and permission levels for Snowflake and BI tools When needed, performing stakeholder related work, such as dashboards or analysis Integrating and productionizing analyst and data science models as needed Build data expertise, best practices and own data quality for all analytical data needs Define and manage SLA for all data sets in allocated areas of ownership  Things that will help you succeed in the role:  2+ years working with a data warehouse/BI-tool (Snowflake experience is a plus) 3+ years experience with self-service BI tools (e.g. Tableau, Looker or Domo) Advanced knowledge of  SQL data modeling (dbt experience is a plus) Python REST APIs Git and CI/CD best practices   Exposure to Airflow and/or DAGs in general  Nice-to-haves:   AWS or GCP development and operations experience (EMR, Spanner/Redshift/BigQuery, S3/GCS, data pipelines, etc.) Experience working with an analytics team Experience with autoML platforms (H2O, DataRobot, Google autoML, etc.) A solid math and statistics background   Hiring philosophy & process  Look, we know job searching is hard, time-consuming, and stressful. We aim to let you know everything we can, when we can. We want to make sure you have all the time you need to learn more about us. We also want to have the time we need to learn more about you. Once we surpass the threshold, we want to move forward.  Perks  Distributed team nationwide (pre- and post-COVID)  Competitive comp and equity packages  Open and flexible PTO  Medical, dental, vision, life insurance, and 401(k)  Anticipated process for top candidates:   Drop your application with us here  Zoom interviews with People Ops, Data, Engineering Regular check ins to see if the role is still right for you  Reference checks, negotiation, and offer   Feel right for you?   We'd love to hear from you no matter your background. Drop your resume in one click and we'll be happy to answer your questions from there.",Sin experiencia,Jornada completa,Tecnología de la información,"Software, Internet, Servicios financieros",39,None,False,,286,ACTIVELY_HIRING_COMPANY
173,2268756981,2020-11-02,Oracle,Machine Learning Engineer,United States,"Preferred Qualifications - ExternalDigital Assistants are disrupting the very foundation of user experiences and forever changing the way people interact with technology. The Oracle Digital Assistant (ODA) team is building the world’s largest SaaS Digital Assistant and Insights platform to enable customers to build conversational AI experiences for every conceivable need. Everything from banking services to interactive digital storefronts to patient tracking tools for doctors at the forefront of the COVID-19 response.  Our diverse team of creators and inventors are building the future of conversational interfaces, making real improvements in the lives of real people across the world. We act with the speed and attitude of a start-up, but with the scale and customer-focus of the world’s leading enterprise software company. We have a big charter and lot of creative freedom to get it done.We’re looking for talented developers with cloud computing and AI skills to help solve some of the hardest AI problems in Natural Language, Speech, Vision, Document Processing, and Recommendations. Come join us and grow your career in this exciting arena. Preferred QualificationsB.S. or equivalent degree in Computer Science (Masters and PhD are plus)4+ years’ experience building and delivering software systems.Strong programming skills in a language such as Python,Java, C, C++ .AI/ML knowledge in NLU, Text, Speech, Document, Vision and Image ProcessingSolid understanding of machine learning and deep learning concepts and experience in building and tuning machine learning models. Experience working with at least one major machine learning framework such as TensorFlow or PyTorchFamiliarity with data structures, algorithms, operating systems, distributed systems, and cloud infrastructure technologies such as Kubernetes, Docker, Prometheus, and GrafanaFluency in spoken and written English",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Servicios y tecnologías de la información,447,None,True,,1336,COMPANY_RECRUIT
174,2219021805,2020-10-29,Dotdash,Data Engineer,"Ontario, Canada","About Your Role: Dotdash is looking for a Data Engineer, with an interest in building data pipelines for content migrations, text processing, and user-facing utilities and APIs for data processing.Working with the Product Team and the rest of the Technology organization, you will help build data pipelines to facilitate the transformation and migration of data within and between internal Dotdash systems and external APIs and data stores. About your contributions: Work in a backend python environment within our Python codebase built upon AWS services and both SQL and NoSQL data stores.Help develop data pipelines to automate content migrations between both internal and external data sources.Build and maintain user-facing data loading tools.Build and maintain APIs to serve our data to other teams’ systems and to support user-facing data loads.Investigate and integrate with new cloud technologies and data processing tools.Explore methods for using Natural Language Processing and Machine Learning to enhance our pipelines and to solve new problems relevant to the business. About You:2+ years of experience with Python, Unix, and MongoDB, PostgreSQL or similar database2+ years of experience working with Data Pipelines, Data Warehousing, ETLs, or Data ScienceComfortable with Object-Oriented programming and architecting software systems for reusability, maintainability, and modularityComfortable using the tools of a modern collaborative Agile+Scrum SDLC, including Git, Jira, etc",Algo de responsabilidad,Jornada completa,"Ingeniería, Tecnología de la información","Internet, Software, Marketing y publicidad",175,None,False,,814,ACTIVELY_HIRING_COMPANY
175,2198715310,2020-10-21,Montash,Big Data Engineer,"Amsterdam, North Holland, Netherlands","Big Data Engineer – Freelance/Contract/Secondment – Amsterdam, The Netherlands Are you open to exploring new Big Data Engineering opportunities? Then look no further, Montash are looking for a Big Data Engineer to be based in Amsterdam. This is working for an innovation booster team, building streaming capabilities on the public cloud.  Big Data Engineering Responsibilities:Work independently and drive solutions end-to-end leveraging various big data technologies to solve data problems and develop innovative big data solutions.Participate in technical design discussions aiming for optimal performance building streaming capabilities on the public cloud.Work on Big data components to build large scale data processing systems.Leverage development operations techniques and practices like Continuous Integration, Continuous Deployment, Test Automation, Build Automation and Test-Driven Development to enable the rapid delivery of working code utilizing tools like Git, Bit Bucket.Be part of a scrum team and provide big data solutions for within an agile methodology.Ensure code adheres to enterprise standards and principles. Big Data Engineering Profile:Experience in engineering Big Data platforms (based on technologies like: Spark, Kafka, Hive).Well versed in Python or Scala.You have experience in data warehousing and / or data modelling experience.Experience with AWS or Microsoft Azure.Experience with Cloudera / Hortonworks Hadoop Distributions.You have strong written and verbal communication skills and work well on teams with representatives from a diverse set of technical backgrounds.",Intermedio,Contrato por obra,Tecnología de la información,Servicios y tecnologías de la información,111,None,True,,359,ACTIVELY_HIRING_COMPANY
176,2243035399,2020-10-26,AssemblyAI,Deep Learning Researcher - Speech Recognition,United States,"How to Apply If you're interested in applying to this position, please fill out the application here: https://forms.gle/AoapbvkyE8RmGK1Q6 About AssemblyAI At AssemblyAI, we use State-of-the-Art Deep Learning to build the #1 most accurate Speech-to-Text API for developers. We're backed by leading investors in Silicon Valley like Y Combinator, John and Patrick Collison (Stripe), Nat Friedman (GitHub), and Daniel Gross. Customers use our API to transcribe phone calls, meetings, videos, podcasts, and other types of media. Our accurate transcripts are used to power features like visual voicemail, call analytics, closed captioning, meeting summaries, and a slew of other features. We deploy our Deep Learning models into production to process millions of API requests per day. About the Role We are growing rapidly and looking for an experienced Deep Learning Researcher to join our Speech Recognition Team. We're a small, creative, and democratic team interested in pushing the state of the art forward. You'll be leading the efforts on things like: Work with large scale datasets to research and train Deep Learning models for Speech RecognitionConduct research and experiments in order to improve accuracy of Deep Learning ASR pipelines like CTC and RNN-TsDig into weaknesses and failure points of our current ASR models, in order to identify further areas for improvementWork with the broader Speech Recognition Team to publish papers on novel findingsContinually push the State of the Art in Speech Recognition to get to human level performance Qualifications 4+ years of experience with Python and C++3+ years of experience with modern Deep Learning based ASR systems (CTC, LAS, RNNTs)3+ years of experience training distributed deep learning models on GPUs2+ years of experience with Deep Learning frameworks like PyTorch and TensorFlow",Algo de responsabilidad,Jornada completa,None,Servicios y tecnologías de la información,62,None,True,,323,ACTIVELY_HIRING_COMPANY
177,2213578215,2020-10-26,Habitissimo,Data Scientist,España,"¿Quiénes somos? Somos un equipo multifuncional trabajando codo a codo para conseguir ser el portal de reformas de referencia en todo el mundo. Nos apasiona todo lo relacionado con el mundo de los datos y por ello queremos seguir avanzando en nuestro objetivo de apoyarnos en ellos para conseguir los mejores resultados posibles.  ¡Aquí entras tú! Nuestro equipo crece y queremos incorporar a un/a Data Scientist en nuestras oficinas de PALMA DE MALLORCA o en REMOTO. Como Data Scientist tendrás el reto de analizar información muy variada y responder a preguntas complejas utilizando nuestros datos, para hacer crecer una empresa líder del sector y presente en nueve países. Si crees que contar historias con los datos es una de las tareas más divertidas posible y no te conformas con que las decisiones se tomen sin preguntar qué dicen los datos, ¡te estamos esperando! Tus funciones serán:Extraer y analizar datos para proporcionar conclusiones aplicables al negocio.Desarrollar visualizaciones que faciliten la toma de decisiones.Dotar al resto de la empresa de conocimiento analítico.Defender una cultura de empresa basada en los datos.Implantar y promover buenas prácticas en el análisis de los datos.Colaborar con los equipos de desarrollo para recoger datos que permitan comprender y predecir el comportamiento de los usuarios.Medir el impacto de las distintas acciones tomadas sobre el producto y detectar oportunidades de mejora. Requisitos:Experiencia previa en puesto similar superior a 2 años.Titulación universitaria en análisis de datos, estadística, matemáticas, física, economía, informática o similar.Altos conocimientos de estadística y visualización de datos.Experiencia en herramientas automatizadas de visualización de datos, como Tableau o similares.Experiencia en el lenguaje Python aplicado al análisis de datos.Conocimientos avanzados de SQL.Pasión por los datos y pensamiento analítico.Habilidades comunicativas.Trabajo en equipo.Actitud positiva.Nivel medio de inglés. Se valorará:Experiencia en análisis de webs y aplicaciones móviles.Conocimientos de Machine Learning y Deep Learning.Experiencia previa en trabajos en remoto.  ¿Qué ofrecemos?Salario a negociar en función de la experiencia.Contrato indefinido.Onboarding a medida, aprendizaje continuo y formaciones interdisciplinarias.Descuento en el seguro médico (puede incluir hijos y cónyuges/convivientes).Al año tendrás 27 días laborables de vacaciones: 24 días de vacaciones + el día de tu cumpleaños libre + 24 y 31 de diciembre libres.Jornada intensiva todo el año. Entrada flexible entre las 8h y las 9h.Además, tendrás 4 días a tu disposición para acudir a eventos, conferencias o cursos de formación. Un día al mes disfrutarás de nuestro data hack-day, en el que dedicamos todo el día a la investigación, innovación y aprendizaje en equipo sobre cualquier aspecto relacionado con Data Engineering y Data Science.Queremos que estés cómodo/a desde casa por lo que se te facilitará un ordenador de alta gama, con doble monitor y teclado mecánico. Si crees que necesitas algo más también contarás con un presupuesto para poder equipar tu oficina en casa.Y gozarás de un inmejorable ambiente de trabajo.  Si crees que puedes encajar en esta oferta, haznos llegar tu CV para que podamos contactar contigo. No dudes en visitar nuestro Instagram para conocer el día a día en las oficinas @teamhabitissimo y nuestro blog técnico: https://labs.habitissimo.com.",Algo de responsabilidad,Jornada completa,"Tecnología de la información, Análisis",Servicios para el individuo y la familia,315,None,True,,940,ACTIVELY_HIRING_COMPANY
178,2204922507,2020-10-23,Voicemod - We're Hiring!,Data Engineer,"Ámsterdam, Holanda Septentrional, Países Bajos","About Voicemod: We exist so that everybody can express themselves through sound, so that every experience is amplified. To do that, we build expressive, immersive audio tools that make it easy for anyone to create a unique sonic identity or interact with others via sound in a personal way. We create sounds that can take people anywhere. That allow them to become anyone or anything. But more than anything else, we help people sound more like themselves – than ever before. Voicemod has become the go-to companion for gamers looking to take the online gaming experience to another level, and for content creators who want to enhance their personalities and captivate their audiences. It's also great for conferencing and voice communication, allowing you to react and express yourself in a way that makes every conversation more immersive. Having been in the audio tech game for over 10 years, we’re the leading brand in real-time voice and audio modulation. We currently have more than 2 million users per month in over 200 countries. Working at Voicemod means: Putting people first: That means creating delightful audiovisual experience for people and building a culture that our team, our creators and our communities love.Staying in tune: We pay attention to what's going on in the world we live in, keeping an open mind, staying on the pulse, taking on feedback and acting upon it accordingly.Taking play seriously: We like to find the fun in everything we do, and to find new ways to create experiences that people truly enjoy.Following your rhythm:  We trust in each other's skills and experience and encourage everybody who works at Voicemod to work in the way that best suits them.Mastering our sound: We strive to be the best in everything we do, pushing the boundaries of what's possible. Sounds like you? Our Culture: We’re a diverse, multidisciplinary team of over 80 people mostly based in Valencia (Spain). What we share is a passion for putting people first, a desire to listen closely to the world around us, and a knack for finding the fun in everything we do. We welcome people from all backgrounds who share these values, who seek the opportunity to help build the perfect company and a quality product that enables us all to “amplify ourselves”. About The Role: In the Engineering department, we are looking for a Data Engineer  whose mission will be to define and develop the analytics data pipe and ETL processes to support Data Scientists and organization data needs . What You'll Do: Work with data scientists and software engineers, to build and integrate the analytics platform Design and implement efficient data processing workflows incl. data standardization, data quality & governanceContinue to develop custom data processing pipelines and continuously search for ways to improve the technology stack along their increasing scaleHelp to scale data platform, data pipelines and ETL pipelinesMeasure, analyze and optimize the performance of our data processing pipelineBe one of the key builders of the “Business Insights platform” that will be used by teams to access reporting, deep dives, and seller insights.Support designing data dashboards in services as Tableau, Qlik What You'll Need: Master’s in Computer Science, Engineering or equivalent4+ years of overall work experience and 2+ years of practical experience on analytical tasksExperienced with PythonConsiderable experience to deal with SQL, large amount of data or SQL-like tools.Experience on AWS cloud services as S3, RDS, Redshift, Athena, EMR, Data Pipeline...Ideally also experience with some of the business intelligence and reporting tools as Tableau, Qlik...Have a passion for working with data and professional experience in data mining, statistical analysis, predictive modeling, and data manipulation.Willingness to help with data and kpi requirements across organizationA true passion for Voicemod mission, our products, and the company's technology and content natureA never-ending desire to grow and learnEnglish professional proficiency level Extra points: If you’re a natural leader who’s always guiding and helping others to give their bestIf you’re an eGames (or other streaming channels) loverIf you worked with Agile methodologies before and if you have a Lean mindsetIf you played with FirebaseIf you’re a tech visionary who’s always reading about and sharing new cool stuff If you join our team, you'll enjoy… Flexible working hours.Possibility of working remotely.English or Spanish classes.Private Health Insurance.Christmas and New Year´s Eve off.",No corresponde,Jornada completa,"Ingeniería, Tecnología de la información","Software, Entretenimiento",182,None,True,,792,COMPANY_RECRUIT
179,2268465073,2020-10-08,Beeswax,Senior Machine Learning Engineer,"London, GB","Beeswax's mission is to build great advertising software. Our product is an easy to use, massive scale and high availability advertising platform founded by industry veterans who worked together at Google. We offer our customers the most extensible and transparent advertising system in the world and process billions of transactions per second.  We are looking for a Senior Machine Learning Engineer with an in-depth working knowledge of the latest in Machine Learning/Data Science technologies and cloud platforms to join our Optimization team.  In this role you'll work on a wide range of computational challenges such as: CTR prediction, forecasting, bidding models, and delivery optimization. We practice an effective data science process that recognizes the uncertainty in explorations for ML solutions but also emphasizes an agile software engineering workflow. We use the most popular tools in the Python data science ecosystem and embrace innovation.  Our tech stack is always evolving to meet the challenges of the massive scale of transactions on which we operate. To manage the firehose of data coming in, we explore complex tradeoffs and carefully architect high performance distributed systems. Those in turn require elegant and thoughtfully designed interfaces to make the systems accessible to both our team and our customers.  What You'll Be Doing:    Lead data science projects and ensure they deliver business value Work with the Product and Engineering team to build data model pipelines to power customer-driven products Guide major architectural changes as we scale to improve our engineering velocity Implement and test the latest research works Mentor other engineers on architecture and process  What You Should Have:   MSc or above in a STEM (science, technology, engineering, mathematics) subject 5+ years of an excellent track record with Machine Learning/Data Science in industry Strong understanding and experience in distributed computing frameworks, especially in Apache Spark Expert-level proficiency in Python and SQL Practical experience with Data Warehousing (especially Snowflake), Deep Reinforcement Learning and out-of-core algorithms   Good understanding of engineering best practices, agile (as it applies to Data Science), and version control  Effective collaboration with Product, Customer, and Engineering teams An appreciation for (or tolerance of) bee puns  Successful Engineers at Beeswax Value:   An ethic of service and a belief in putting the customer first A powerful sense of pragmatism to figure out what needs to be done right versus right now A curiosity about technology and a desire to use it in all sorts of domains Openness and a team first attitude An appreciation of repeatability, observability, and operational simplicity  More About Beeswax:   Beeswax was founded in 2014 and since then we've raised $28M in funding from leading VCs including RRE and Foundry Group and have grown rapidly. We believe in and invest in personal growth and we've got the results to back it up: we've been recognized as one of America's Fastest Growing Companies by Inc. 5000, we've won several Best Places to Work awards, and our team loves the culture. We value diversity and incorporate an array of professional experiences on our product & engineering teams. Some of our teammates hail from tech companies like Google, Amazon and Facebook: others from financial giants like Bloomberg and Bank of America: and more from some great software engineering cultures such as Compass and x.ai.",Algo de responsabilidad,Jornada completa,"Ingeniería, Tecnología de la información","Marketing y publicidad, Software, Internet",None,None,False,,33,ACTIVELY_HIRING_COMPANY
180,2195206435,2020-10-20,"Pinnacle Group, Inc.",Machine Learning Engineer- SageMaker,"Dallas, Texas, United States","The Data Innovation Team rapidly builds and tests new, cutting-edge data architectures to enable Data Science and Innovation initiatives across the enterprise. Specifically, the Team is responsible for developing and delivering a Data Innovation Environment that will provision data in new and innovative ways. This includes working with the Data Science and Innovation Teams to better understand their data requirements, identifying the right sources for the data, and then rapidly providing the data that will power both the Data Science models and Innovation initiatives. Experienced Analyst / Engineer with data centric experience. Must have experience asking effective questions, probing for important details and translating into actionable recommendations. The Engineer must have a deep understanding of Data Management software and tools in both operational and analytical solutions, the architecture needed to support these solutions, as well as experience in Data Management consulting methods and tools. Required Skills  At least 10 years of experience in data warehouse architecture, data modeling, ETL Mapping, data flows, data analysis using NoSQL concepts Demonstrated delivery of results on past projects leveraging various analytics, data integration and management technologies involving both operational and analytical applications Strong communication skills with consumers at various levels. Able to present complex and technical information clearly in business language. Ability to gather data from various systems using database languages and/or programming languages (such as but not limited to)SQL & NoSQLPythonJavaAb InitioUnix Shell Scripts Demonstrated expertise in working with several databases (such as but not limited to)TeradataOracleSQL server",Intermedio,Jornada completa,Tecnología de la información,Servicios y tecnologías de la información,250,None,True,,810,ACTIVELY_HIRING_COMPANY
181,2234946895,2020-09-29,MKS2 Technologies,REMOTE- Data Scientist,"Remote, OR, US","Are you excited at the prospect of unlocking the secrets held by a data set? Are you fascinated by the possibilities presented by the IoT, machine learning, and artificial intelligence advances? In an increasingly connected world, massive amounts of structured and unstructured data open up new opportunities. As a data scientist, you can turn these complex data sets into useful information to solve global challenges. Across private and public sectors — from fraud detection, to cancer research, to national intelligence — you know the answers are in the data.  We have an opportunity for you to use your analytical skills to improve our clients’ ability to provide content to appropriate parties faster with far greater accuracy and generating a significant cost time savings and ability to reallocation of staff to more important tasks. You’ll work closely with your customer to understand their questions and needs, and then dig into their data-rich environment to find the pieces of their information puzzle. You’ll develop fully automated Natural Language Processing (NLP) and Machine Learning (ML) algorithms and use the right combination of tools and frameworks to turn that set of disparate data points into objective answers to help our client achieve its first AI-based accredited software to make informed decisions. You’ll provide your customer with a deep understanding of their data, what it all means, and how they can use it. Join us as we use data science for good in helping our clients to continue their mission with AI.  Empower change with us.  You Have:  2+ years of experience with various machine learning algorithms, statistics, and mathematics principlesExperience with multiple programming languages, including Python and RExperience with Natural Language ProcessingActive Secret clearanceBA or BS degree in Mathematics, Physics, CS, Engineering, or Statistics  Nice If You Have:  Experience with tools, including Qlik Sense, Power BI, or Stream SetsExperience with AWSExperience with C#MA, MS, or PhD degree in Mathematics, CS, Engineering, Physics, or StatisticsAWS Certification  Clearance:  Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information: Secret clearance is required.",No corresponde,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Software, Servicios financieros",22,None,False,,185,ACTIVELY_HIRING_COMPANY
182,2176213624,2020-10-12,Evidera,Research Scientist (Principal Investigator) -Patient Preferences,"London, England, United Kingdom","*This position can be in either of our Evidera offices (Seattle, Bethesda, Waltham, London) or can be based remotely Position SummaryAs a Research Scientist, you will be an independent PI, with scientific and strategic responsibility for preference and/or multi-criteria decision analysis studies (MCDA) projects: delegating project management tasks to more junior scientific staff. You will oversee and participate in a large project portfolio, innovate scientifically, produces output of high scientific quality, and assume significant responsibilities for sales targets and client development. You would be joining a fast-growing, successful team, operating at the cutting edge of the science of incorporating stakeholder preferences into health care decision making. We have developed an innovative, collaborative culture, aimed at developing and sharing good practice in preference research, both internally and externally. We are looking for someone who will thrive as a leading member of this team, shaping our science, and with the relationships and reputation to boost our sales.  Key Skills and AttributesDeep and demonstrated understanding of preference elicitation techniques, such as discrete choice experiments (DCE), best-worst scaling (BWS), or swing weighting.Knowledge of relevant regulatory requirements and guidelines.Understanding of the pharmaceutical industry.Strong analytical and problem-solving skills Ability to direct large portfolio of projects in terms of dollar volume and number of projects.Able to provide oversight, management, and mentoring to more junior staff.Excellent ability to develop and maintain client relationships.Excellent written and oral communication skills: scientific, professional, and consulting.Ability to develop positive, collegial, and productive relationships with colleagues and clients.Excellent time management and logistic skills to be highly effective in fast-paced, deadline-driven work environment. Job ResponsibilitiesScienceLeads studies of high scientific quality, presenting scientific work in peer-reviewed journals and at professional meetings Provides scientific leadership to team members, and contributes to the development of the way that preference methods are delivered by the team.Strategy/ConsultingDevelops and maintains client relationships.Identifies scientific methods/plans that help clients meet their goals.Helps clients prepare for regulatory meetings and attend regulatory meetings with clients as requested.Financial & Business DevelopmentBrings in proposal leads.Writes proposals and managing proposal writing process.Closes sales.Project Management Responsible for ensuring client timelines are met.Responsible for ensuring project does not to exceed contracted budget.PCR Operations SupportSupervises mid- level scientific staff.Develops and presents internal scientific trainings.Participates in staff recruitment efforts (phone screening, interviewing, attending presentations, etc.).Conforms to SOPs and other requirements.Actively supports new product development and scientific innovation.Education Level/Years of ExperienceDoctorate in scientific discipline and more than one year experience in relevant field: orMaster’s degree in scientific discipline and more than 5 years’ experience in relevant field Computer programming or software skills required for positionMS Word, PPT, Excel: familiarity with SAS or similar data analysis software About Evidera:Evidera is a business within in Pharmaceutical Product Development, LLC (PPD) a leading global contract research organization (CRO), and a is a preeminent provider of evidence-based solutions. We provide integrated scientific expertise and global operational capabilities to help clients generate the evidence needed to optimize the market access and commercial potential of products.  Perks:We offer a competitive salary and benefits package, with clear opportunities for growth and career progression. You will have the opportunity to work on multiple projects with some of the industry’s leading researchers. Our offices boast a fun and collaborative working environment, frequent social events and a robust support system. We are committed to providing training and professional development, with ample opportunity to advance, for all our staff. Evidera’s Core Competencies:Customer FocusInitiativeTeamworkProblem Solving/JudgmentAccountability  If you resonate with our core competencies and want to contribute to research and consulting services driven by world-class science and thought leadership, then please submit your application – we’d love to hear from you. Evidera, Inc. provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, genetics, sexual orientation, gender preference, disability, or status as a qualified individual with a disability or protected veteran.",Intermedio,Jornada completa,Investigación,"Investigación, Industria farmacéutica",18,None,False,,294,ACTIVELY_HIRING_COMPANY
183,2243165407,2020-10-01,G2A.COM,UX Researcher (remote),"Kraków, PL","In G2A you will be responsible for:   UX / usability research coordination: planning, implementation, analysis of the results and presentation of the report. Especially: A / B tests, moderated qualitative research, remote qualitative research, in-depth interviews Searching and developing reports on solutions used in products and services available on the market Analyzing quantitative data and identifying areas for improvement or in-depth research Close cooperation with Product Owners, Business Managers and Product Designers in defining and verifying business goals Participating in team development and the improvement of research methods and processes  We are looking for people with:   At least 2 years of experience in the area of UX research Practical experience in conducting usability tests Excellent knowledge of research methods Good command of English (B2 level)  Fluent Polish language   Nice to have:   Experience in e-commerce / marketplace Education related to research, statistics, analysis Knowledge of standards and principles of CX, UX, HCI Basic knowledge of HTML / CSS / JS  What we offer:   Remote work A non-corporate working atmosphere in a professional team focused on common goals Working in rapidly growing international organization Private medical care Work available immediately Multisport card Elastic schedule",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Servicios financieros",11,None,False,,113,ACTIVELY_HIRING_COMPANY
184,2218812319,2020-10-28,Urbint,Staff Machine Learning Engineer,"New York City, NY, US","At Urbint, our mission is to make communities more resilient. We do this by pairing external data with artificial intelligence to identify areas of high risk and prevent catastrophic loss for utilities and infrastructure operators across the country. We are a team of close-knit engineers, entrepreneurs, and data geeks who obsess over problem-solving, new technologies, and making a positive impact in our communities.   Job Summary   Urbint is looking for a staff-level machine learning engineer to help guide our team’s effort on its next-generation machine learning platform. Urbint is a product with machine learning at its very heart: as a senior member of the ML team, job is to help refine this vision, continually making machine learning as impactful for our clients as it can be. Your will design and build machine learning tools to build models efficiently, effortlessly and predictably, models with a high degree of predictive accuracy. You will contribute to a strategy for collecting and fusing diverse sources of data to power our predictive systems, as well as building the tools needed for understanding the performance of models deployed in production settings. Finally, you will be a mentor, improving an already high-performing machine learning team through the breadth of your experience.  We encourage people from underrepresented groups to apply.   What You’ll Do   Be a Technical Leader - Provide technical guidance to the team to build an infrastructure that helps scientists to build models, test hypotheses, run experiments, and deploy at scale in production environments. Explore Data - Understand and identify preliminary signals in the data prior to deep processing. Quickly analyze the dataset to assess its usefulness for machine learning. Prototype Models ­- Develop features, uncover patterns, and build models. Explore Techniques - From simple regressions to neural networks, we use a variety of techniques. You'll have the freedom to explore multiple methods to squeeze insights out of data. Productize Models - ­A pattern is good, but a prescriptive solution is better. Build products that help our customers get the most out of their data and workflows.    Who You Are    Masters in a quantitative discipline (e.g. Stats, Math, Physics, Engineering, CS, etc.) 8+ years of experience in data science/machine learning roles Experience solving concrete machine learning problems in diverse settings Advanced knowledge of machine learning methods and statistical principles, including experience in Bayesian statistics, anomaly detection, and/or time series forecasting Well versed in Python or R (and willingness to continue to learn the Python ecosystem) Proven experience designing and delivering solutions using large, diverse, real-world datasets to support business decisions Up to date with the current best tools and practices in the ML and data science ecosystems  Nice to Have  Ph.D in a quantitative discipline Familiarity modeling with spatial data Experience doing machine learning on networks or in connected environments    Benefits   Mission Driven - Some companies use AI to serve better digital ads and trade stocks, we seek to make our communities safer and more resilient Top Compensation - Competitive compensation package Best in Class Medical Coverage - 100% benefits and premiums paid Health Perks - Wellness reimbursement and citibike membership Weekly lunch stipend Remote work monthly stipend  We're an equal opportunity employer. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Software,24,None,False,,211,ACTIVELY_HIRING_COMPANY
185,2202209475,2020-10-12,Vertical Trail,Data Engineer,"Chicago, Illinois, United States","Vertical Trail LLC is a rapidly growing consultancy focused on delivering modern Analytics, Big Data, and Cloud solutions. Vertical Trail is looking for a strong Data Engineer to become an integral part of our advanced analytics team. This Data Engineer will focus on using modern technologies to transform mountains of data into meaningful insights. Candidates must be able to work for Vertical Trail as a W2 employee. Vertical Trail is not considering third party or contract candidates for this role. Our Data Engineer will: Assist with development and data management tasks as needed to support Big Data and analytics projectsWork closely with developers, consultants, and business analysts to understand needsDesign, build, and launch new data extraction, transformation, and loading processes in productionAssist with the design, build, and launch of new production data modelsSupport existing processes running in productionMonitor cluster connectivity and securityDevelop scripts and tools to automate common administration tasksTroubleshoot data load, transformation scripts, and performance issues Data Engineer Requirements:4+ years of working experience as a Data Engineer3+ years of experience using ETL tools to perform data cleansing, transforming, and scheduling various workflows3+ years of experience building and optimizing SQL Views in a relational database or data warehouseProficient coding and scripting in PythonExperience creating and maintaining large-scale data structures that help users generate, store, and manage Big DataKnowledge of relational database modeling conceptsExperience with AWS cloud services: Lambda, S3, Glue, and Redshift Employment with Vertical Trail is an exciting opportunity that offers ample avenues for professional growth and development as well as attractive benefits including: Comprehensive Health, Dental, and Vision insuranceEmployer-Paid Life and Disability insurance401(k) / Retirement PlanProfessional Development Plan If this opportunity sounds like the right one for you, please contact us today!",Intermedio,Jornada completa,"Tecnología de la información, Consultoría, Ingeniería",Servicios y tecnologías de la información,173,None,True,,507,ACTIVELY_HIRING_COMPANY
186,2218581084,2020-10-19,Earnest Research,Data Engineer,New York City Metropolitan Area,"THE EARNEST RESEARCH COMPANYEarnest Research is a VC-backed data innovation startup driven to change the way professionals understand consumer and business behavior. Working with world-class data partners, we transform raw data into a source for business and investment professionals to ask better questions so they can make better decisions. We believe, in the right hands, data has the power to change the way we work.  DATA ENGINEER, DATASETS TEAMEarnest Research is seeking a Data Engineer to join our Datasets Team. The Datasets Team is responsible for the ingestion, transformation, and productization of dozens (and growing!) disparate datasets. This position requires a highly motivated problem solver with strong communication skills, analytical ability and attention to detail. RESPONSIBILITIESExtract and process raw data at scale (including writing scripts, calling APIs, writing SQL/Spark, etc.)Process unstructured data into a form suitable for analysisWork closely with product owners and data analysts to gather and understand requirementsInterface with Data Platform engineers and give valuable feedback that guides toolingParticipate in code reviews and design discussions, give and receive constructive feedbackCreate, extend and own data pipelines that power the company’s productsEnsure high Data Quality and pipeline stability QUALIFICATIONSRequired skills:Experience processing large amounts of structured and semi-structured dataProgramming experience in Python, SQL and Bash2+ years writing and maintaining ETL at a terabyte level scale 1+ years experience working with Hadoop applications (Spark)Experience with version control systems (Git) Preferred skills:Code-based data orchestrator such as Apache Airflow, Dagster, LuigiKnowledge of aws, emr, redshift/snowflakeSpark-Scala / PySpark ExperienceExperience with Docker containerizationStrong knowledge of and experience with statisticsEnthusiasm for Open SourceData Warehouse modeling experienceExperience with or willingness to learn functional programming (Haskell)Experience using Data Build Tool (DBT)Experience automating Data Quality checks either through DBT, Great Expectations or company tooling  BENEFITS & PERKS:100% company paid medical plan options (additional medical, dental and vision plans available too!)401K retirement plansFlexible and generous time offGenerous Parental Leave PoliciesPre-tax savings plans for public transportation and parking expensesRegular company happy hours, lunches & events Earnest Research is an equal opportunity employer, and we encourage people with a diverse range of backgrounds to apply.",Algo de responsabilidad,Jornada completa,Ingeniería,"Servicio de información, Servicios financieros, Investigación de mercado",122,None,False,,438,None
187,2251821445,2020-10-29,RiskIQ,Data Engineer,"San Francisco, CA, US","RiskIQ is the leader in attack surface management, providing the most comprehensive discovery, intelligence, and mitigation of threats associated with an organization's digital presence. With more than 75 percent of attacks originating outside the firewall, RiskIQ allows enterprises to gain unified insight and control over web, social and mobile exposures. Trusted by thousands of security analysts, RiskIQ's platform combines advanced internet data reconnaissance and analytics to expedite investigations, understand digital attack surfaces, assess risk and take action to protect the business, brand, and customers. Based in San Francisco, the company is backed by Summit Partners, Battery Ventures, Georgian Partners and MassMutual Ventures.  We are looking for a Data Engineer to join our Engineering team. This role will be based remotely.  Role Overview  RiskIQ uses internet-scale data sets to build complete pictures of our customers' attack surfaces, allowing us to help them identify, manage, and protect their attack surfaces. Our data engineers connect the disparate data sets together in novel ways to allow us to make connections. They focus on the ongoing quality of our existing data pipelines and on the development of new, high-quality data pipelines.  Your Responsibilities Will Include  Designing and implementing the data pipelines necessary for our new product development Working closely with application developers, architects, and devops engineers to ensure that we produce high-quality code and infrastructure Maintaining the high-quality of our data pipelines in production, ensuring that the data quality and performance are good   Requirements  5+ Years writing Java code Prior experience with at least one of the following big-data technologies HBase CLDB MFS Hadoop   Desired Experience  Prior experience with Kafka or related quing technologies Prior experience developing data pipelines for data sets above 1 TB Prior experience with Spring, Hibernate, and SpringBoot  Why work at RiskIQ?  Fascinating work - Welcome to the dark underbelly of the Internet. RiskIQ's ability to help organizations map and monitor their attack surface, detect internet-scale threats, and investigate adversaries led to skyrocketing adoption by security teams around the world. It is the golden age of internet crime, and we are at the forefront of defensive efforts to stem the tide. Internet security is a global growth industry, and the knowledge you acquire here will be a marketable skill for decades to come. We're a company on the forefront of a burgeoning industry - RiskIQ experienced explosive growth in 2018, including a 362.5 percent increase in net new product sales due to the steady adoption of attack surface management across the world. We also experienced a 365 percent increase in registration for RiskIQ community, our freemium entry-level product, showing the increasing role of security outside the firewall to the growth of businesses.  Top Leadership - Our CEO is a renowned cybersecurity veteran known for his expertise. Our leadership group is poised and experienced with a track record in technology and cybersecurity. Unbounded opportunity - We're growing! At RiskIQ, you'll be provided with as much responsibility as you can handle—new career development opportunities constantly arise given our rate of growth.  Flexibility - You'll have a large workload, but also the freedom to accomplish it on your own terms.",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Seguridad del ordenador y de las redes",19,None,False,,278,ACTIVELY_HIRING_COMPANY
188,2025119006,2020-10-16,dunnhumby,Insights Consultant,United States,"Most companies try to meet expectations, dunnhumby exists to defy them. Using big data, deep expertise and AI-driven platforms to decode the 21st century human experience – then redefine it in meaningful and surprising ways that put customers first. Across digital, mobile and retail. For brands like Tesco, Coca-Cola, Procter & Gamble and PepsiCo.  Dunnhumby is seeking a Client Lead who expects more from their career. You will be a trusted advisor for our retail and CPG clients, working side-by-side with them to ensure their success. Using customer insights derived from our data platform, you will own and develop a client plan that delivers recognizable value, client satisfaction and return on investment. You will be responsible for driving collaboration between business partners, understanding key business challenges, and embedding a Customer 1st approach into decision making.   What we expect from youBachelors degree in a relevant subjectManage assigned Retail or CPG client relationships and workplansSupport team effort to instil a Customer 1st approach and process to managing their businessBecome an expert and teacher of our Data Science, Software, and approachesSupport sales and renewal efforts with your Retail or CPG client stakeholderUndertake projects, partnering with Data Scientist colleagues, to dive deep into client data and make recommendations to clients to achieve positive business results and an improved customer experienceManage implementation of new processes, tools, and solutions with the client and as part of a large team environment1-2 years relevant experience * This role will be remote until spring 2021. There is an expectation to work onsite in the future.   What you can expect from us We won’t just meet your expectations. We’ll defy them. So you’ll enjoy the comprehensive rewards package you’d expect from a leading technology company. But also, a degree of personal flexibility you might not.Plus, thoughtful perks, like early finish Friday and your birthday off. You’ll also benefit from an investment in cutting-edge technology that reflects our global ambition. But with a nimble, small-business feel that gives you the freedom to play, experiment and learn. And we don’t just talk about diversity and inclusion. We live it every day – with thriving networks including dh Women’s Network, dh Proud, dh Parent’s & Carer’s, dh One and dh Thrive as the living proof. Everyone’s invited. Our approach to Flexible Working  At dunnhumby, we value and respect difference and are committed to building an inclusive culture by creating an environment where you can balance a successful career with your commitments and interests outside of work. We believe that you will do your best at work if you have a work / life balance. Some roles lend themselves to flexible options more than others, so if this is important to you please raise this with your recruiter, as we are open to discussing agile working opportunities during the hiring process. For further information about how we collect and use your personal information please see our Privacy Notice which can be found (here)",Algo de responsabilidad,Jornada completa,"Estrategia/planificación, Tecnología de la información, Desarrollo empresarial","Venta al por menor, Artículos de consumo, Servicio de información",333,None,True,,1305,ACTIVELY_HIRING_COMPANY
189,2246992002,2020-11-03,WorldQuant Predictive,Lead Data Scientist - Research / Machine Learning,Hungary,"Your role will include the following responsibilities: Collaborating with use case owners to take business requirements and translate them into research problems.Creating formal problem specifications (including how models are tested and evaluated) for those research problems for use with our model development and deployment platform.Creating benchmark models for the research problems.Engaging with research consultants, providing problem support and direction as needed.With senior stakeholders and feedback from research consultants, refining the Global Research Network workstream to optimize engagement and quality of work produced.Helping with technical requirements planning for new features and improvements to our internal platform as part of workstream development.Managing the evaluation process for Global Research Network candidates. Requirements:2+ years of experience in data science.Knowledge of intermediate concepts and approaches in Machine Learning.Experience in building models using Python/R. Python is our shared language, so experience with Python is a big plus.Experience working with Data Scientists and Data Analysts.Confident communicator who is comfortable with technical discussions.Would enjoy interacting with and fostering development of our online community of research consultants.Intellectually curious.Ability to thrive in a flexible, non-hierarchical and collaborative environment.Excellent problem solver.",Intermedio,Jornada completa,"Tecnología de la información, Ingeniería, Consultoría",Software,122,None,True,,376,ACTIVELY_HIRING_COMPANY
190,2259516323,2020-10-31,SR2 - Socially Responsible Recruitment,Data Engineer Fully Remote,"Bristol, GB","Data Engineer | £45,000-£60,000 | Bristol  Are you an experienced Data Engineer looking to join an expanding Scale-Up? Are you looking to join an organisation that prides itself on using the cutting edge in data manipulation tech?  We are excited to be working alongside our client - an established Cyber Security consultancy, partnering their search for an experienced Data Engineer. With the work flooding in, you will be joining an ambitious and forward-thinking data team. You will be working on a mix of large and small projects and be responsible for translating data into valuable insights..  What You Will Be Doing   Designing intelligent data solutions for internal and external stakeholders  Collect, collate, and effectively interpret data to derive meaningful and actionable insights.  Developing fit-for-purpose, resilient, scalable, and future-proof data services that effectively meets client needs.  Be aware of and keep up to date with advances in digital analytics/ manipulation tools. (The organisation prides itself on using and benefiting from the cutting edge in data tech) Effectively producing data models, understanding the best model to use at each turn.  Effectively recognise and minimise any potential deployment risks  Communicating technical jargon in an easily condensed manner to a wider non-technical audience.   Your Tech Skills Will Include   Experience of scripting in Python or Java Script  ETL, data modelling, and data storage experience  Exposure to big data technologies, Spark, PySpark Hadoop  You will be comfortable and have a background in Datawarehouse Building, Data ingestion and Data Migration  What is essential is an inquisitive nature, a constant will to improve and an ambition to help the wider community by delivering effective Data insights. If this sounds like your type of role please apply with an up to date CV, or if you require any more information please contact me",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Dotación y selección de personal",14,None,False,,121,ACTIVELY_HIRING_COMPANY
191,2236741730,2020-09-29,BDSA,Data Scientist,"Boulder, CO, US","Job Level: Professional Job Family: Data Analytics Department: Product Reports to: Director of Product  Location: Boulder, CO 80301 Employment Type: At-will FLSA Classification: Exempt  Job Summary:  As a Data Scientist, you will work on a highly complex client-facing system providing insights to diverse user groups including innovation, marketing, sales, and strategy. Day-to-day activities will include development and refinement of projection algorithms, QC/QA systems support, and input to the product roadmap based on client needs and available data streams. The Product team empowers BDSA through the development of syndicated market research products based on scan data.  Essential Functions and Responsibilities:  Create and deploy data projection models to drive both customer-facing and internal decisions. Execute and evaluate appropriate analyses (cluster analysis, logistic/linear regression, lift, etc.) given an array of tactical and strategic objectives. Utilize statistical and data visualization packages to develop innovative approaches to complex business problems. Extracts, analyzes, identifies, and assesses qualitative or quantitative patterns, trends, and other relationships from large amounts of data. Responsible for the maintenance and management of data assets. Interfaces with data end-users and the data storage/management architecture team to ensure that systems meet business needs. Develops and executes standard or custom queries or reports to retrieve data as required. Streamline existing processes to ensure the highest data quality while minimizing rework and increasing efficiency. Define data needs and external sources: validate, import, curate, and manage data for analytic and discovery projects. Interface closely with technology partners to manage analytical environment, acquire data sets, and develop production applications.   Qualifications  To perform this job successfully, an individual must be able to perform each essential function satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or abilities required to do so. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.  Required Education, Experience, and Other Qualifications:  Degree in data science, statistics, economics, or a similar field with at least five years' work experience preferred (experience may be substituted for educational requirements). Experience working with scan data. Experience working in CPG or a similar industry (e.g., BevAl). Experience analyzing and solving CPG-focused challenges including but not limited to: innovation planning, pricing elasticity, forecasting, projections, assortment, etc. Ability to digest business problems and translate needs into a data-centric context. Self-starter attitude with willingness to learn and master new technologies and analytical techniques. Flexibility to work both independently and within a team. Creativity in the face of constraint: 'I can solve this' mentality. Advanced Excel and PowerPoint skills. Familiarity with data visualization software, such as Tableau, Looker, or PowerBI.  Preferred:  Experience processing and manipulating POS, unstructured, text, and survey data. Experience developing and validating market research models. Experience in the cannabis industry.  Other Information  Benefits: Company paid Medical, Dental, Vision, Life and AD&D coverages. We also provide both Health and Flexible Savings Account benefits, Dependent Care and a 401K with immediate vesting.  Conditions of Employment: Pre-employment background check  Work Environment: Normal office environment  Travel: 0%  BDS Analytics, Inc. is an equal opportunity employer. All aspects of employment including the decision to hire, promote, discipline, or discharge, will be based on merit, competence, performance, and business needs. We do not discriminate based on any pay inequities nor on race, color, religion, marital status, age, national origin, ancestry, physical or mental disability, medical condition pregnancy, genetic information, gender, sexual orientation, gender identity or expression, veteran status, or any other status protected under federal, state, or local law.",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Marketing y publicidad, Servicios y tecnologías de la información, Software",50,None,False,,416,None
192,2275808531,2020-10-10,Snagajob,Data Scientist,"Richmond, VA, US","The Opportunity  In an effort to better serve our 47 million registered hourly workers and over 450,000 employer locations, Snagajob is looking for a Data Scientist to collaborate with key business stakeholders throughout the organization and help fulfill our mission of helping people find their best fit job. The Data Science role at Snagajob includes a heavy emphasis on search, information retrieval, matching, and recommendation, as well as experimental design and measurement of data science impact in the customer-facing product. This role provides an excellent opportunity to make a direct impact in a customer facing product.  Our tech stack includes Python (pandas, numpy, sklearn, pytorch, flask), AWS (EC2/ECS, S3, EMR, Sagemaker), Elasticsearch, Mongo, CircleCi, Docker, Terraform, and other technologies. You might not have experience in every area but if you have a drive to learn and grow, we encourage you to apply.  This role may be based remotely or in our Arlington or Richmond, VA or Charleston, SC office.  What Snagajob Can Promise You  When you join the Snagajob Engineering team, you'll be working on a high-volume, high-traffic site that gets over 50 million visits a month! But that's just the start of it. You get to contribute more than just code: we have a highly collaborative environment, so you'll influence what we build and how we build it. Expand your skills with our weekly tech talks. Learn about, and experiment with, new technologies/ideas in our monthly hack days and chapter meetings. Engineering at Snagajob isn't just about keeping the lights on and the site running. It's a place for you to learn and grow in a supportive team environment.  What You'll Get To Do  Develop new data science models and pipelines that are highly available, scalable, and reliable Collaborate with data scientists, developers, and product managers to integrate and validate machine learning solutions end to end Partner with product teams to analyze key business problems Support and improve existing data science pipelines and systems in production  Test and implement algorithms in scalable, product-ready code Research and investigate academic and industrial machine learning, natural language processing and modeling techniques to apply to our specific business cases   What You'll Bring  Advanced degree in computer science or a closely related field, with a concentration in machine learning, or equivalent experience Experience in advanced analytics and Applied Machine Learning Experience building and deploying models using common machine learning frameworks such as scikit-learn, PyTorch Experience working with relational and/or NoSQL data stores Familiarity working in Linux-based systems and/or cloud computing resources Experience in knowledge graphs and/or recommendation systems  Ability to work with ambiguous problem definitions Ability to communicate technical knowledge to a business audience The ability to live by Snagajob's core values - solidarity, candor, unconvention, fire - by being an ally, speaking hard truths, questioning the status quo, and always doing whatever it takes to meet our mission of putting people in the right-fit positions so they can maximize their potential and live more fulfilling lives   Bonus Points  Experience with A/B testing and analysis of engagement with online marketplaces  Experience working with search and information retrieval systems such as SolR/Elasticsearch, as well as experience with information retrieval success metrics   At Snagajob, we celebrate our differences in an inclusive workplace designed to support the things that make us individuals. Snagajob is proud to be an equal opportunity employer and we strongly encourage candidates from all different backgrounds and identities to apply. Each new hire gives us the opportunity to bring in a fresh new perspective to further diversify our company for the benefit of our employees, products and our community.  Why Snagajob  Snagajob offers a highly competitive compensation and benefits package including medical, dental, vision, life insurance, a 401k plan, health and fitness incentives, PTO, paid community service time, and a casual fun work environment with an award-winning culture. What Snaggers love most is our commitment to work-life blend and the amazing leaders who are dedicated to helping their teams grow personally and professionally. Snagajob promotes a culture of community and support, so once a Snagger, always a Snagger. We pride ourselves on keeping it real and not being afraid to challenge the status quo.  About Snagajob  Snagajob, the country's largest and fastest-growing platform for hourly work, connects more than 47 million active job seekers with employment opportunities at 450,000 employer locations in the US and Canada. Snagajob's mission is to put people in the right fit positions so they can maximize their potential and live more fulfilling lives. Through Snagajob, workers gain the flexibility of working when and where they choose while employers are assured every shift stays filled. For more information, visit www.Snagajob.com or connect with us on LinkedIn, Instagram, Facebook and Twitter.",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Marketing y publicidad, Software, Internet",4,None,False,,41,ACTIVELY_HIRING_COMPANY
193,2198821803,2020-10-21,17LIVE Group,Data Scientist,India,"We are looking for extraordinary data scientists to help build the future of 17 Machine Learning. As part of the Machine Learning team, you will help define our create models to ensure that content on Recommendations is personalized and content is ranked based on user preferences. You will also work on a state-of-the-art streamer management platform that can communicate effectively for the purposes of training and feedback. You’ll work with a cross-functional team of engineers, data scientists, and product managers to launch new features for hundreds of millions of customers. If you are data-obsessed, a creative and analytical thinker, and seek the thrill of making a massive impact on core user and streamer experience on 17, this role is for you! Who We Are Our company's purpose is to enable artists through live streaming. The ML team helps serve that personalized recommendations by making it easy for people to find and join the best streams as they unfold. This team owns machine learning-enabled features for end-to-end delivery on the app and to the internal operations team. What You’ll Do Apply your skills in quantitative analysis, data mining, and the presentation of data to see beyond the numbers and understand how our users interact with both our consumer and business productsBuild a deep understanding of our different types of customers and their needs that recommendations can serveIdentify opportunities for our product to better serve those customer needs and work with data science, research, and engineering partners to craft, test, and launch new product featuresUnderstand the existing steamer operations process and use your skills to automate manual operationsIdeate, Plan, and Execute development with internal engineering resourcesRun quick tests with the product team on various features and spearhead further improvements based on feedbackEvaluating and defining metricsSelecting features, building and optimizing classifiers using machine learning techniques  Who You Are 1-5 years’ experience doing machine learning within a large-scale company or fast-paced environmentExperience in SQL and Relational DatabasesExperience communicating the results of analyses with product and leadership teams to influence the strategy of the productStrong background in Machine Learning, Statistics or Information RetrievalFluency in PythonHands-on experience with Apache Spark and its components (Streaming, SQL, MLLib) is a definite advantageFamiliarity with relational databases and SQLFamiliarity with Tensorflow, Keras, and PyTorchFamiliarity with Parallel Processing, Multithreading, and Edge ComputingCritical thinking: the ability to track down complex data and engineering issues, evaluate different algorithmic approaches, and analyze data to solve problemsCreativity: you can conceive of new data-driven products, features, and technologies You will fit in if you have: Appreciation for StartupsHacker attitude to make your way through unfamiliar territory with little helpEnthusiasm to get things done with responsibilityNon-conformist nature which drives you to achieve tasks tagged as impossible by the worldA belief that Data Science can change the lives of billions for good Benefits Best in class SalaryUnlimited Leaves and Work from Home optionsLeadership opportunitiesOnsite opportunities and transfersOpportunity to work in a dynamic team and learn from the very bestChance to work on a revolutionary vision for the data science fieldFreedom to stamp your vision on future",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información",Internet,812,None,True,,1823,JOB_SEEKER_QUALIFIED
194,2208430205,2020-10-23,CreditNinja,Data Science/Data Analytics Project Manager,United States,"DESCRIPTIONCreditNinja is a FinTech company founded in 2017 by veteran serial entrepreneurs who were part of the core team behind Enova (NYSE:ENVA), a leading publicly traded consumer financial services company. CreditNinja's mission is to provide hardworking Americans with financial solutions when unexpected expenses arise. Unlike traditional banks, CreditNinja works hard to ensure that people with less-than-perfect credit can have quick access to the money they need. Headquartered in downtown Chicago, we are a lean and innovative team seeking like-minded talent to help us disrupt the consumer finance industry.CreditNinja is seeking a Project Manager to join our Risk & Analytics team which is comprised of data scientists, data engineers and analysts. The Project Manager will have the opportunity to apply advanced project management knowledge, skills and tools to prioritize and drive projects that impact company-wide strategic initiatives. The Project Manager will scale our data science and data analytics impact through the delivery of quality, timely work. What You Will Work OnManage the delivery of complex projects that require involvement of cross-functional teamsCommunicate regularly with individuals both within and outside of our team, managing relationships and expectationsDocument and organize requirements, success criteria, milestones and deliverables for projectsManage timeline and scope throughout the course of all assigned projectsLead project teams during all phases of the development life cycle including requirements gathering, design, analysis, implementation and continuous monitoringCoordinate with cross-functional groups to design innovative solutions and product features (Product, Marketing, Operations, Finance, Engineering, etc.)Effectively communicate project updates to all stakeholders in an approachable and easy to understand mannerEvaluate results of delivered projects using company-wide KPIs RequirementsBachelor’s Degree preferably in an analytical field such as Economics, Mathematics, Engineering, Computer Science3+ years of work experience managing and driving the execution of complex projectsExperience in/working in partnership with a technical role, such as an engineer, developer, data scientist, etc. a plusProficient with project management tools and techniques, such as JIRA, ConfluenceExcellent interpersonal communication, conflict management, coordination, and planning skills with cross-functional teamsAbility to assess a project's scope and the team's ability to executeExperience working with relational databases, such as SQLOutcome oriented with the ability to drill down from the big picture to process detailsStrong organizational skills and detail orientedSolid grasp of software technologies and stacksComfortable in a flexible and sometimes ambiguous environmentExperience working with specialty finance or FinTech is a plusApplicants must be currently authorized to work in the U.S. on a full-time basis BenefitsCompetitive salary and benefits packageEquity grantCasual dress policyFun, fast-paced work environmentDynamic start-up cultureAbility to make an immediate impact in a growth stage companyHQ Located downtown Chicago above Union StationEqual opportunity employer",Intermedio,Jornada completa,"Gestión de productos, Gestión de proyectos, Finanzas",Servicios financieros,37,None,False,,224,None
195,2250056234,2020-11-06,Aureon Consulting,User Experience Researcher,Des Moines Metropolitan Area,"No C2C-position will sit onsite in Des moines, IA, this is NOT a remote opportunity. Looking for resources UX Researcher with experience with ethnography and diary studies experience.  Survey design and other qualitative methods. Will be responsible for systematic study of target users and their requirements, to add realistic contexts and insights to design processes.  Solid understanding of analytics and the design process as a whole, but also need soft skills such as adaptability, an understanding of human behaviors, and a willingness to collaborate.",Intermedio,Contrato por obra,Tecnología de la información,Dotación y selección de personal,90,None,True,,523,ACTIVELY_HIRING_COMPANY
196,2234522717,2020-11-03,Systems Integration Solutions,AI / ML Engineer,"Sunnyvale, California, United States","Data Scientist - AI/ML Engineer Excellent knowledge and good practical skills in major ML algorithms as applied to Natural Language Processing, information retrieval, data mining.Deep understanding of Python, CUDA or other GPGPU is a plus.Practical experience with deep learning based solutions highly valued.Passion for continuing to learn state-of-the-art techniques in ML/Data science",Intermedio,Contrato por obra,Tecnología de la información,Servicios y tecnologías de la información,197,None,True,,451,ACTIVELY_HIRING_COMPANY
197,2234202040,2020-11-02,Empiric,Big Data Engineer – (Python + PySpark),Switzerland,"Big Data Engineer – Python, PySpark, Java, Scala, Spark, Analytics, ETL Rate: 600 CHF DayLocation: SwitzerlandDuration: 8 months initiallyStart date: immediate  SkillsAlso an application Development background along with knowledge of Analytics libraries, statistical and big data computing librariesSpark, PySpark, Python/Scala/java programming is a must ResponsibilitiesCoding, designing, and develop complex data pipelines using big data technologiesDeveloping applications on Big Data. Design and build highly scalable data pipelinesIngest data from files, streams, and databases. Process the data using Spark, PythonDevelop programs in PySpark and Python as part of data cleaning and processingDesign and develop distributed, high volume, high-velocity multi-threaded event processing systems Nice to have (not essential)Knowledge of Palantir would be added advantage Integration aspects to OA Finance modules",Intermedio,Contrato por obra,Tecnología de la información,Servicios y tecnologías de la información,62,None,True,,276,ACTIVELY_HIRING_COMPANY
198,2203145299,2020-10-13,Frost & Sullivan,Freelance Market Researcher - Maldives,Maldives,"We are seeking for experience market researchers who are keen on a remote 3 months engagement opportunity. If you meet the below requirements, please share a copy of your profile along with your monthly rate. Candidate Profile:Candidate should have a least 3-5 years of experience in healthcare sector - pharma, medical devices, healthcare services and have an understanding of domestic healthcare industry.Candidates with experience in public sector in healthcare such as ministry of health, public health policy, regulatory department etc. will be preferred. The candidate should be able to identify sources of physicians, healthcare professionals, researchers to build a database and also have a network in the healthcare industry. Understanding of market research process will be an advantage.Experienced in B2B researchMust be proficient in local language, and currently based in Maldives  If engaged, your work scope would include:- Identification and mapping of possible stakeholders / stakeholder groups for advocacy purposes- Healthcare professionals, Research/Scientific Community, Policy Makers in Maldives- Engage the stakeholders in preliminary discussions to understand the receptiveness of the RRPs concept and potential of advocacy engagement- Further engage the potential Key Opinion Leaders (KOLs) in in depth discussions to take them forward with the advocacy program  Note: only shortlisted candidates will be called for interview.",No corresponde,Contrato por obra,"Investigación, Análisis, Redacción y revisión","Consultoría de estrategia y operaciones, Investigación de mercado",56,None,False,,882,ACTIVELY_HIRING_COMPANY
199,2222442598,2020-10-29,tetrel.ai,Senior Data Scientist,Germany,"tetrel ist ein Start-up für Machine Learning basierte Softwarelösungen. Unsere Kunden sind Unternehmen oder Non-Profits in Deutschland und Europa. Unsere Lösungen helfen unseren Kunden dabei, ihren Betrieb, ihre Prozesse und Produkte zu verbessern.  Wir decken die komplette Data Science Wertschöpfungskette ab, von Beratung über Data Engineering, der Entwicklung von Algorithmen bis hin zum Deployment als API oder App.  Wir suchen einen Senior Data Scientist (w/d/m) für unser Team, remote innerhalb von Deutschland oder vor Ort in Berlin-Kreuzberg.  Deine RolleAls Mitglied unseres Teams löst du komplexe Geschäftsprobleme für unsere Kunden. Dazu entwickelst du eigenverantwortlich Analysen, Algorithmen und, zusammen mit dem Team, komplette Machine Learning Pipelines und Software.Du setzt Projekte um, von Piloten bis hin zu vollständigen Softwarelösungen, in enger Abstimmung mit uns und unseren Kunden.Du entwickelst nicht nur ein technisches Verständnis für die Daten unseres Kunden sondern durchdringst auch die dahinterliegenden Geschäftsprobleme und -mechanismen.Du probierst zudem regelmäßig neue Methoden, Technologien und Tools aus, die unsere Projekte besser und effizienter machen und integrierst sie in unsere Workflows. Dein ProfilDu entwickelst seit mindestens 5 Jahren Software und beherrscht Python sehr sicher. Du hast ein tiefes Verständnis von und praktische Erfahrung mit angewandter Statistik und Machine Learning.Dein Code ist strukturiert und verständlich. Du bist vertraut mit moderner Software-Entwicklung (Agile, DevOps, Cloud Computing) und dem Python Data Science Stack (z.B. Numpy, Pandas, scikit-learn, pyTorch).Du kommunizierst sicher, professionell und mit Empathie auf Deutsch und Englisch.Du arbeitest selbstständig und zielgerichtet in einem durch schnelle Veränderungen geprägten Umfeld. Probleme zu lösen, zu lernen und Dich weiterzuentwickeln macht Dir Spaß. Du hast einen Wohnsitz und eine Arbeitserlaubnis in Deutschland.Idealerweise hast Du einen Universitätsabschluss (oder sogar eine Promotion) in einem quantitativen Feld, wie z.B. Mathematik, Physik, Informatik oder Ökonometrie.bereits Erfahrungen mit Deep Learning, Causal Inference, Reinforcement Learning oder Natural Language Processing.  Was wir bieten Flexible Arbeitszeiten. Wir haben keine festen Vorgaben - Du bist selbst dafür verantwortlich, dass deine Arbeit erledigt wird.Keine Zeitverschwendung mit Politik. Wir sind ein kleines Unternehmen mit schnellen Entscheidungswegen und einer “Hands-on” Mentalität.Keine Slack Notification Hell. Wir entwickeln eine Arbeitskultur in der so viel wie möglich asynchron kommuniziert wird. Damit ist mehr Raum für konzentrierte Arbeit ohne ständige Unterbrechungen.Viele Möglichkeiten zum Lernen und zur Weiterentwicklung - sowohl persönlich als auch technisch.Spannende Projekte und Fragestellungen mit direktem Impact für unsere Kunden.Arbeite remote oder aus unserem Büro in Berlin-Kreuzberg.  BewerbungsprozessOne-Click Bewerbung auf LinkedIn (oder per Email mit Lebenslauf).Eine Python Code Challenge. Schreibe ein paar Funktionen, die von uns gestellte Unit Tests erfüllen (maximal 1 Stunde Aufwand) und beantworte eine Frage.Video Call, zum gegenseitigen Kennenlernen (30-45min).Interview zu technischen Themen und Raum für Deine Fragen (in Berlin oder remote). Angebot.",Algo de responsabilidad,Jornada completa,None,Software,151,None,True,,859,JOB_SEEKER_QUALIFIED
200,2240596745,2020-10-01,Jun Group,Machine Learning & Data Engineer (Remote),"New York City, NY, US","Jun means truth, and our culture is about openness and honesty. Jun Group is a mobile advertising company that delivers beautiful full-screen video and display ads to millions of people. Advertisers like Audi, Merck, Intel, and WebMD trust Jun Group because everything we do is brand safe, viewable, and transparent.  We are looking for a software developer to join our amazing server team. This position is full-time and 100% remote with the option of working on-site once it is safe to do so. Jun Group will only consider candidates for this position who are currently legally authorized to work in the United States.  Who You Are  You enjoy a fun, creative, and engaging working atmosphere free of brilliant jerks You want to be part of a small team inside a large company with massive opportunity for growth You enjoy collaboration with other teams including product, biz dev, and our in-house QA team You eagerly dig into complex engineering problems   What You'll Do  Contribute to exciting greenfield projects Develop new predictive machine learning models to optimize our ad server Collaborate with our server engineering team to improve our existing machine learning models and tooling Experiment with new tech to find the right tool for the job Use Kanban to manage multiple releases per week Maintain high code quality through code reviews and automated tests   Qualifications  You have hands-on experience implementing production machine learning systems at scale in Java, Python, Scala, or similar languages Experience working with streaming and batch data processing tools like Apache Beam, Spark, Flink, etc. You've built and maintained an ETL pipeline using a data warehouse like BigQuery or Redshift Data engineering experience, including SQL and manipulating large structured or unstructured datasets for analysis Practical knowledge of how to build efficient end-to-end ML workflows Familiarity with Python machine learning tools like scikit-learn, pandas, etc. Familiarity with AWS and Google Cloud big data products   What We Offer  A highly competitive compensation package 401k with company match Paid vacation, work from home, and sick days Annual personal development budget to attend a conference of your choice Designated time to work on company-related projects you feel strongly about Macbook Pros and any other equipment you need to work effectively from home Monthly company events   Jun Group is a high-powered, collaborative environment. We are looking for candidates who work well in teams, enjoy learning, and challenging the status quo. We work hard, and we have lives, too. We'll pay competitively based on experience, and we're open to allowing the right person to learn our industry on the job.  Interested parties should send a resume along with a cover note. We have excellent perks and benefits, and we welcome diversity and non-traditional paths into all of our roles. We believe in hiring the right person as opposed to the right combination of keywords.",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Marketing y publicidad, Medios de comunicación en línea, Internet",34,None,False,,171,ACTIVELY_HIRING_COMPANY
201,2184302749,2020-10-14,Cohere Health,Machine Learning Engineer,"Boston, Massachusetts, United States","Opportunity overviewCohere Health is simplifying healthcare for patients, their doctors, and all those who are important in a patient’s healthcare experience. Our focus is to enable an efficient, transparent patient journey where patient goals are central to decision-making. We are a mission-driven and fast-growing company obsessed with eliminating the wasteful friction patients and doctors experience, particularly for diagnoses that require expensive procedures or medications. To that end, we build products and services that ensure the appropriate plan of care is understood and expeditiously approved, so that patients and doctors can focus on health, rather than payment or administrative hassles.  In this role, you’ll join our growing team of world-class engineers, statisticians, and clinical experts to deploy machine learning algorithms that help automate burdensome administrative clinical practices. You will be tasked with finding the most promising opportunities for impact and then delivering on them. What you will do:Find the signal in incoherent clinical dataBuild reliable and scalable production machine learning systemsWork on feature engineering, statistical analysis, developing novel ML techniques, understanding classifier performance, and ensuring fit-for-purpose.Work cross-functionally across diverse stakeholders, including product managers, statisticians, EHR data specialists and physicians. What you will have: You have at 3 years experience in applied ML in the industry with a degree or higher (MS/PhD) in computer science, machine learning, mathematics or similar fieldClear understanding of model building, model maintenance and the measures that optimize models for product useUnderstand experimental design and can independently perform collection, measurement, and interpretation of resultsExpert in R, SQL,Python or other common analytical data toolsExpert in linear regression and classification approaches Bonus points if:Have experience with healthcare data such as claims and EMR dataHave hands on experience building NLP models using Spacy from clinical narrativesExperience with TensorFlow is also a plus. We can’t wait to learn more about you and meet you at Cohere Health!",Algo de responsabilidad,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Atención sanitaria y hospitalaria",335,None,True,,806,ACTIVELY_HIRING_COMPANY
202,2193212178,2020-11-05,"HireStarter, Inc.",Senior Data Engineer,"Austin, Texas Metropolitan Area","Ideally based in Austin or Nashville, but open to remote. No C2C. Unable to sponsor or transfer visas. As a Data Engineer, you will be working on projects that help bridge the gap between the engineering and analytics teams. As a member of the team, you will be expected to share knowledge, relentlessly problem solve, have a superior work ethic and be an excellent communicator in an easy-going environment.  Responsibilities:• Design and implement ingestion pipelines to handle and transform large amounts of structured and semi-structured data from a multitude of sources.• Write, optimize, and automate data processing tasks.• Design monitoring around ingestion and processing tasks and develop runbooks in case of an outage.• Build systems with reusability and scalability in mind• Collaborate with the technology and analytics teams on developing new conventions and processes.• Optimize our search engine and help build relevancy models around results Requirements:• 3+ years of experience with Python• Experience with PostgreSQL, or a similar RBDMS• Experience with Elasticsearch• Familiarity with a cloud provider, e.g. AWS, GCP, Azure (We use Azure)• Knowledge of design patterns and software engineering best practices. Bonus!• Experience with Airflow or Luigi• Experience with R• Experience building RESTful APIs for serving processed data• Experience with Databricks",Intermedio,Jornada completa,Tecnología de la información,Software,96,None,True,,310,JOB_SEEKER_QUALIFIED
203,2195126340,2020-11-06,Medical Solutions,Sr. Data Engineer,Omaha Metropolitan Area,"Lead Data Engineer Our team is currently looking for a Lead Data Engineer who is passionate about creating awesome analytics solutions for our customers and our teammates. As a Lead, you’ll be responsible for guiding the business intelligence team in best practices, coding standards, and data ops processes. You’ll be hands on with solution delivery, a mentor, and encouraging the team to be flexible, proactive, and solution focused. The ideal candidate will identify and implement solutions that enable self-service functionality while maintaining data integrity.We value open and honest communication and we strive to create a positive and fun team-based environment. We want teammates that challenge themselves, as well as those around them to create high quality analytical products and services. Essential Functions:Develop and maintain enterprise data warehouse and business intelligence solutionsDesign, build, and test solutions for data transformation from a variety of data sources while modeling data in an efficient and performant mannerWork directly with customers to understand reporting and analytics needsCollaborate with customers and BI analysts to design and build BI semantic solutions to enable governed self-serviceAssist in building technical roadmap for analytic productsBe a resource to your team and organization as a subject matter expertProvide technical and professional mentorship to your teammatesWork with Product Owners and Scrum Masters to help determine priority and assess timelinesBe a committed agile teammate who guides the team to reach their goalsParticipate in all agile ceremonies, including: planning, pointing, demos, and retrosEnforce industry and company best practices within your teamPrioritize unit tests, both manual and automated, to ensure the highest code qualityResponsible for timely and thorough code reviewsResponsible for documenting all solutions and metadata to the required company standardContinually learn and stay up-to-date with the ever-changing analytics technical landscapeMentor other team members on new technologies and practicesWork with external vendors to ensure deliverables meet company needs and standardsOwn the data ops delivery pipeline and processesParticipate in architectural design decisions and communicate those to your team Job Qualifications:Bachelor’s degree in Data Analytics, Computer Science, Management Information Systems, Mathematics or similar analytical fieldMinimum 5 years of experience working with data warehousing design and delivery with preference given to cloud DW experience in Snowflake or Azure SynapseDeep knowledge of data transformation tools such as Azure Data Factory or SSIS and push down ETL methodologies and toolsExperience building and designing BI semantic models in SSAS tabularWorking knowledge of data visualization tools, with preference to PowerBIExperience with Microsoft Office Suite with emphasis on Excel (pivot tables, v-lookup, working with data from BI semantic models)Knowledge of paginated and tabular reporting tools (e.g. SSRS)Advanced knowledge of SQL and tuning SQL including analysis of query plansExperience and expertise in Python and familiarity with application of modern data science languages such as Python, R, etc.",Director,Jornada completa,"Ingeniería, Tecnología de la información",Dotación y selección de personal,100,None,True,,340,ACTIVELY_HIRING_COMPANY
204,2253931884,2020-10-29,Vyaire Medical,Data Scientist,"Lake Forest, Illinois, United States","About US At Vyaire, we help the world breathe easier. As a global leader in respiratory care, we know what we do enables, improves and extends lives. We are a young company with a long history of revolutionary products. We devise extraordinary solutions that allow patients to lead ordinary lives. We believe the best way to create value for our customers, is to become invaluable. We know a dynamic culture with diversity of thought makes this possible. Our colleagues are people who specialize in exceeding expectations, building lasting relationships and making it a priority to listen. We are dedicated to anticipating what’s next and get it done. We thrive on contributing and making a difference. To learn more, visit our website: www.vyaire.comWatch our video: https://www.youtube.com/watch?v=ZDrQoMbMRrI&feature=youtu.be About this role Vyaire teams are dedicated to connecting clinicians and patients with the highest quality respiratory healthcare solutions in the market. At Vyaire, you will find a company that puts the customer at the center of all we do. Our culture is one that rewards performance and each interaction we have with a customer furthers our mission to be the global leader in respiratory care.  We have an exciting opportunity for a Biostatistician with demonstrated expertise in clinical study design and analysis, who specializes in statistical methodologies used to support analytical and clinical validation of medical technology. Working in collaboration with scientists and physicians, you will provide advanced statistical and analytical expertise to Vyaire. You will use your knowledge of clinical study design and biostatistics to provides technical leadership, knowledge, experience and expertise by planning, conducting and supervising clinical development and evidence management projects. You will contribute to the clinical development strategy and ensure statistical integrity, optimal study designs and data and evidence needs are reflected and fulfilled within that strategy. To achieve Vyaire’s objectives, you provide out-of-the-box thinking to develop innovative clinical study designs, quantitative decision making and the incorporation of evidence from disparate sources of big data.  Critical deliverables include the design and formulation of statistical methodologies and input that ensure quality and consistency of key data deliverables across studies. You will analyze data and prepare and review study protocols, statistical analysis plans, interim study reports, manuscripts, abstracts and other technical documents and procedures pertaining to statistical methods.  Essential Functions: Be an integral member of product development team responsible for supporting claims development, and data management in clinical studies.Possess data management expertise and advanced knowledge in biostatistical concepts and practical application of such concepts to the assessment of medical device technology.Serve as a subject matter expert in biostatistics, epidemiology, data mining, data analytics, and data management.Provide study design and biostatistical guidance to Offering Management, Marketing and Development teams.Provide functional excellence in the areas of statistics, data analysis and data processing for the department.Apply extensive fundamental and specialized knowledge to the development of clinical protocols for device validation, respond to FDA questions, implementing new approaches to automated data processing for clinical trials.Propose new ideas and recommend implementation plans leading to enhanced efficiencies and faster review and analysis of data.Provide statistical input and advice to clinical teams for the design of studies and sample size/power estimations, including the design, writing and review of study protocols, development of statistical analysis plans and development of analyses requiring advanced statistical methodologies.Design and lead the preparation of statistical components of protocols which meet project objectives, health authority guidelines, and clinical trial methodology standards.Lead the analysis, evaluation and planning for methods of approach, and organizes means to achieve the solution to highly complex problems.Interpret and evaluate statistical data and results of the most complex investigations and develop appropriate recommendations.Lead the development of reports, charts, graphs, and other documents which support claims recommendations.Lead building the data and evidence for Vyaire offerings.Support develop the standards for clinical conduct, data collection, management and/or reporting.Provide clear and regular technical and administrative input to professional, technical and administrative personnel assigned to a project.Recognize and address issues which may impact the statistical integrity of the evidence development program or recognition of datasets for which different statistical tools may add value. Qualifications: PhD or MS degree with 5+ years of experience in a Healthcare medical device or Life sciences pharmaceutical regulated process mature environmentExperience with clinical decision support systems and/or software as a medical device is critical.Demonstrated experience of applying statistical methods in biomedical research, pharmaceutical, medical device or CRO experience is required.Good knowledge of ICH GCP guidelines, FDA regulations and demonstrated experience with pharma and/or medical device clinical trials and FDA/NDA submissions is required.Experience with study design methodology such as adaptive design or pragmatic clinical trials, state-of-the-art modeling approaches, incorporation of real word evidence or experience analyzing big data.Ability to understand scientific questions and formulate statistical and data-analytic methods to provide solutions to novel problems.Sound knowledge of statistical methodologies such as analysis of variance, regression, experimental designs, contingency tables.Expertise with SAS and R.Ability to work independently and in project teams.Excellent communication skills (written and spoken).",Algo de responsabilidad,Jornada completa,"Análisis, Investigación","Servicios médicos, Biotecnología, Atención sanitaria y hospitalaria",19,None,False,,302,ACTIVELY_HIRING_COMPANY
205,2254987440,2020-10-29,Venturi Ltd,Azure Data Engineer ( Data Factory / Databricks / DevOps ),"London, England, United Kingdom","Azure Data Engineer ( Data Factory / Databricks / DevOps ) Remote3 Months ASAP£400-450/day (Outside IR35) Azure Data Engineer ( Data Factory / Databricks / DevOps ) is needed to join a leading Microsoft Gold Partner Consultancy. As the Azure Data Engineer ( Data Factory / Databricks / DevOps ) you will work as part of an Agile development team in a large scale DevOps production environment.  This a remote working Contract for an initial 3 months, with the potential of extension.  Desired skills and experience for the Azure Data Engineer  ( Data Factory / Databricks / DevOps ) includes: Strong Azure Data Platform experienceAzure Data FactoryAzure DatabricksAzure DevOps",Intermedio,Contrato por obra,Tecnología de la información,Dotación y selección de personal,22,None,True,,126,JOB_SEEKER_QUALIFIED
206,2247095925,2020-10-27,Gentis Solutions,Data Engineer,"Boca Raton, Florida, United States","Gentis Solutions is seeking a Digital Data Developer to lead and participate in the design and implementation of large and/or architecturally significant applications Required Skills and Experience:﻿7 + years of experience in systems analysis, design or programming, and the associated development methodologiesExperience with project planningProven communication and presentation skills to effectively communicate information to customers and to all levels within the organizationAbility to interact well in a team environmentTechnologies:SSASSSISSQLSSRSData Modeling  Desired Previous Job Experience/Education:Bachelor’s degree in IS or related equivalent work experience in an Information Systems position5 + years of experience in systems analysis, design or programming and the associated development methodologies with large size or highly complex projectsPrior experience with project planning with large size or highly complex projects Position Duties:﻿Lead and participate in the design and implementation of large and/or architecturally significant applicationsChampion company standards and best practices: work to continuously improve software delivery processes and practicesBuild partnerships across the application, business and infrastructure teamsDevelop programming specifications: design, code and unit test application code using Software Development Life Cycle (SDLC) best practicesComplete estimates and work plans independently as appropriate for design, development, implementation and rollout tasksCreate technical system documentation and ensure that this documentation remains current throughout all phases of the SDLCCommunicate with the appropriate teams to ensure that assignments are managed appropriately and that completed assignments are of the highest qualitySupport and maintain applications utilizing required tools and technologies: provide support for applications, including involvement with the Support Center, NOC, Infrastructure teams, and vendors as appropriate, provide off-hours support (24 x 7) as requiredAssist other personnel on assignments including mentoring or providing on-the-job training to more junior associates: mentor team members in software development principles, patterns, processes and practicesMay direct the day-to-day work activities of other team membersMust be able to perform the essential functions of this position with or without reasonable accommodation",Intermedio,Jornada completa,Tecnología de la información,Servicios y tecnologías de la información,50,None,True,,205,ACTIVELY_HIRING_COMPANY
207,2287624552,2020-10-13,Vic.ai,Data Scientist,"New York City, NY, US","Senior Data Scientist  Location: NYC Office or Fully Remote  About Vic.ai  Vic.ai is creating the 'Intelligent Accounting' era, using artificial intelligence to automate accounting and provide advisory, business insight, and eventually business foresight.  We're a Series A stage start-up, founded by three Norwegian entrepreneurs and backed by renowned Silicon Valley investors (including Costanoa Ventures, Cowboy Ventures, and GGV Capital). We're US-based, but our team is global, from New Zealand to California. We're bringing AI to Finance and Accounting because the industry is ripe for automation and big-data insight and the market is huge: $200B just in the US.  We have two main office locations, New York and Oslo. We have a well established remote-work culture, and over 50% of our team has worked fully remotely since we started.  About You  You've been a software engineer for 5+ years, but you've been a tinkerer and a builder your whole life. We're a team of builders—when we aren't building Vic.ai, we're tinkering with a personal project, contributing to open source, modding a drone, building a computer from components, etc.  You know a great data pipeline from a standard one, because you started out building textbook ones, and learned through experience all the things that make a pipeline robust, transparent, and scalable.  You're ready for the next step in your career, ready to take on fast-moving challenges. You're enthusiastic about AI and the possibilities it opens for software development and transforming traditional work. You aim at reaching greatness and delivering exceptional outcomes in your work.  As a team player, you are not afraid of reaching out to your colleagues to discuss development challenges, especially when you are stuck trying to solve a specific issue.  You are fluent in English.  Role details   You will become part of our core back-end team reporting to our Engineering Manager and responsible for the systems that tie everything together into a production environment for our customers. The main focus of the role is to develop and scale our core cloud-based processing service, which includes our OCR technology, extracting data from various sources into databases, generating datasets for machine learning and structuring communication with our AI models.  We mainly develop in and use  Python Pandas AWS (EC2, RDS, KMS, SNS, etc) Docker + Kubernetes + Rancher Git  extensively throughout our platform, so advance knowledge of these is highly preferred.  In addition, our technology stack includes the following components, knowledge of which is desired:  Django Celery Elixir + Phoenix Angular.io / TypeScript Tesseract + Textract TravisCi  Key areas of responsibility  You will own the data pipelines that feed and interact with our AI models! You will build them, monitor them, scale them. Our AI eats large amounts of data. You will work closely with our AI team to set up scalable data storage solutions, for managing our datasets. As part of continuous improvement take ownership of relevant system components to improve functionality, stability and/or capability   Qualifications  Bachelor or Master's Degree in Computer Engineering, Computer Science, Statistics, or similar studies  Experience  Experience (3+ years) with Python, including extensive experience with Pandas. Experience operating, scaling, and optimizing databases and storage systems on the cloud. Strong AWS experience preferred You know that deploying software is as much about the environment as it is about the code: experience with docker, unit testing, Ci systems (TravisCi or CircleCi preferred), performance monitoring, log monitoring, and security   What We Offer  An exciting work environment operating at the forefront of AI technology development A company full of talented, curious, and friendly people A competitive compensation package Company-paid benefits for employees such as medical, dental, vision, disability, and life insurance The opportunity to work fully remotely Flexible time schedules A workstation and tools of your choice",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Software, Internet",None,None,False,,10,ACTIVELY_HIRING_COMPANY
208,2276199893,2020-11-04,Unite Us,Data Scientist,"New York City, NY, US","Who we are:  Unite Us is reinventing the delivery of health and human services. We connect service providers on a common platform, enabling scalable, accountable and measurable delivery of wraparound care. Our technology provides collaborative infrastructure for these communities. We care deeply about the work we do and the communities our software benefits. We're looking for people to join our team who share that passion for our mission to reinvent Health & Human Services and aspire to make a lasting difference for future generations. No matter how large our team grows, we will always be family. Unite Us prides itself on offering a competitive salary, full benefits, and the opportunity to change the world. Come to Unite Us and together we can build healthier communities for everyone.  Description:   Unite Us seeks an experienced, multi-faceted Data Scientist, to be a part of our Data Analytics team. Unite Us brings health care and social services together into a single, integrated network. We believe the network creates value beyond the sum of its parts, and our data science mission is to measure and enhance that impact. The ideal Data Scientist candidate will combine thorough understanding of both descriptive and predictive analytics and will have the skills necessary to communicate the value of that work to both internal and external stakeholders.  The Data Analytics team supports functions across Unite Us including Product, Engineering, Sales, Customer Success and Marketing. Deliverables will be both client-facing and internal and will range from client reporting, to impact analysis, to predictive modeling. The Data Scientist needs to be a strong team player, as well as influencer within the company and beyond. This position combines a unique blend of leadership and practical quantitative output. This is the opportunity of a lifetime for a person who loves numbers, has strong business acumen and communication skills, and is a born change-maker.  What You'll Do:    Identify data benchmarks and social care ROI that can be leveraged across the company - you will be supporting Sales, Marketing and Customer Success  Develop predictive analytics capabilities by identifying and leveraging both internal and external data sources and creating tools that support referral decision-making, calculate risk scores and identify client needs.   Transform data captured by our health systems partners to power the Unite Us platform by identifying key insights.  Partner with Business Development, Product and Engineering to understand our partners and the health and social care data landscape.  This role provides a unique opportunity to be part of the founding team focused on social data expansion across the country: helping health systems, health plans and CBOs realize their SDOH data strategy.  What's Required:    3+ years experience with modern programming languages (Python, R, SQL) and tools/libraries (pandas, scikit-learn, TensorFlow, etc) used in data science.   Robust understanding of the statistical foundation of machine learning and experience with experiment design and causal inference.   Comfort with geospatial analysis techniques.   Experience scaling work from R&D to a production predictive pipeline built on a modern stack.   Experience with healthcare data and analytics is preferred.   You're a kind, passionate and collaborative problem-solver who seeks and gives candid feedback, and values the chance to make an important impact.   You love numbers, and have an orientation to find practical solutions to complex problems   You like to teach others, have strong communication skills and experience briefing leadership on outcomes and recommendations   You are flexible and excited to work in a fast-paced environment with evolving needs   You have a passion for working with data and understanding how it can be turned into products.   You have a 'get it done' mentality, self-motivated and comfortable with ambiguity  You thrive in a cross-functional environment, and enjoy working collaboratively with a diverse team of individuals with different backgrounds and skill sets  You are a strong communicator with an ability to adapt communication style across stakeholders, both internal and external, with varying levels of seniority   Education and Experience:    3+ years of work experience in Analytics or Data Science, including experience managing teams. Growth company experience is highly preferred.   Experience working with health data, or in a healthcare related field preferred.   Degree in quantitative field such as statistics, computer science, math, data science. Advanced degree preferred.   Environmental Job Requirements & Working Conditions:     This position is remote  This position requires 10% travel   Unite Us is committed to building a diverse team and fostering an inclusive culture, and is proud to be an equal opportunity employer. We embrace and encourage our employees' differences in race, religion, color, national origin, gender, family status, sexual orientation, gender identity, gender expression, age, veteran status, disability, pregnancy, medical conditions, and other characteristics",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Software, Atención sanitaria y hospitalaria",103,None,False,,534,ACTIVELY_HIRING_COMPANY
209,2208406236,2020-10-23,Remind,Head of Data Science and Analytics,United States,"About the companyRemind, the leading communication platform in education, helps educators reach students and parents where they are: their phones. With nearly 30 million active users, we’re one of the fastest-growing companies in education technology, but we have our sights set on something bigger: giving every student the opportunity to succeed. Remind runs one of the largest free services in education, one of the fastest growing school/district SaaS businesses (the Remind Plan), and a revolutionary new direct to consumer business (Remind Coaching). The common thread through each of our product lines is the belief that success in education is driven by relationships, and the Remind communication platform is when the next generation of education relationships live. About this roleWe have a small 3 person data org right now, but we are hoping to double that in the next 12 months. We need an experienced data and analytics leader to help us transition from reactive to proactive, to help us build out our data engineering function, to help us more rapidly deliver insights to our product development team, the Sales and Success org, and our users and customers.As Head of DSaA, you will partner with executive leadership to ensure we are delivering the most high value insights to the teams and customers who need them. Reporting to the VP of Product, you will set budget and staffing to support our vision, and partner with executive leadership to set investment profile for data infrastructure, insight delivery, and operational or productized data. About you:The three main focuses of this role will be: analytics and experimentation, data engineering, and machine learning/prediction. You should have a depth of experience in at least one area — and a strong grasp on all three.You have worked in a high growth, consumer or SaaS company and seen what it takes to build a high performing data org.You have experience managing, mentoring and developing a team of data scientists, analysts, and data engineers.You seek impact that accelerates our business and our mission. Also have a demonstrated ability to create real value from analysis.You are proficient in modern data stacks: ours is Redshift, Spark, Luigi, Fivetran, Looker etc - you know how to navigate that and build upon the existing foundation.You build high performing teams— from hiring top level people, helping junior people grow into senior ones.You are a cultural leader who will up-level how every team at Remind uses data.You combine business insight, technical acumen, and human understanding to drive an immaculately prioritized data roadmap. What you'll do:Grow and manage your team of data scientists, analysts and engineers.Drive focus and execution for that team, and craft the ways in which they interface with every other org in the company.Drive investment in our data infrastructure to allow us to more reliably and rapidly product insights.Identify as of yet unknown areas that data investment could make an impact to our business and users. Compensation:Competitive salary and equity401K100% health coverage for you and your dependentsOpen vacation policyPaid parental leave Remind is an equal opportunity employer, and we're committed to diversity and inclusion in the workplace. We aim to represent the students, teachers, and parents we serve, and we welcome, support, and empower all the diverse individuals in our community.",Intermedio,Jornada completa,Tecnología de la información,Internet,76,None,False,,534,COMPANY_RECRUIT
210,2237166818,2020-11-03,Eurofins Lancaster Laboratories,Entry Level Data Review Scientist(s),"Lancaster, PA, US","Company Description   Eurofins Scientific is an international life sciences company, providing a unique range of analytical testing services to clients across multiple industries, to make life and our environment safer, healthier and more sustainable. From the food you eat, to the water you drink, to the medicines you rely on, Eurofins works with the biggest companies in the world to ensure the products they supply are safe, their ingredients are authentic and labelling is accurate. Eurofins believes it is a global leader in food, environmental, pharmaceutical and cosmetics products testing and in agroscience CRO services. It is also one of the global independent market leaders in certain testing and laboratory services for genomics, discovery pharmacology, forensics, CDMO, advanced material sciences and in the support of clinical studies.   In over just 30 years, Eurofins has grown from one laboratory in Nantes, France to over 47,000 staff across a network of more than 900 independent companies in over 50 countries and operating more than 800 laboratories. Eurofins offers a portfolio of over 200,000 analytical methods to evaluate the safety, identity, composition, authenticity, origin, traceability and purity of biological substances and products, as well as providing innovative clinical diagnostic testing services, as one of the leading global emerging players in specialised clinical diagnostics testing.   In 2019, Eurofins generated total revenues of EUR € 4.56 billion, and has been among the best performing stocks in Europe over the past 20 years.     Job Description   Employee Responsibilities:   Ensure that the client receives quality data by reviewing laboratory data for accuracy, clarity, and adherence to GMP and/or GLP regulations Review simple and complex routine and non-routine data (for three or more areas) according to departmental, corporate, and client SOPs: read and undestand analytical procedures: ensure all work is performed according to GLP/GMP requirements and apply GLP/GMP in all areas of responsibility as appropriate Perform analysis of proteins and the impurities or raw materials associated with their production using various analytical techniques Determine if data is compliant and defendable based on industry regulations and methodology Verify data is of sound quality following all method, industry, and client requirements where applicable Diagnose problems, solve simple problems, and suggest solutions to complex problems in professional area: perform complex calculations Troubleshoot method and instrumentation problems Use office and instrumentation specific computer software Produce written reports (e.g., SOP, OMC, client reports)    Qualifications   The Ideal Candidate would possess:   Strong computer, scientific, and organizational skills Excellent communication (oral and written) and attention to detail Ability to work independently and as part of a team, self-motivation, adaptability, and a positive attitude Ability to learn new techniques, perform multiple tasks simultaneously, keep accurate records, follow instructions, and comply with company policies Minimum Qualifications:   Bachelor's or Master's degree in biology or other related degree concentration, or equivalent directly-related experience 1-3 years of experience in a directly-related experienceAuthorization to work in the United States indefinitely without restriction or sponsorship   Additional Information   Position is full-time, Monday - Friday 8:00am - 5:00pm. Candidates currently living within a commutable distance of Lancaster, Pa are encouraged to apply.  Excellent full time benefits including comprehensive medical coverage, dental, and vision optionsLife and disability insurance401(k) with company matchPaid vacation and holidaysEurofins is a M/F, Disabled, and Veteran Equal Employment Opportunity and Affirmative Action employer.",Sin experiencia,Jornada completa,"Investigación, Ciencias",Biotecnología,43,None,False,,389,ACTIVELY_HIRING_COMPANY
211,2268190240,2020-10-08,"Georgia IT, Inc.",Data Engineer-Remote,"Miami, FL, US","Data Engineer Location:-Miami,FL (Remote) Duration:-10+ Months Rate:-DOE Visa:- USC/GC  Job Description  Prefers 12-15 years' experience (SR ROLE) Data Engineer Temp to hire 90 percent sits on oracle ETL Dev/Data Solutions engineer creating data pipelines Oracle Informatica Talend ADF Python OOP would be ideal or any OOP Need strong SQL writing skills Need some type of cloud ideally Azure if not AWS or Google cloud as a+ Domain experience is a + Working across different business lines, working with business not all heads down Ideally Miami on site, East Coast if not on CTH Collaborative Team, must be a person that can work well with others - we all do not have the answers",Sin experiencia,Contrato por obra,Tecnología de la información,"Servicios y tecnologías de la información, Software, Servicios financieros",4,None,False,,34,None
212,2253832005,2020-11-06,Christy Media Solutions,"Data Scientist (Madrid, Spain / Remote) - 12m FTC","Madrid, Community of Madrid, Spain","We have a highly unique job opportunity for multiple Data Scientists at all levels of experience, with R or Python programming skills, to join our world-renowned sports digital media client.  As part of a very exciting expansion strategy for their Data Analysis division, these vacancies can either be based in Madrid, Spain or remote and will be offered on an initial 12-month fixed-term contract basis, with potential to be extended for a further duration. As a Data Scientist, you will be responsible for a wide array of data related activities focused on driving sports fan engagement worldwide, including data architecture & integration, measuring business performance, advanced forecasting, A/B testing, applied machine learning and predictive modelling.  Working across the full digital ecosystem (websites, OTT video, apps and social media platforms) and omnichannel personalisation projects (paid marketing, advertising, email campaigns and push notifications / technology), you will play a vital role in helping key business stakeholders make data-driven decisions regarding digital strategy, content, products and features.  You will carry out in-depth data analysis, visualisation, modelling and data science to answer critical commercial questions and provide recommendations which deliver real value.  You will also provide important input into data infrastructure decisions, data compliance & security and machine learning techniques, collaborating with a variety of business partners and producing reports for senior management. Candidates will have previously worked in a similar capacity - gathering, analysing, interpreting and presenting data, ideally across online digital content (websites, apps & social media) or marketing (optimising online advertising).  Solid experience of exploratory data analysis using either R or Python, working with statistical approaches such as Frequentist and Bayesian and a strong knowledge of clustering techniques are essential.  You will be adept with machine learning algorithms, including linear regression, PCA (Principal Component Analysis), KMeans, MCMC (Markov Chain Monte Carlo), Random Forests and Neural Networks, and be able to formulate queries in SQL. Familiarity with version control using Git and cloud environments, such as Amazon Web Services (AWS), is also required.  Alongside your technical skills, you will be highly driven and hungry to learn, willing to step outside of your comfort zone and develop your skills further. You will have a team player attitude, be happy to help others & collaborate and easily adapt to change.  Exceptional English communication skills are vital, both written and verbal, with the ability to explain data driven insights to non-data specialists in a clear, concise way. You must also be able to build relationships with business stakeholders and influence key decision-makers at all levels, with great persuasion and negotiation skills.  This is a unique, “once in a lifetime” type opportunity to join a prestigious brand in the sports media world, offering the chance to continually learn and grow in a nurturing, dynamic, multicultural and close-knit team and play a key role in delivering the best digital experiences to audiences around the globe.  If you feel you have a relevant data science background, hands-on R or Python skills and the aptitude to succeed in this role, then please apply now with a copy of your latest CV / resume.",Intermedio,Temporal,"Ingeniería, Ciencias, Investigación","Medios de difusión, Medios de comunicación en línea, Marketing y publicidad",61,None,True,,294,ACTIVELY_HIRING_COMPANY
213,2265016076,2020-10-07,Paige,Data Engineer,"Toronto, CA","Paige is on a mission to accelerate and transform the diagnosis and treatment of cancer. Paige is creating a digital platform for pathologists to transform their workflow and is developing a new class of computational diagnostics positioned to drive the future of pathology. A career at Paige is deeply mission-driven where you will work with state-of-the-art technologies alongside leaders in the field and to improve cancer care every day. We reach high, help each other succeed, and believe in creativity, curiosity, and creating amazing products.  We're seeking a Data Engineer who will be working the development and support of software applications, tools and data management pipelines for research and clinical purposes. Following modern product development practices, you will also assist in the design, implementation and maintenance of tools that extract and manipulate data from various sources, including in-house and external databases. This is an extraordinary opportunity to be part of a high-performing team and to pursue a life-changing mission with unique technical challenges!   This position is fully remote for Canadian based applicants.  Responsibilities  Work on Data Warehouse, Data Lake and BI projects and architectures at Paige. Create and implement ETL pipelines that enables the extraction, transformation and transfer of large amounts of structured and unstructured data from various filesystems and databases, that are destined for the development of computation pathology algorithms. Handle the challenges that come with managing terabytes of data. Build tools to manage, automate and monitor our data and data processing infrastructure. Design and develop software tools into existing resources. Be responsible for design, coding, testing, packaging, debugging, documentation and deployment of software systems. Work independently to produce required functional, technical, and user documentation (e.g., business requirements, functional and technical specifications, system architecture, data flows, end-users training requirements) on assigned projects. Work and collaborate with data engineers, scientists, engineers, IT operations and medical doctors to build tools manipulating data in order to build a new generation of artificial intelligence applications for cancer detection and treatment.   Requirements  Experience in architecting, implementing and testing data processing pipelines (e.g. Spark, Beam, ...) and data mining / data science algorithms either on-premise or on a cloud environment. Experience in administrating and ingesting data into standard data warehouses (e.g. Amazon Redshift, Microsoft SQL Server, Google BigQuery or Snowflake). Experience architecting data warehouses and/or data lakes for large amounts of structured and unstructured data. Experience with data lakes and expertise with designing and maintaining a BI solution. Experience with workflow management tools and platforms, such as Airflow. Extensive experience in Python programming, or related language. Experience with RDBMS and NoSQL databases (e.g. MongoDB). Experience in packaging and deploying applications on-premise and in the cloud (e.g. AWS). Familiarity with modern development practices and DevOps. Interest in building non-standard medical software applications, in collaboration with medical partners. Cross-disciplinary and strong analytic skills. Bachelor's degree in computer science or a related field, or equivalent years of experience. 3+ years of industry experience as a data engineer.",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Atención sanitaria y hospitalaria",29,None,False,,228,ACTIVELY_HIRING_COMPANY
214,2216442464,2020-10-18,Whitehat Analytics Limited,Senior Data Scientist,United Kingdom,"ABOUT WHITEHAT ANALYTICS Whitehat Analytics is a boutique data science consultancy specialising in providing expertise in technology-driven business transformation and advanced analytics R&D to solve our client’s most complex business problems, principally in the life sciences, retail/consumer, public sector and financial industries. We pride ourselves on the quality of technical and science talent we have. We value our developers as people as well as employees. We also offer a very attractive benefits package including 24 days annual leave, private health care, dental treatment, discounted gym membership & private pension. We are an equal opportunities employer and value diversity. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. POSITION OVERVIEW We are expanding our team and are looking for a senior data scientist who is driven, passionate and able to develop innovative and effective approaches to solve our clients’ most critical business and analytics challenges. The ideal candidate will possess a background in computer science, natural sciences, mathematics or similar. We are looking for individuals that thrive in cross-functional teams and are eager to share their knowledge and learn from others. We engage with our clients to serve as a catalyst pushing their abilities to apply Data Science and Data Engineering in production settings. As such we offer a varied working environment with exciting and challenging projects that ensure continuous opportunities to develop and progress. Most of our work is onsite with one of our clients in London or Southeast England, with travel to other parts of the UK as necessary. The company will cover any travel and accommodation costs. With the current situation involving Covid-19, this role may start as remote before moving on to client sites.  KEY RESPONSIBILITIES · Statistics and Machine Learningo   Conduct exploratory analytics by designing experiments and testing hypotheses on data.o   Write scripts for feature engineering and creation of data assets.o   Develop supervised and unsupervised machine learning models on diverse datasets across structured and unstructured data.o   Design and build models using algorithms appropriate to data volume, type, quality and velocity.o   Perform model validation and hyper-parameter optimisation. · Project Managemento   Project ownership – responsible for key aspects of projects, including identifying business needs and determining tools, data and techniques to address it.o   Rapid prototyping and agile development techniques. · Communicationso   Creation of engaging visualisations to communicate key findings to both technical and business-focused clients.o   Presenting and depicting the rationale of findings in simple, engaging and easy to understand business terms to a diverse group of stakeholders.o   Communicating with, coordinating and supporting, business experts.o   Mentoring junior data scientists via the creation of personal development plans, encouraging team-wide diffusion of knowledge and being a source of analytical best practice. KNOWLEDGE & EXPERIENCE · Technical Skills – Essential:o   Machine learning algorithms, predictive analytics and statistical techniques (e.g. H20.ai, Tensorflow, Torch, Keras, Caffe, Mahout, Theano, Xgboost, Adaboost libraries)o   High-level programming language(s) (preferably Python, Scala, Java, C, C++)o   Statistics and quantitative analytics, forecasting, multivariate testing, and optimization algorithms (e.g. R, Python numerical stack – Pandas, Scipy, Numpy, Jupyter, Numba, Dask, Seaborn, Bokeh, Matplotlib)o   Understanding of dimensionality reduction and ensemble learning techniques.o   SQL, NoSQL and MPP databases (Maria, MySQL, Teradata, HBase, MongoDB, Neo4j, Dynamo, Couchbase)o   Experience with reporting and visualisation technologies.o   Experience bringing Data Science solutions to production.o   Experience working in cloud (preferably AWS)o  Good working understanding of systems, SCM and virtualisation (Docker, Git, Linux/bash) · Technical Skills – Desirable:o   Background in Computer Science or experience in Software Engineering.o   Domain-specific knowledge in natural language processing, computer vision, image recognition, speech recognition, anomaly detection or time-series data (e.g. OpenCV, CMU Sphinx, gensim, spaCy, SpeechRecognition libraries).o   CI/CD and the DevOps toolchain (e.g. Kubernetes, Jenkins, Ansible, Puppet, Maven, Gradle, Vagrant).o   Front end and API development (e.g. Flask, Django, Tkinter, Swing, AWT).o  Search tools (e.g. Lucene/Elasticsearch). ·  Project & Leadership Skills:o   Agile project/product development.o   Project ownership and task prioritisation.o   Understanding business needs.o   Developing, applying and business cases for a wide variety of stakeholders.o   Presenting technical topics and business cases to stakeholders and co-workers.o   Team leadership. APPLICATIONTo apply, please submit your CV and cover letter care of Human Resources to jobs@whitehatanalytics.com with the subject line: Lastname, First name - Job ID: 000_106 by the closing date of 19th November 2020. We look forward to hearing from you. PROCESSAs much as we would like to hire everybody, we do have to ensure that we both fit together.· Initial call with hiring team· In-person or remote meet and greet with executive team: this will include a technical test and presentation, the content of which will be flexible but should highlight the excellence of your work· Spending time with the team, so we can both understand howwe fit together to make your time with us as rewarding as it will be for us",Intermedio,Jornada completa,Tecnología de la información,Servicios y tecnologías de la información,134,None,True,jobs@whitehatanalytics.com,537,None
215,2236731916,2020-10-24,"o9 Solutions, Inc.",Sr.Data Scientist-EMEA,"Amsterdam, North Holland, Netherlands","“Organizations with superior decision making processes are better stewards of the earth’s precious resources, and are more inspiring, happier, places for employees. Making it happen is our mission” Who is o9?With the recent status of Unicorn, o9 Solutions is one of the fastest growing AI Digital transformation companies in the world today. Smart. Fast. Fun. All words to describe our environment at o9 Solutions. An exciting and high energy environment that drives us to grow and AIM 10x. The perfect place to be innovative, collaborative and dynamic as an organization. We’re always looking for great talent to join our o9 team. Company Overview o9 is the premier AI-powered platform for driving digital transformations of integrated planning and operations capabilities. We help enterprises to digitally transform their supply chain with a cloud-based platform that connects the supply chain end-to-end. Whether it is driving demand, aligning demand and supply, or managing P&L, any process can be made faster and smarter with o9’s AI powered digital solutions. Our headquarters are located in Dallas, and we currently have offices in Amsterdam, Barcelona, Bangalore, Tokyo, and Seoul. We expanded our value-adding activities to companies including Google, Nike, Walmart, Starbucks, Bridgestone, Caterpillar, Pirelli, General Electric, etc. In a nutshellDesign and operationalize various kinds of descriptive, predictive and prescriptive analytics relevant in the planning space. While the analysis can happen in R, Python, Excel, SQL or o9’s tool, ensure the results are presented in a usable fashion for consumption in the o9 platform. You will: Experience using statistical computer languages (R, Python, SQL, SAS, etc.) to manipulate data and draw insights from large data sets.Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.Exposure to distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc.Experience in genetic algorithms, logistic and linear regression, PCA, decision tree analysis and statistical methodsDeep understanding of common business metrics and the ability to generate new ones as neededImprove upon existing methodologies by developing new data sources, testing model enhancements, and fine-tuning model parameters. ﻿You have: 4+ years of experience in implementing ML algorithms using R and/or Python, preferably in the planning domain. (Hiring for both junior and senior roles based on the relevant experience).Ability to analyze problems by synthesizing complex information, evaluating alternate methods and articulating the result with the relevant assumptions/reasonsKnowledge of statistical and machine learning algorithmsExperience of applying analytics in the field of planning, using advanced ML algorithms like demand planning, market intelligence, optimal assortments/pricing/inventory levels, etc.Experience in implementing planning applications will be a plusKnowledge of SQL, experience with ETL tools like Informatica/SSIS will be a plusHaving an educational background in Operations Research/Industrial Engineering/Business Analytics will be a plus. We give: A unique chance to join a unicorn in hypergrowthBe part of a winning team with an amazing AI Tech innovative platformExtended possibilities to travel and exposure to the biggest brands in the worldA flat organization with a very strong entrepreneurial culture (and no corporate politics)A great team to support you and that you can supportPossibility to really make a difference in a scale-up environmentLaptop, possibilities to be home based &/or in our regional office o9 is an equal opportunity employer and seeks applicants of diverse backgrounds and hires without regard to race, colour, gender, religion, national origin, citizenship, age, sexual orientation or any other characteristic protected by law",Intermedio,Jornada completa,"Consultoría, Cadena de abastecimiento, Análisis","Software, Artículos de consumo, Alimentación y bebidas",156,None,True,,589,ACTIVELY_HIRING_COMPANY
216,2211176616,2020-10-26,Trust In SODA Ltd,Data Engineer,"New York City, NY, US","Trust in Soda is partnered with a Global Leader in Research & Development. As a Data Engineer, you will be part of a cross-functional team that is responsible for continuously developing and deploying tools for the data & Machine Learning pipeline. The technology stack includes Spark, Go, Python, R and different database solutions (SQL and NoSQL) running in the cloud. They use a microservices and containerization (Docker, Kubernetes) approach to develop new solutions. You will develop, maintain, and improve the data pipeline within the scope of:  We expect a data engineer to bring a broad software engineering experience:  Back end development in any programming language of your choice.Design of web services.Algorithms and complexity analysis.Linux system administration, development, and production environments.Cloud, container and microservices infrastructures.Software security.Development work flow automationAbout You:  And a strong focus on data processing:  Databases, theory, and practice.Distributed data processing.Real-Time event processing.Concepts of functional programming.Data privacy and anonymization techniques.Enterprise data warehousing, Business Intelligence and ETL principles.Statistics and analytics.Machine learning.Preferred  Experience with developing Big Data ETL pipelinesExperience with Cloud Platforms, like GCP, AWS or AzureExperience with CI/CD toolsFoundation of Machine Learning and basic algorithms.",Intermedio,Jornada completa,Consultoría,Servicios financieros,79,None,False,,372,ACTIVELY_HIRING_COMPANY
217,2211858819,2020-10-16,Big Cloud,Data Engineer,Atlanta Metropolitan Area,"Are you an experienced data engineer? Are you available for an initial 6-month contract? One of the worlds biggest healthcare companies is seeking to recruit a Data Engineer for an initial 6-month contract. As a Data Engineer, you’ll be designing developing and maintaining scalable data models and pipelines, collaborating across all analytics teams to develop efficient end products and building data architecture. Other responsibilities: Implements processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processesWrites unit/integration tests, contributes to engineering wiki, and documents work.Works closely with other data scientists and engineers to develop a strategy for long term data platform architectureSupporting issue analysis and fix activities during test phases, as well as production issue resolution.Contribute to project planning and implementation to ensure that solutions are delivered on time and on requirementsCollaborate and actively contribute in discussions to help define technology and development approach within the team You’ll need: 2+ years data engineering experienceMinimum bachelors degreeStrong experience in PythonCloud experience – ideally Azure or Google CloudProficiency in data modelling, database technologies (both SQL and NoSQL)Data Architecture and data pipeline design experience",Intermedio,Contrato por obra,"Tecnología de la información, Ingeniería","Atención sanitaria y hospitalaria, Seguros",110,None,True,,275,ACTIVELY_HIRING_COMPANY
218,2279903570,2020-10-11,PayU,Data Engineer,"Poznań, PL","Location: Poznan or Warsaw, Poland  SUMMARY OF THE ROLE:  Be part of a new global Data Engineers team that will provide data as a service for both internal purpose and to our customers. You will be involved in architecture of new data systems and build scalable, robust, and high-quality data pipelines/imports/migrations of our Global data by cooperating with varied data producers and consumers, ranging from product, business analytics to data science and global data teams (Poland, Israel, Turkey, Romania, Colombia)  ABOUT THE TEAM:  Your projects will span geographies and cultures. We want passionate and open minded software engineers to work in a innovative and democratic environment where your voice will matter.  EXCITED YET? CONTINUE READING TO FIND OUT MORE ABOUT THE ROLE  What you'll be doing:  Architecture and suggesting new technologies and tools Perform code reviews and prioritize the requirements for the team, understanding the business needs. Hands-on, E2E responsibility for data pipelines from design to production. Including monitoring and ensuring our SLAs. Work closely with engineering teams, data scientists and product managers to support features development on top of the data. Evaluate and deploy new technologies to expand our data tech-stack and support our products requirements Support the current ETLs and design new strategies to improve these  What are we looking for?  Mandatory:  Proven experience of more than 5 years with Scala (Play, Akka, HTTP, S, Cats, Tapir, ZIO) and GitLab Hands-on experience with Big data tools and streaming technologies: Hadoop, Spark, Airflow, Kafka etc. Experience with AWS services such as EC2, EMR, RDS, Redshift or other Cloud technology Experience with distributed systems and micro services architecture  More than 3 years of experience with Relational SQL and NoSQL databases More than 3 years proven experience of acting as a senior data engineer working on architecture, business logic processes, data warehouse modelling and insight delivery BS or MS in Computer Science, Engineering or related technical discipline or equivalent experience  Very nice to have:  Proven experience with Kubernets Proven experience with Data lake solutions such as Snowflake  Proven experience with other programming language (Python, Java, NodeJS, Go…) Concept – CICD pipelines In a nutshell, passion for programming and not just for a programming language   What We Offer (Standard)  A diverse working environment within a multicultural setting An inclusive environment that ensures we listen to a diverse range of voices when making decisions. A positive, get-things-done workplace A dynamic, constantly evolving space (change is par for the course – important you are comfortable with this) Ability to learn cutting edge concepts and innovation in an agile start-up environment with a global scale A democratic work environment where you can drive your outcomes  ABOUT US:  At PayU, we are a global fintech investor whose vision is to build a world without financial borders where everyone can prosper. Being part of Prosus, one of the largest technology investors in the world, gives us the presence and expertise to make a real impact.  We developed our own payment processing products and services in order to give people in high growth markets the financial services and products they need to thrive.  Expertise in 18 high-growth markets enables us to extend the reach of financial services. This drives everything we do, from recruiting best engineering and product teams to investing in technology entrepreneurs, offering credit to underserved individuals and helping our merchants buy, sell and operate online. Find out more www.payu.com  Our Commitment to Building A Diverse and Inclusive Workforce  As a global and multi-cultural organization with varied ethnicities thriving across locations, we realize that our responsibility towards fulfilling the D&I commitment is huge. Therefore, we continuously strive to create a diverse, inclusive and safe environment, for all our people, communities and customers. Our leaders are committed to create an inclusive work culture which enables transparency, flexibility and unbiased attention to every PayUneer so they can succeed, irrespective of gender, color or personal faith. An environment where every person feels they belong, that they are listened to, and where they are empowered to speak up. At PayU we have zero tolerance towards any form of prejudice whether a specific race, ethnicity, or of persons with disabilities or the LGBTQ communities.",Sin experiencia,Jornada completa,Tecnología de la información,"Telecomunicaciones, Recursos humanos, Servicios financieros",None,None,False,,32,ACTIVELY_HIRING_COMPANY
219,1969995287,2020-08-21,Elitewide,Associate Consultant(Researcher),"Guangzhou, Guangdong, China",工作职责：· 根据Leader制定的目标人选搜索方案，通过各个渠道搜寻候选人，并专业地进行第一轮电话面试筛选；· 协助Leader对行业职能市场信息进行收集并及时反馈，保证工作效率及有效性；· 安排及协调候选人与客户公司的面试；· 紧密跟进候选人端，严谨地控制招聘进程。 任职要求：· 性格积极主动，对结果及任务导向的专业工作充满热情；· 全日制本科或以上学历（条件优秀者，可放宽至大专），1年以上客服/猎头/销售的工作经验；· 勤奋踏实，认真负责，具有团队精神，能在压力下完成任务；· 喜欢在互联网上搜寻及获取新资讯，有快速学习能力；· 良好的沟通技巧及英语能力。 机会特点：· 我们的核心团队都来自于跨国顶尖猎头公司，专业扎实，并且具有很强的团队精神；· 我们由Leader亲自带您，提供全方位专业的培训，同时需要您真正具备快速学习的决心及任务导向的责任感，因为我们的客户对我们有更严格的要求；· 我们会有定期的sharing，工作气氛积极向上。,Algo de responsabilidad,Jornada completa,"Consultoría, Recursos humanos, Ventas","Recursos humanos, Consultoría de estrategia y operaciones",66,None,True,,675,JOB_SEEKER_QUALIFIED
220,2201836070,2020-10-22,Henderson Scott,Data Engineer,"Austin, Texas, United States","Are you a Data Engineer with a passion for building robust Data Solutions? Do you like working with like-minded people to develop products that can really impact the quality of life of millions of people? Our partner in Austin TX is looking for an experienced Data Engineer to help build out new Data Pipelines for their growing business. They provide improved pricing solutions for essential drug products and therefore create a better customer experience. What we need from you: Computer Science or STEM degree or equivalent experience Previous experience working as a Data Engineer developing data pipelines for analyticsSolid knowledge and understanding of Big Data & Data Warehousing concepts, data structures, algorithms and design patternsData Flow automation solutions development Technical skills covering: RDBMSnoSQLServer Side technologies including Python, Kotlin, NodeJSCloud Development experience with Google Cloud Platform background an added bonusFull development life cycle experienceAgile Extreme Programming experience In return you will get: A competitive salary and career development optionsFlexible / remote working Flat hierarchy structure where you have a voice Interested? Send your resume for immediate consideration and a confidential chat!",Intermedio,Jornada completa,Tecnología de la información,Software,161,None,True,,481,JOB_SEEKER_QUALIFIED
221,2268216042,2020-11-02,Insights,Researcher,United Kingdom,"Insights is a learning and development company with our product at our heart.Our purpose is to create a world where people truly understand themselves and others, and are inspired to make a positive difference in everything that they do. The role of Researcher at Insights is to help the business know more about our users today, than we did yesterday, and to help the business know what questions we need to ask our users tomorrow. In doing so Research will provide insight to inform and de-risk decision making, by ensuring insight is habitual within delivery. Researchers plan, design and carry out research activities with users that help teams get a deep understanding of the people that use our services. Their research informs proposition, service, content and interaction design so that services work well for users and achieves our business outcomes. User-led Researchers at Insights focus on understanding user behaviours, needs, and motivations through observation techniques, task analysis, and other feedback methodologies. They work across discovery and delivery of the end-to-end journey of a service, supporting our Service Designers in problem space and our Interaction Designers in the emotional space, providing the evidence to help the business de-risk its decision making. Researchers are part of the Research & Design team, part of the Customer and Digital Function. Research and Design is a cross functional team supporting Learning & Experience, Future Experience & Partnerships, Marketing and Product Technology in delivering the right end to end experience for our customers and the business. Researchers at Insights are discipline-led in a specific aspect of research, whilst also have broad understanding and knowledge across design and research as a whole. Skills required You will need the following skills for this role, although the level of expertise for each will vary, depending on the role level.- Analysis and synthesis: You understand and can help teams apply a range of methods to analyse research data and synthesise findings. You know how to engage sceptical colleagues in analysis and synthesis. You can advise on choice and application of techniques, and can critique colleagues’ findings to assure best practice. - Communication skills: You can listen to the needs of technical and business stakeholders, and interpret them in a way that is clear for both audiences. You know how to manage stakeholder expectations. You can be flexible and you are capable of proactive and reactive communication. You know how to facilitate difficult discussions within the team or with diverse senior stakeholders.- Inclusive research. You can help teams understand the diversity of users of our services. You know how to include all kinds of users in appropriate research activities. You can advocate for inclusive practices and help teams design and deliver accessible services that work for all users.- Research skills: You have experience of, and can help teams adopt, a wide range of user research methods. You can plan user research for services with challenging user needs and complex user journeys. You can advise colleagues on the choice and application of research methods to assure best practice. - Role discipline: You know how to share your knowledge and experience of your discipline with others, including tools and techniques. You can define those most appropriate for the problem.- Stakeholder management: You can influence stakeholders and manage relationships effectively. You know how to build long-term strategic relationships and communicate clearly and regularly with stakeholders.- Strategic insight: You can define strategies, providing guidance to others on working in the strategic context. You know how to evaluate current strategies to ensure business requirements are being met and exceeded where possible. - User-centred and agile practices: You understand and have experience of a range of user-centred practices. You can help inexperienced teams adopt user-centred practices and embed them into their agile workflow. You can advocate for user research and engage sceptical colleagues and stakeholders. What you’ll do to succeed - Discover: You’ll help the business to identify, understand and prioritse problems to deliver maximum value to it and our customers.- Define: You’ll uncover their needs of our customers and that of the business, and design services that deliver against them.- Develop: You’ll collaborate with other researchers, designers and stakeholders to take services from concept to delivery, evidencing design thinking through appropriate methodologies.- Deliver: You’ll constantly evaluate the success of our services, seeking to understand how we iterate upon them.- Responsibility / Ownership: You focus predominately on the tactical problems this business is facing. You can contribute to moving items through the design process: from idea to value.- Authority / Autonomy: You contribute to the work, endeavoring to work autonomously, but are expected to lean on the experience of other team members to support with method or approach.- Impact / Reach: The output of your work is predominantly consumed across other disciplines within your team. What you’re great at﻿- You’ll have a proven and successful record of supporting the delivery of a service project, through evidencing decision making from the design stage all the way through to its launch and beyond.- You can work with a range of stakeholders to uncover and validate user needs and business requirements, utilising customer data to help all departments and teams better understand the needs of our customers.- You can translate concepts and requirements of stakeholders into research proposals, choosing the appropriate methodologies.- You have a wide knowledge of qualitative and quantitative research methods and tools, and know which to apply to any given problem space.- You can engage with our customers and practitioners to better understand their needs.- You have strong communication and presentation skills, and are to clearly articulate ideas and recommendations, both written and verbally.- You have experience in working in research-led design teams.As a User-led Researcher- You have and intense curiosity about people and their problems and a genuine curiosity and a real desire to understand users, clients, and stakeholders through interviewing, observations and surveying.- You can work with stakeholders to define and focus on business problems, and identify the required actionable insights.- You understand the different stages and methods of research as you move across the design life-cycle from discovery, definition, design and delivery.- You can transform research results into actionable guidance through analysis and interpretation of data, and how the findings fit into business strategy.- You can temper idealism with pragmatism, understanding you can’t exclusively represent the users, and also have to consider business needs and find solutions that satisfy both business and user goals.- You can separate your personal opinion from the research, ensuring you are without bias when collecting data and disseminating it to stakeholders.- You understand the diversity of users of our services, and know how to include all kinds of users in appropriate research activities to help teams deliver accessible services.- Foundation education at Masters level in Psychology, Sociology, Anthropology or Human Geography.- You can contribute to the work of the Research and Design community.- You can advocate and communicate what a team does to create trust and authenticity and can respond to challenge.- You know how to give and receive constructive feedback, facilitating the feedback loop.",Intermedio,Jornada completa,"Investigación, Análisis, Tecnología de la información",Formación profesional y capacitación,93,None,False,,866,ACTIVELY_HIRING_COMPANY
222,2220515493,2020-10-28,Holy Cow Studios,User Experience Researcher,"Gurugram, Haryana, India","Holy Cow Studios invites Researchers, who have curiosity about human behavior. You must have experience as User Experience Researcher. You would be responsible for designing, analyzing and presenting User Experience Research. [ https://holycowstudios.in ] What you gain from us?Travel and work experience in Europe. You would be travelling to Europe at client's site.A handsome salary package as per European standard. Health Insurance as well as other bonuses would also be included as per European standard.You would have flexible hours of working. You would also be attending team building events, guest lectures and international conferences etc.A life time chance to work with international projects and build your career. Responsibilities we seek from youAn attitude to take responsibility and work independently.Proficiency in English Language.Proficiency in survey design.Conduct discussions and moderate interviews.Ability to analyze data (Qualitative and Quantitative). Experience with Information technology tools for data analysis.Ability to convert research findings into actions and recommendations.Solid presentation skills and ability to tailor message for various stakeholders associated with research. QualificationsCompleted Bachelors in Engineering.Completed Master or Ph.D. in any field.Knowledge of various Information Technology Tools for data analysis.At least 3 years of work experience as User Experience Researcher.Trust, Integrity, Gratitude and Teamwork as personality traits. The job requires you to travel in Europe. You must have a valid travel document (Passport).Holy Cow Studios is a Digital Marketing Agency to help you grow. We support new ideas or existing brands in digital world by growing new customers or clients. We are your Digital Helpers.",Intermedio,Jornada completa,"Tecnología de la información, Investigación, Análisis",Servicios y tecnologías de la información,115,None,False,,679,JOB_SEEKER_QUALIFIED
223,2213000358,2020-10-26,Demyst,Platform Data Engineer,United States,"Our Solution Demyst unlocks innovation with the power of data. Our platform helps enterprises solve strategic use cases, including lending, risk, digital origination, and automation, by harnessing the power and agility of the external data universe. We are known for harnessing rich, relevant, integrated, linked data to deliver real value in production. We operate as a distributed team in the US and Asia and serve over 50 clients globally as a strategic external data partner. The Challenge As a Data Engineer at Demyst you will be working daily with new and innovative data sets from leading and emerging data providers around the world. You will play a key role in ensuring that the data we're providing to our clients is of the highest quality. Given that this data fuels our ability to solve our clients' problems, this role is a crucial element of what we do. This is a remote position working with Engineers across the globe (US, Austria, Singapore, Australia). You will report to the Director of the Data Service Team. RESPONSIBILITIES Performing data appends, extracts, and analysis to deliver curated data to clientsCollaborating with project management, automation, and sales teams to solve clients' business and technical problemsUnderstanding wide arrays of data provider landscapes including consumer, business, and property dataBuilding automation to download, clean, structure, import, and host dataOpportunities to work on entity detection, record linking, and NLP projects will also be availableOther tasks as necessary REQUIREMENTS: Computer Science or Data Science degree (or commensurate work experience): Master's degree preferred1-3 years of Python programming (with Pandas experience)Experience with CSV and other common formatsData cleaning and structuring (ETL experience)Experience with SQLExperience with GitInterest or experience in machine learning, data modeling and/or API integrations Benefits:Work with the largest consumer and business external data market in an emerging industry that is fueling AI globallyHave an impact in a scaling but small team offering real autonomy and responsibility for client outcomesStretch yourself to help define and support something entirely new that will impact billionsWork within a strong, tight-knit team of subject matter expertsSmall enough where you matter, big enough to have the support to deliver what you promiseDistributed working team and culture, recognition of outcomes and merit, not presenteeismGenerous benefits & competitive compensation DemystData is committed to creating a diverse, rewarding career environment and is proud to be an equal opportunity employer. We strongly encourage individuals from all walks of life to apply",Algo de responsabilidad,Jornada completa,Análisis,Servicios y tecnologías de la información,55,None,False,,223,ACTIVELY_HIRING_COMPANY
224,2266786122,2020-10-08,Graphika Inc.,Data Engineer,"New York City, NY, US","Company Overview  Graphika empowers the world to understand and navigate the Cybersocial Terrain. We create large-scale, in-depth maps of social media landscapes and conversations to discover how communities form online and how influence and information flow within large scale networks. Our interdisciplinary team uses our unique, patented set of technologies and tools to create and apply new, rigorous analytical methods to answer difficult questions about online conversations.  About The Role  Graphika seeks an experienced data engineer to join our technology team. The technology team at Graphika builds the tools that drive our cutting-edge analysis platform. We work with large scale graph algorithms and streaming data to tackle interesting questions in new ways. The Data engineer will contribute to building and scaling our various data pipelines, working closely with our data science and analysis teams. The data engineer will also collaborate with various other members of the team (including other backend engineers, frontend engineers and product team) to help plan and implement solutions to fix business problems.  This job is not an analyst or data science role. It is not intended as a stepping stone to either of those roles within the organization. It is not directly involved in the highly publicized reports Graphika generates. This job ensures the robust, clean data on which those reports and further scientific discovery can be based with integrity.  Areas of Responsibility  Help create and optimize large-scale batch and real-time data pipelines that ingest large quantities of structured and unstructured data from a variety of sources Actively own systems which support diverse applications across Product, Tech, and Labs teams Design and implement ETL processes through cloud-based solutions Share ownership in ensuring the quality of our data and data infrastructure Consistently test code and systems for robustness Strategize around new data storage solutions and support existing ones  Ideal Candidate Profile  You have demonstrated the ability to build, deploy and maintain large-scale, data-driven solutions. You love to take on complex data-related problems, and can direct your own work. You have the skills and desire to interrogate data sets to understand their various foibles, and respond accordingly. You have a working knowledge of CS fundamentals like algorithms, data structures, and time complexity. You can imagine and design architectural solutions at scale.  You think beyond the task at hand to deeply understand the 'why' behind what you are doing. You can maintain a focus on shipping software products, understanding that done is often preferable to perfect.  You are an enthusiastic teammate, who engages in collaboration and proactive discussion. You are an effective communicator who can explain technical concepts to product leaders, customer support, and other engineers. You work with confidence and without ego. You have deep knowledge and exercise a high degree of ownership in your daily work. You have loosely-held, defensible ideas, and advocate for what you believe is right. You can surface your unarticulated assumptions. You are also adept at identifying and evaluating trade-offs, willing to be proven wrong, and quick to support your fellow teammates.  Qualifications  Required:  Experience in writing production quality software in Python which is understandable, testable, and has an eye towards maintainability.  Familiarity with AWS services: S3, Lambda, Kinesis, SQS, etc, or similar cloud-based tools Knowledge of and ability to interact with DevOps tooling (Terraform, Ansible, Packer, Docker, etc.) Knowledge of tradeoffs between different distributed systems architectures Comfort with designing and scaling massive munging efforts on unstructured data Experience with the Python data science stack (numpy, pandas, matplotlib, sklearn, Jupyter, etc.) Ability to lead data architecture discussions Knowledge of SQL and common relational database systems such as PostgreSQL and MySQL Familiarity with schema design for a variety of domains Well-informed about data storage solutions Dedication to code quality, automation and operational excellence: unit/integration tests, scripts, workflows. Ability to work legally in the US without visa sponsorship  Nice to have:  Hands-on experience with Apache Spark Acquaintance with social media data sources and formats Experience with workflow management systems (such as Airflow or Luigi) Knowledge of NoSQL technologies like Redis  All Graphika Tech Team Members...  understand and appreciate good software engineering practices, including version control, code reviews, testing, and refactoring are comfortable debugging and optimizing code write tests to make sure code is reliable help shape technical decisions within the team collaborate within and across departments to ensure successful product creation have the ability to pick up new tools and technologies as needed  Education Requirements:  Bachelor's degree or equivalent work experience  Benefits  Unlimited PTO, with a company-mandated minimum of ten days of vacation time taken per year. 100% healthcare (health, vision, dental) premium coverage for employees: 50% premium coverage for families For NYers, access to 'Graphikafé,' our NYC small office setup with bookable hotdesks, meeting rooms, and phone booths Remote personal office setup stipend + 20% of home internet costs covered  An important note about joining Graphika during this extraordinary time:   Graphika is growing! Despite the downturn and accompanying reductions in other sectors and companies, Graphika is retaining current employees and is actively hiring for full time positions.  In the BeforeTimes, Graphika's Technology Team was fully co-located in our NYC office. On March 12, 2020, Graphika moved to a fully-distributed model, and we've been working together as a company to respond to the changing realities of the AfterTimes. As a result, we are happy to consider applicants who are located in the continental US, with the caveat that the Technology Team works on Eastern time and begins their day at around 10am. Daily Standup is at 10:30am EST.",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Internet",5,None,False,,81,ACTIVELY_HIRING_COMPANY
225,2227347396,2020-10-30,The Open University,Integration Data Analyst / Data Engineer,"Milton Keynes, England, United Kingdom","Integration Data Analyst / Data Engineer Unit: CIO PortfolioSalary: £41,526 - £49,553Location: Milton KeynesFixed Term Contract until 31st July 2022Closing date: Friday 20th November 2020 - midday Change your career, change lives The Open University is the UK’s largest university, a world leader in flexible part-time education combining a mission to widen access to higher education with research excellence, transforming lives through education. The Data and Student Analytics team (D&SA) are spearheading a transformation of the university’s data analytics capability. Our aim is to support our key stakeholders in the university by enabling evidence driven decision making through data and analytics. The role The Integration Data Analyst / Data Engineer role is a new, exciting, varied role that sits within the Data & Student Analytics team. As an Integration Data Analyst / Data Engineer, you will be responsible for building, maintaining and enhancing the enterprise data warehouse. You will combine a wide range of technical skills with business knowledge to deliver knowledge and value from key OU data.  You will collaborate with other teams across the OU to understand their mid to long-term business objectives and help them to deliver by conducting analyses to support strategic activities across the business as well as designing and developing appropriate internal business solutions. Skills and experience Do you possess an Undergraduate degree, or equivalent experience, with strong engineering, mathematics or computing elements?Do you have experience of developing and maintaining MI systems to support decision making and management information needs?Do you possess substantial experience of building an Enterprise Data Warehouse with MS Azure?Are you a confident communicator at all levels and do you have experience in managing projects?Are you able to work under pressure to manage competing demands for time and to meet demanding deadlines? If the answer to these questions is yes – we want to hear from you! The full summary of duties and person specification can be found via the 'Apply' link above.  What you get in return We offer a great range of benefits that support our employees and their families for the long term. Benefits include 33 days holiday per annum plus Bank Holidays and Christmas closure days and an attractive pension proposition. Closing date: Friday 20th November 2020 - middayInterview date: TBC  If you are interested in finding out more and would like the opportunity to apply, then please click the 'Apply' link above which will direct you to our Careers website. We value diversity and we recognise that different people bring different perspectives, ideas, knowledge and culture, and that this difference brings great strength. Applications from candidates with protected characteristics are welcomed. Where you start in life doesn’t dictate where you go.",No corresponde,Contrato por obra,"Tecnología de la información, Investigación",Enseñanza superior,22,None,False,,333,COMPANY_RECRUIT
226,1705852140,2020-11-04,ConsultNet,AWS Python/Data Engineer,"Edison, New Jersey, United States","TITLE: AWS Python/Data EngineerLOCATION: Edison, NJ (REMOTE)DURATION: 6 months project with a possible extension 3RD PARTY VENDORS/CANDIDATES AND RECENT GRADS DO NOT APPLY!  UPON APPLYING, PLEASE ATTACH YOUR UPDATED RESUME  ONLY QUALIFIED LOCAL CANDIDATES WITH AWS, PYTHON, DATA LAKE AND DATA PIPELINES EXPERIENCE NEED APPLY!  JOB DESCRIPTION: Strong understanding of creating Data Lakes on AWSSignificant experience creating Data Pipelines on AWSExperience using Lake Formation or other third party tools for expediting creations of data pipelinesPython, Spark, PySparkHive SQL (HiveQL), SQL ServerAWS S3 (Store/Retrieve in S3 buckets), CLI, LambdaAWS Data Lakes related skills Athena, Redshift, Glue, QuickSightApache Ranger C# is a plusFamiliarity with Linux Shell Scripting",Intermedio,Contrato por obra,Tecnología de la información,Banca,2002,None,True,,7074,ACTIVELY_HIRING_COMPANY
227,2219330999,2020-10-27,Womply,Senior Machine Learning Engineer,"Lehi, Utah, United States","This position is Remote or can sit in Lehi, UT. Our mission is to help local businesses thrive in a digital world. Founded in 2011, Womply is a local commerce platform that provides apps, APIs, marketing, and financial tools to make local commerce happen for over 500,000 American businesses and their customers. All of Womply’s products and services are powered by the Womply Commerce Graph, a proprietary data asset that offers the most complete view of local commerce.  YOUR RESPONSIBILITIES:Build end-to-end ML systems of designing, training, testing and deploying Machine Learning modelsWrite production-level codes to train your ML models into working pipelines and services to serve production online trafficHave the ability to apply machine learning to solve complex business problems and optimize critical business metrics, and work closely with Product Managers and Data analysts to frame Machine Learning problems within the business contextAnalyze experimental and observational data, communicate findings, and facilitate launch decisionsParticipate in code reviews to ensure code quality and distribute knowledge OUR REQUIREMENTS:A Bachelor's/Master's degree (or higher) in a technical field (Computer Science, Statistics, Economics, Operations Research, Math, Physics, Engineering, etc.) or equivalent work experience required.Minimum of 3+ years of professional experience in Data Science or Applied Machine Learning requiredSolid engineering and coding skills with the ability to write high-performance production quality codeGood understanding of common families of machine learning models, feature engineering, feature selection and other practical machine learning issues, such as overfittingStrong communication skills. Explaining complex technical concepts to product managers, data analysts, and other engineers shouldn't be a problem for you. OUR PREFERRED QUALIFICATIONSIndustry experience building and productionizing innovative end-to-end Machine Learning systemsExperience in Python, Scala, Java, C++, Go and other equivalent languagesExperience with computing frameworks like Spark, Hadoop, Hive, and AirflowExperience with ML frameworks like Scikit-Learn, Spark MLlib, XGBoost, Tensorflow, and PyTorch ﻿Make an impact at Womply!We’re a fanatically values-based company with $50 million raised to accelerate our growth. Womply is a remote-first company with one physical office in Lehi, Utah. We’re always looking for top talent in product, engineering, DevOps, design, data science, sales, marketing, business development, account management, and more. If you want to make a big impact, let’s talk. Learn more at www.womply.com/careers.   PLEASE NOTE - Direct applicants ONLY. Any recruiter/3rd party submissions we receive will be considered a gift.",Intermedio,Jornada completa,"Tecnología de la información, Ingeniería","Internet, Software",110,None,True,,274,ACTIVELY_HIRING_COMPANY
228,2219903477,2020-10-20,SDG Group Iberia,Senior Data Scientist,España,"Want some DataFun? SDG Group es una firma de consultoría global con un alto grado de especialización, ayudamos a nuestros clientes a rellenar el espacio que existe entre las acciones de negocio y los datos relevantes para la toma de decisión. Nos comprometemos en mejorar el rendimiento de nuestros clientes aplicando las mejores prácticas y los métodos y arquitecturas tecnológicas más innovadoras. Queremos atraer al mejor talento del país, y por ese motivo el trabajo se realizará en remoto y no importará en qué lugar te encuentres.  ¡Atrévete a conocernos y únete a nuestro equipo!   Qué harás:  Liderazgo en el desarrollo de proyectos de Advanced AnalyticsSoporte al desarrollo de personas en la práctica de Advanced AnalyticsSoporte al desarrollo del portfolio y de la propuesta de servicios de Advanced AnalyticsSoporte a la generación de negocio en el ámbito de Advanced Analytics y en todo el espectro de disciplinas asociadas: Data Mining, Machine Learning, Predictive Modelling, Cognitive Computing, AI, NLP, etc.  Qué necesitas:  Formación superior: Ingeniería, Matemáticas, Informática, Estadística, Telecomunicaciones, Física o similarExperiencia mínima de 3 años diseñando modelos analíticos: Decision Trees, Scoring, Clustering, pattern discovery, trends, regressions, RN, Deep learning.Experiencia en Advanced Analytics sobre ecosistemas Big Data: Hadoop, Spark, y entornos como R, Mahout, Impala, Python, H2O, TensorFlow, Knime, RapidMiner, etc.Valorable el conocimiento y aplicación de Data Science en diversos sectores e industrias: banca, seguros, telco, retail, etc.Pasión por los datos y la analítica: desde las Data Architectures hasta la Visualización pasando por BI, Data Mining, Machine Learning o Predictive ModelingAnalytics Storytelling, con alta capacidad para comunicar y presentar eficazmente a Negocio, a IT, Analistas y Data ScientistsEspíritu innovador con orientación equilibrada a cliente, negocio y tecnologíaInterés por los retos, compromiso, integridad, madurez, capacidad de trabajo en equipo y alto sentido de la responsabilidadInglés nivel alto  Qué ofrecemos: Formar parte de un equipo de primer nivel en el área de Data & AnalyticsLa oportunidad de integrarte en una empresa joven, dinámica, en plena expansión, con muy buen ambiente de trabajo, en la que se potencia el trabajo en equipo, la colaboración, el asumir nuevos retos y responsabilidades y se ofrecen múltiples oportunidades para crecer y desarrollarse personal y profesionalmenteUn plan de carrera profesional personalizado, trabajando en grandes proyectos, clientes y corporaciones a nivel local e internacionalUna retribución a la altura de la aportación profesional, negociable en función de la experiencia y los valores aportados  ﻿Garantizamos absoluta confidencialidad en todo el proceso de selección",Intermedio,Jornada completa,"Consultoría, Tecnología de la información",Consultoría de estrategia y operaciones,66,None,False,,556,ACTIVELY_HIRING_COMPANY
229,1974044205,2020-11-08,CareSet,Mid-level Data Engineer with Python/PHP Experience,United States,"Mid-level Data Engineer with Python/PHP Experience Mission: Smooth our data pipeline by extending and improving automation. You have experience writing, testing and reviewing SQL statements and otherwise managing multi-stage SQL data pipelines. MariaDB and MySQL feel very comfortable for you. You know how to write PHP/Python code to execute SQL commands and how to work with the Linux command prompt generally. You find the notion of being on a team that builds and maintains healthcare data ETL for the long haul exciting.  This role would be a fit for a senior PHP/Python engineer who is interested in repurposing a developer career into data engineering and/or data science. Or someone who already is a mid-level data engineer/data scientist with MySQL experience.  Outcomes:Understand the underlying data structures in our data pipeline, including our data sources and how they are managed in our data warehouse within 1 monthContribute to the maintenance of our ETL pipeline system within 1 monthWrite reports to assist data analysis within 2 monthsCollaborate with other employees in SQL report-writing within 3 monthsWrite new SQL-based data ingestion pipelines to expand the contents of our data warehouse, where the SQL is encased in lightweight PHP/Python scripts that exist only for this purpose within 3 monthsCreate and maintain multiple-stage raw-SQL ETL transformation pipelines, including complicated data fixing and repair process, within 3 months.Develop and use custom command-line-based data munging tools within 6 monthsIf you know PHP, become familiar with Python. If you know Python become familiar with PHP. Within 6 months. Competencies:At least 2 years experience using SQLAt least 1 year experience using SQL for ETL At least 2 years experience working with MySQL or PostgreSQLBachelors in IT/Comp Sci or equivalent experienceUnderstand how to use SQL to do ETL tasks. Understand which ETL tasks are better performed outside of SQL.Understand advanced index techniques in MariaDB as they apply to various DB engines (InnoDB vs MyISAM etc).Communicate technical subjects clearly in writing.Operate in a fully pun-compliant environment.Document code so that others can easily understand it.CLI Scripting experience in either PHP or Python.SQL generally, MariaDB specifically. You will be tested on the differences between types of JOINS, a basic understanding of the different permutations of the “CREATE TABLE” syntax, etc.Capable of breaking complex data transformations into several distinct SQL statements that run one after another.  Bonus Competencies:Python for data analysis (Pandas, Jupyter, etc)X12/HL7, claims data and/or other clinical data standardsSAS (the statistical programming language) R, Stata or SPSS and/or statistical methods Reporting engines Web-development Agile software development principles Unit testing and/or other test-drive development methods  Location: Houston, TXPosition Type: Full-time permanent  About CareSet SystemsCareSet (https://careset.com) is transforming the way biomedical companies go to market. We believe in getting the best treatments to the right patients quickly and efficiently. We do that by analyzing government data sources, such as Medicare claims data. With CareSet, biomedical companies become better at serving the patient community.",Intermedio,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Atención sanitaria y hospitalaria",79,None,True,,401,ACTIVELY_HIRING_COMPANY
230,2204967932,2020-10-23,Full Circle Recruitment Ltd,"Data Analyst, £35-45,000, London + remote working",United Kingdom,"Data Analyst, £35-45,000, London + remote working London office (20%-40% of time) – remote working (60-80% of time) This highly successful fintech provides loans for UK SMEs and now needs a Data Analyst to join their growing analytics function. ResponsibilitiesYour role will focus on descriptive analytics – devising robust commercial answers to a range of queries that come to the analytics team from directors, investors and clients. You will be involved in exploring the questions posed, understanding their business context, and conducting appropriate analysis to produce answers. The right candidate will look to develop the analysis further – to devise ways to enhance results by, for example, introducing new ideas/analysis to help address questions in a more valuable way. You will be answering queries relating to their customer base, their market, and relevant trends or developments in the world of corporate credit and analytics.  Part of your work will involve creating and running SQL queries and using other data tools as required, eg Python. Initially, the role will be more commercial than data focused. You will be applying your analytical skills in a very commercially-oriented way, and the opportunity is there to build your technical analytics capabilities as you develop. Requirements  2-3 years’ experience in a business-oriented analysis functionKnowledge of or interest in the world of fintech, and particularly corporate credit/lending or, more broadly, business bankingExperience of interpreting/manipulating data to produce answers/insightsCuriosityExcellent communication skills What’s in it for you? Working for a leading fintech and being part of a high-growth firm that is making a valuable and meaningful impact on its marketCareer growth – as well as being very commercially-focused, the role will enable you to develop your analytics skills further. You could go on to focus your career as a Business Analyst, Data Scientist, or Consultant.Working with some of the leading authorities in the worlds of analytics and commercial lending.",Intermedio,Jornada completa,"Análisis, Finanzas","Banca, Servicios financieros",386,None,True,,1036,ACTIVELY_HIRING_COMPANY
231,2222455054,2020-10-29,Attentive,Senior Data Engineer,New York City Metropolitan Area,"Attentive is a personalized text messaging platform changing the way consumers interact with businesses and organizations. The company is one of the fastest growing startups in New York City and recently raised a $230 million investment led by Coatue in September 2020, just 5 months after its Series C round due to strong customer traction. Other investors in Attentive include Bain Capital Ventures, Sequoia, IVP.   We work with 2,000+ of the most innovative brands like Sephora, Coach, Urban Outfitters, CB2, PacSun, Lulus, and Jack in the Box. Attentive was founded in 2016 by the co-founders of TapCommerce, a mobile marketing platform that was acquired by Twitter in 2014. Role Background:We’re looking for a Senior Data Engineer to be the technical leader of our growing Analytics team. You’ll be responsible for all things data: building out our streaming ETL, cleaning and anonymizing data that’s being generated from various sources, designing the data warehouse schema, and so on. We’ll expect you to have an in-depth knowledge of distributed systems and data flows. Combined with an understanding of business intelligence and performance requirements, you’ll breathe life into Attentive data and help make it an invaluable part of the platform and business.   If you are a self-starter, excited about building a culture around data-driven decisions, motivated by making an impact, and pushing the boundaries of your knowledge, you will excel here and do great things! You at Attentive:Design, implement, and maintain an ever-growing ETL pipeline using state-of-the-art technologyLead the burgeoning data engineering team Establish best practices and standards for managing large collections of dataDiscover and integrate with new data sourcesWork closely with data analysts and data scientists, enabling them to provide insight into key performance metrics of the businessIdentify ways to improve data reliability, efficiency, and quality Your Qualifications:5+ years of experience designing and developing a data warehouse, Snowflake preferredExperience designing, developing, and maintaining a high-throughput and low-latency ETL pipelineYou are knowledgeable about data modeling, data access, and data storage techniquesExperience with big data tools such as Kinesis, Kafka, Spark, or Amazon EMRStrong data-modeling skills. Good understanding and experience in building star schema and denormalized data structures.Experience with SQL (MySQL or Postgres preferred), ETL, PythonSuccessfully implemented data applications and pipelines in the public cloud, especially Amazon Web Services Benefits & PerksRobust health benefits packages including access to a 401k and various medical, dental and vision plans, and $100/month fitness reimbursementFull support for remote work during COVID-19Daily lunch delivery credit and other goodies sent to homeRegular company-wide social events (even virtually!)Generous annual education stipend toward job-related external learning opportunitiesAn extremely enthusiastic team that appreciates collaboration  Attentive is an Equal Opportunity Employer. We’re committed to diversity and maintaining a work environment that is free from harassment and discrimination. We’re committed to them because our core values demand it - values like Integrity First, Listening & Cultivating Discussion, and Default to Action. We believe in embracing “self” and that our true strength lies in the diversity of our employees. For this reason, applicants from all backgrounds are encouraged to apply, and will not be discriminated against on the basis of any protected status under federal, state, or local law.",Intermedio,Jornada completa,Ingeniería,Marketing y publicidad,38,None,True,,179,ACTIVELY_HIRING_COMPANY
232,2166922999,2020-11-02,Parexel,"Data Scientist, Scientific Data Steward, Americas (Home-Based, US)",United States,"Parexel was recognized with the first-ever Scrip Award for Best Use of Real-World Evidence, and the Team is growing! If you’re looking for an opportunity to use your medical informatics expertise and leverage RWE to help move healthcare forward, please consider applying to the Data Scientist/Scientific Data Steward role for the Americas. The Data Scientist/Scientific Data Steward ensures that the scientific or real-world data used in a given solution is fit-for-purpose and is used in a manner compliant with the data use agreement and applicable law. Consultation is provided to users of the data in order to ensure that use is optimized.  The Data Scientist/Scientific Data Steward will also be responsible for accountability supporting activities which will include the following:Scientific and Real-World Data Asset AccessRecognize gaps in Parexel's data access and pursues solutionsWorks on complex issues related to data application and analyses requirements to remedy themServes as a consultant to others on the use of the data in clinical researchIdentify, assess, and recommend options to expand access to RWD and scientific dataContribute to decision-making on whether to strategically partner with select data providersDevelop working knowledge of data sets assigned to stewardKeep specifications up-to-date in the data catalog (e.g., new functionality)Promote updates to common patient counts (non-project)Match data asset/partner w/ specific project needs (coordinate with SD Solutions Architect) He/she will also be responsible for vendor / provider management which will include the following:Serves as relationship manager / primary point of contact for data providerEstablishes governance structure for relationship (e.g. Including regular meeting on status, performance, capability, emerging requirements)Identify ways in which the partnership can be strengthened (e.g., improve direct access, feasibility turnaround)Ensure data partner's needs/expectations are being metWork with Procurement/LRM to establish/manage MSAsFollow up on how projects are going and what can be improved in terms of the PXL-partner relationship Additionally, he/she will also be responsible for infrastructure & platform design which will include the following:Evaluates data requirements to optimize services, and grow the PAREXEL RWD based market shareDevelop descriptive content that can be used in capability presentations, proposals, protocols/SAPs, study reports, etc.Surfaces observations and trends that can inform further growth The Data Scientist/Scientific Data Steward will also be responsible for relationship management which will include the following: Develop and maintain working relationships with business units, clients and SDO functional units, vendors, providers: at minimum, Global Data Operations, Corporate IT, Technical Quality Management, Legal and Risk Management, Procurement, Data Privacy, Project team personnel, Leaders of internal businesses SDO is supportingChampions the development of and delivery against the mutual business objectives of the data organization and its business partners Lastly, he/she will also ensure compliance with operating standards, policies, regulations, SOPs, privacy and data security standards: facilitate project-specific contracting needs: represent PAREXEL in professional societies: and present on behalf of Parexel at key events and meetings. Qualifications To ensure success at Parexel as a Data Scientist/Scientific Data Steward, individuals must possess the following: Skills: Excellent oral and written communication skillsExcellent customer focus (internal and external)Excellent interpersonal skillsAbility to manage multiple projectsAbility to work with a decentralized teamAnalytical and problem-solving skillsAbility to align day to day activities with SDO strategy Knowledge and Experience: In depth understanding of the clinical research process and business, medicines and medical device development, healthcare market and related sectorsBroad cross-functional experience in the healthcare, scientific and real-world data environmentDemonstrated ability to apply scientific or real-world data solutions to address clinical or commercial questions and needsExperienced in budgets and cost evaluation of RWD based solutionsExcellent understanding of project management principles8 or more years of experience Education:Bachelor’s degree in biomedical informatics, public health, data science, life sciences or related field requiredAdvanced degree in biomedical informatics, public health, data science, life sciences or related field preferred EEO DisclaimerParexel is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to legally protected status, which in the US includes race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status.",Director,Jornada completa,"Investigación, Consultoría","Industria farmacéutica, Biotecnología, Atención sanitaria y hospitalaria",58,None,False,,526,ACTIVELY_HIRING_COMPANY
233,2239753034,2020-11-03,Summit Human Capital,100% Remote Lead Data Engineer,United States,"Summit Human Capital is seeking a highly motivated Lead Data Engineer to support our client in the utilities, and renewable resource industry. This engagement supporting cutting edge initiatives regarding Renewable Energy Data to address global issues that will positively impact the fabric of our environment for many years to come! The ideal candidate will meet the following criteria:   Requirements: Extensive hands-on experience utilizing PythonApache Spark experience regarding big data workloads, and large-scale data processingExperience with AWS and their cloud services such as, Glue, Kinesis, Lambda, S3, Redshift, DynamoDBGreat written and verbal communication skills  Desired: Experience regarding projects/applications that deal with Renewables Data, or Energy DataManagement/Leadership experience  Responsibilities: Lead a team of developers through code reviews, design reviews, and mentorshipImplement new development, as well as prototyping, bootstrapping, build and design workPerform impact analysis to determine all the portions of the application which will need updating to implement the proposed changesDevelop and unit test code in accordance with the defined technical designsCreate unit test plans which detail test conditions and expected resultsDesigning and developing high volume, low latency applications for mission critical systems and delivering high availability and performance",Intermedio,Jornada completa,Tecnología de la información,Servicios y tecnologías de la información,34,None,True,,150,ACTIVELY_HIRING_COMPANY
234,1988193285,2020-10-29,Herman Miller,Data Engineer,United States,"You can make a salary. Or you can make a difference. Or you can work as a Data Engineer at Herman Miller and make both. About this OpportunityAs a Data Engineer, you'll move and integrate data across multiple disparate systems. You will clean, normalize, and aggregate Herman Miller corporate reporting and analytics. You'll also provide support to functional areas by acting as expert in tools and methods for accessing, analyzing, and reporting corporate data. What You'll DoYou'll have opportunities to speak up, solve problems, lead others, and be an owner every day as you...Assist end users in reporting and analysis tools.Collaborate with Analytics and Business Teams to improve data models that feed business intelligence tools, increase data accessibility, and foster data-driven decision making across the organization.Define company data assets (data models).Design data integrations and data quality framework.Develop and maintain scalable data pipelines and build out new API integrations to support continuing increases in data volume and complexity.Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for the key stakeholders and business processes that depend on it.Perform data analysis to troubleshoot data-related issues and assist in the resolution of data issues.Work closely with a team of Application Developers, Architects, and Analysts.Work closely with all Business Units and Software teams to develop strategy for long-term data platform architecture.Write unit/integration tests and document work.Perform additional responsibilities as requested to achieve business objectives. Sound Like You?You might be just who we’re looking for if you have...A Bachelor's degree in Computer Science or a related technical field.Fully proficient data engineering abilities, typically gained through five years of working with Python/Java, SQL, working schema design, and dimensional data modeling.At least five years of experience, or and equivalent combination of education and experience.Experience designing, building, and maintaining data processing systems.Experience working with cloud services and cloud data warehouses.Experience with retail and online retail data.Experience with Snowflake, Matillion, Tableau, Business Objectives, and Net Suite (desirable).The ability to manage and communicate data warehouse plans to internal clients.Expert knowledge of best practices and IT operations in an always-up, always-available service.Experience with or knowledge of Agile Software Development methodologies.Advanced problem-solving and troubleshooting skills with the ability to identify and solve complex business needs.The ability to be process-oriented with great documentation skills.Excellent oral and written communication skills with a keen sense of customer service.The ability to perform all essential job functions of the position with or without accommodations.  Herman Miller is committed to diversity and inclusion. We are an equal opportunity employer including veterans and people with disabilities.",Intermedio,Jornada completa,Tecnología de la información,Mobiliario,281,None,False,,1589,ACTIVELY_HIRING_COMPANY
235,2234517395,2020-11-03,VEDA Data Solutions,Data Engineer,United States,"VEDA helps patients get the care they need by untangling technical healthcare complexities with fresh scientific approaches and generous collaboration. Our technology reflects what our people provide: quality without ego, honesty backed by science, and warmth in an industry not known for having much heat. Ready to build the future with us? VEDA is looking for sharp-minded do-gooders who share our values: Inclusive Collaborative Just Gritty  About the Position We iterate quickly in a multi-account cloud architecture, with numerous data sources and models – that’s where you come in.You’ll work closely with our engineers, data scientists and security team to manage and maintain ETL processes including data ingestion, modeling, implementation and deployment.You will help move our software development practices forward and can help mentor others on design and best practices.You will be an active participant in product and platform architecture, keeping security and cost in mind.You will be responsible for ensuring quality data and tooling for the Data Science team to leverage for machine learning breakthroughs.  About You Demonstrated hands on software development projects in Python are required. You have direct experience in software build, deployment, version control, configuration and testing of applications using modern best practices.You have experience working with AWS cloud architecture such as EC2, RDS, S3, ECS, Lambda, DynamoDB, and machine learning operations in general.You’re opinionated about tooling and curious about new trends and technologies in the software development world.You like to work collaboratively with developers, data scientists and UX teams to improve the quality and resiliency of the products you’re releasing.You have a background in data collection and management, with a focus on automation and stability.You have working knowledge of data processing, parallelization and performance improvements including Pandas, SciPy and NumPy, or other toolkits.You have years of Python development experience, and are proficient with SQLYou have excellent verbal and written communication skills with a focus on good technical writing. Skills You Might Have Experience working in highly regulated industries like finance, health care or defense.Understanding of networking and network design principlesExperience working with Linux, RedHat and/or CentOS operating systemsKnowledge of virtualization and/or containerization strategies and technologies (Docker, VMWare, Kubernetes, etc.)A working knowledge of JavaScript/TypeScript. Additional languages are a bonus.Experience working in an Agile team  Benefits offered by VEDA: VEDA is made up of talented professionals that are driven to do meaningful work to change healthcare from the inside out. We are also friends, parents, partners and caregivers. VEDA’s benefits reflect our values—we offer fully paid, low or no-deductible medical, dental and vision insurance for our employees and their families. We ensure that employees can take time off to recharge and have flexibility to care for themselves and their families.Our COVID Commitment: VEDA is committed to prioritizing the health, safety and emotional well being of our employees and their families. That means allowing our employees to choose to work remotely until there is a widely available vaccine. All employees are required to be located within the USA. We look forward to learning more about you -- apply to join the VEDA team today!",No corresponde,Jornada completa,"Tecnología de la información, Ingeniería","Servicios y tecnologías de la información, Atención sanitaria y hospitalaria, Software",16,None,False,,146,None
236,2215516852,2020-10-27,Logikk,Senior Data Scientist,"London, England Metropolitan Area","Senior Data ScientistLondon£80,000 DOE Are you passionate about creating unique intelligence from data? Are you a Data Scientist who enjoys cutting-edge R&D and who wants to contribute to game-changing global products for one of the most exciting AI start-ups in Europe? As a Senior Data Scientist, you will be tasked with building unique AI and ML technology into products that are easy to deploy, manage and use for the end customer.The company itself is partnered with some of the biggest players within the E-commerce space however has long term plans to utilise their technology across multiple sectors. As a Senior Data Scientist, you will need to create the very best Machine Learning models in order to take this very unique platform to the next level. This is a hands-dirty type role where you will be owning the data pipeline along with the predictive models, therefore you will need to have a solid understanding of the engineering piece also. This position will mature and develop into a leadership role where you will be able to sculpt your own Data unit. Required Skills A PhD or MSc in a related discipline such as Statistics, Machine Learning, Computer Science, NLP or similar.3-4 years within an industry environment.Experience with the deployment of ML models in the cloud.Ideally will have experience with consumer product data and recommendation systems.Will have worked on a diverse range of datasets including images & text utilising techniques such as detection, extraction & classification.  Experience with cloud platforms, ideally GCP or AWSExpert level programming within Python, C++ or Java/Scala.Experience with Deep Learning / Machine learning libraries such as TensorFlow, Torch, Theano, Caffe, scikit-learn etc.  For more information contact John at Logikk on john@logikk.com",Intermedio,Jornada completa,"Tecnología de la información, Ingeniería, Investigación","Software, Servicios y tecnologías de la información, Investigación",111,None,True,john@logikk.com,342,JOB_SEEKER_QUALIFIED
237,2268197649,2020-11-02,VANRATH,Data Engineer (Contract),"Belfast, Northern Ireland, United Kingdom","THE CLIENTMy client is one of the most impressive global fintech houses and are in need of a Data Engineer (Contract) to come on-board, in a fully remote capacity and work on one of their largest market data teams. The successful Data Engineer will help to populate my client’s data lake and also manage the consumption of data. The appointed Data Engineer will be responsible for leading the technical delivery of systems that must achieve a unique blend of low latency performance, big data scalability, and rock-solid reliability and integrity, all while undergoing rapid release cycles. The Data Engineer (Contract) must be able to solve problems creatively, communicate effectively, and possess the ability to lead others to achieve the critical mission of the team. RESPONSIBILITIESHands-on with detailed design and architecture plans for complex, large scale efforts within a multi-cloud environment.Assists with system design, working with the various teams to build fit for purpose platforms.Works ahead – ensuring the architecture is responsive to evolving needs.A team player – Assists the teams as required to achieve delivery milestonesUtilises the expertise of the team to develop architecture through consensus and team approach.Works with the enterprise architecture team, to gain an understanding of the evolving enterprise, to make efficient decisions on the application architecture, and priorities.Applies expert knowledge of cloud technologies, java language, DBMS, and middle-ware technologies in independently designing and developing key services.Participates in code reviews, proactively identifying and mitigating potential issues and defects.Defines key metrics driving code optimisation and refactoring.Understand the data and how it works to help develop functional solutionsTakes part in preliminary story review, providing constructive feedback and input on both work effort estimation as well as architecture/design improvements.Works with analysts to interpret high-level requirements for complex, large scale initiatives and decomposing them into independent stories and sub-tasks for the team. THE IDEAL PERSONBachelor’s degree (with honours) or equivalent/better strongly preferred, but substantial relevant experience could substituteExperience in python, Java, Linux, AWSExperience architecting enterprise software applicationsExperience in developing and automating solutions directly related to Continuous Integration/ Continuous Delivery and infrastructure automation ﻿REMUNERATION£350-£450 a dayFULLY REMOTE6m+ contractFirst time contractors welcome  Please see below for some of my recent testimonials available on Google: “Orla is one of the best contract recruiters I have worked with: she is professional, considerate, and trustworthy and I would highly recommend her to any contractor. “ “Since I started my career in software engineering VANRATH has continuously provided me with great opportunities within the industry…They are extremely reliable when it comes to payments (for contractors) and act as a safety buffer around client invoicing. Orla Fitzsimons has been my go-to contact for all new opportunities and queries around current client engagements. She has been extremely professional and helpful, and I would highly recommend contacting her if you’re interested in the contracting market.” For further information on this vacancy or any other Contract IT job in Belfast or wider Northern Ireland, please apply via the link below or contact Orla Fitzsimons in the strictest confidence. Follow VANRATH on LinkedIn for:Expert Career Advice. The Latest Top Jobs. Industry News. And much more…",Intermedio,Jornada completa,Tecnología de la información,Servicios y tecnologías de la información,28,None,True,,122,ACTIVELY_HIRING_COMPANY
238,2212252043,2020-10-16,Curative Inc.,Data Scientist,United States,"At Curative we’re on a mission. We’re working to provide communities across the US with 24-hour COVID-19 testing at scale with a simple-to-use, painless and accurate self-collected COVID-19 PCR test with a fast turnaround of test results. Founded in March 2020, we have grown rapidly and are now positioned at the forefront of the fight against the pandemic. We are committed to data driven and informed decision making and we now seek a Data Scientist to join our Data Science team to work with marketing, product and engineering teams to analyze our marketing campaigns and our patient experience. Responsibilities:Interpreting data and analyzing results using statistical techniquesDeveloping and implementing data analyses, data collection systems and other strategies that optimize statistical efficiency and qualityAcquiring data from primary or secondary data sources and maintaining databasesGeospatial analysis to optimize marketing resources and testing site location You should be:Confident with R, python or similar scripting languages and comfortable with SQLExperienced with UX statistical, user funnel optimization, ad campaign designDriven and thrive in a fast moving, start-up environment. Previous experience working in a high growth start-up is a big plus.A natural problem solver with a can-do attitude and ability to work confidently and collaboratively with a remote team",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Biotecnología,400,None,True,,1003,ACTIVELY_HIRING_COMPANY
239,2278645586,2020-10-11,QueryClick,Data Engineer - (Python / Cloud) UK Remote,"Edinburgh, GB","Description  Who are QC?  QC combines performance marketing services with our unique data rebuilding software, to help clients to remove wasted spend and grow at the lowest possible CPA.  Founded in 2008, we’re an independent digital marketing agency and SaaS provider focused on data-driven insights and pioneering in-house technology. We are a 'Remote First' company with offices in London and Edinburgh. We deliver multi-channel insights and strategic consultancy so blue-chip businesses can maximise growth, working with well-known brands such as BT, EE, Quiz and Aggreko, treating our clients as partners and putting their business objectives at the heart of what we do.  The QueryClick vision: reinventing the future of marketing by delivering results that no one else can. We use our flywheel to make that happen, bringing our vision, passionate people, and client-centred approach together in one continuous cycle. This builds momentum for sustainable growth while also inspiring innovation among our team and clients. And at QueryClick, “culture” is more than a buzzword. We’re committed to making our agency a great place to work by hiring talented people and investing in their growth and wellbeing  What are we looking for?  We are building a brand new software product. Powered by machine learning and capable of handling massive amounts of marketing behaviour data, the Corvidae product allows its users to understand the value of their marketing activity and use this information to automatically optimise that activity. We need skilled, passionate technical team members to be part of building Corvidae from initial working version into a fully fledged, production capable software product.  As our Data Engineer in the Corvidae project you will be expected to implement, deploy, and manage the data pipeline and storage components of the Corvidae delivery process from end to end, effectively and efficiently. Understanding the data pipeline requirements which enable the reporting and modelling needs of the product and ensuring that enables high quality and robust delivery to Corvidae clients. You will be responsible for setup, deployment, and maintenance of data processing infrastructure (cloud storage, cloud compute, clustering, etc.), data cleansing, and data enrichment.  Requirements  Are you QC?  Extensive professional experience in the building and maintenance of production quality data management pipelines  Excellent experience with Python, SQL and commonly related tools and libraries  Excellent experience of the setup, use, and maintenance of cloud storage and cloud compute products (preferably Azure)  Experience in the setup and maintenance of container solutions such as Kubernetes Experience in enabling output delivery through data enablement  Experience working with web technologies  Working knowledge of database administration Experience in data extraction and manipulation  Using distributed/clustered computing systems   Benefits  Some of our benefits include: Your Development We believe in continuously investing in your talent and offer an industry-leading training and development programme Work/Life Balance Remote First, flexi hours, reduce travel costs and still have office space to collaborate as a team.  Monthly staff rewards Flexible annual leave (34 days) with options to buy/sell leave. Travel loan options & Technology loans and discounts Perkbox - high street discounts, reduced gym membership and cycle to work scheme Company pension contributions, life insurance and private medical scheme   Location  UK Remote - Although role is remote there will be expected travel to our Edinburgh office, this will be easier, more accessible for those who are already UK based or those happy to relocate to UK.  Competitive Salary Dependent On Skills And Experience  Follow our company instagram for a snapshot into life at QC @Queryclick  If you are QC then please apply now - we look forward to receiving your application.",Sin experiencia,Jornada completa,Tecnología de la información,"Marketing y publicidad, Software, Internet",3,None,False,,14,ACTIVELY_HIRING_COMPANY
240,2291161778,2020-10-22,Recruiting for Good,Remote Data Scientist 1 Year Contract,"Los Angeles, CA, US","Must Live in the United States  Have Excellent Communication Skills  Data Scientist Provide technical and thought leadership designing, testing and implementing methodologies to forecast and monitor metric time series.Develop algorithms to detect anomalies, assess risks/threats, and core metric fluctuations.Conduct ad-hoc analysis to understand unexpected metric movements and communicate results to other data scientists, product managers and company leadership.Interface with engineers, product managers and product analysts to understand data needs and help build data products.Drive the design, building, and launching of new data models and data pipelines in production.  Minimum Qualifications 5+ years' experience doing quantitative analysis or statistical modeling5+ years writing SQL statements.Snowflake experienceWorking knowledge of at least one modeling framework (e.g. scikit-learn, TensorFlow, SAS, R, MATLAB)Familiarity with basic classes of ML algorithms, concepts in feature extraction and selection.Ability to communicate your analysis with clarity and precision.Experience implementing statistical models in production-grade code.",Sin experiencia,Contrato por obra,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Software, Seguridad del ordenador y de las redes",0,None,False,,5,JOB_SEEKER_QUALIFIED
241,2277694179,2020-11-05,Sprinklr,UX Researcher,"Portland, OR, US","As the world moves even more online due to the coronavirus pandemic, customers are connected and empowered like never before. Customers want an immediate, personalized and consistent experience, no matter which channel they choose to engage with a brand. Sprinklr helps brands meet the demands of today's customers by providing them with the insights they need to make every interaction matter. Sprinklr is a Customer Experience Management (CXM) platform for modern enterprises with 1,900 employees helping the world's most valuable enterprises make their customers happier.  UX Researcher  Candidates need to be located in Portland, Oregon  Sprinklr is 2,000 employees strong, valued at $2.7 billion, and positioned at the forefront of the customer experience management industry. At a time when consumers are connected and empowered like never before, Sprinklr is helping the world's largest brands provide unique experiences at every turn.  Sprinklr offers powerful social capabilities that allow our clients to reach, engage, and listen to customers across 35+ Modern Channels including social, messaging, chat and text. We empower entire organizations to work together – across marketing, advertising, research, commerce, and customer care – to manage customer experience at scale.  Sprinklr works with more than 1,000 of the most recognized brands worldwide, including Nike, JPMorgan Chase, Verizon, McDonald's, Microsoft, P&G, and more than 50% of the Fortune 50.  UX Researcher - Portland, Oregon  At Sprinklr, we strive to celebrate our users in everything we do. We are seeking a UX Researcher with a passion for understanding user needs and motivations, as well as the ability to empathize with people from all roles, industries and backgrounds. The ideal candidate understands that technology interactions can affect our work day, personal life and overall happiness. Thus, they will be an enthusiastic, fearless advocate for our Sprinklr users by converting their needs and desires into actionable insights and impactful solutions.  As an integral part of our Design team, you will serve as a champion for our end users throughout the design and development process. Leveraging research methodologies, you will interact directly with users from the world's leading companies to develop a strong comprehension of their daily tasks and end goals. You will work closely with Sprinklr's talented pool of designers, product owners, and engineers to translate user insights and feedback directly into our products. Throughout the fast pace of software development, you will consistently ground us with your deep knowledge and understanding of the users to help create products they trust and love.  The Sprinklr Design team is tasked with designing the world's most loved enterprise software. Find out more about what we do at https://sprinklr.design/  Responsibilities:   Collaborate with designers, product owners, engineers and fellow researchers to prioritize research needs and opportunities in a fast-paced environment Host and facilitate research sessions with Sprinklr's rich user base, including all role levels, industries and geographical regions Develop strong understanding of Sprinklr user personas, workflows and behaviors to represent users throughout design process Analyze and distill user feedback into actionable insights to inform product and design decisions Identify, implement and iterate new research methodologies as Sprinklr's UX Research operations continue to evolve  Qualifications:   Bachelor's Degree in Psychology, Sociology, Human-Computer Interaction, Information Science, Design or related field :2 years UX Research/Design or relevant industry experience In-depth knowledge of UX Research + Design principles and methodologies Strong written and verbal communication skills, including confidence corresponding with senior stakeholders and high-profile customers Ability to work in fast-paced, ambiguous environments against software release timelines Ability to collaborate and build relationships with fellow team members and stakeholders Curious, empathetic mindset, including intuition to ask effective questions to receive actionable feedback Strong problem-solving and critical thinking skills  Why You'll Love Sprinklr: We offer a flexible work environment, unlimited vacation, and generous pay and benefits packages. While we have some amazing perks, at the end of the day, Sprinklrites are here for the opportunity to grow, learn, and affect the industry with incredible ingenuity. #Sprinklrlife  We focus on our mission: We believe social technology is the future of customer-brand relations across all departments, and we seek to make each of those experiences excellent at every touchpoint. This is how we all make the world more social together.  We invest in our people - Sprinklrites passionately, genuinely care about seeing one another succeed in making an impact on the industry. We pride ourselves on having an honest, open environment and a supportive culture where we can take risks together.  We believe in our product - Sprinklr is the most complete enterprise social technology in the world, and we're not just saying that Forrester Wave said it for us! As such, we have many of the world's largest brands as our clients, and our employees have the opportunity to work closely alongside them.  Employment Policy  Sprinklr's policy is to provide equal employment opportunities to all applicants and employees without regard to race, color, religion, creed, gender, gender identity or expression, age, national origin or ancestry, citizenship, disability, sexual orientation, marital status, pregnancy, veteran status, membership in the uniformed services, genetic information, or any other basis protected by applicable law. Sprinklr, Inc. participates in the E-Verify Program. As a participating employer, Sprinklr, Inc. will provide the Social Security Administration (SSA) and, if necessary, the Department of Homeland Security (DHS), with information from each new employee's Form I-9 to confirm work authorization. Sprinklr, Inc. follows all federal regulations including those set forth by The Office of Special Counsel for Immigration-Related Unfair Employment Practices (OSC). The OSC enforces the anti-discrimination provision (274B) of the Immigration and Nationality Act (INA), 8 U.S.C. 1324b.  Disclaimer  Our careers site is only for individuals seeking a position with Sprinklr and its holdings companies. Staffing and recruiting agencies and individuals being represented by an agency are not authorized to use this site or to submit profiles, applications, or resumes, and any such submissions will be considered unsolicited. Sprinklr does not accept unsolicited resumes or applications from agencies. Please do not forward resumes to our job alias, Sprinklr employees, or any other company location. Sprinklr is not responsible for any fees related to unsolicited resumes/applications.  Any offer (s) of employment are contingent upon a satisfactory background and criminal records check, which will be conducted in accordance with local legal regulations.  Why you'll love Sprinklr: We're committed to creating the kind of culture where you feel like you belong, are happier today than yesterday, and your contributions matter. At Sprinklr, our goal is to treat everyone like family and passionately, genuinely care. We offer flexible paid time off and paid parental leave, medical plans, dental and vision plans, life insurance, 401(k) savings plans, employee stock options, gym and wellness discounts, Plum benefits, Lifemart discounts, and paid time off to invest in learning and career development.  We focus on our mission: We founded Sprinklr with one mission: to enable every organization on the planet to make their customers happier.  We believe in our product: Sprinklr was built from the ground up to enable a brand's digital transformation. Its platform provides every customer-facing team with the ability to reach, engage and listen to customers around the world. At Sprinklr, we have many of the world's largest brands as our clients, and our employees have the opportunity to work closely alongside them.  For the fifth consecutive year, Sprinklr has been named to the Forbes Cloud 100, the definitive ranking of the top 100 private cloud companies in the world. We were also named a 2020 Gartner Peer Insights Customers' Choice for Social Marketing Management. And in 2019, Sprinklr was the only leader in the Forrester Research, Inc. report, The Forrester Wave™: Social Suites.  We invest in our people: At Sprinklr, we believe every human has the potential to be amazing. We empower each Sprinklrite in the journey toward achieving their personal and professional best. For wellbeing, this includes daily meditation breaks, virtual fitness, and access to Headspace. We have continuous learning opportunities available with Audible for Business, Linkedin Learning, and more.  The Sprinklr Way  EEO - Our philosophy on inclusion: Our goal is to ensure every employee feels like they belong and are operating in a judgement-free zone regardless of gender, race, ethnicity, age, and lifestyle preference, among others. We value and celebrate our sense of belonging and fervently believe every employee matters, and should be respected, listened to, and have opportunities to contribute to the magic of Sprinklr!  We celebrate differences, and we seek to hear unique perspectives because it helps us all to learn. We seek to understand. We believe we are stronger when we belong because collectively, we're more innovative, creative, and successful. As we continue on our growth journey, we know that bringing together diverse talent leads to better company-wide innovation, improved financial results and better decision making.  Sprinklr is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. See also Sprinklr's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know.",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Marketing y publicidad, Servicios y tecnologías de la información, Software",71,None,False,,431,ACTIVELY_HIRING_COMPANY
242,2225533768,2020-10-21,Yonder,Sr. Data Scientist,"Austin, Texas, United States","You're looking to tackle complex problems, drive change, and help build the next generation of machine learning tools for detecting malicious and inauthentic behavior online. You want to collaborate with others, creatively solve problems, make decisions with conviction, and connect with a team that nerds out about the internet. You thrive in an environment of continual improvement, and you aren’t afraid to try new things and make mistakes with others. If this sounds like you, we want you on our team! Yonder is an information integrity company on a mission to bring authenticity to the Internet. We use artificial intelligence and machine learning to help brands identify the groups that drive online conversations. Our technology unlocks the hidden map of the Internet.  We're looking for a Data Scientist with 3 or more years of experience in building products in partnership with software engineers. The ideal candidate will also have experience building and deploying machine learning software. This role will report to the CTO. Most of our team is based in Austin, TX, but we are remote-first and encourage candidates in other areas to apply. Interviews for this role will be conducted remotely over video during Covid-19, for the safety of our employees and candidates. The problem we are solving is complex and requires diverse voices and perspectives. We are united by our passion for an authentic internet, but we are empowered by the differences in how we think, how we live, and what we’ve experienced. We strongly encourage candidates with diverse backgrounds to apply to this role, especially from groups traditionally underrepresented in tech.  What You’ll Do:In this high impact role, you will:Work with data scientists, machine learning engineers, software engineers and product managers to formulate, research and implement machine learning solutions to detect and analyze inauthentic behavior onlineUnder collaboration with product managers, interpret and develop solutions to complex business problems using a range of techniques, such as statistics, machine learning techniques, and other methodsIdentify opportunities to add customer value and use a broad and evolving Python machine learning stack to build proofs-of-concept and prototypes in support of these ideas  What You Have:3+ years experience collaborating with teams of data scientists and software engineers to implement data science-enabled features in a commercial application.Experience building scalable software products and data pipelinesWell-rounded knowledge of statistics, machine learning, and experimental designFamiliarity with state of the art ML researchExperience with a Python machine learning stack (e.g. tensorflow/keras, sklearn, pandas)Comfort with exploring real-world data to uncover insightsSkills to communicate challenging technical problems to a non-technical audienceSkills to operate effectively in a fast-paced, complex businessPreferred:Familiarity with Git, Docker and SnowflakeExperience with data visualization, interpretability, NLP, and exploratory analysisExperience leading a team What You’ll Get:Purpose-driven work A team of dedicated and supportive colleagues Encouragement to bring your whole self to workRemote-first organization, with an office available in Austin if preferred (availability is dependent on Covid-19) Market-leading salary and equity compensationCoverage under best in class, flexible medical, vision and dental plans401(k) with 100% company match up to 4% of salary and immediate vestingUnlimited vacation that you’re encouraged to takePaid parental leaveMonthly virtual social events",Intermedio,Jornada completa,Ciencias,Servicios y tecnologías de la información,111,None,False,,456,None
243,2215791767,2020-11-06,Interactive Resources - iR,Big Data Engineer,"Nashville, Tennessee, United States","JOB SUMMARY The Data Engineer is responsible for coding and continuous testing of complex modules and applications in support of the platform. This role will also be charged with understanding and interpreting requirements to contribute to the technical architecture and the associated design documents. PRIMARY DUTIES AND RESPONSIBILITIESWriting, debugging, unit testing, and performance test code in the data access layer in accordance with standards.As an agile team member, participate in code reviews, design reviews, etc.Utilize domain driven techniques and design patterns to build and contribute to technical design.Develop and maintain strong knowledge of implemented requirements and detailed application behaviors. EXPERIENCE 7+ years of experience in a cloud computing environment.Strong understanding and familiarity working in the Linux operating environment.Familiarity and experience executing several software development methodologies and life cycles preferred. SKILLS7+ years of developing software using object-oriented or functional language experience5+ years of SQL7+ years working with open source Big Data technology stacks (Apache Nifi, Spark, Kafka, HBase, Hadoop/HDFS, Hive, Drill, Pig, etc.) or commercial open source Big Data technology stacks (Hortonworks, Cloudera, etc.)3+ years with document databases (e.g. MongoDB, Accumulo, etc.)3+ years of experience using Agile development processes (e.g. developing and estimating user stories, sprint planning, sprint retrospectives, etc.)2+ years of distributed version control system (e.g. git)3+ years of experience in cloud-based development and deliveryFamiliarity with distributed computing patterns, techniques, and technologies (e.g. ESB)Familiarity with continuous delivery technologies (e.g. Puppet, Chef, Ansible, Docker, Vagrant, etc.)Familiarity with build automation and continuous integration tools (e.g. Maven, Jenkins, Bamboo, etc.)Familiarity with Agile process management tools (e.g.  Atlassian Jira)Familiarity with test automation (Selenium, SoapUI, etc.)Good software development and Object Oriented programming skills.Strong analytical skills and the ability to work with end users to transform requests into robust solutions.Excellent oral and written communication skills.Initiative and self-motivation to work independently on projects. EDUCATIONBachelor's computer information technology, computer science, management requiredMaster's preferred",Intermedio,Jornada completa,Tecnología de la información,"Software, Atención sanitaria y hospitalaria",49,None,True,,200,ACTIVELY_HIRING_COMPANY
244,2183095374,2020-10-14,Lime,Senior Data Scientist,San Francisco Bay Area,"Remote Friendly. As long as you are located in the Pacific or Mountain time zone regions within a 3 hour flight to San Francisco to meet up with team monthly or quarterly, you are welcome to work from where you love to live and still be a key part of Lime! Lime operates electric scooters and bikes, but our mission is larger. We believe in transforming cities through green, affordable, and accessible transportation for everyone. Headquartered in San Francisco, USA, we operate in more than 120 cities in 31 countries, with plans to expand responsibly. To do that, we need great people.   Data is at the core of every decision at Lime - from designing vehicles, to deploying them, enhancing the user’s experience, optimizing our supply chain or warehouse operations. Every team at Lime engages with Data Science & Analytics. Our goal is to provide data insights and models that drive better business outcomes.  We are looking for intellectually curious, highly motivated individuals to join our Data Science & Analytics team. You will partner with our Engineering, Product, and Operations teams to identify critical issues to the business, develop a deep understanding of them, and design scalable solutions. You will leverage your quantitative and modeling skills to transform signals into insights, and insights into actions. You should have strong analytical skills, excellent communication abilities, and a knack for working across teams in a fast-paced environment. What you'll do: Develop a deep understanding of a particular problem space that’s relevant to the business and propose solutions to improve itConduct statistical analysis to extract insights from the data and communicate findingsGuide product and strategic decisions with experimentation and in-depth analysesBuild models that help optimize business decisionsDevelop solutions that make data insights accessible to all About you:MS or PhD in Economics, Statistics, Applied Mathematics, or other quantitative fields5+ years of industry experience as a Data ScientistProficient in SQL and a programming language such as PythonHands-on experience with data pipelines and visualization toolsDeep and practical understanding of probability and statistics, including causal inferenceSolid understanding of Machine Learning algorithms - practical experience building ML models preferredAbility to communicate technical concepts to a general audienceGreat product intuition and ability to generate hypotheses aloneCapable of turning insights into actionable product ideasStrong communication skills with a consistent record of collaborating across a wide variety of teams and disciplines in a dynamic environment Lime is an Equal Opportunity Employer, but that’s only the start. We want people with different backgrounds, abilities, identities, and mindsets to join us—not just to do great work, but to build a better, more representative world.",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Servicios y tecnologías de la información,170,None,False,,989,ACTIVELY_HIRING_COMPANY
245,2219334938,2020-10-30,Stealth Startup,Sr. Data Scientist,United States,"Sr. Data Scientist ﻿We are seeking a hands-on Senior Data Scientist to skillfully apply mathematics, statistical analysis, machine learning, prediction, and other data science disciplines and technologies, in order to aid us in the development and deployment of a new data analytics product / service.The candidate will systematically identify outliers or unnatural patterns in our data so that we may curate a quality dataset that customers trust.Most importantly, the candidate will work with our product team to identify ways to augment and enhance our data in order provide insight beyond what can be gleaned from the data we have today.Responsibilities:Dig deep into our data right away to understand the scope and structure of what we have, what we don’t have, where it is, and how it all connectsConceive of - and answer - scientific business and technical questions in order to help us drive our analytics product roadmap forward in an informed and evidence-based mannerConceive of, model, and aid in the implementation, testing, and monitoring of new monetizable data features and data augmentations. Experiment with data early to vet ideas before involving the full engineering team.Systematically identify and address data quality problems, such as historical gaps, low sampling rates, and strange outlier patterns in the data themselves. Design and drive solutions to those problems, including proposal of new data acquisition / augmentation strategiesMeasure usage and correlation of these figures with realities that they purport to represent so that we are aware of the accuracy of our data and can continually improve itWork with PM and leadership to validate proposed business model(s) for monetizing our dataAssist PM in his/her product analysis to understand real user behavior and its impact to KPIs.Deal creatively with ambiguity: create and press for progress in the face of unknowns Requirements4+ years of hands on data science experience·       BS degree in Computer Science, Computer Engineering, or related field.Expert SQL (eg: Postgres)NoSQL a big plus (eg: Elasticsearch)Experience with Data Pipelining / Querying across disparate databases, REST APIsBig data a plus (eg: Apache Spark, Cassandra, Kafka)Machine Learning a plusExpert in leveraging data to gather user and product insights: SQL, Tableau, SiSense, Excel.Strong curiosity and capability to search/troubleshoot data problems on your own. Excellent written, verbal, and leadership skills, attentive to detailExperience in a startup or entrepreneurial environments is a plusExperience with working with executives and handling competing priorities.Bonus: Time series databases, Visualizing cyclicality, and Data aggregation techniques and testing. We are not offering visa sponsorship at this time. Only candidates who are US Citizens or Green Card holders will be considered. EQUAL OPPORTUNITY EMPLOYER. It is our policy to abide by all federal, state and local laws prohibiting employment discrimination based on a person’s race, color, religious creed, sex, national origin, ancestry, citizenship status, pregnancy, childbirth, physical disability, mental and/or intellectual disability, age, military status, veteran status (including protected veterans), marital status, registered domestic partner or civil union status, familial status, gender (including sex stereotyping and gender identity or expression), medical condition (including, but not limited to, cancer related or HIV/AIDS related), genetic information, sexual orientation, or any other protected status.",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Internet,135,None,True,,566,JOB_SEEKER_QUALIFIED
246,2289891535,2020-10-27,PTP,Data Scientist - REMOTE,"Gold River, CA, US","About Us  We are a growing company with a solid customer base, excellent compensation and benefits, and a collaborative yet flexible work environment. If you enjoy challenging projects, using new technologies to deliver innovative business solutions, and you're interested in working for an entrepreneurial company, we may have a home for you.  PTP is looking for a Data Scientist to join our Customer Experience practice. At PTP, we value aptitude and creativity as well as experience. We are a diverse organization and are looking for bright, passionate and committed professionals who strive to be the best at what they do.  Responsibilities  Use machine learning techniques to create scalable solutions for business problems Analyze and extract key insights from rich stores of customer data Implement highly innovative models for predictive learning for applications like recommendations and targeting Establish scalable, efficient, automated processes for large scale data analyses, model development, model validation and model implementation Research and implement novel machine learning algorithms for new business problems   Requirements  PhD. in Computer Science with a focus on machine learning Track record of having developed novel machine learning algorithms, SIGKDD/ICML/NIPS Hands-on experience in predictive modeling and analysis over large volumes of data Strong problem solving ability Strong programming skills in C/C++ or Java Experience with R/SAS/SPSS Experience with SQL and MPP databases Experience with large scale distributed programming paradigms – experience with the Hadoop stack(HDFS/MR/Pig/Hive) Familiarity with AWS and other cloud-based technologies that can be used with large mapReduce efforts Experience in free-text analytics / natural language processing (NLP) Excellent written and verbal communication and skills  Compensation is DOE and is extremely competitive.",Intermedio,Contrato por obra,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Software, Consultoría de estrategia y operaciones",0,None,False,,7,None
247,2290199648,2020-11-08,ASTEK Polska,DATA ENGINEER - 100% remote/Warszawa,"Warszawa, Woj. Mazowieckie, Polska","Currently, we are looking for DATA ENGINEER 🌍 Location: 100% REMOTE/ Warszawa 💲 Salary: up to 960 PLN/MD, B2B (depending on skills and experience) Responsibilities:✔ Analysing, maintaining and building different cloud-based data processing solutions:✔ ETL data flows design, implementation and deployment (including business requirements analysis):✔ Data quality checks implementation:✔ Designing, managing and maintaining tools to automate operational processes: Requirements:✔ Experience with analytics, databases, data systems and client support:✔ Good knowledge of SQL:✔ Knowledge of ETL processes and databases:✔ Good command of English:✔ Proactive approach, research, problem solving and analytical skills. Nice to have:✔ Practical knowledge of AWS (Redshift, S3):✔ Working knowledge of JSON and RESTful APIs:✔Experience with coding in Python:✔ Experience with working and scripting in Unix/Linux environments:✔ Experience with working with DevOps environment and toolset (e.g. Jenkins, Docker, jFrog Artifactory, Bitbucket, JIRA). If you are interested, apply: istutzka@astek.pl",Intermedio,Jornada completa,Ingeniería,Servicios y tecnologías de la información,15,None,True,istutzka@astek.pl,85,ACTIVELY_HIRING_COMPANY
248,2290070598,2020-11-05,QA Ltd,Data Engineer - Fully Remote,"London, GB","Data Engineer, Fully remote, up to £80k  This is an opportunity to work for a cutting-edge consultancy minus the travel. This client is looking for Data Engineers to help their clients deploy data pipelines and build data platforms, all from the comfort of your own home.  Why join?  Work for FTSE 100 companies.Hone your data engineering skills on the most cutting-edge technologies.Working in an ultra-agile environment.Work alongside the best in the industry.  Job Description  The role consists of working in DataOps teams in an agile environment to deploy pipelines and build cloud-based data platforms.  Skills Required  Python.Experience with either Azure or AWS.Experience with a NoSQL database.Worked with either Kafka or Kinesis.Experience with Hadoop.  Nice To Have  Scala or Java.Worked with Spark or Databricks.Experience with: YARN, HDFS, MapReduce, Hive/Impala.Skilled with SQL. Please do get in touch if you would be interested in discussing this role or having a confidential chat about your career.",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Dotación y selección de personal",0,None,False,,3,ACTIVELY_HIRING_COMPANY
249,1912749181,2020-09-03,Exiger,"Due Diligence, Risk, and Compliance Researcher (Chinese)",Canada,"Exiger Diligence is excited to welcome to its team experienced due diligence, compliance, and risk research professionals. We are searching for talented research professionals who know this industry and are passionate about research. We are also pleased to be expanding the geographic reach of our team by seeking professionals based across Canada who are interested in working in a fully remote capacity. Exiger Diligence focuses on due diligence research for a variety of clients using a wide range of research tools to gather risk and compliance intelligence on individuals and companies. The research is then analyzed and developed into a narrative report, which is used by clients to understand the general background of the subject, assess the subject’s legitimacy and reputation, and inform strategic decision-making. This is a full-time, fully remotely-assigned opportunity. Due Diligence, Risk, and Compliance Researchers are creative and inquisitive. They seek to provide thorough and accurate information to the client in every report they complete. Researchers work both independently and collaboratively on research and reports for a variety of domestic and international clients. Key ResponsibilitiesExtensive primary and secondary research using a variety of open-source and public records web-based tools.Identification of pertinent information and development of useful insights into the subject.Write clear, concise and thorough reports for clients.Learn to own cases from start to finish with review of cases by senior researchers.Assist with research, writing, and editing of large and complex cases.Utilize best practices in research methodology to effectively complete reports for various different clients and of various different scopes.Commitment to integrity and thoroughness of research.Travel may be required under certain circumstances. Knowledge & SkillsPrevious experience conducting due diligence, risk, or compliance research.Familiarity with public-records research and an understanding of due diligence research methodology.Excellent writing and editing skills.Rigorous attention to detail.Superior comprehension and analytical abilities.Excellent logical deductive skills.Ability to work in fast-paced and self-driven environment.Ability to manage and prioritize several projects and assignments simultaneously.Organizational and time management competency required.Ability to mentor others.Understanding of current events, international affairs, financial regulations, economics and/or finance.Professional fluency/proficiency in a foreign language a plus with a particular emphasis on Chinese. ﻿Professional Experience RequiredBachelor’s degree required, Master’s degree preferred0-3 years of due diligence research, review, and management experienceDemonstrated ability to thrive in dynamic, high-pressure, and deadline-driven environments.Solution-oriented professional focused on achieving optimal outcomes for clients, the business, and the team.Professional fluency/proficiency in a foreign language with a particular emphasis on with a particular emphasis on Chinese. About Exiger At Exiger we work everyday to make the world a safer place to do business in. Our experts and technology help clients prevent breaches, respond to risk, remediate issues and monitor activities. We are searching for people who think creatively to solve complex problems related to governance, risk and compliance thus delivering first class solutions for our corporate and government partners. Exiger’s core values are courage, excellence, expertise, innovation, integrity, teamwork and trust. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.",Algo de responsabilidad,Jornada completa,"Investigación, Redacción y revisión","Consultoría de estrategia y operaciones, Servicios financieros",184,None,False,,1461,ACTIVELY_HIRING_COMPANY
250,2201819506,2020-10-22,Icertis,Principal Data Scientist,India,"The Principal Data Scientist is a detail oriented forward thinking individual who will utilize data mining, data analysis, machine learning and natural language processing to bring innovation and differentiated capabilities to the Icertis Contract Intelligence. You will be at ease with contemporary machine learning, natural language processing frameworks and quantitative approaches and will be able to critically evaluate and design, build, and support pipelines that can analyze contract document collections at scale. When no suitable approaches are available, is able to craft new and innovative machine learning and language processing solutions. Knowledge of enterprise level software architecture and components is a big plus though is not required. You will have strong verbal and written communication skills, be effective in interacting with technical and non-technical professionals, and be comfortable with team building and working in a team.  Responsibilities: Partners with business stakeholders to translate business objectives into clearly defined analytical projects.Identify opportunities for text analytics and NLP to enhance the core product platform, select the best machine learning techniques to the specific business problem and then build the models that solve the problem.Own the end-end process, from recognizing the problem to implementing the solution.Define the variables and their inter-relationships and extract the data from our data repositories,leveraging infrastructure including Cloud computing solutions and relational database environments.Build predictive models that are accurate and robust and that help our customers to utilize the core platform to the maximum extent. Skills and Qualifications: 12 to 15 yrs' of experience.An advanced degree in predictive analytics, machine learning, artificial intelligence: or a degree in programming and significant experience with text analytics/NLP. He shall have a strong background in machine learning (unsupervised and supervised techniques). In particular, excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, logistic regression, MLPs, RNNs, etc.Experience with text mining, parsing, and classification using state-of-the-art techniques.Experience with information retrieval, Natural Language Processing, Natural Language Understanding and Neural Language Modeling.Ability to evaluate quality of ML models and to define the right performance metrics for models in accordance with the requirements of the core platform.Experience in the Python data science ecosystem: Pandas, NumPy, SciPy, scikit-learn, NLTK, Gensim, etc.Excellent verbal and written communication skills, particularly possessing the ability to share technical results and recommendations to both technical and non-technical audiences.Ability to perform high-level work both independently and collaboratively as a project member or leader on multiple projects.",Intermedio,Jornada completa,Otro,Servicios y tecnologías de la información,216,None,True,,671,ACTIVELY_HIRING_COMPANY
251,2240666799,2020-10-25,Facebook,"Data Scientist, Analytics-Remote Presence","Bellevue, WA, US","Facebook's mission is to give people the power to build community and bring the world closer together. Through our family of apps and services, we're building a different kind of company that connects billions of people around the world, gives them ways to share what matters most to them, and helps bring people closer together. Whether we're creating new products or helping a small business expand its reach, people at Facebook are builders at heart. Our global teams are constantly iterating, solving problems, and working together to empower people around the world to build community and connect in meaningful ways. Together, we can help people build stronger communities - we're just getting started. Messenger remote presence infra team powers audio and video calling for millions of users. This is a real time calling infrastructure for Messenger, Instagram, Workchat and Portal. We are looking for Data Scientists with deep knowledge in infrastructure systems to join us.Some of the key questions you will be working on: Systematic understanding of media stack of infrastructure with data, quantify media quality and explore how media quality affect user engagement: improving networking stack and working on cutting edge technology to make remote experience more real time and fun. With this role, you can learn a lot of skills to make you an awesome DS: dive deep into tech stack of infra, experimentation (A/B testing), operational support. There is a good balance between diving deep on technical side as well as influencing engineering leaders on this role - data scientists are the key partner to deliver insights and uncover opportunities and drive engineering roadmap on the team. Team is based in Bellevue.  Build long term product vision and strategy and scope out the area for the teamGenerate product ideas that affects millions of users to connect real timeUnderstand the complex E2E real time infrastructure system and identify the bottlenecks and opportunitiesBuild and validate the hypothesis of product ideas and infrastructure improvementsLeverage data to inform the right business decision, such as designing how to evaluate the product performance and whether they should be launched5+ years of hands-on data science experience, Data analysis skill, willing to get your hands dirty with dataExpert knowledge of SQL, Python, RExperience on working with multiple cross functional partners and influence decision making based on dataExperience initiating and drive projects to completion with minimal guidanceExperimentation- AB testingEducational background in Computer Science, Math, Physics, Engineering, or related quantitative fieldExpert in experimentationExperience with large data sets and distributed computing (Hive/Hadoop)Exposure to large scale infrastructure systems, comfortable with technical discussions Facebook is proud to be an Equal Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law.  Facebook is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.",Algo de responsabilidad,Jornada completa,Tecnología de la información,Internet,75,None,False,accommodations-ext@fb.com.,680,COMPANY_RECRUIT
252,2202521792,2020-10-12,HCL Technologies,Cosmos Data Engineer,"Redmond, Washington, United States","Job Description:  C# Skills: (3+ years coding experience), SQL/Scope, Cosmos, Scripting language  Experience with Azure or any big data platform. Very strong in SQL Server  Very Strong on Developing Data Solution on Azure  Azure Data Factory, Azure Datawarehouse, Power BI,Understand how to sync onshore / offshore Excellent communication, Experience of working with Realtime data / Large data set",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Servicios y tecnologías de la información,64,None,True,,314,COMPANY_RECRUIT
253,2246783943,2020-10-02,Nigel Frank International,GCP Data Engineer - Remote - UK Based,"London, GB","Data Engineer - London Based - Remote  up to £65,000  My client based in London would like to speak to Data Engineers in London and surrounding areas that are looking to join a fast-growing team that is always at the forefront of working with the new technologies. You will be surrounded and supported by a great team that always has a can-do attitude.  They are looking for people who help create cutting-edge, durable, and loved data solutions. While also having fun at the same time. This is a great environment to be around.  Skills & Qualifications Google Cloud PlatformStrong Programming & Architectural experience,Building Big Data solutionsPassionate about Data and AnalyticsExperience with ETL toolsHadoop-based technologies   Benefits 25 days holiday plus bank holidaysGreat pension schemeHardwareSocial events and team offsitesNetworking events, Mentoring events & conferencesExposure to expertsExplore the latest tools/technologies  This would be a great time to join this team as they are looking to expand even further and increase their client portfolio.  Do you not have all the skills mentioned above? I'd still like to hear from you.  If you are looking for an excellent salary, flexible working with minimal travel, private medical care, ongoing training, and career progression then this is the job for you.  Office Line: 0191 338 7667 Email: d.manzini@nigelfrank.com  LinkedIn: 'Dee Manzini'  Rest assured, anything discussed will remain completely confidential and fully compliant with GDPR.",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Dotación y selección de personal",None,None,False,d.manzini@nigelfrank.com,4,ACTIVELY_HIRING_COMPANY
254,2269290506,2020-11-03,ApparelGenius,Computer Vision Researcher,India,"Get into the heart of this exciting Australian-based and funded startup that is set to revolutionise online fashion by solving the size & fit problem holding back the entire industry. ApparelGenius has created a set of innovative systems to accurately measure multiple features of the human body with a Smart device. We are looking for researchers with experience in designing ML algorithms for computer vision use cases related to human body landmark identification and size measurement prediction. Essential:Active researcher in Fashion-AI space related to 3D image modeling , virtual fitting and anthropometric modeling.Published papers in fashion tech space in conferences (SIGGRAPH, CVPR, ACM, KDD Fashion, AI4Fashion, ACM Fashion Recsys etc).Machine learning and deep learning experience with libraries such as PyTorch, TensorFlow.Software engineering experience to process data and prototype algorithms using Python/Jupyter notebooks.Good communication and writing skills. Responsibilities:Formulate, implement and evaluate algorithms to analyse 3D data, predict landmark points in human images and extract size measurements.Write reports to document the design process for the iteration and publish the findings at the end of each iteration.Work with stakeholders to understand the requirements, document data requirements and communicate the challenges/findings. Please apply here https://aa1veeui.paperform.co",No corresponde,Jornada completa,None,Servicios y tecnologías de la información,90,None,False,,533,ACTIVELY_HIRING_COMPANY
255,2239853732,2020-09-30,Built In,Data Engineer,"Chicago, IL, US","Hello, We're Built In  Built In unites companies and people around their shared passion for tech and the universal need for purpose. To help our partners attract qualified talent, we create content that tells their story in a way no job post ever could — and we put their jobs in front of people who were born to do them. Our audience of sought-after candidates use Built In to find their professional purpose and connect meaningfully to the tech community, including by reading our content, networking at our events and applying to jobs at companies they believe in.  Headquartered in Chicago, we also serve Los Angeles, Colorado, Austin, New York, Boston, Seattle, San Francisco, and Nationwide.  When you work for Built In, you have the opportunity to change lives by giving talented people access to purpose, not just a paycheck. And you'll make an impact on some of the most exciting companies in tech, helping them hire their next wave of elite talent. Be part of Built In, and be part of the future of tech.  We're looking for a Data Engineer (Chicago HQ or Remote)   The Data Engineer works on the back-end of our platform, focused on building data pipelines that power our Job, Company and other search, recommendation and personalization services. This work is often done with Python and intersects with the core systems written in Go and Vue: knowledge of both would be preferable, but Python is required. All Data Engineers should follow our engineering standards, including a commitment to unit-testing and to SOLID design principles.  How You'll Contribute  Ownership of Built In's Data Pipeline: this is the data that we pull from our home-built data pipeline and create analytics based on raw events. Must collaborate with other members of the engineering team, whether as mentor or mentee—especially via pair-programming. Is primarily expected to be an individual contributor, focused on writing and reviewing code. Must advocate for focus on technical debt in concert with execution of new features, and has an understanding that doing so allows our team to scale with the demands placed upon us in a stable and robust manner. Be passionate about programming and learning new technologies: focused on helping themselves and the team improve their skills. Must be comfortable with and supporting other other engineering teams by contributing to our service oriented architecture.   What You Need  4+ years of experience within the field of data engineering or related technical work. Proven experience with Python. Understanding of Go. Experience with data warehousing and data pipeline tools (examples being Snowflake and Airflow). Exposure to principles of automated testing and commitment to testing as a way of producing robust code. Experience with Git and understanding of our basic workflow (branching for your own work: pull requests to commit work back). Experience with Unix on the command-line, whether via terminal in MacOS or directly on a version of Linux/*BSD, is greatly valued.  We'd love to have you aboard  Our HQ is in Chicago, however we are open to remote candidates for this position. In fact, a number of our technologists on the team are remote as well.  Due to the effects of COVID-19, Built In has decided to protect our current and future employees by managing our entire business remotely. We are continuing to hire for all open roles, and will be interviewing and onboarding virtually until further notice. Everyone new to the team, along with our current employees, will temporarily work from home until it is safe to return to our offices.  That said, we're still offering our full perks & benefits including: health, dental, and vision insurance, 401k, equity opportunities, discretionary PTO, food & tech stipend while remote, virtual culture activities, flexible working hours, and more.  Built In is an equal employment opportunity employer and values diversity. Qualified candidates are considered for employment without regard to race, religion, gender, gender identity, sexual orientation, national origin, age, military or veteran status, disability, or any other characteristic protected by applicable law",Sin experiencia,Jornada completa,Tecnología de la información,"Marketing y publicidad, Software, Internet",10,None,False,,113,ACTIVELY_HIRING_COMPANY
256,2186378053,2020-10-30,F1 Consulting & Services,Data Engineer,Italia,"F1 Consulting & Services è un'azienda italiana presente sul mercato da oltre dieci anni, con forti competenze nella consulenza aziendale e strategica, che offre servizi e soluzioni informatiche innovative per importanti grandi e medie imprese. Per cliente multinazionale, siamo alla ricerca di un Data Engineer, che possa implementare un nuovo progetto, in collaborazione con il resto del team. Attività:La persona sarà chiamata a partecipare alla creazione delle infrastrutture per l'analisi dati e avrà il cruciale compito di progettare, costruire, installare, testare e mantenere i sistemi di gestione dei dati, gestendone il flusso dalle fonti alle piattaforme di Data Management.In prima battuta, si preoccuperà dell’integrità e disponibilità dei dati e collaborerà con il team di Data Analyst per definire le esigenze e implementare l’infrasturttura. Skills:Ottima conoscenza del linguaggio PythonOttima conoscenza di ScalaPregressa esperienza di almeno 1 anno nel ruoloGradita la conoscenza della lingua inglese. Disponibilità: immediata La tipologia contrattuale verrà concordata con il candidato in base all’esperienze e allecompetenze possedute per ricoprire la posizione.",Algo de responsabilidad,Jornada completa,"Tecnología de la información, Consultoría",Servicios y tecnologías de la información,101,None,True,,533,ACTIVELY_HIRING_COMPANY
257,2254626587,2020-11-06,Entelligence,Big Data Engineer,"Washington, District of Columbia, United States","Position Title: Big Data EngineerLocation: 100% RemoteClient: Top 5 Fortune 500 Company*Must be eligible to work on W2 basis without sponsorship Position Overview:Entelligence’s Top 5 Fortune 500 client is in need of a 100% remote Big Data Engineer to join their team! Responsibilities:Evaluating on-premise infrastructure and applicationsIdentifying migration best practices and patternsOptimizing and scaling infrastructure and application layersDeveloping Python/Shell script utilities and frameworksEducating customers on GCP, NoSQL, and document store best practices Requirements:Experience migrating NoSQL and document store databases (HBase, Cassandra, CosmosDB and/or MongoDB) to the cloudUnderstanding of NoSQL/document store infrastructure and application layersMust also be familiar with cloud migration methodologies and modern reference architecturePython/Scala/Bash scripting experienceExperience with Hadoop, Cloud Spanner, and/or BigTableDevOps experience (CI/CD, automation, and deployment patterns) Benefits:Competitive compensation Medical, dental, vision and life insurance  Vacation, PTO and paid holidays Matching 401(k) program  ENTELLIGENCE. ALWAYS READY. Since 1997, Entelligence has provided mission critical project delivery capacity for uninterrupted growth and long-term market leadership to the industry’s biggest enterprise IT brands. Our commitment to close working partnerships and a proven approach for sustainable success is why Entelligence is Always Ready to help the world’s technology leaders quickly deliver their most advanced IT solutions to their most important customers.  Entelligence.com 713-355-4450     great2b@entelligence.com",Intermedio,Jornada completa,"Tecnología de la información, Ingeniería",Servicios y tecnologías de la información,39,None,True,great2b@entelligence.com,134,ACTIVELY_HIRING_COMPANY
258,2268974147,2020-11-02,Synergy Interactive,User Experience Researcher,United States,"Senior User Experience ResearcherWe're partnered with the leading digital transformation firm seeking a Sr. User Experience Researcher to join their team. Why should you apply? This company has been leading the way in digital transformations on a global scale, and there's ample opportunity to work with the biggest names in top industries. Here's what we're looking for:5+ years of research experienceUsability/concept testingqualitative researcher THIS IS A LONG-TERM, 100% REMOTE, CONTRACT! (more information will be provided during the interview) *No 3rd party candidates will be considered for this position",Intermedio,Contrato por obra,Tecnología de la información,Servicios y tecnologías de la información,50,None,True,,194,ACTIVELY_HIRING_COMPANY
259,2023520425,2020-10-20,Botkeeper,Senior Data Engineer,"Charlotte, North Carolina, United States","Botkeeper is an automated bookkeeping solution transforming the accounting industry. Named one of America’s Best Startup Employers by Forbes in 2020, we’re building a team that isn’t afraid to push the boundaries of what's possible. Together, we work hard, collaborate constantly, lift one another up, and challenge each other without fear. Following our recent round of Series B funding led by Point72 Ventures, we’re now scaling to achieve the future of bookkeeping! Our Engineering Team:We are a group of T shaped engineers, who have an insatiable desire to learn new technologies, implement exciting scalable solutions, and teach each other as we collaborate on projects. Being a part of this team provides an opportunity to work across a variety of technical domains, while contributing insights from your own experiences and domain expertise. Position Overview:Botkeeper is looking for an experienced data engineer to help us build the world's most advanced bookkeeping platform. You will be focused on designing, building, securing and managing our data acquisition and transformation pipelines and the associated cloud infrastructure. You will work closely with our ML and Platform teams to identify, acquire and normalize the myriad of data sources necessary to automate, speed up and improve the quality of the bookkeeping process. If you are a team player with strong communication skills and attention to detail, we want to talk to you! MUST BE WILLING TO RELOCATE TO CHARLOTTE, NC or BOSTON, MA Responsibilities:Architect and implement robust data acquisition strategies and ETL pipelinesMaintain and expand our unified data layerDefine and document data models to unify the accounting industryDefine and implement a robust 3rd party integration strategyOversee data governance across the organizationWork closely with information security to define and implement data classification, logging and access controlsInfluence the features and direction of our products with your own ideasActively contribute to our code review cultureLead and mentor junior/mid level engineers, and help establish coding standards Qualifications:7+ years data engineering experience5+ years experience in either Python or JavaScript (Node.js) 5+ years of experience with schema design and data modeling5+ years experience designing, building, and maintaining data processing systems5+ years experience with relational (e.g. PostgreSQL, MySQL, Oracle) and NoSQL databases (e.g. MongoDB, CouchDB, HBase)Expertise in optimizing query and data processing performanceExperience working with a Map Reduce system on any size/scaleExperience using cloud-based ETL and data warehousing solutions like AWS Glue and Redshift preferredStrong database design experience and SQL proficiency3+ years of experience developing within distributed systems / microservices architecture2+ years of experience with Docker containerizationExpertise in security-related best practices including OWASPExperience working in a Unix environment with proficiency in shell scriptingMust be detail-oriented, self-motivated and professionalGood communication and problem-solving skills About Botkeeper:Botkeeper provides bookkeeping to businesses using a powerful combination of skilled accountants and automated data entry through the use of machine learning and AI. Our clients receive 24/7 accounting and support as well as incredible insight into their financials with beautiful dashboards and unlimited reporting. The platform easily integrates with a client’s bank accounts, credit cards, HR system, and POS system, and makes appropriate entries and adjustments to their QuickBooks Online accounts, providing businesses with a 24/7 AI-driven Botkeeper. The company is headquartered in Boston, MA.  Botkeeper Benefits:We offer unlimited PTO, competitive compensation and healthcare, remote work, and 12 weeks of parental leave. Additional benefits include our annual company retreat, incredible opportunities for career growth, continued professional education, and collaboration with our team of smart, supportive colleagues. Equal Employment Opportunity Statement:Botkeeper is proud to be an Equal Employment Opportunity employer and we encourage all to apply to join our team! We do not discriminate based upon race, religion, color, national origin, sex, sexual orientation, gender identity, age, military or veteran status, disability, or any other applicable characteristics protected by law.",Intermedio,Jornada completa,Tecnología de la información,Software,134,None,True,,712,ACTIVELY_HIRING_COMPANY
260,2155355967,2020-10-26,A Cloud Guru,Data Engineer,"Austin, Texas Metropolitan Area","The Data EngineerCOLLABORATE | OPTIMIZE | EVOLVEAs a Data Engineer at A Cloud Guru, you will ensure the data platform infrastructure and architecture supports the evolving requirements of the Data Engineering and Data Analytics teams as well as other parts of our business! You will work closely with the Director of Data Engineering to develop a strategy for our long term Data Platform architecture to identify gaps in the data processes and drive improvements while mentoring and coaching other team members. Thanks to your contributions, our data platform will continue to optimize and revolutionize. This role reports to the Director, Data Engineering.  Hello, we're A Cloud GuruOur friends call us ACG. We're on a mission to teach the WORLD to cloud. A Cloud Guru is the largest online cloud school on the planet. Our training feels more like logging into Netflix or Spotify - it's entertaining and playful. The people are the #1 reason employees say they stay at ACG. We’re a quirky, tight-knit crew that cares about our customers and each other. No egos here. Our leaders encourage thoughtfulness, compassion, being humble, and we have a bit of fun along the way.It’s an exciting time to join the team, because we’re in a really unique space. We have an amazing product that people want, and we're in an industry that's tripling in size overnight. What makes the Product & Engineering team awesome...Learning to cloud means unlocking a world of possibilities for our students. Using the latest tech, we design the tools to teach people cloud faster and better. The team is talented (and a little quirky), and we’re all in it together.Cutting edge tech. We've built a cloud-first Serverless Architecture with tools like Lambda, API Gateway, GraphQL, and ReactJSFounded by engineers. Having a CEO that is also an engineer is nice, because he knows the effort it takes to make things awesome.We're friendly. We're down-to-earth and collaborative. There's no high-performing jerks, there's no heroes, there's just great teams.We're hungry, and humble. We are dedicated to learning all the things to create the best product possible. If you're down to earth and enjoy a laugh while also working hard you'll love it here. - Joanna, Avocado to Guac Ratio Guru (and Product Manager) As a Data Engineer at ACG, you’ll get to:Be an essential part of designing and building ACG’s new data platform, as we evolve the existing databases into a cutting-edge solution to meet the needs of our 2021 data plans and beyondExplore and contribute to discussions around technologies under consideration, such as Snowflake, Kappa/Lambda architecture, Delta Lakes and Data VaultDevelop, test and maintain existing architecture, including databases, data pipelines and large-scale processing systemsCollaborate with the Analytics team on transformation processes to populate data modelsRecommend ways to improve data reliability, efficiency and quality of the data platform and optimise for performance, scalability and costDiscover opportunities for data acquisition and explore new ways of using existing dataIdentify gaps in data processes and drive improvementsCoach and mentor other team members What you bring to the tableWe focus on hiring values aligned people, because we believe the right person can learn all the things to be successful in their role. Self-confidence plays a big part in what you apply for. We encourage all job applicants to apply even if they are nervous to do so. College degrees aren't required for any roles, and career gaps or switches are totally welcome.Essential2+ years of Data Engineering, Data Warehousing, or related experience2+ years of development experience with Python or similar scripting language2+ years of SQL experience, including experience with schema design and dimensional data modellingExperience working with AWS services such as DynamoDB, Glue, Lambda, Step Functions, S3, CloudFormation or RedshiftExperience with ETL development, metadata management, and data qualityDesirableKnowledge of software engineering best practices with experience with implementing CI/CD, monitoring & alerting for production systemsExperience with complex data structures and No-SQL databasesExperience with open source orchestration platforms (e.g. Airflow) We want the people who care about doing a good job. The ones who have the humility and hunger to learn. - Sam Kroonenburg, Co-Founder and CEO More than a jobWhere you work isn’t just a career decision -- it’s a life decision. We get it. That’s why we want all of our Gurus to feel a sense of belonging that comes from feeling supported in all areas of their lives. Everyone has family, friends and interests outside of their careers, so we offer perks and benefits to make work, work better for you.4 weeks PTO, plus 10 sick days, and holidays. Whether it's hiking to a waterfall in Costa Rica or bonding with your couch, we all need downtime. All Gurus get four weeks paid time off, 10 sick days, and enough holiday to make a banker blush.Let's get lunch. Lunches are catered three times per week, and our kitchen stays stocked with a smorgasbord of the team’s most requested snacks and drinks.Parking is on us. We have your Downtown parking covered. We offer paid garage parking nearby the office. We also have perks for going green by walking and taking public transit.We’ve got you covered. We offer insurance plans that pay for 100% of your medical, dental, and vision, and 80% for your family/dependents.Gender-neutral paid parental leave. Expanding your family? We offer 12 weeks of gender-neutral paid parental leave, and reimburse up to $10,000 for eligible adoption expenses.$1,000 continuing education budget. All Gurus get $250 a quarter to spend on personal development, and 2 hours each week reserved for learning something new. Remote where?The A Cloud Guru team has grown a lot since it was just two brothers with a dream of teaching the world to cloud! We now employ gurus in 30 states of the USA as well as in Australia and the UK. For the time being that’s as far as we can go. We won’t bore you with the details, but setting up the extra operations we would need to employ people in new states or countries is a little bit more expensive than replicating your database in another AZ, if you know what we mean. So as much as we would love to have staff in as many countries as we have students, we are only opening this role to applicants in areas we currently have operations.If you’re not sure if your US state is included, please still apply! We will let you know if you are in a state that we currently don’t have operations. If anything changes we will reach back out. ﻿What’s the interview process like at ACG?Applying for a job can feel intimidating and like a full-time job of its own. You shouldn’t have to burn through a week of sick time or all your best out-of-office excuses just to put feelers out for a new career opportunity. We want to be as transparent about the process as possible to help ease your mind. It’s our goal to provide you a fair, efficient interviewing experience that respects you and your time — and to do it all with a sidecar of delight.Once you submit an application, we’ll review it. If you’re a good fit, you’ll have an initial chat with a recruiter over the phone. A phone interview with a manager typically follows. Depending on your role, you might then be asked to do a little homework (but nothing too time consuming). Then we’ll schedule a Zoom call to meet other members of the team, answer any questions you have, and give you a feel for what it’s really like to work at ACG. If you're on the fence, just give it a try.Keep being awesome, Cloud Gurus.",Intermedio,Jornada completa,"Educación, Ingeniería, Tecnología de la información",E-learning,157,None,False,,767,ACTIVELY_HIRING_COMPANY
261,2234258361,2020-11-03,Figure,Staff Data Engineer,Greater Seattle Area,"About Figure At Figure, we’re on a mission to transform financial services through blockchain, bringing speed, efficiency and savings to both consumers and institutions. Accomplishing this kind of transformation requires building really big things. And we understand that building big requires a creative, team oriented and supportive environment where everyone can do their absolute best work. The Figure team is comprised of incredibly driven, innovative, collaborative and curious people who love architecting and building from scratch. Everyone at the company is encouraged to be an individual contributor but also a team collaborator.  We value team members who bring an entrepreneurial mindset to every task and will embrace our culture of innovation. Every day at Figure is a journey in continuous learning yet a daily focus on getting work done that makes a difference.This is an opportunity to work with a team of proven leaders who have already created billions of dollars in value in the Fintech space. Join us! ** More about our recent Series C funding! http://www.figure.com/blog/series-c Here's our Blockchain Business, Provenancehttps://www.provenance.io/about/#hash About the Role Figure is excited to be growing our businesses and creating new teams. We are looking for curious, innovative and collaborative team members. Engineering is at the heart of the action, building out our blockchain protocol and direct to consumer products that will transform the financial services industry. Everything is from scratch development and every engineer has a big impact on the team and the growth of the company.  As part of our Data Engineering team, you’ll work closely with various business functions to understand Figure’s analytic, data science, and reporting needs and to develop data products that address those needs. You will be contributing to data engineering’s vision and development from day one. This team has an incredible engineering challenge: integrate very large datasets that outline intricate details about consumers’ credit profiles and real estate holdings, expose those datasets to data scientists in a way that enables their ML and modeling efforts, and shape those models into scalable, production-quality processes. In addition, the team provides the foundations for internal analytics and for internal and external reporting by transforming data from Figure applications and external vendors into clear data models. What You’ll DoLeverage Spark, Airflow, Google Kubernetes Engine, BigQuery and other tools to build robust and efficient data pipelines.Expand and optimize our data and data pipeline architecture, as well as optimizing data flow and collection for cross-functional teams.Collaborate with project leads and other software engineers across multiple teamsWork on data software solutions that will transform the consumer lending and blockchain spaceBe a leader, use your voice, apply your tech skills to solve real world problems What We Look ForBS degree in Computer Science or related technical field, or equivalent practical experience.6+ years of proven working experience as a data engineer3+ years’ experience with Spark, either in Python or in Scala. Bonus points for Spark on EMR, Dataproc, or Kubernetes.Working knowledge of Google Cloud tools (compute, cloud storage, GKE, GCR, AutoML, etc.)  Expertise building and optimizing data pipelines using Kafka (preferred), Kinesis, or other event bus.Deep experience with data frameworks and tools like Spark, SparkML, Spark Streaming, Apache Beam, and Airflow.Comfort with and experience working within CI/CD processes and tools and software development practices.Experience with production machine learning workflows and processes.Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of SQL and NoSQL databases, including BigQuery (preferable), MySQL/MariaDB, Postgres or Cassandra.Expertise in data modeling for data science, reporting, and analytics, including dimensional and transactional models. Nice to have: experience building real-time transformations and learning models on streams.Ability to thrive in a fast-paced growing company. Benefits To YouCompetitive salaryFirm-wide performance based bonusCompetitive stock options packageA flexible paid time off and vacation policyComprehensive health, vision, dental insuranceCompany FSA, 401k, commuter benefitsAnd much more to come! Figure will NOT sponsor work visas for this position. In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification form upon hire.",Intermedio,Jornada completa,Finanzas,Servicios financieros,14,None,False,,186,ACTIVELY_HIRING_COMPANY
262,2234501300,2020-11-03,"IDR, Inc.",Associate Data Engineer,"Boston, Massachusetts, United States","Associate Data EngineerIDR’s client is seeking an Associate Data Engineer to join their North American team. This position will be 100% remote. Candidates located in Eastern & Central time zones are required, candidates not in these time zones will not be considered at this time. Responsibilities of the Associate Data Engineer include:Collaborate with their team to create enterprise-scale solutions to meet client needsDevelop & configure data pipelines, factoring in synergies with data pipelinesDemonstrate strong written and verbal communication Required Skills/Experience of the Associate Data Engineer:5+ years of extensive Data Engineering and data modeling experienceExtensive experience with AWS or Azure Bachelor’s degree in IT or Computer Science or equivalent educational/professional experienceProficiency with data processing technologies such as Databricks & SparkExperience utilizing KafkaAbility to work within Azure Data Factory (ADF) and with data lake implementation(s).Experience with version control and Github integrationRequired knowledge of various query languages including Pl – SQL, PostgreSQL, and T – SQLPrevious experience in building data marts, warehouses, customer profile databases, etc.Additional experience using Cosmos  What’s in It for You?Join a flexible, friendly, laid back work environmentEnjoy extremely competitive compensation and benefits packageEnjoy true work/life balanceJoin an extremely secure organization that offers job stability Why IDR?20+ years of proven industry experience in major marketsEmployee Stock Ownership ProgramDedicated Engagement Manager who is committed to you and your successMedical, Dental, Vision, and Life InsuranceClearlyRated’s Best of Staffing® Client and Talent Award winner 6 years in a row",Algo de responsabilidad,Contrato por obra,Tecnología de la información,Servicios y tecnologías de la información,106,None,True,,313,ACTIVELY_HIRING_COMPANY
263,2275639203,2020-10-10,Cloudbeds,Data Engineer (Remote),"London, GB","Cloudbeds is a travel SaaS technology company that works to make the world a more welcoming place. Heavily leveraging Amazon Web Services (AWS), we build advanced cloud-based hospitality software for hotels, hostels, vacation rentals, and groups that manages reservations and guests, distributes room availability, sells inventory, and collects payments. Our hundreds of team members are globally distributed across over 40 countries and, altogether, we speak 20+ languages. How do we do it? On a #remotefirst platform that allows every member of our team to work from wherever they are around the globe. We’re looking for people who want to disrupt the travel industry and love to travel as much as we do.  As a Data Engineer at Cloudbeds, you will implement our company-wide data strategy across all teams and departments to deliver a best in class data experience to our customers and partners in over 150 countries, as well as internally within Cloudbeds. You will work closely with our Business Intelligence, Reporting, and Infrastructure teams to progress and optimize our data lake architecture and drive the data transformation lifecycle to process terabytes of platform and industry data from multiple databases and origins in an automated and serverless fashion. The right candidate will be very experienced using Amazon Web Services (AWS) tools enabling data lake, warehousing, and processing capabilities. As a Data Engineer at Cloudbeds, you will have endless opportunities to innovate and drive the industry leading, comprehensive, and global data experience for travel.  Location: Europe (Remote)  What You Will Do:  Code ETL data transformations in PySpark/Spark.Design and manage processing pipelines via AWS Glue and/or EMR clusters.Manage ingestion and replication via DBMS from cloud MySQL databases.Process external sources like Salesforce via Appflow or kaggle datasets.Manage AWS Athena views and endpoints for consumption.Creation, modification, and maintenance of data infrastructure (Redshift [with Spectrum], S3 Parquet data, DBMS, Notebooks, etc.)Implement logging and debugging approaches in a standardized fashion.Collaborate with Business Intelligence, Analytics, and Infrastructure teams on a daily basis.Develop a framework for future extensions through standardized modern workflows. You’ll Succeed With:  Bachelor’s degree in computer science or related field, or equivalent experience.3+ years experience as a Data Engineer.2+ years experience working with Amazon Web Services.Expert knowledge and experience developing efficient ETL data pipelines having multiple sources using PySpark/Spark and DataFrames.Strong knowledge and experience developing workflows with AWS Glue, EMR, Redshift, Athena, and LakeFormation.Strong knowledge of modern data lake, data warehousing, and ETL/ELT concepts.Strong knowledge of how to compose and implement structural data models.Experience molding fresh environments into efficient mature data platforms.Experience with performance optimization for processing and storage via data partitioning and indexing techniques.Ability to take a consultative approach to data strategy.Ability to work in an Agile Scrum environment.Ability to thrive in a fast-paced environment.Ability to work remotely and manage your own time in an international team.Exceptional written and verbal communication in English.  Our company culture supports flexible working schedules with an open PTO policy and the opportunity to travel and work remotely with great people. To make it easy for our team to travel we offer 2 corporate apartment accommodations near our San Diego and Sao Paulo offices. At Cloudbeds we dedicated to your personal and professional development. You will have access to over 10,000 courses within LinkedIn Learning when you join our team for your unique individual growth! If you think you have the skills and passion, we’ll give you the support and opportunity to thrive in your career. If you would like to be considered for the role, we would love to hear from you!  Company Awards to Check Out!  Best Startup Employers in 2020 | ForbesBest Places to Work | HotelTechReport (2018, 2019, 2020)Deloitte’s North America Technology Fast 500 (2019)Inc. 500 Fastest Growing Companies (2018 & 2019) Inc. Best Places to Work (2017 & 2018) Best Places to Work | Inc Magazine (2017 & 2018)Start-Ups to Watch in 2018 | ForbesConnect MIP Award (Technology) Powered by JazzHR  FqstiHuKS2",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Internet",4,None,True,,42,ACTIVELY_HIRING_COMPANY
264,2246310746,2020-11-04,Confidential,Data Scientist,"Hartford, Connecticut, United States","Greymattertech, Corp is a leading boutique consulting & Staffing organization at the intersection of Industry, Technology and all things digital.   One of our clients is looking for:   Data ScientistLocation: Hartford CT / RemoteDuration: 6-12 months Job Description: • Significant hands-on industry experience in data science  • Experience with machine learning.• Experience in one or more of: natural language processing, deep learning, geospatial, or time series analysis.• Perform large-scale data analysis on cloud-based data platforms • Expertise in AWS or Google cloud preferred.• Expertise in SQL/databases and/or Hadoop/Spark.• Expertise in Python and associated data analysis libraries. • Linux Environment background• GIT & Jenkins knowledge• Data Sourcing, Data Manipulation, Data Pipeline, strong data analytics background • Strong communication skills and customer management skills.",Ejecutivo,Contrato por obra,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Atención sanitaria y hospitalaria",86,None,True,,290,COMPANY_RECRUIT
265,2243522625,2020-11-04,Creation Recruitment,Senior Data Scientist,"London, England Metropolitan Area","Senior Data Scientist BioTech Company Remote Competitive salary, share options and benefits As a central member of a dynamic, multi-disciplinary team of scientists passionate about reinventing the way new medicines are developed, you will bring your deep understanding of data science to enhance of ability to perform key research, data visualisation, insight gathering and decision making from big data and real world evidence. Your work with experts in artificial intelligence, deep learning, informatics, statistics, drug discovery and clinical translation/commercialisation will enable us to discover robust clinical insight that will ultimately make a difference to the lives of patients across a range of therapeutic areas. How you'll help:·        Perform robust data analysis and communicate results with sophisticated visualisation methods·        Create and implement statistical & machine learning algorithms, assessing their effectiveness through solid validation workflows·        Clinical project support to guide decision making and create analytical solutions to address questions of interest to our pharma stakeholders.·        Assisting with the publication of scientific papers and abstracts Requirements:·        Advanced degree in an applied quantitative field statistics, biostatistics, mathematics etc.)·        Expertise with the analysis of clinical data and the support of projects within Life Sciences·        Knowledge of data science, machine learning and visualisation.·        Proficiency with programming and scripting languages (R/Python)·        Ability to work independently and effectively in a fast-paced, team-based environment: project management and coordination skills: ability to prioritise tasks and meet multiple deadlines on concurrent projects·        Experience working with clinical data and/or working in the biomedical field is highly desirable·        Excellent verbal and written communication and presentation skills: excellent organisational skills: and excellent interpersonal skills to work effectively in a diverse team·        Experience in any of these is a plus: SQL, NoSQL, Shiny, Graph database, Knowledge Graph, Tidyverse",Intermedio,Jornada completa,"Tecnología de la información, Investigación",Biotecnología,61,None,True,,182,ACTIVELY_HIRING_COMPANY
266,2249359784,2020-11-05,Propel,NLP Data Scientist - Remote,United Kingdom,"This is an exciting opportunity of a Data Scientist with a passion for NLP to join analytics focused Health tech business that is looking to provide a social good.Having recently received series A funding this HeathTech Business is looking to invest heavily in its data science and software engineering function. This is a fantastic opportunity for an NLP expert to join the team and help deliver on the build of a greenfield project that provides a social good. As an NLP data Scientist you will work in a collaborative team to: Improve the NLP capabilities of the company’s core productEmploy Techniques such as topic analysis, sentiment analysis, named entity recognition and more!Work in an agile development team to collaborate with developers data scientists and product managers.Be involved in the full data science lifecycle from design to testing and Launch. About you: Strong knowledge of Computational Linguistics, NLP and Machine learning rule based systemsIdentify the bets NLP techniques to deliver experiments on Large volumes of social media data.3 Years commercial NLP development experience. If you would like to apply for this NLP Data Scientist vacancy please email jake.kings@propel-together.com",Intermedio,Jornada completa,"Tecnología de la información, Ciencias",Dotación y selección de personal,101,None,True,jake.kings@propel-together.com,339,JOB_SEEKER_QUALIFIED
267,2186312956,2020-10-21,People Tech Group Inc,Data Engineer,"Seattle, Washington, United States","Job Title: AWS Data EngineerJob Location: Bloomfield, CT# Positions: 3Candidate Constraints: Advanced AWS experience is a MUST for this req. Client is hungry for Sr.-level AWS/hands-on engineering talentDuration: Long-termWork Eligibility: All Work Authorizations are Permitted - No Visa Transfers Key Technology: AWS Glue, Terraform, S3, Redshift, SNS, SQS, Lambda, EMR Salary: DOE. Job Responsibilities:Design and support the database and table schemas for new and evolving sources of data being brought into the data warehouseCreate and support the Analysis ServicesMonitor and troubleshoot performance issuesDefine and promote the team’s design principles and best practicesWork with business teams to be able to define requirements for real time reporting Skills and Experience Required:Required:7+ years of experience in IT as a Data Engineer (10+ strongly desired)AWS experience: Glue, Terraform, S3, Redshift, SNS, SQS, Lambda, EMRExperience with the following: Python, Hadoop, Hive, and Spark (either Pyspark or Scala)-------------------------------------------------------------------------------------------------------------Data EngineerLocation – Redmond, WADuration – 12 months Work Experience9 + years development experience.7+ of SQL Server development experience writing complex stored procedures, triggers, views, etc.Strong understanding of BI areas. Ability to work in large, complex development BI projects including the proactive identification of issues and coordination of resolutions.Expertise in T-SQL, DW Concepts, Tabular Cube.Experience with Power BIStrong Analytical and troubleshooting skillsExcellent coding and debugging skills.Able to work independently to implement a solution with minimal guidance.Ability to communicate with Business and developers accordingly.Strong communication skills in both written and spoken English.Working knowledge on Cosmos / Big Data Platforms (Azure, Databricks) is recommended.Excellent communication skills and ability to work under continual deadline constraints are necessary------------------------------------------------------------------------------------------------------------- Role: Snowflakes DeveloperLocation: Seattle WADuration: Long term Job description:Snowflake SQL Writing SQL queries against Snowflake Developing scripts Unix, Python etc. to do Extract, Load and Transform data 3+ years of experience in Data management (e.g. DW/BI) solutions.Min 4 years of exp with Azure & AWS ( Data Analytics tools)Hands-on experience with Snowflake utilities such as SnowSQL, SnowPipe, Python, Tasks, Streams, Time travel, Optimizer, Metadata Manager, data sharing, and stored procedures.In-depth understanding of Data Warehouse/ODS, ETL concept and modeling structure principlesExperience in Data warehousing - OLTP, OLAP, Dimensions, Facts and Data modeling.Experience gathering and analyzing system requirementsGood working knowledge of any ETL tool (Informatica or SSIS)Good to have familiarity with data visualization tools (Tableau/Power BI)Proven analytical skills and Problem-solving attitudeStrong interpersonal, written and verbal communication skillsAbility to effectively function in a cross-team’s environmentUnderstanding of Insurance domainGood to have exposure to AWS / Azure Data eco systemMust have good knowledge of architecting and implementing very large scale data intelligence solutions around Snowflake Data Warehouse. ------------------------------------------------------------------------------------------------------------Data EngineerSeattle, WALong Term Primarily looking for someone with Accounting/Finance domain experience 5+ years of relevant work experience with ETL development, data modeling, data warehousing and applying analytics Experience with SQL using databases like MySQL, Redshift or similar Experience in data visualization tools using Excel, Tableau, Quick Sight, Power BI or similar Experience with Python, R, VBA, or other automation-focused languages Excellent data presentation skills and demonstrated ability to successfully partner with business and technical teams Experience in gathering requirements and formulating business metrics for reporting.",Intermedio,Jornada completa,Tecnología de la información,Servicios y tecnologías de la información,105,None,True,,491,ACTIVELY_HIRING_COMPANY
268,2249371035,2020-11-05,Aderant,Data Scientist,"Atlanta, Georgia, United States","Global provider of market leading solutions. Dynamic team culture. Competitive bonus programs. Collaborative cross-functional teams. World class benefits. Challenging and Rewarding work. At Aderant, we power the world’s leading law and professional services firms. We focus on delivering world class products and services which are developed, marketed, sold, and supported by superior talent. The expertise and talent of our people have made us the largest independent provider of law firm technology in the world, and our people will drive our success in the future. About Aderant’s Data Services. Aderant is launching a new business that leverages data to provide transparency, insights and improvements in efficiency. Be a part of a brand new, highly collaborative team whose mission it is to bring innovation to the industry.As a Data Scientist, you will have the opportunity to be part of a new team and bring new and innovative insights to law firms globally, leveraging data about cases, timekeeping, financials and other operations. Your work will impact all members of the law firm from lawyers to the finance department.  ﻿Responsibilities:Applying data mining techniques and statistical analysis to large amounts of internal data that has historically been highly underleveragedConsulting and building the ideal data environment that will enable data insights to be delivered in reports and fully integrated modules within productsWorking with product and cloud operations teams to determine how best to utilize resourcesLeverage machine learning and NLP technology to develop sophisticated data modelsEnhancing data collection procedures to include information that is relevant for building analytic systemsProcessing, cleansing and verifying the integrity of data used for analysisConducting ad-hoc analysis and presenting results in a clean, clear and actionable mannerCreating automated anomaly detection systems and constant tracking of its performance Skills & Requirements:A Master’s degree or foreign equivalent in: Applied Mathematics, Statistics, Economics, Data Science, Information Systems, Computer Science or other relevant degreeExperience using statistical data analysis techniques on business projectsExperience working with large, complex data sets, normalizing and building training sets and modelsExpertise in translating strategic questions into tactical work plans and outputsUsing advanced machine learning techniques to combine and compare large data setsExperience with common data science toolkits, such as R, Python, Weka, MatLab, etc. Experience with data visualization toolsProficiency in using query languages such as SQLStrong applied statistics skills, such as distributions, statistical testing, regression, etc.Strong scripting and programming skillsExperience with machine learning and NLP techniques and algorithms a plus",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información, Consultoría","Software, Servicios jurídicos",68,None,False,,242,ACTIVELY_HIRING_COMPANY
269,2213040324,2020-10-26,Horizontal Talent,Data Engineer,"Austin, TX, US","Description  We are seeking a Data Engineer who is eager to tackle the challenges of processing vast amounts of EHR data originating from multiple sources.  You will need to develop a deep understanding of the data and drive efforts to maintain and improve data quality and usability.  You should understand the importance and value of writing maintainable, documented, and well-tested code throughout the entire product lifecycle.  Above all, you should be curious about what is possible in healthcare with the right tools and infrastructure.   Projects The Candidate Will Be Working On  Combine two of the fastest-growing fields on the planet with a culture of performance, collaboration and opportunity and this is what you get.  Leading edge technology in an industry that’s improving the lives of millions.  Here, innovation isn’t about another gadget, it’s about making health care data available wherever and whenever people need it, safely and reliably.  There’s no room for error. Join us and start doing your life’s best work.(sm)   Primary Responsibilities  Design and maintain data pipelines and services using best practices for data management and governance  Deploy machine learning and NLP applications in production  Work with EHR data across teams with ETL, NLP engineers and data scientists, researchers and clinicians to provide data services with high data quality control standard  You’ll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in   Team And Team Size  Small core NLP Team  13 core team members (data scientists, project manager, medical informaticists) with support from  12 clinical annotators integrated into the team via vendor contractor   Top Responsibilities  Programming experience, including solid Python experience, following software engineering best practices  Experience building and maintaining data pipelines and data assets  Experience with distributed data processing frameworks such as Spark or MapReduce  Experience as an individual contributor, hands-on developer, non-manager role executing on engineering projects as a primary job responsibility  Demonstrated knowledge of data management best practices  Prioritization skills: ability to manage ad-hoc requests in parallel with ongoing projects   Software Tools/skills  This data engineer will be maintaining, and if necessary re-architecting our data pipelines that ingest notes from a bunch a text files delivered to us on a share drive, move then over to HDFS, do some normalization (convert HTML to plain text, etc) and load them into Hive tables  Sqoop some CDR tables (like MDM) from Oracle  Schedule and run various NLP “apps” developed by data scientists  This is someone that will interface with the ProdOps team (for example, they are the ones delivering to us the notes as text files), with the CDR BE team (NLP2Panther) and others such as dCDR and Life Sciences engineering.  Someone that will also be responsible for good data management practices (for example to make sure we can efficiently retire data from H-groups that need to be retired).  Currently the main technologies we are using are Spark, Hadoop, Hive, Luigi, Python (and a little bit of Scala) and the platform we use is the on-prem Hadoop cluster. We need to make sure the candidate is solid with at least some of these technologies, and follows good engineering practices (such as testing, code reviews and putting in place monitoring systems like dashboards or alerts).  Additional skills that would be good to have: cloud (since there is push for OA to move to AWS, nothing says we will stay forever on the on-prem cluster), and Elasticsearch (we need to build and keep up-to-date Elastic indices to allow users external to our group to search the notes).  Familiarity with containers might also be good to have.   Skills/attributes  Python  Spark  Data pipeline experience  Preferred Qualifications:  Experience running machine learning or NLP applications at scale Experience with data pipeline frameworks such as Airflow, Luigi or Oozie Experience with search engines (Elasticsearch or Solr) Experience with cloud-based computing (AWS or Azure) Experience with Scala, in particular with Spark Scala API Familiarity with EHR data and standards (HL7 or FHIR) Experience with HBase or other non-relational data bases Experience with code and process documentation Experience with explaining, educating, presenting and/or training non-engineers on engineering concepts and processes Experience with continuous integration and delivery Experience with ETL  ,",Sin experiencia,Jornada completa,Tecnología de la información,"Marketing y publicidad, Servicios y tecnologías de la información, Software",217,None,True,,705,ACTIVELY_HIRING_COMPANY
270,2220582542,2020-10-28,Enilon,Performance Marketing Manager - Remote,United States,"Hi there! We’re looking for an experienced multi-channel performance leader with a deep executional understanding of marketing analytics. Your background will be critical as we continue to tie our programs to real numbers. Be prepared to demonstrate your in-depth knowledge of Google Analytics, Tag Manager, Facebook ads and Data Studio during the interview process. Your expertise and knowledge will drive several key areas of the business with an exciting mix of leadership, management, and hands-on work. You will be instrumental in helping us bring our solutions together in a single story for our clients based on data and real insights.Hands-on work leveraging your experience to directly generate and implement innovative analytics strategies across our programsManagement and oversight of our performance group including SEO, Paid Media, Analytics, and Performance StrategyLeadership responsibilities include fully understanding our business, representing the performance group, and helping to create and implement growth & scale strategies The ideal candidate will have 3+ years working with campaign-level digital marketing data, have a solid understanding of tagging, and a robust analytics skill-set. You don’t need to be a data scientist but you should know Google Analytics, Tag Manager, and Data Studio like the back of your hand. About Enilon:Enilon is a work-from-anywhere digital marketing agency headquartered in Fort Worth, TX and founded in 2005. We take our work seriously and partner with our clients to deliver data-driven, consumer focused digital programs. About You: What motivates you:You are a deductive thinker. A self-starter and get stuff done. You know SMB and enterprise customersYou’re a big picture thinker who also loves getting down in the details. You’re able to set the strategic agenda to help our clients win over the long term You’re well-versed in established multi-channel marketing goals, assets, and deliverables. You are comfortable with complex challenges ranging from testing new channels and attribution to driving campaigns across the full funnelYou’re a problem solver at heart. You are a hypothesis-driven problem solver who tests theories with data and quickly identifies levers/sources of valueYou’re committed to being an excellent teammate. You are a positive change agent who is highly accountable and moves things forward About the position expectations: 25% | Management and team oversightBeing the trusted expert for your groupBringing a vision for what your team needs to learn and grow and making that a reality. Inspiring greatness   Fostering a team approachRecruiting both employees & contractors as neededOnboarding & training team membersDelivering performance evaluations and growth plans for each team memberResolving escalated issuesCreating effective relationships with clients, team members, and vendors.Negotiating contractor rates as needed 50% | Hands-OnWorking closely with our clients to present the holistic performance story, to listen and understand their business intricacies and goals, and how those insights relate back to our campaigns for evolved performance strategiesTying complex, multi-channel programs into stories for our clients and team to create actionable insightsEnsuring quality control for all performance deliverables. This includes reviewing your team's reports, deliverables, and resultsManaging $300K/mo in media budgets with a diverse portfolio including B2B and B2C clients in varying industriesProficiently using optimization and measurement tools and techniquesWork hands-on daily with platforms and data integration including CRM, marketing automation, 3rd party data sources, Instagram, LinkedIn, Google Search, Google Analytics, Google Tag Manager, Google Display, and other related toolsWorking both directly with clients as well as other Enilon team members (Client Partnerships, Project Management, Operations, Sales, etc.) to clearly understand client goals and business in order to formulate effective plansReporting channel performance to client team and forecast paid search growth and conversion opportunity 25% | Leadership ResponsibilitiesContinuing to drive and enhance the vision of our performance delivery groupDriving impact in a fast-paced agency environment while juggling multiple accounts and priorities effortlesslySelling ideasPassionately advocating for performance and creating a team-oriented cultureDemonstrating excellent business judgment, problem-solving, and analytical skillsEstablishing best practices for the performance group and optimize processesPromoting our “Difficult. Done.” culture. You are scrappy and can navigate constraints with a positive attitude and creative thinkingEncourage cross department collaborationManaging department budgets and P&LAdvising, innovating, and managing our tool set and platformsDriving innovative strategy and operative management of individual channels like paid search, social ads, display, SEO, and affiliate marketingConstantly learning and remaining on top of industry trends and best practices Your experience:Bachelor’s degree, with coursework in related area (marketing, data science, advertising, business, technology)3-5 years of hands-on Google Analytics, Tag Manager & Data Studio experience across multiple industries and appropriate certifications1-2 years of hands-on experience managing a combination of PPC and Display campaigns and bringing them together with dataAbility to analyze a wide variety of performance metrics including PCP, CPA, CPL, and conversionExperience working with full digital programs including Digital Strategy, Analytics, SEO, Paid Media, Content, and Website Design & DevelopmentExperience working in collaboration with account and project managersStrong interpersonal, written, and verbal communication skillsAbility to work effectively and lead in a cross-functional dynamic team environmentAbility to maintain a positive, professional demeanor at all timesStrong attention to detailAbility to work autonomously in a remote working environmentYou must have a reliable home-office or remote working space available for focused work and video conferencingPrevious remote working experience preferred Benefits and Culture:Work from anywhere in the U.S.Competitive payExcellent Health Benefits. Benefits start the first day of the month after the hire dateMatching 401k up to 4%10 Paid holidays per yearUnlimited PTODaily dedicated “do not disturb” time for everyoneStrong Life/Work balance philosophy How To ApplyIf you are interested and meet the requirements above, please click the link below to apply. You will be asked to fill out a 2-question survey and then upload your resume. portal.cultureindex.com/public/survey/general/AA6F270000",No corresponde,Jornada completa,"Marketing, Publicidad",Marketing y publicidad,22,None,False,,248,ACTIVELY_HIRING_COMPANY
271,2192262059,2020-10-19,LineTen,User Experience Researcher,"London, England, United Kingdom","We have an exciting opportunity for a UX Researcher at LineTen, to join our Product Team. *LineTen is a remote working company and everyone is eligible for share options* You will be someone who loves to work on challenging design problems and collaborate with product teams to ensure our customers have delightful experiences across all our products. Our products help businesses to capture online orders, to receive them in their POS system, and to book deliveries to their customers. Summary of UX Researcher Position: You will be responsible for leading and conducting user and business research activities to understand business requirements, user behaviour and optimal UI design, while also encouraging research-based product development throughout the business. In this role you should be an analytical and creative researcher who is able to grasp user needs and solve problems. A strong portfolio of successful UX and other technical projects is essential.Ultimately, you will make our products serve the needs of our customers better, through user-friendly and intuitive software that attracts and retains them. Responsibilities include: Collaborating with Product Owners, Designers and Developers to create intuitive, user-friendly softwareUnderstanding user and business needs, competitor products and industry trendsMentor and guide others and work to continuously improve the research processUnderstand product specifications and user psychologyConduct concept and usability testing and gather feedbackCreate personas through user research and dataDefine the right interaction model and evaluate its successDevelop wireframes and prototypes around customer needsUse analytics and other data points to drive evidence-based design and developmentFind creative ways to solve UX problems (e.g. usability, findability)Work with UI designers to implement intuitive, effective designsCommunicate design ideas and prototypes to developers Requirements: Proven experience as a UX researcher / designer or similar roleStrong portfolio of UX developmentsFamiliarity with interaction design and information architectureProficient in design and prototyping software (e.g. Figma, Balsamiq)Problem-solving aptitudeAnalytical mind with a business acumenExcellent communication skillsUX qualifications desirable LineTen is building a global, data-driven parcel delivery network. We connect a growing list of delivery providers to a likewise growing list of retailers to increase route density for delivery providers and shipping options for retailers and their customers. Due to continued demand, we are seeking to double in size over the next 12 months to 140 employees, creating excellent career opportunities for all who join us. Due to continued demand, we are seeking to double in size over the next 12 months to 140 employees, creating excellent career opportunities for all who join us.",Intermedio,Jornada completa,Tecnología de la información,Logística y cadena de suministro,136,None,False,,853,None
272,2220703108,2020-10-28,Applause,User Experience Researcher (India-based freelancer),India,"Usability studies are an Applause core service offering where we provide user feedback and UX studies to our customers. There are upcoming projects in India and we are currently looking for a UX Researcher who is a native or near-native speaker and living in-country or very familiar with the country.  Role: UX Researcher (freelance)Location: Remote, but local in-country IndiaLanguage: Native Hindi: able to communicate effectively in EnglishDuration: Long term, open-endedCapacity: Variable, demand-based hours Responsibilities:Defining, planning and conducting user researchDelivering compelling insights to the Product and Design teamsProviding actionable feedback to guide Product and Design decisionsDeveloping, innovating and evangelizing user research best practices Qualifications:1+ years in a Usability Research role or relevant professional experienceFormal education in user experience or similar work experienceBroad experience in qualitative research methods, especially remote and unmoderated methodsComfortable with metrics: able to synthesize quantitative data with qualitative user researchProficiency in planning, scoping, conducting, analyzing and communicating researchEffective communicator able to work in native language and EnglishVery collaborative with a demonstrated ability to work effectively in a dynamic and creative environment",Intermedio,Media jornada,Tecnología de la información,Servicios y tecnologías de la información,280,None,True,,919,ACTIVELY_HIRING_COMPANY
273,1969993615,2020-08-17,广州市英睿纬企业管理咨询有限公司,Associate Consultant (Researcher),"Guangzhou, Guangdong, China",工作职责：· 根据Leader制定的目标人选搜索方案，通过各个渠道搜寻候选人，并专业地进行第一轮电话面试筛选；· 协助Leader对行业职能市场信息进行收集并及时反馈，保证工作效率及有效性；· 安排及协调候选人与客户公司的面试；· 紧密跟进候选人端，严谨地控制招聘进程。 任职要求：· 性格积极主动，对结果及任务导向的专业工作充满热情；· 全日制本科或以上学历（条件优秀者，可放宽至大专），1年以上客服/猎头/销售的工作经验；· 勤奋踏实，认真负责，具有团队精神，能在压力下完成任务；· 喜欢在互联网上搜寻及获取新资讯，有快速学习能力；· 良好的沟通技巧及英语能力。 机会特点：· 我们的核心团队都来自于跨国顶尖猎头公司，专业扎实，并且具有很强的团队精神；· 我们由Leader亲自带您，提供全方位专业的培训，同时需要您真正具备快速学习的决心及任务导向的责任感，因为我们的客户对我们有更严格的要求；· 我们会有定期的sharing，工作气氛积极向上。,Algo de responsabilidad,Jornada completa,Recursos humanos,"Consultoría de estrategia y operaciones, Recursos humanos",41,None,True,,449,JOB_SEEKER_QUALIFIED
274,2222403224,2020-10-30,Masentó Group,Senior Data Engineer - GCP,"London, England Metropolitan Area","Masentó is working with a media organisation that are looking for a Senior Data Engineer to join their team on a 6 month contract based in central London/remote. You will work closely with Commercial and Analytics stakeholders across their brand to deliver data capabilities aligned with their business objectives. You will be responsible for:Designing and building the appropriate data schemas and data martsImplementing end to end ETL data flows - either transforming existing data within the warehouses or creating new pipelines Experience required:Extensive SQL experience as a primary ETL tool, experience in Python to use Airflow, ComposerStrong experience in data warehousing and Business Intelligence in an enterprise setting to drive commercial growthAble to use Data modelling techniques like dimensional modelling for the creation of data marts and conformed dimensionsExperience working with cloud based data warehouses and other cloud based technologies, preferably GCPExperience working with digital advertising from 3rd party providersMedia, publishing or related industry experienceExcellent communication skills",Intermedio,Contrato por obra,Tecnología de la información,Dotación y selección de personal,52,None,True,,219,JOB_SEEKER_QUALIFIED
275,2291139646,2020-10-14,The Knot Worldwide,Data Scientist,"Washington, D.C., DC, US","WHAT WE DO MATTERS:  Here at The Knot Worldwide, we believe in doing work that matters. In 15 countries around the world, our leading family of brands (The Knot, WeddingWire, Bodas, GigMasters, The Bump, How They Asked, Lasting, and more) inspire, inform, and celebrate our communities as they move through life's milestones. From the proposal to creating a home, and starting a family together, we're there for every step of the journey. Our couples and business partners depend on us. They're all in. So are we.  ABOUT THE ROLE AND OUR TEAM:  The Knot Worldwide is in search of a full-time Data Scientist. Our Data Scientists work with stakeholders across all departments within the company. They answer strategic questions and provide insight to internal decision makers ranging from executives and senior management to product managers and team leads. They also work with our product team to develop data driven algorithms that improve features on the website.  This opening is for our Marketplace zone which connects over 2 million engaged couples with +50,000 local wedding vendors (e.g. Venue, DJ, Florist, etc.) across the US each year. This position plays an essential role in solving complex problems across our two-sided marketplace in areas such as pricing, product strategy, and go-to-market optimization.  RESPONSIBILITIES:   Create smarter product solutions for our couples and vendors Answer strategic questions by analyzing behavioral data Communicate, collaborate and present results to clients within The Knot Worldwide Explore novel ways to look at our data  SUCCESSFUL DATA SCIENTIST CANDIDATES HAVE:   Master's Degree or Ph.D. preferred Experience implementing auction based business models Strong product experience Proficiency in key statistical and machine learning techniques (predictive modeling, classification, clustering, text analytics, recommender systems , data mining methods, forecasting, and other advanced techniques) Proficiency with R or Python Familiarity with common Linux command line tasks and version control software like git or svn preferable Ability to communicate effectively and influence others Ability to work in a fast paced environment and shift gears quickly  At The Knot Worldwide, we believe you are more than a resume and invite you to go for it, take the leap of faith, and apply for this job if it sparks your passion to join TKWW and make a difference!  WHAT WE LOVE ABOUT YOU:   You Dream Big. You iterate and experiment to drive innovation. You Love Our Users. You keep our global community at the center of everything you do. You Respect All Voices. Inclusion strengthens us and powers your decisions. You Hustle Every Day. You favor urgency and own your outcomes.  You Win Together. People are at the heart of our success and you play as a team.  WHAT YOU LOVE ABOUT US:  The Knot Worldwide offers a unique employee experience and we are deeply proud of our award-winning culture. From flexible vacation and generous parental leave benefits to promoting wellness and giving back to our community, we believe in happiness above all else—in and out of the office.    The Knot Worldwide provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, or disability. In addition to federal law requirements, The Knot Worldwide complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. The Knot Worldwide expressly prohibits any form of workplace harassment based on race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, genetic information, disability, or veteran status.  --  This position is not eligible for sponsorship.  --  If you are a resident of California, by submitting your application, you acknowledge that you've read the California Privacy Notice.",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Marketing y publicidad, Software, Internet",0,None,False,,2,ACTIVELY_HIRING_COMPANY
276,2203319040,2020-10-22,RED SKY Consulting,Data Engineer,"Lincolnshire, Illinois, United States","Data Engineer  ﻿Location: RemoteJob Type: Direct Hire (Full-Time)   Bottom Line / In a Nutshell:  4+ years of experience in Data Platform Administration/Engineering. Hands on experience with AWS based solutions such as EMR, S3, RDS, Lambda, Dynamodb, Redshift, EC2.Experience and tools/frameworks within the Big Data ecosystem: experienced in Agile methodologies. Proficiency in one of the scripting languages such as Shell/Python/Scala/Java.Good understanding of Big Data technology trends, with knowledge of technologies such as Kinesis, Kafka, Spark, Hive, pySpark.Experience in version control systems such as Git, GitLab, etc.Ability to work in a fast-paced, rapidly changing environment. 1+ years of experience using Cloud technologies and AWS Cloud Services certificationExperience with Analytical/Reporting Solutions like Alteryx, Tableau, PowerBI  Overall:  Understands best practices in software engineering, data management, data storage, data compute, and distributed systemsApply cloud-based AWS services to solve challenging problems around big data processing, data warehouse design, and BI self-serviceFocuses on automation and optimization for all areas of DW/ETL maintenance and deploymentComfortable with a degree of ambiguity and willing to develop quick proof of concepts, iterate and improve. Comfortable presenting findings to leadershipDesign, develop, and operate highly scalable, high-performance, low-cost, and accurate data pipelines in distributed data processing platforms with AWS/cloud technologiesAdopt next-generation data architecture strategies, proposing both data flows and storage solutionsCollaborate with Engineers and Scientists in the organization to construct complex data sources for algorithms and machine learning modelsBuild, analyze and present actionable data to drive marketing business development and product management decisionsKeep up to date with big data technologies, evaluate and make decisions around the use of new or existing software products to design the data architectureCollaborate with Business Intelligence Engineers to recognize and help adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation Qualifications: 4+ years of experience with and detailed knowledge of data warehouse technical architectures, data modeling, infrastructure components, ETL/ ELT, reporting/analytic tools and extracting value from large datasetsExperience with Big Data technologies e.g. Hadoop, Hive, Oozie, Presto, Hue, Spark, Scala and solutions in AWS/AzureProficiency in Python or other similar languagesStrong understanding of scaling, performance and scheduling, batch and streaming data architectureKnowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operationsExperience on data platform re-architecture projects or handling operational excellence in DW via automationExperience communicating with management as well as with colleagues from engineering, analytics, and business backgroundsStrong technical and analytical aptitude: Excellent oral and written communication skills Education:Bachelor's degree in computer science, engineering, mathematics, or a related technical discipline",No corresponde,Jornada completa,Tecnología de la información,Servicios y tecnologías de la información,51,None,True,,183,ACTIVELY_HIRING_COMPANY
277,2211996202,2020-10-25,Coda,Lifecycle Marketer,San Francisco Bay Area,"Coda is a rapidly growing startup building a platform that enables people to build docs as powerful as an app. We're backed by some of the Valley's leading venture capitalists, and have assembled a world-class team across offices in San Francisco, Mountain View, and Seattle. Here's a quick overview of what we do. The role:Coda is looking for our first lifecycle marketer to oversee our user journey and develop the programs for how we guide users through our product. The ideal candidate will use a combination of data, testing, and a high degree of customer empathy to drive activation, engagement, conversion, and expansion. Since Coda is used across a diverse set of customers and use cases with many potential points to drive engagement, this is a unique role for an analytically-inclined customer marketer to be both creative and drive measurable results. Coda reimagines documents, spreadsheets, and how “applications” are developed. While documents and spreadsheets have remained relatively unchanged for the last 40 years, their paradigms still dominate how businesses and people operate. We're taking a fresh approach at what these fundamental surfaces are ー empowering anyone to start with something as simple as a document that can easily evolve into a powerful, connected application. We’ve seen customers make docs to plan product launches, manage marketing campaigns, coordinate country-wide remote education opportunities, and to run their business full stack (to name a few). As the founding member of Coda’s Lifecycle Marketing team, your fingerprints will be all over the process, culture, and company we build in the years to come. Responsibilities:Drive engagement, retention, conversion, expansion, and resurrection across our customer base by crafting personalized campaigns and in-app experiencesDevelop lifecycle marketing campaigns across email and in-app messaging channels. You’ll help drive the adoption or build-out of advanced customer engagement toolingExplore, test, validate, and refine potential new engagement and growth channelsWork with product teams to craft and launch experiences to onboard and activate users to new product featuresDeeply understand, research, and segment our users to deliver customized experiences to the right audience. You’ll understand the data driving our customer actions and A/B test your way to better experiencesMaintain a rigorous and organized view of the experiences and communications we are delivering across our key customer segmentsRequirements:Experienced across all aspects of the customer journey - retention, engagement, conversion, and everything in between. You're interested & invested in how customers move through and experience a product - and how you can help get them thereAnalytically-driven and rooted in high Emotional Intelligence. Experienced with SQL - you don’t need to be a Data Scientist, but you need to be self-sufficient. You're obsessed with A/B testing, iteration, and finding insight, and love scaling your findings to adjacent areasAware of how brand assets and creative efforts are perceived, and hold your customer-facing work to a high standard of quality. You can design and create professional-looking communications independentlyEager to roll up your sleeves with a fast-growing startup and can plan ahead to let your efforts scale down the line. Experienced with the latest marketing and engagement tools and excited about the opportunity to add new ones to our tech stackProven collaborator with strong ability to communicate and drive process with a wide range of stakeholders",Intermedio,Jornada completa,"Marketing, Desarrollo empresarial",Software,48,None,True,,231,COMPANY_RECRUIT
278,2188739553,2020-10-16,Pivotal Solutions,Senior Data Engineer - REMOTE,United States,"Hello,Our client is looking to hire a REMOTE Data Engineer as a consultant. ***This position can be worked REMOTELY from anywhere in the US (Ex: Home office, share co working space, etc,) Project Duration: 12+ months I have attached below a detailed job description for your review.If you have the required experience and interest, please email me a current resume, along with your responses to the following questions:  *** How much experience do you have with Python?*** How much experience do you have with Airflow?*** How much experience do you have building and designing ETL/ELT pipelines?*** How much experience do you have with SQL? *** What is your visa status (US Citizen, Greencard Holder, H1-b, etc.)?*** What is your all-inclusive hourly rate (1099/Corp to Corp)?  *** Where do you currently live (city, state)?*** Are you able to work REMOTELY?*** What is your availability to start a new role? Thank You!Brian Edelman, CPADirector of RecruitmentPivotal Solutions, Inc.3 Grace Avenue, Suite 105Great Neck, NY 11021Tel: 516-472-0751b.edelman@PSI-Staffing.net www.pivotal-solutions.net",Intermedio,Jornada completa,Tecnología de la información,Software,44,None,True,516-472-0751b.edelman@PSI-Staffing.net,214,ACTIVELY_HIRING_COMPANY
279,2239710175,2020-11-03,"Business Intelligence Advisors, Inc.",Open Source/Public Records Researcher,United States,"Business Intelligence Advisors, Inc. (“BIA”) is an independent investment research firm that provides a unique edge to institutional investors and hedge funds. BIA uses its proprietary behavioral assessment methodology, developed by U.S. intelligence professionals, to critically analyze the language and behaviors from company disclosures to ascertain for investors when management teams are conveying incomplete and unreliable information. BIA’s Investment Intelligence business line is seeking qualified candidates who are interested in conducting open source research and identifying sources to provide insight to help our clients make investment decisions. As a new hire, you will work closely with the Director of Open Source Collection and project managers to conduct independent open source research and identify appropriate sources. You will develop online research and writing skills. Since BIA is an entrepreneurial company, your work will directly contribute to the growth and success of the business and, if you excel, you will frequently be given opportunities to stretch your project management, leadership and client-facing skills and grow your responsibilities. The ideal candidate finds doing open source research online and in public records databases stimulating, has an investigative mindset, and has the ability to think outside the box when presented with challenging situations. They are interested in doing due diligence work for clients in the financial services sector, developing open source research skills, and working with others in a fast-paced environment.   Roles & Responsibilities:Use open source databases and conduct due diligence online and through social media profiles to analyze publicly available information on individuals and companies.Identify relevant individuals in a company and/or industry through resume databases and online.Write reports that include a concise overview of information collected.Use rigorous analytical thought processes to discern the availability of public information.Competencies: Strong analytical skills and the ability to work independently and multi-task across and among multiple client projects.Strong time-management skills and the ability to think outside the box.Familiarity with open source databases similar to LexisNexis, WestLaw, Factiva, Bloomberg Law, etc.Ability to quickly analyze information and summarize in a report for external distribution.Demonstrated ability to learn rapidly.Comfortable receiving direct feedback.Self-motivated and able to deliver high-quality results under tight deadlines.Qualifications & Experience: Bachelor’s degree required. All majors considered. Coursework in business, international relations, history and other relevant subjects preferred.Multilingual candidates a plus.Early career professionals with three to four years of directly related work experience ideal. Interested candidates should submit a cover letter and resume for the Open Source Researcher role. Business Intelligence Advisors welcomes candidates that bring unique and diverse backgrounds and experiences. A commitment to serving clients, teamwork, accountability, and integrity form the foundation of a challenging and exciting career at BIA. Direct candidates only and no phone calls, please. BIA can only consider candidates who are legally authorized to work in the U.S. without sponsorship. For more information about BIA, please visit: www.biadvisors.com.",No corresponde,Jornada completa,"Investigación, Análisis",Servicios financieros,67,None,True,,180,ACTIVELY_HIRING_COMPANY
280,2159732833,2020-10-31,DataLink Software,ETL Data Engineer II (Remote),"Tampa, FL, US","Data Operations Engineer II  Data Operations  Summary  DataLink Software is seeking a highly qualified, experienced Data Operations Engineer. The right candidate for this position is someone who enjoys challenging work in a fast-paced environment and solving complex business problems with data and analytics enabling our customers in their pursuit of better healthcare outcomes for their members. This is a remote role and we are seeking individuals who work within the following states AR, CO, DC, FL, IN, MI, TX, or WI. Demonstrated knowledge of value-based care, HEDIS, STARS, and risk adjustment experience preferred. This is remote role and we are seeking individuals who work within the following states AR, CO, DC, FL, IN, MI, TX, or WI.  Essential Functions  Design, develop and implement ETL solutions for ingesting, cleansing, business rules execution and pushing customer data into DataLink’s systems. Significant participation in analysis, interpretation, and translation of complex health plan data, issues, trends and relationships to provide our customers detailed insights into their data Analyze and interpret complex data on source and target systems, identify the gaps, and provide solutions Ability to write complex SQL queries Optimizes SSIS package execution and SQL execution to minimize load times. Ensures data integrity throughout the ETL process and appropriately handle errors Work closely with Scrum team members using Agile processes to iteratively develop and improve ETL pipelines. Proactively provide feedback and process improvement recommendations to the team and management Other duties as assigned   Qualifications  Bachelor’s degree in Computer Science, Management Information Systems or related discipline Overall 5+ years of experience designing and developing ETL processes 3+ years of experience with SSIS, SSRS, SQL Server and T-SQL Data analysis, data presentation, spread sheet and database capabilities 3+ years of experience automating ETL pipelines with a heavy emphasis on quality, validation and tracking Experience with SAS or other statistical applications Experience with SSAS, Tabular Models and/or Star Schemas Experience with Healthcare data Experience with NoSQL Database such as Hadoop and MongoDB   About Us  DataLink Software empowers better health through real-time data aggregation of disparate sources and systems, illuminate value-based performance management, and simplify the next steps in the care journey by enabling an intelligent point-of-care solution for all provider types across all delivery settings. We enable health plans, providers, and care partners, such as MSOs, ACOs, IPAs, medical groups, and patients with Evoke360, our enterprise platform that drives value, reduces the cost of care, improves quality scores, ensures risk adjustment accuracy, and simplifies healthcare navigation.  Benefits Of Joining Our Team  Excellent Medical, dental, and vision coverage Life and disability insurance for income protection 401(k) plan to save for your future, including company match of up to 4% Competitive time off benefits including PTO, sick and holiday Professional development reimbursement program of up to $1,500 per year Tech-modern office space with casual dress code Competitive time off benefits including PTO, sick and holiday Coffee machine w/cappuccino and espresso, along with free snacks all-day/every day Onsite Unisex hair stylist available at no cost to the employee Onsite fitness center   Non-Solicitation  We work with a carefully selected set of recruitment agencies, and we are not looking to add to this roster, so please do not call or email if you are a recruitment agency. We do not accept unsolicited agency resumes so please do not send resumes to our ‘jobs’ or any other email addresses, or our employees. We are not responsible for any fees related to unsolicited resumes.",Sin experiencia,Jornada completa,Tecnología de la información,"Software, Seguros, Atención sanitaria y hospitalaria",90,None,False,,653,ACTIVELY_HIRING_COMPANY
281,2271240147,2020-11-03,Qintess,Cientista de dados,São Paulo e Região,"CIENTISTA DE DADOS PERFIL:• Conhecimento em banco de dados e linguagem sql:• Experiência profissional em linguagens de programação: Python, R ou SAS:• Experiência em manipulação de grandes bancos de dados:• Experiência em modelagem preditiva. Contratação é CLT Full + benefícios Horário de trabalho: de segunda à sexta-feira (horário flexível – 8hs diárias). Local de Trabalho: Home office Envie seu cv paraDouglas Talarico Bento <douglas.bento@qintess.com> Acontece na Qintess: Certificações custeadas pela empresaConvênio com desconto em instituições de ensino e cursos de Idiomas:Cursos e treinamentos na Plataforma EAD própria da Qintess:Projetos ESG , diversidade nas pessoas da empresaParticipação Qintess LabHackathonPOdCast semanais com temas da atualidadeWebinar mensal onde você fica por dentro de tudo o que rola na empresaIGNITE Startups – participação de todos os nossos colaboradores em projetos desafiadoresCampanha Eu Indico- valorizamos nossa rede de colaboradoresPapo Aberto com o Nana – interação dos nossos colaboradores com o Presidente.Omnichamel – Canal direto com o RHTelepresença - interação direta com todo o time    #Vempraqintess !!!!!!! vem ser #qintersslovers",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Servicios y tecnologías de la información,345,None,True,douglas.bento@qintess.com,1260,ACTIVELY_HIRING_COMPANY
282,2180228996,2020-10-13,"Mission Critical Partners, LLC",Data Scientist,United States,"Please Note: United States Citizens, Green Card Holders and those authorized to work in the United States are encouraged to apply. We are unable to sponsor H1b candidates at this time. Our growth and client-centric vision has created a career opportunity for a self-motivated individual looking to establish a career with a fast-paced rapidly growing company. The purpose of the Data Scientist is to help us discover the information hidden in vast amounts of data both structured and unstructured. The position will help us to build and deliver products and services that utilize machine learning and analytics for public safety and criminal justice clients. The role requires a client-focused professional committed to success by embracing and living our core values of Persistence, Integrity, Trust, Accountability and Prudence. ExpectationsApply and enable data mining techniques and statistical analysis to build high quality prediction and pattern matching systems integrated with our solutionsLead and/or aid in the implementation of data analytic solutions sold to end user clients Interpret customer requirements and information: speak with customers to understand their end user needs and relay this information to process flows and diagrams Perform technical presentations that demonstrate how data analysis information and process flow can benefit and meet customer needsProvide technical specifications and statements of work for a quote or proposal and aid in preparing accompanying materialsPrepare technical reports by collecting, analyzing, and summarizing information and data trends Adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action Assess the effectiveness and accuracy of new data sources and data gathering techniques Process, cleanse, and verify integrity of data used for analysisProvide pre-sale technical assistance and product education to the Growth Team and prospective clientsMaintain customer confidence and protect operations by keeping information confidentialServe as liaison with other teams and divisions within the company to gather and share technical expertise for supporting growthAttend weekly service delivery meetings and ensure business development opportunities are compliant with company capabilitiesContribute to team effort by accomplishing related results as neededWork with the Division management team for pricing an opportunity Basic Requirements, Knowledge, and SkillsBachelor’s Degree in Statistics, Mathematics, Computer Science, or another quantitative field. Master’s Degree preferred 5-7 years of experience manipulating large data sets from multiple sources and building statistical modelsDemonstrated experience using a variety of data mining/data analysis methods, building, and implementing models, using/creating algorithms, and creating/running simulations Proven background working with and creating machine learning data architectures to include selecting features, building, and optimizing classifiersGood applied statistics skills, such as distributions, statistical testing, regression, etc.Mastery experience with at least one common data science toolkits, such as R, Weka, NumPy, MATLAB, etc. Experience with data visualization tools, such as D3.js, GGplot, R, Python, Tableau, etc.Proficiency utilizing MapReduce techniques and frameworks such as Apache HadoopExperience with advanced statistical techniques and concepts. Maintain in-depth knowledge of data mining and analysis tool capabilitiesUnderstanding of criminal justice data and predictive analyticsStrong problem-solving skills.  Detailed-oriented, analytical, and inquisitiveHave a passion for discovering solutions hidden in large data setsEffective organizational and time-management skills with the ability to work as part of a team and independentlyExemplary Communications, both oral and written. Writing for presentations, and technical reports. Exceptional listener. Understanding client goals and how they measure success. Identify needs, present concepts, develop specifications and recommendations, and deliver solutions Estimated travel is 30%Valid Driver’s License with the ability to drive to client sites and MCP regional office locations About Us: Mission Critical Partners, LLC       Mission Critical Partners (MCP) is a leading independent consulting and information technology (IT) support services firm that helps clients evolve their public safety systems and operations and improve emergency response through our extensive experience, knowledge, and resources. By providing insight and support every step of the way, our clients are able to transform their mission-critical operations, maximize the value of their investments and ensure optimal performance and success. Additional information and career opportunities are available at www.MissionCriticalPartners.careers    As an Affirmative Action and Equal Opportunity Employer, Mission Critical Partners shall abide by the requirements of 41 CFR 60-1.4(a), 60-300.5(a) and 60-741.5(a). These regulations prohibit discrimination against qualified individuals based on their status as protected veterans or individuals with disabilities, and prohibit discrimination against all individuals based on their race, color, religion, age, sex, sexual orientation, gender identity or national origin. Moreover, these regulations require that covered prime contractors and subcontractors take affirmative action to employ and advance in employment individuals without regard to race, color, religion, age, sex, sexual orientation, gender identity, national origin, disability or veteran status.",Algo de responsabilidad,Jornada completa,"Tecnología de la información, Ingeniería","Protección civil, Judicial, Cumplimiento de la ley",201,None,True,,622,ACTIVELY_HIRING_COMPANY
283,2191708524,2020-10-17,Twilio Inc.,"Data Scientist, Marketing Communications","San Francisco, CA, US","Because you belong at Twilio   The Who, What, Why And Where  As Twilio redefines the market for customer engagement software, companies globally are looking to see how we do it. We have succeeded on the strength of creative programs and strict execution. But we've yet to tap the mountains of data we collect across product usage, clickstream, and ad impressions. We are excited to add a Data Scientist who will optimize the yield of over $100M in marketing investment and directly influence the story we take to market.  Who?  You Should Have Most Or All Of  Twilio is looking for a Data Science professional who wants to build hypotheses and design experiments in the domain of marketing and advertising. You are eager to learn and inspire, and you like to think at scale and work with real-world problems, distilling takeaways for less-technical audiences.  Masters or PhD degree in Mathematics, Statistics, Computer Science or another quantitative field, or equivalent experience  Strong background in statistics (design of experiments, estimation theory, hypothesis testing, time series analysis, Bayesian inference) Validated experience in data mining and visualization Proficiency in machine learning (supervised and unsupervised learning, reinforcement learning and multi-arm bandits) 3+ years of hands-on experience with Python (preferred) or R, experience with C/C++ or Java/Scala is a plus Bonus: Familiarity with distributed systems (e.g. Spark), streaming data platforms (e.g. Kafka) and Google Analytics  What?  Key Responsibilities  As a Data Scientist in Marketing, you will collaborate with marketing teams such as Demand Generation, PR, Content, and Marketing Ops. You will often collaborate with a distributed guild of other Data Scientists, embedded in their respective functions across Twilio.  Cultivate a POV with market trends and use anonymized Twilio product data to validate and support storylines for our PR team to pitch to journalists. Optimize existing measurement tools to develop a regular cadence of reports which highlight the business impact of Twilio PR results, content and social media efforts. Refine our multi-touch attribution model to understand which programs are supplying the most revenue. Evaluate ground breaking ML algorithms (such as multi-arm bandit) to accelerate our time-to-insight with experiments in-market.  Twilio looks for leaders who live the Twilio Magic . For this role, it's especially important to demonstrate:  DRAW THE OWL: Ability to apply sophisticated math techniques in novel ways to measure the result of advertising and marketing campaigns. BE AN OWNER: Ability to step up and lead cross-functional projects for which the team builds new infrastructure. WRITE IT DOWN: Ability to articulate clear test plans and a business case. RUTHLESS PRIORITIZATION: Ability to decide (and explain) which tests should run first. EMPOWER OTHERS: Ability to build tools and frameworks that other teams in Marketing use to bring to bear insights on a go-forward basis.  Why?  Our Marketing team evaluates investments on the basis of pipe-to-spend. I.E. how much pipeline can we build for the Sales team with our budget? Every year, we not only grow our budget but also our pipe-to-spend efficiency. The better we do, the more sales reps Twilio can hire, and the faster we can redefine how the world builds software. We see potential to increase our pipe-to-spend by another 20% in 12-18 months.  Twilio is a company that is empowering the world’s developers with modern communication in order to build better applications. Twilio is truly unique: we are a company committed to your growth, your learning, your development, and your entire employee experience. We only win when our employees succeed, and we're dedicated to helping you develop your strengths. We have a cultural foundation built on diversity, inclusion, and innovation, and we want you and your ideas to thrive at Twilio.  Where?  We employ diverse talent from all over the world and we believe great work can be done anywhere. Around the world, Twilio offers benefits and perks to support the physical, financial, and emotional well being of you and your loved ones. No matter where you are based, you will experience a company that believes in small teams for maximum impact: seeks well-rounded talent to ensure a full perspective on our customers’ experience, understands that this is a marathon, not a sprint: that continuously and purposefully builds an inclusive culture that empowers everyone to do their best work and be the best version of themselves.  About Us  Millions of developers around the world have used Twilio to unlock the magic of communications to improve any human experience. Twilio has democratized communications channels like voice, text, chat, video and email by virtualizing the world’s communications infrastructure through APIs that are simple enough for any developer to use, yet robust enough to power the world’s most demanding applications. By making communications a part of every software developer’s toolkit, Twilio is enabling innovators across every industry — from emerging leaders to the world’s largest organizations — to reinvent how companies engage with their customers.",No corresponde,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Internet, Telecomunicaciones",129,None,False,,662,COMPANY_RECRUIT
284,2184055462,2020-10-15,Addition Solutions,Senior Data Scientist,"London, England, United Kingdom","An opportunity has arisen for a permanent, Senior Data Scientist, to join a leading social network client located in Central London. Do you have a passion for Data ScienceThis is a ‘once in a lifetime’ opening for an experienced Data Scientist to join a remarkable market leading client. As Senior Data Scientist your main responsibilities will include:Establish and develop appropriate monitoring infrastructure for production models. Be a key contributor to the direction of the people recommendations product roadmap from a machine learning perspective. Identity individual user preferences and determine how these can be best accounted for in the algorithm.Establish an improved process and infrastructure in order to deploy recommender models on production. Skills/Experience required:Extensive experience and knowledge of recommender systems with two-sided preferences (two-sided is essential).Solid technical knowledge and confident in terms of programming and scripting (strong Python essential).Demonstrable experience implementing machine learning models from initial conception right through to the final productionalised model.Strong knowledge in additional areas of data science such as computer vision and NLP.",Intermedio,Jornada completa,Tecnología de la información,Medios de comunicación en línea,134,None,True,,400,JOB_SEEKER_QUALIFIED
285,2256104320,2020-10-30,Meetup,Senior Machine Learning Engineer,"New York City, NY, US","Getting together with real people in real life makes powerful things happen. Side hustles become careers, ideas become movements, and chance encounters become lifelong connections. Meetup brings people together to build thriving communities. Show up. Change lives.  Every year, millions of people RSVP to an eclectic variety of Meetups around the world. Activity on Meetup is growing faster than ever and by studying it, we're learning how to help members discover the groups and events that are right for them -- sparking new ways to make their worlds come alive than ever before. We are a collaborative and dedicated team seeking machine learning engineers to join us in designing and building the future vision of Meetup.  What you'll get to do:  You imagine a world more easily connected, where people come together in real life, meet, and do more of the things that empower personal growth through real human connections. We are looking to add engineers to our machine learning team to:   Use machine learning to improve Meetup's recommendation, search and notification systems Design, build, and own every aspect of our low-latency personalization platform Develop your leadership skills while mentoring other specialists Collaborate with product and design to leverage data and algorithms to improve the user experience Recruit and present on behalf of Meetup at technical conferences and Meetup events  Who you are:   BS+ degree in Computer Science, Engineering, Statistics or related programs 5+ years work/educational experience building data products (e.g. recommendations, predictions, NLP) Contributed to large codebases in Scala, Java or Python Hands-on experience using machine learning frameworks to robustly build, validate, test, and monitor statistical models Implement machine learning algorithms in cloud and horizontally scalable environments (MapReduce, Hadoop, Spark) Experience with both relational and NoSQL (DynamoDB, Redis) databases and RESTful APIs  Meetup employees are bold, supportive, and passionate about enabling people coming together and creating the future of real community: a future where people embrace their differences and similarities, show up, do things, and turn to each other to improve their lives. We care about moving fast, real-world change, and proud to be an equal opportunity employer committed to hiring and developing diverse, dynamic teams in a safe and inclusive environment.",Algo de responsabilidad,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Software, Internet",26,None,False,,174,ACTIVELY_HIRING_COMPANY
286,2277506206,2020-10-12,Robert Walters,Data Engineer (Remote w/Nationwide Travel),"North West, GB","Are you a Data Engineer currently working for a consultancy but you feel pigeon-holed into a particular area? Perhaps you'd like to join an organisation that actively invests in on-going training courses to help you develop your Data career? You could be an experienced Data Engineer looking for a move into the exciting world of consultancy, and yearning for an opportunity to experience dynamic and fast-paced, changing environments? If you're a Data Engineer with experience working with SAS, Scala, Python, Hadoop, R or other Big Data Stacks, please read on...  My client, a very well-respected and nationwide consultancy are looking for a Data Engineer to join at an exciting period of growth, this is working for a business that truly values investment into its employees, investing in ongoing training courses and well-being packages. Working on-site with a respectable array of clients across the UK, you'll use your experience with tech stacks such as: Python, R, Scala, SAS and Hadoop (to name a few) to bring innovative solutions to your customers. This is a fantastic role within a consultancy that champions internal development, and when you're not on-site with a client, offer completely remote-working.  Key Responsibilities  Regular, nationwide travel to an array of well-respected and innovative clients. Gathering requirements from non-technical stakeholders and offering consultative solutions to Data Management Regularly using tools such as: Python, R, Scale, Hadoop, SAS, SQL etc.    Key Requirements  Demonstrable experience of using big data tech stacks such as :SAS, Scala, Python, R, Hadoop,Spark etc (essential) Exception stakeholder management skills The ability to explain technical concepts in layman's terms to non-technical stakeholders.  Nationwide travel to on-site clients Drivers Licence  If you're an experience Data Engineer looking for a role within an established and respected Consultancy. Please get in touch…",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Dotación y selección de personal, Servicios financieros",0,None,False,,12,ACTIVELY_HIRING_COMPANY
287,2219324627,2020-10-27,Edelman Financial Engines,Staff Data Engineer (Analytics),United States,"At Edelman Financial Engines, we believe every hardworking American deserves to move their financial life forward, and we’re growing our team so we can help more clients every day.The Data Engineering team at Edelman Financial Engines is looking for an experienced Staff Data Engineer to build out and enhance our robust enterprise-wide data analytics platform for our Finance department. The data analytics platform consists of the enterprise data warehouse (AWS Redshift), AWS data lake, business dashboards (Tableau), key corporate data marts, and the data pipelines (Apache Airflow). Responsibilities and Roles:This member will be responsible for expanding and optimizing our data and data pipeline architecture across Finance, as well as optimizing data flow and collection for other cross functional teams.This role will work on data initiatives, including data quality and data governance and ensure optimal data delivery architecture is consistent throughout ongoing projects.The individual must be independent and comfortable supporting the data needs of multiple teams, systems and products with guidance.As part of Data Engineering team, contribute towards scaling and maintaining our data analytics platform Requirements:8+ years of hands-on experience as a developer in Data Engineering working with data warehouse systems and data pipelines.Intermediate to Expert level / 6+ years hands-on experience like Redshift, SQL and Python.Experience working with data formats such as Apache AVRO, Apache Parquet, and common methods in data transformationExcellent teamwork and communication skillsExperience working as Data Engineer in Finance/Financial Analytics is a strong plusBS or MS in Computer Science, Software Engineering, or similar Experience with AWS Big Data technology stack and AWS Certification is a plus.  About Edelman Financial Engines   Since 1986, Edelman Financial Engines has been committed to always acting in the best interest of our clients. We were founded on the belief that all American investors – not just the wealthy – deserve access to personalized, comprehensive financial planning and investment advice. Today, we are America’s top independent financial planning and investment advisor, recognized by both InvestmentNews1 and Barron’s2 with 150+ planner offices across the country and entrusted by more than 1.2 million clients to manage more than $220 billion in assets. Our unique approach to serving clients combines our advanced methodology and proprietary technology with the attention of a dedicated personal financial planner. Every client’s situation and goals are unique, and the powerful fusion of high-tech and high-touch allows Edelman Financial Engines to deliver the personal plan and financial confidence that everyone deserves.  For more information, visit www.EdelmanFinancialEngines.com and www.FinancialEngines.com © 2019 Edelman Financial Engines™, LLC All rights reserved. All advisory services provided by Financial Engines Advisors L.L.C. Financial Engines Advisors does not guarantee future results.  For California residents, please see the link for the Privacy Notice for Candidates. California law requires that we provide you this notice about the collection and use of your personal information. Please read it carefully and reach out to Jill O’Connell (857-305-8555 or joconnell@edelmanfinancialengines.com) with any questions.  Edelman Financial Engines encourages success based on our individual merits and abilities without regard to race, color, religion, creed, sex, gender identity or expression, sexual orientation, pregnancy, marital, domestic partner, or civil union status, national origin, citizenship, ancestry, ethnic heritage, genetic information, age, legally recognized disability, military service or veteran status.  1 Ranking and status for 2019. For independence methodology and ranking, see InvestmentNews Center (http://data.investmentnews.com/ria/):   2 The 2019 Top 50 Independent Advisory Firm Ranking issued by Barron’s is qualitative and quantitative, including assets managed, the size and experience of teams, and the regulatory records of the advisers and firms. Firms elect to participate, but do not pay to be included in the ranking. Investor returns/experience are not considered. 2018 ranking refers to Edelman Financial Services (EFS), which combined its advisory business in its entirety with Financial Engines Advisors L.L.C. (FEA) in November 2018. For the same survey, FEA received a precombination ranking of twelfth.",Intermedio,Jornada completa,Tecnología de la información,Servicios financieros,10,None,False,joconnell@edelmanfinancialengines.com,102,ACTIVELY_HIRING_COMPANY
288,2207367542,2020-10-14,Cognoa,Principal Data Scientist,"Palo Alto, California, United States","**** TO ENSURE EQUAL OPPORTUNITY FOR ALL APPLICANTS, PLEASE DO NOT ATTEMPT TO CONTACT COGNOA PERSONNEL ABOUT THIS JOB OPENING THROUGH ANY CHANNEL OTHER THAN THE APPLICATION FORM PROVIDED **** Are you a seasoned team leader with a passion for applying data science to challenging real world applications? Do you have an appetite for healthcare applications of AI?The AI department at Cognoa is looking to make a key hire to contribute to ongoing research and improvement of AI-assisted child behavioral diagnostics and therapeutics. Our cutting edge algorithms use ML predictive modeling, as well as DL computer vision and computer audio analysis to streamline the diagnosis and therapy of conditions like Autism, ADHD, and speech and language disorders for pre-school children. We are looking for an experienced scientist with a proven track record in taking ML and DL algorithms from concept to production. Past experience in clinical science and/or AI assisted diagnostics a big plus. MUST HAVES:Passion to crack difficult problems with relentless resourcefulness and the audacity to experiment with unorthodox solutionsThirst for learning and eagerness to share learnings with team members and guide the overall team trajectory to successSolid foundational education in each of: Machine Learning, Statistical analysis, and Deep Learning / Computer vision5+ years proven track record of successfully applying ML predictive modeling to real world problems5+ years proven track record of successfully applying statistical analysis to real world problems2+ years proven track record of successfully applying DL-based computer vision or computer audio modeling to real world problems",Intermedio,Jornada completa,"Tecnología de la información, Análisis, Ingeniería","Atención sanitaria y hospitalaria, Software",41,None,False,,477,JOB_SEEKER_QUALIFIED
289,2237149586,2020-11-03,Arkano Software,Senior Data Engineer,"Santiago, Región Metropolitana de Santiago, Chile","¡¡Arkano Software tiene una posición esperando por ti!!  ¿Eres un profesional apasionado por la tecnología, líder y hábil trabajando con equipos altamente especializados?  Nacimos hace 13 años en Uruguay con la misión de transformar los desafíos de nuestros clientes en soluciones de valor, de forma ágil, creativa y con especialización en tecnologías Microsoft. Buscamos generar relaciones de confianza, trabajo colaborativo, con integridad y orientación a resultados.  Crecemos diariamente conformando un equipo de más de 100 personas y entregando más de 300 proyectos a una amplia gama de clientes en todo el mundo. A la fecha, tenemos presencia en 5 países: Chile, Perú, Argentina, Paraguay y Uruguay, habiendo sido reconocidos 7 veces como Partner of the year en Microsoft.  Buscamos talentos con orientación al cliente, comprometidos con el cumplimiento de sus objetivos brindando soluciones de negocio. Hoy, continuamos creciendo, y estamos en buscando un colaborador con perfil en Data Engineer, que cuente con sólidos conocimientos en Power BI, SQL Server, SSIS, SSAS, ETLs. Para más información ¡Te invitamos a postular!   ¿Cuál es el perfil que buscamos? 1a 3 años de experiencia en Power BI. Inglés fluido hablado y escrito (deseable) Responsable Proactivo Excelentes habilidades comunicacionales. Disponibilidad inmediata.  Skills técnicas:  Power BI, SQL Server, SSIS, SSAS, ETLs. Azure Datafactory, Azure Datalake, Azure Datawarehouse (deseable)  ¿Qué encontrarás en Arkano?  Sumarte a una Empresa innovadora en búsqueda constante de nuevos retos. Pertenecer a un equipo profesional dinámico, enérgico y apasionado por los desafíos. Participar en el rediseño de los procesos en las principales industrias a través de la incorporación de tecnología. Crecimiento profesional sin límites, tu defines hasta donde ir.  ﻿¡Te estamos buscando!",Intermedio,Jornada completa,Tecnología de la información,Software,19,None,True,,164,ACTIVELY_HIRING_COMPANY
290,2151491547,2020-10-20,"Datasource Consulting, an EXL company",Data Engineer Consultant,Greater Chicago Area,"Datasource Consulting, an EXL Company is looking to grow heading into 2021! We're looking to network with Data Engineering and BI Development professionals who meet the below qualifications to become full-time consultants on our talented teams! If you're looking to expand on your data management skills & experience in a fast paced consulting environment, then please apply for further considertion! This role is remote with potential travel requirements when safe to do so.  Summary:The Engineer Consultant plays an important role in the implementation of Enterprise Data Management (EDM) Solutions for Datasource Consulting/EXL Clients. They may be asked to assist with requirements gathering/analysis, development, testing, documentation, and deployment tasks. This is a business-facing role in which the consultant will have to work independently and collaboratively with internal and client teams to ensure project success. The Engineer Consultant should have practical experience developing EDM solutions, strong working knowledge of the technologies listed below, and an eagerness/ability to learn and train on new technologies. They should be able to fill different positions in multi-functional and multi-shore project teams. This position will require frequent travel to client sites in the U.S. (up to 80%). Qualifications:Practical experience in art least 3 of the following areas:Data IntegrationBusiness IntelligenceData QualityCloud PlatformsMaster Data ManagementBig DataData GovernanceBusiness and Data AnalysisData ModelingPractical development experience with an object-oriented programming languagePython and Java preferredExperience with version control frameworks such as Git and Subversion preferredBachelor’s degree or equivalent experienceHighly proficient in SQLProficient at writing complex SQL statements and interpreting resultsProven experience in operational analysis, data analysis, and problem resolution activitiesProficient with PowerCenter or SSIS ETL design and developmentExposure to/a willingness to learn modern data platforms involving AWS, Azure, GCP, Snowflake, Denodo, etc.Experience in decision support, business intelligence environments utilizing tools such as Tableau, Business Objects, Cognos, TIBCO, MSBI, Oracle BI, etc.o  Contributes to MDM best practices and methodologies by reviewing, updating, and developing documents such as templates, presentations, trainings, and moreo  Experience with or willingness to learn MDM software in various environments (e.g. Dev/Test/Prod/Backup)·       Experience with Informatica MDM, Orchetra EBX, or similar tools a plusCollaboratively drafts detailed documentation (i.e., Design Specs, Test Plans, etc.) that have a professional appearanceDeals effectively with all team members and builds strong working relationships/rapport with themDemonstrates ability to organize tasks and time necessary to complete assigned tasks/deliverables Responsibilities:(70%)Works with the Data Warehouse Architect to perform source system analysis, identification of key data issues, data profiling and development of normalized and star-snowflake physical schemas.ETL design, development, optimization and support, creates and implements scheduling strategy, and develops error handling processes.Coordinates with Project Managers and help drive project planning.Works with business partners to review prototypes and develop iterative revisions.Oversees and performs troubleshooting and provides resolutions to reporting issues.Works closely with and assists other consultants, leadership, and clients to understand and interpret data through stakeholder interviews and by defining, analyzing, and validating data.Drives and participates in discovery and design sessions. Involved in all aspects of data management implementations including translation of architecture and design documentation into configured solution components, including data models, mappings, rules, reports, and more.Evaluates and tests new tools and technologies. Develops and executes test cases/plans to ensure high-quality releases.Supports testing and deployment activities and assists in producing detailed and comprehensive documentation. Installs and configures software in on-premises and cloud environments. (15%) o  Communicates consistently with other team members, leadership and clients outlining status, risks, issues and key decisions (10%) o  Attends training courses focused on data management skillsets and technologies such as AWS, Azure, Snowflake, Informatica, Information Builders, PowerBI, Tableau, Collibra, and more. (5%) o  Other duties as assigned or identified",Intermedio,Jornada completa,"Tecnología de la información, Consultoría",Servicios y tecnologías de la información,190,None,True,,482,ACTIVELY_HIRING_COMPANY
291,2166901311,2020-10-26,Supply Clinic,Lead Data Scientist,"Chicago, Illinois, United States","Lead Data Scientist - Can Be Remote During Covid Supply Clinic is the online marketplace for healthcare and dental supplies. We’re a two-sided marketplace, helping healthcare offices buy supplies directly from distributors and manufacturers on our platform. We’re a fast-growing digital company disrupting an old-school industry, making waves as we expand in the place of traditional distribution channels. We are growing Data Team, looking to bring a talented Data Scientist on board. If you’re passionate about making a real impact at a young startup company, Supply Clinic may be a great match. Lead Data ScientistSupply Clinic is looking for a Lead Data Scientist to help drive our Data Team, working closely with multiple team members to collect data, design and run various analyses, and help implement changes based on findings. Short term projects include: analysis of customer sitemap patterns, building product correlation maps, and identifying areas of seller behavior improvement. Longer-term projects include: using ML and other techniques to gather new insights into customer behavior and purchase patterns, thorough review and improvement of our internal search algorithm to improve customer experience, and optimizing logistical seller performance and order fulfillment on a micro and macro level. Primary Responsibilities:Using Python and Postgresql (and on occasion Excel) for user-level data analysisWorking with our data warehouse, specifically through MODE and HEAP analyticsWorking within the Data Team and alongside development teams to better scale data collection of relevant product and user data pointsAssisting in building necessary data infrastructure to continue to expand our analysis capabilities Required Skills:Experience with statistics and data analysis an absolute mustFluency with coding, including but not limited to both Python and SQLExperience pushing models to production on a platform such as AWS or Azure, and iterating on the model based on data collectedFluency with data querying and database maintenance/reference tools and techniquesMust be a creative thinker able to problem-solve to accurately measure and test queriesExperience with stochastic and/or probabilistic modeling a plu Perks:Health, dental, and vision insuranceFlexible role in terms of remote workOffice space on Michigan Ave. by the Loop for an easy commute (once we return to the office!)Amazing, dynamic team (if we do say so ourselves)Office snacks, coffee, and wide variety of teas, just waiting for our return to the officeCasual, collaborative team environmentFriday happy hours (once we return to the office!) PLEASE NOTE: While our office is currently open, we greatly limit occupancy at any given time, and by default generally work remotely. We are closely following guidance of health and government officials, and will continue to evolve as new guidance arises. Rest assured, we've implemented procedures to ensure health and safety best practices, and that there is an ample supply of masks and sanitizer available. We are an equal opportunity employer. We do not discriminate on the basis of race, religion, ethnicity, national origin, citizenship, gender, gender identity, sexual orientation, age, veteran status, disability, genetic information, or any other protected characteristic.",Algo de responsabilidad,Jornada completa,None,Atención sanitaria y hospitalaria,265,None,True,,806,JOB_SEEKER_QUALIFIED
292,2269877344,2020-10-17,Socure,Senior Data Scientist,"New York City, NY, US","Founded in 2012, Socure is the leader in high-assurance digital identity verification technology. Named to Forbes' 2019 AI 50 list as one of America's most promising AI companies and a recent winner of API World's Best Data API, Socure's technology applies artificial intelligence and machine learning techniques with trusted intelligence from email, address, phone, IP, social media, and the broader Internet to verify identities in real time. Socure's customers include three of the top five U.S. banks, seven of the top 10 U.S. card issuers, as well as the majority of leading digital banks, lenders and insurers across the U.S. Socure is funded by some of the world's best investors and entrepreneurs including Scale Venture Partners, Commerce Ventures, Work-Bench, Santander InnoVentures, and Two Sigma Ventures.  At Socure, the only way we can further our mission of becoming the single trusted source of identity verification and eliminating identity fraud is by building the best team on the planet. This is where you come in!  We are currently looking for a Senior Data Scientist for our Compliance Products DS R&D team, to be based anywhere remotely in the USA.  The Socure Compliance Products DS R&D team is responsible for developing entity-resolution improvements, building data-processing pipelines, evaluating the performance of new data sources, and providing analytical support to the Socure compliance and regulatory product suite, which includes a highly acclaimed Know-Your-Customer (KYC) product.  What You'll Do:   Develop machine learning, data mining, statistical, and graph-based algorithms designed to analyze massive data sets. Analyze large data sets to develop multiple, custom models, and algorithms to drive innovative identity-verification solutions. Understand and resolve computational limitations related to parallelizing algorithm application and data processing. Provide analytic support to the compliance-product teams. Develop improved models, and perform A/B analysis of production data. Report on project status to senior management. Work well in a fast-paced cross-functional environment.    What You'll Bring:   Ph.D (preferred) or MSc. in a relevant technical field or equivalent work experience A minimum of 3 years of experience working in a similar role. Experience in developing data-driven algorithms in information retrieval, relevance, or machine learning and working with distributed systems. Familiarity with UNIX systems, Java or Scala, Python or R, and SQL. Familiarity with Spark, common ML libraries, and the AWS ecosystem, including EMR and S3. Experience with data mining, unsupervised machine learning algorithms, and statistical- tools and underlying theory. Additionally, experience with Neo4j, Elasticsearch, and Airflow (or equivalents) is a big plus!",Algo de responsabilidad,Jornada completa,Otro,"Servicios y tecnologías de la información, Software, Internet",2,None,False,,22,ACTIVELY_HIRING_COMPANY
293,2233146965,2020-10-23,Canvia,Big Data Engineer,"Lima, Perú","Somos Canvia, formamos parte del portafolio de Advent International y contamos con 34 años de presencia en el mercado local. Nuestro propósito es hacer más fácil la vida de las personas, innovando e implementando proyectos de transformación digital de nuestros clientes de manera ágil y segura.  ¡Te invitamos a ser parte de nosotros, postulando a la posición de Big Data Engineer (Remoto)!  ¿Qué perfil buscamos? ·        Profesional de Ingeniería de Sistemas, Informática o técnico de carreras afines.·        Manejo de Python, SQL, Spark.                                                                                                                                            ·        Conocimiento avanzado en herramientas del ecosistema: Hadoop (HDFS, MapReduce, Hue, Impala, Kafka, Hive, Pig, Sqoop, Oozie, Solr, Flume, etc..) y manejo de Spark.·        Manejo de librería Pandas.·        BD relacionales (mySQL, postgreSQL, Oracle) y no relacionales (Cassandra, MongoDB, HBase, ElasticSearch etc.)·        Home office·        Sin personas a cargo.                                                                                                                                                                          ¡Nuestros beneficios! • Si deseas tener un seguro privado ¡cubrimos hasta el 81% de tu prima!• Contamos con convenios educativos post-grado con diferentes Institutos y Universidades.• Podrás participar en Talleres y Meet Ups que contribuirán con tu desarrollo.             ¡En Canvia cuentas con Seguro Vida Ley desde tu primer día laboral!                   En esta empresa está prohibida la discriminación – Ley N° 29973",Intermedio,Jornada completa,Tecnología de la información,Servicios y tecnologías de la información,82,None,True,,576,ACTIVELY_HIRING_COMPANY
294,2231243339,2020-11-01,Hummingbird,Senior Data Engineer,"San Francisco, CA, US","Hummingbird is a platform for managing anti-money laundering and counter-terrorist financing operations. We are driven by the shared mission of fighting financial crime. Our work helps fight terrible crimes like human trafficking, political corruption, weapons sales, and drug cartels.  We are a customer-obsessed team. We love building and shipping great products. Our customers are financial crime fighters who are often drowning in paperwork and bureaucracy. We set a high bar for our work, and expect you to do the same. We challenge our assumptions, seek diverse opinions, and support each other to do great work.  As a lead for our data engineering practices, you will be responsible for managing our data infrastructure as it scales. You will help design, architect and build our data pipelines. You will work on a system for integrating third-party data sources, as well as leveraging data we collect from our customers, to detect and categorize criminal financial activities and help us incorporate the most advanced algorithms to compliantly fight financial crime with software. You will begin as an individual contributor, but hiring and building a team to support your efforts will be a core responsibility.  We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.  Responsibilities  Build and lead the data engineering practice area at Hummingbird. Ensure data is viewed as a first class entity in all product, architecture, and strategy discussions. Identify and ingest third-party data sources from public sources and external vendors to augment our data in a way that eases compliance workflows for our customers.  Architect an infrastructure that can scale with our business. Facilitate data science work both internally at Hummingbird and for our customers. Provide the infrastructure, features, and analytics to support machine learning development. Work closely with team members in Engineering, Product, Design, Sales, and Regulatory to understand customer and compliance requirements and define roadmaps for better data practices into our product solutions. Build and maintain scalable data pipelines, ETLs and other infrastructure to structure data and make it available for analysis and model training. Shadow customers when possible to build empathy for their problems, understand their workflows, and build user experiences that best support their needs. Review the plans and work of other engineers on the team for use in your practice area as well as general maintainability, performance, and correctness. Seek out and evaluate new libraries and vendors that compliment our technology. Work with other senior members of the team to shape the culture of the Hummingbird engineering to be productive, inclusive, and welcoming.   Requirements  Experience. You have extensive experience building data pipelines and infrastructure that can adapt and scale as data volume grows and customer needs evolve. Subject Matter Expertise. You understand this area deeply and are excited by both simple data problems and seeking out the most advanced, cutting edge technologies. Making trade offs. You've built enough things that you can make trade offs when building features and systems.  Comfort with ambiguity. You can take a high-level customer request, product idea, or company requirement and build a solution to meet the need. Nothing is precious. You love the process and the iteration. You’re not married to specific ideas or solutions, and regularly throw out work (we do this through all parts of Hummingbird). Impact beyond code. You want to be more than hands on a keyboard, and know that your impact goes beyond the lines of code you write. Honesty and humility. You're honest with yourself and your peers about your strengths, weaknesses, and what you can accomplish. You're constantly questioning your assumptions.  Security and safety. You care about correctness, automated testing, and data security. You are careful and methodical and incorporate security into your thinking at every stage of development.  Growth mindset. You want to learn and know that you can. You like digging deeply into new technologies, new domains, or new ideas. You're excited to take on something you've never done before.  Self prioritization. You constantly ask yourself what your top priorities are and if you’re supporting the overall goals of the company. When things are not certain, you’re not shy about asking for help. Entrepreneurial spirit. You want to build something incredibly valuable and have real impact on the world. You're excited to get your hands dirty in pursuit of that goal.   Nice-to-Haves  You've previously integrated common data sources for financial information. Examples include KYC/KYB sources, watchlists including OFAC & Sanctions lists, news sentiment data, massive document libraries, etc. You’ve worked on products that must conform to federal compliance requirements (HIPAA, PCI, etc). You have experience building products with real-time, high-throughput data streams. You have past experience with tech leadership or engineering management. You've used Rails and React before.   Technologies We Use And Teach  Ruby/Rails React, JavaScript, TypeScript, d3 AWS, Heroku PostgreSQL, Redis  The salary range for this position is $165,000 - $180,000",Algo de responsabilidad,Jornada completa,Ingeniería,Software,15,None,False,,142,None
295,2279395255,2020-11-05,Inventables,Data Engineer,United States,"ABOUT INVENTABLESOur vision is to ignite a new product revolution by bringing manufacturing capability into the hands of millions of people. To do this we are building accessible tools to help makers generate income from their work. The tools we build are software and hardware products designed to help businesses do their own manufacturing cost effectively. Our revolutionary, web-based Easel software is easy to use, whether you are new to designing products or familiar with CNC software. When you’re ready to carve, our X-Carve machine empowers users to create products out of a variety of materials ranging from beautiful hardwoods to colorful acrylics.  While our downtown Chicago office and workshop is a space where employees can meet, work, and use our products, we are a remote-first company and welcome talent located across the country. ABOUT THE POSITIONThe Data Engineer will be the first member of our new data team, reporting to the CTO. This team’s mission is to develop data systems, flows, and tools to help our team make data-driven decisions. You will collaborate with stakeholders throughout the company to ensure that the information they need is accessible, accurate, and always up to date. The Data Engineer will: Collaborate with internal stakeholders to understand data storage, processing, and reporting requirements for the businessDevelop, test, and maintain data architectures including databases, and business intelligence platforms that meet stakeholder requirementsDesign and implement automated processes to collect and transform data from various internal systems into a centralized reporting platformRecommend ways to improve data reliability and qualityEmploy a variety of languages & tools to join data across multiple systems into a unified modelAssist stakeholders in building, using, and interpreting business intelligence dashboards that track their key performance indicators How We WorkOur internal data platform is built with python, Amazon RDS, and Amazon Quicksight. We use agile development techniques to craft software and tools that help team members make data-driven decisions. We work collaboratively and iterate constantly. We choose the right technology for the job. We use automated testing to ensure our software is operating correctly and to allow us to make changes with confidence. We believe in making time for exploration and innovation. You'll have your own creative project budget, along with access to our workshop. In addition, we set aside every Friday for each engineer to direct their own R&D–whether exploring new technologies, or working on problems they think are important. QUALIFICATIONSRequired:Bachelor’s degree3+ years programming experience with a modern computing language that supports data engineering work (Python, R, C#, JVM-languages like Java)Strong SQL skillsExperience using BI reporting tools such as Looker or AWS QuicksightExperience implementing automated data pipelinesGeneralist with a strong interest in using data to answer big questionsComfortable working individually (will be first member of the data team)Experience with agile processesCurious, creative, and collaborative working styleAlways assumes positive intentAbility to take initiative and persevere in the company’s success  Values the exchange of constructive feedback with a desire to improve Preferred:Bachelor’s degree in science, math, or engineeringExperience constructing and maintaining Postgres databasesExperience working with a cloud service such AWSExperience with PythonExperience with linux shell scriptingExperience with source control systems such as git BENEFITS & PERKSBCBS Health Insurance401(k) program Flexible Accrued Vacation 'Take what you need' policyAnnual “exploration budget” to feed your curiosityAnnual “creative project budget” to help you stay creativeAnnual Conference BudgetExcellent Parental Leave PolicyA complimentary Inventables 3D Carving Machine *No staffing firms please",Intermedio,Jornada completa,"Tecnología de la información, Ingeniería",Software,73,None,True,,222,ACTIVELY_HIRING_COMPANY
296,2207107499,2020-10-23,ChowNow,Senior Data Engineer,"Los Angeles, California, United States","Are you looking to get in on the ground floor as a founding member of a data team? Are you looking for an opportunity to influence technology choices and direction? If having an immediate impact on ChowNow’s business sounds good, then we might have the perfect opportunity for you.  About Us  ChowNow is unique among tech startups in the restaurant space. We power branded online ordering systems for independent restaurants across North America – via websites, Google, Instagram, and through branded iOS and Android apps – and we do it all for a reasonable monthly fee regardless of order volume. We operate this way because of our belief in being fair, sustainable, and equitable with our restaurant partners. And the same goes for our workplace.  Diversity, teamwork, and mutual respect are among our core company values. And we pride ourselves on giving our teams plenty of opportunities to make their mark. To date we’ve created over 18,000 apps for our restaurant partners – something that’s never been done before in our category. And as we expand to new markets, further spreading the word about the ChowNow difference, those opportunities to create, build, and grow will only increase. If this sounds like the kind of workplace, and the kind of mission, that appeals to you, we’d love to talk.  Learn more by checking out our reviews on Glassdoor (they’re excellent). Together we can preserve neighborhood flavor, one restaurant at a time.  About The Position  As a Senior Data Engineer at ChowNow you will be part of the Data Engineering team within the Data & Analytics Department. You will be responsible for ChowNow’s data and analytics platform, built on AWS and Snowflake. You will build and support solutions that ingest, transform and empower consumption to high quality analytics data and other key operational workflows through the organization. This is a unique time to be joining a fast growing Data and Analytics organization that is developing a modern state-of-the-art data and analytics stack, has executive sponsorship and contributes directly to the company strategy, business growth and product development  About The Team  ChowNow is unique among tech startups in the restaurant space. We power branded online ordering systems for independent restaurants across North America – via websites, Facebook, Google, and through branded iOS and Android apps – and we do it all for a reasonable monthly fee regardless of order volume. We operate this way because of our belief in being fair, sustainable, and equitable with our restaurant partners. And the same goes for our workplace.  Reports to Lead, Data Engineering  Within 30 Days You’ll Progress through our Ramp Camp (ChowNow’s New Hire Onboarding Experience)Get to know the current state of data at ChowNow, from original source to the data warehouse to visualization and reporting.Work closely with the Analytics and Business teams to understand needs and use casesLearn ChowNow’s engineering practices by contributing a change to the code base.Learn ChowNow’s analytics practices by making a table in the DWH and a dashboard  Within 60 Days You’ll Contribute changes to the data pipeline and transformations to improve availability, quality and consumption of data.Work with the Lead of Data Engineer to plan for the future of the ChowNow data platformUnderstand the other data sources in use by the various customers across the business (starting with the Analytics team), improvement opportunities and new data to make accessible  Within 90 Days You’ll Partner with analyst and data scientists to understand key uses cases, pain points and opportunities to improve the data platformIdentify opportunities to and begin building to improve our core data transformations and begin building themIdentify opportunities and begin building to improve availability and quality of central dataIdentify opportunities and begin building solutions to improving consumability of data and scalability of analytical workflows.  You Should Apply If You have experience building ETL pipelines into a data warehouse and event layerYou have experience with using Python in a production environment.Your SQL and relational DB experience is excellent (Snowflake is a plus)You have experience with AWS technologies You are able to gather data from a variety of sources and interfaces, including REST APIsYou have experience working in a high-volume data environment such as e-commerce and SaaS environments5+ years data management, data engineer or analytics engineer experience (practical non-data engineering experience is also valued)You enjoy iterative, agile-esc development process with frequent releasesYou like collaborating with multiple stakeholders within and outside the Data & Analytics teamYou make decisions based on data and evidenceYou take great pleasure in writing quality, highly maintainable codeYou thrive in environments supporting your growth, and where you can support othersYou are excited about new technologies and spend time staying up to date in the industryYou have experience and passion to fitting pragmatic solutions to problems (building, open source, vendor)  About Our Benefits Competitive SalaryOngoing training and growth opportunities.A 'Best Place to Work' winner multiple times where we focus on creating a great employee experienceRock solid medical, dental, and vision plans.Mental Health Coverage - we offer several programs to support your mental health and wellness goals.3 weeks paid vacation: paid holidays: we expect you to work hard, but still enjoy your personal life6 weeks of baby bonding time for all new parents (within the first year of birth or adoption), 6 Weeks of Paid Pregnancy Leave.401(k) MatchingEmployer-contributing student loan assistance program.Commuter benefits (including Uber Pool).Employee Stock Incentive Plan.Pet insurance for your fur babiesQuarterly Industry Speakers Series.Quarterly Tech Events (Women, LGBTQ, Diversity, Inclusion).Consistent & fair leadership: we’ll share info, set clear goals, show you respect, and treat everyone fairly.Enough freedom to spread your wings while still holding you accountable.Fully stocked kitchen and cold brew on tap.  As one of ChowNow’s core values, “Celebrates Diversity”, we are committed to an inclusive and diverse work environment. ChowNow is an equal opportunity employer. We do not discriminate based on race, color, ethnicity, ancestry, national origin, religion, sex, gender, gender identity, gender expression, sexual orientation, age, disability, veteran status, genetic information, marital status or any legally protected status.",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Internet, Software",19,None,False,,111,ACTIVELY_HIRING_COMPANY
297,2250411409,2020-10-03,Token Metrics,Senior Data Scientist / Machine Learning Engineer (Remote),"Washington, D.C., DC, US","Token Metrics is searching for a strategic and inquisitive Senior Data Scientist to develop and run with data-centered projects.  In keeping with this overarching aim, the Senior Data Scientist will be required to outline work requirements, assign tasks to junior staff, and monitor performance within the team.  You should also harness your mastery of Data Science to consult on various aspects of these and other projects.  To be successful as a Senior Data Scientist, you should use data to ultimately inform and promote the company's expansion.  Top-notch Senior Data Scientists will assume a prominent role in the development of junior staff.  Senior Data Scientist Responsibilities Formulating, suggesting, and managing data-driven projects which are geared at furthering the business's interests.Collating and cleaning data from various entities for later use by Junior Data Scientists.Delegating tasks to Junior Data Scientists in order to realize the successful completion of projects.Monitoring the performance of Junior Data Scientists and providing them with practical guidance, as needed.Selecting and employing advanced statistical procedures to obtain actionable insights.Cross-validating models to ensure their generalizability.Producing and disseminating non-technical reports that detail the successes and limitations of each project.Suggesting ways in which insights obtained might be used to inform business strategies.Staying informed about developments in Data Science and adjacent fields to ensure that outputs are always relevant.Senior Data Scientist Requirements Advanced degree in Data Science, Statistics, Computer Science, or similar.Extensive experience as a Data Scientist.Proficiency in Python and Tensorflow.In-depth understanding of SQL.Competent in machine learning principles and techniques.Demonstrable history of devising and overseeing data-centered projects.Ability to relay insights in layman's terms, such that these can be used to inform business decisions.Outstanding supervision and mentorship abilities.Capacity to foster a healthy, stimulating work environment that frequently harnesses teamwork.Compliance with prevailing ethical standards.   About Token Metrics   Token Metrics helps crypto investors build profitable portfolios using artificial intelligence based crypto indices, rankings, and price predictions.  Token Metrics has a diverse set of customers, from retail investors and traders to crypto fund managers, in more than 50 countries.",Algo de responsabilidad,Jornada completa,Otro,"Software, Internet, Servicios financieros",6,None,False,,54,JOB_SEEKER_QUALIFIED
298,2204980085,2020-10-23,Sigmar Recruitment,Data Engineer,"Dublin, Ireland","Data Engineer – Permanent – Dublin City Centre Full stack/Data engineer - Financial services - 12-month initial contract - Day rates up to €350per day Sigmar are looking for a motivated Full stack/Data Engineer to join a large financial Institution on a contract basis to join their team in Galway.Fully remote for time being. Must be based in IrelandWhat you need :5 years Software/Data Engineering experienceOracle PL/SQL and SQLAngular/JavaScriptPython/java or .NetCI/CDSnowflake/Nifi/SparkETL (informatica)In order to applyEU, Stamp 4, Stamp 1G spousal visa . No sponsorship required   If you are interested in this job or other Data Jobs, email your cv to ttubbert@sigmar.ie or call 01 4744643.",Intermedio,Jornada completa,"Tecnología de la información, Ingeniería, Análisis","Software, Servicios y tecnologías de la información, Servicio de información",108,None,True,ttubbert@sigmar.ie,532,ACTIVELY_HIRING_COMPANY
299,2203370416,2020-10-22,Gretel.ai,Sr. Machine Learning Engineer,"San Diego, California, United States","Gretel is a startup founded by engineers from AWS and Google to help developers to safely and quickly experiment, build, and collaborate with data. At Gretel, we believe that access to data needs to become easier, more accessible, and safe. We are innovating with machine learning to help developers make sense of complex data, and privacy-enhancing technologies to streamline developer access to data safely. We are looking to hire highly skilled machine learning engineers to join our rapidly growing team- working across topics including synthetic data generation, natural language processing, data privacy, bias and fairness. Are you an experienced machine learning engineer with a strong desire to work on products that help other engineers get the most out of their day? Do you want to help engineering teams develop new capabilities by leveraging their data more effectively? Want to work as part of a remote, distributed team? If so, please join us! ResponsibilitiesYou will be involved in end-to-end development, exploring new applications and techniques within NLP, synthetic data generation, and privacy. Minimum qualifications:M.S. or PhD in Computer Science, related technical field or equivalent practical experience.A strong understanding of fundamental concepts in deep learning and related mathematics.The ability to quickly implement infrastructure, iterate on it, and evaluate it empirically.Strong communication skills - you speak, and write, your mind well. We’re a distributed team so we’re extra mindful about communicationExperience working with distributed systems.At least 5 years of professional experience in software development. Preferred experience:Experience building applications with Python and/or GoExperience with ML frameworks such as Tensorflow, HuggingFace, PytorchExperience with ML algorithms such as Transformers, LSTM, RNN, language models, NLPExperience working remotely in a distributed company We also value:An interest in data visualization, interfaces, and experience using web technologies to build them. We believe that the ability to build visualizations and interfaces is a huge enabler in studying neural networks. We think the best ideas come from the blending of diverse perspectives. Our team is comprised of the best minds in their fields - and we believe that adding perspectives will make our solutions much stronger. We hire people who are superb at what they do, drawn to the cool edges where fields touch, and like to laugh. We are deeply collaborative, apolitical, and mission-oriented.",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información","Software, Investigación",140,None,True,,405,ACTIVELY_HIRING_COMPANY
300,2268755962,2020-11-02,US Tech Solutions,Data Visualization UX Design Researcher,"New York, United States","Job Description    US Tech Solutions is seeking a “Data Visualization UX Design Researcher” for a 12 Months+ Contract position with a client in 100% Remote (NYC or TX or IL or SFO) Job Poster: Ankit Saxena Mandatory Skills: 1.       A portfolio that illustrates your communication and research skills.2.       Capabilities consistent with: Large scale data collection and analysis (e.g., collecting data from online communities, scraping social networking sites, crawling websites for landscape analyses, etc.).3.       Automated processing of visual data (e.g., experience with automated image classification, OpenCV, etc). Social network analysis (e.g., mapping networks of resource usage).4.       Visualization, especially of information rich sets of data.5.       Research instrument or prototype development skills Experience of research with target users that include Software Developers and User Experience Designers Bachelor's degree preferred (In related field) ·       You will need Critical thinking in human behavioral analysis normally evidenced by Master’s degree level or equivalent on a human centered research course, for example HCI, Psychology, Human Factors, Social Psychology, Anthropology.·       Familiarity with experimental design basics, including setup, understanding and explaining trade-offs of method, understanding populations and sampling, familiarity with issues of validity, bias, and the ability to construct or critique possible experimental setups.·       A track record of decision-making based on using a variety of practical techniques in a successful software-product development environment. Including responsibility for designing and facilitating goal directed and task directed usability assessments of software interactions on a range of different software platforms (iOS, Android, Web)·       Excellent communication skills illustrated through participant management, interview planning and management, workshop facilitation using focus group techniques and translation of findings into impactful design stories.·       Ability to construct, deploy and analyze surveys that have high quality structure, content and question structure.·       Demonstrable experience analyzing, synthesizing and distilling insights from both quantitative and qualitative data sources. About US Tech Solutions: Your talent, our opportunities - This is the premise behind US Tech Solutions.You have the skill we have the opportunity. As a team, we work passionately for you to get the right career opportunity across industry verticals and functions. For past sixteen years, leading GlobalCompanies and Fortune 500 come to us to get the right talent. Whether you want to work as full-time, contractor or part-time, technical or non-technical our talent consultants will connect with the right career opportunity globally.Connect with our talent team today.USTECH was founded in 2000 by Manoj Agarwal. Today, we are a global firm offering talent solutions to 150 customers including 20% of Fortune 500 across Financial Services, Healthcare, Life Sciences, Aerospace, Energy, Retail, Telecom, Technology, Manufacturing, and Engineering. We are headquartered in New Jersey with 40 global locations across the USA, Canada, Europe, and India. Deloitte has recognized USTECH as one of the fastest growing private businesses for the past five consecutive years and INC 500 for the past three. We have also been rated “The Top Business in the US' by Diversity Business since 2011. To learn more about how US Tech Solutions visit our website: www.ustechsolutions.com.“US Tech is an Equal Opportunity Employer' and “US Citizens & all other parties authorized to work in the US are encouraged to apply.' Apply: Interested candidates are requested to send their resume to Ankit at Ankit.s@ustechsolutions.com",Intermedio,Contrato por obra,Tecnología de la información,Servicios y tecnologías de la información,47,None,True,Ankit.s@ustechsolutions.com,177,ACTIVELY_HIRING_COMPANY
301,2172576375,2020-11-05,Intelletec,Principal Data Scientist (Machine Learning),"Massachusetts, United States","Intelletec has partnered with a leading healthcare provider who shares a common purpose: “helping people on their path to better health”! They are already transforming health care through innovations that make quality care more accessible, easier to use, less expensive, and patient-focused.  Due to rapid growth, they are seeking a Principal Data Scientist where you’re be joining an elite team of MDs, PhDs, MBAs, and MSc from top tier universities and industries that bring their clinical, technical, and economic experience to bear on some of the toughest targets in healthcare – chronic disease. Who they are looking for:Healthcare data wizards that can help translate clinical hypotheses into data andinterventions. Data scientists with deep experience working with claims/healthcare data – particularly those that have an understanding of its implications, and it's scientific and/or clinical value. Research and Development data scientists who have deep experience architecting andevaluating cutting edge mechanistic and empirical models. Deep experience coding and developing pipelines, in coordination with our other spheres and our data engineering colleagues. Skills and Qualifications: An expert (+5 years) in experimental design, causal and empirical modelling methods, model explainers, and healthcare dataHave 5 or more years of technical data science leadership, focusing on the application of ML to large datasets for healthcare or similar applicationsHave deep (+3 years) clinical and research understanding of chronic diseases and their and associated disorders and comorbiditiesHave deep (+2 years) technical experience in healthcare business case development, and med cost savings estimationHave strong (+2 years) consultatory, clinical and commercial stakeholder management, and leadership skills, and Preferred qualifications:MD and/or PhD in a technical field or equivalent practical experience (e.g., PhD in machine learning, computer science, or statistics and modelling heavy engineering field (chemistry and bioengineering)).A real passion for ML and experimental design.A real passion for patients.",Intermedio,Jornada completa,"Gestión de productos, Ingeniería",Atención sanitaria y hospitalaria,327,None,True,,953,ACTIVELY_HIRING_COMPANY
302,1885531217,2020-10-29,Premier Inc.,Principal Data Scientist,"Charlotte, NC, US","Principal Data Scientist  Our team works on some of the hardest problems in healthcare and is comprised of some of the most dedicated and talented people in the industry. As a fully remote team, we embrace independent thinking and collaborative problem-solving.  We use a variety of AI approaches including state of the art Deep Learning methods for natural language processing and predictive modeling. In this role, you will advance our health AI platform to extract and infer information from patient records.  Requirements Expertise in applied machine learningStrong technical knowledge of machine learning principlesCoding experience in PythonAbility to work in a diverse multi-disciplinary team including engineers, data scientists and, clinicians Problem-solving mindset10 years of related experienceMasters in Computer Science with a focus in AI/ML Nice to Have Experience with Tensorflow or other Deep Learning FrameworksPublished work  Premier is looking for smart, agile individuals like you to help us transform the healthcare industry. Here you will find critical thinkers who have the freedom to make an impact. Colleagues who share your thirst to learn more and do things better. Teammates committed to improving the health of a nation. See why incredible challenges require incredible people.  Qualified applicants will receive consideration for employment without regard to unlawful discrimination because of their age, race, color, religion, national origin, ancestry, citizenship status, gender, sexual orientation, gender identity, gender expression, marital status, familial status, pregnancy status, genetic information, status as a victim of domestic violence, covered military or protected veteran status, disability, or any other applicable federal, state or local protected class, trait or status or that of persons with whom an applicant associates. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. In addition, as a federal contractor, Premier complies with government regulations, including affirmative action responsibilities, where they apply.  Premier also provides reasonable accommodations to qualified individuals with a disability. If you need assistance in the application process, please reply to diversity_and_accomodations@premierinc.com or contact Premier Recruiting at 704.816.5200.",No corresponde,Jornada completa,"Ingeniería, Tecnología de la información","Atención sanitaria y hospitalaria, Servicios y tecnologías de la información",156,None,False,diversity_and_accomodations@premierinc.com,1620,ACTIVELY_HIRING_COMPANY
303,2179924225,2020-10-29,Convex,Senior Data Engineer,San Francisco Bay Area,"At Convex, data is not an incidental byproduct of our app. The data team is not a support function or an experimental lab. Data is the star of our app, and the data team is at the heart of our business.   Our product, Atlas, provides rich data on virtually every commercial property in the country (and all of the workflow software built on top of that to make it useful). Think Redfin for every commercial property, with Salesforce functionality to organize and track your work. For our users who serve these properties, this data and workflow becomes their secret weapon: there's nothing else like it available in the market today. Our market is under the radar, but massive and ubiquitous commercial services industry. Our customers are responsible for the air we breathe, the water we drink, and the lighting, safety, security, and dozens of other privileges that we are incredibly fortunate to take for granted in buildings across all of America.   Our customers live and work in almost every state in America. They include some of the largest enterprises in the country, like Siemens and Carrier, and smaller businesses we care just as deeply about. The Data OpportunityBecause data is core to our product, your role is central to our entire business. Your data features in the product frequently close massive deals and drive best-in-class retention. Every customer experiences your improvements, in prod, immediately – this is not an internal BI role. From an engineering perspective, every commercial property means massive data sets – and demanding performance and architecture requirements for your features to be put through. Geospatial data often requires GIS techniques to wrangle datasets – something different than the average SQL join. Data on virtually every commercial property in the US means a chance to see the country by way of satellite imagery, property boundaries, and several hundred other data elements we have already developed.   The RoleWe are looking for an experienced Data Engineer / Data Architect to build scalable platforms that enable efficient data movement within Convex across various sources, sinks, and support continuous data integration and processing with external enterprise systems via secure APIs and connectors. You will have a chance to:Design and implement reusable solutions and architectures for data sharing and processing use casesSupport and improve our multi-tenant data pipeline, processes, infrastructure, and stackDrive end-to-end performance, scaling, observability, and monitoring of our platformsCreate data governance models, including assets, relationships, domains, and communitiesWork in the heart of a business with multiple partner teams to build cross-functional customer solutions You have the following qualifications:Bachelor’s degree in Computer Science or related technical field or equivalent practical experience5+ years of software backend/data engineering experience, including familiarity with data modeling, ETL, schema and system design, planning, implementation, maintenance, and documentation. Professional development experience in Python/Pandas, Java, Go, and SQLExperience with large-scale distributed storage and database systems (SQL or NoSQL, e.g. Postgres, Cassandra, Hadoop, HDFS)Sound knowledge about database concepts such as transactions, indexing, concurrencyHighly analytical, passionate about data quality and availabilityEffective communicator: able to help drive data engineering roadmap and keep stakeholders updated It would be nice if you have:Masters or Ph.D. in Computer Science or related fieldExperience identifying and solving major architectural problemsExperience building geospatial services and datasets, such as maps data Hands-on experience building Spark applications or similar Big Data pipelines / frameworks / services (e.g. Hadoop, Hive, Kafka, Presto, Beam, Parquet, Avro etc.) Familiarity with API integrations and development on respective CRM platformsSome understanding of data-science & machine-learning data use cases About Convex At Convex (YC W19), we’re building the leading B2B full-stack software platform for the $400bn+ commercial services market. It's a 100-year-old industry impacting millions of people every day. We already work with some of the largest enterprise companies in the sector and were one of the fastest growing companies in the Winter 2019 YC batch. Our team is a unique mix of industry veterans from Carrier, Siemens, and Honeywell as well as founders from MIT, Harvard, and Georgia Tech. Based in San Francisco, our investors include Emergence Capital, 1984 Ventures, UP2398, Liquid2 (Joe Montana), YCombinator, the founders of PlanGrid, and others. Benefits- Join an early stage company with a lot of momentum, lead by a top tier leadership team and backed by top tier investors- Competitive salary and generous equity- Medical and dental insurance- Commuter benefits- Generous parental leave policy- Company outings & team retreats- Dog-friendly, renovated office in South Park with Bay views Convex is an equal opportunity employer and values diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. To all recruitment agencies: Convex does not accept agency resumes. Convex is not responsible for any fees related to unsolicited resumes.",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información","Software, Servicios y tecnologías de la información",117,None,True,,441,ACTIVELY_HIRING_COMPANY
304,2220912022,2020-10-20,DTG Finance & Capital Markets,Biotech Equity Researcher (hedge fund),New York City Metropolitan Area,"Sizable fund in NY seeks Biotech Research Associate for its expanding investment management team.Primary Responsibilities: Perform technical analysis for both prospective and existing public and private biotech investments Review, synthesize, and present disease pathophysiology, drug mechanism of action, PK/PD, preclinical and clinical data, CMC/regulatory considerations, and prevalence/incidence data for internally-generated reports and presentations Know, or be willing to learn, how to evaluate the above data points to generate actionable investment theses Monitor a variety of data sources to detect changes in fundamental and sentiment changes for portfolio positions, and identify potential risks to current investments Maintain a critical approach to data interpretation, with a focus on independent verification of assumptionsRequirements: A strong passion for biotech investing on both the public and private side At miminimum MS degree, preferably M.D. or Ph.D. in a life sciences field  A desire to learn how to synthesize highly complex information, distill it to key questions, generate an investment theses, and test theses objectively Excellent analytical, organizational, written, and verbal communication skills Ability to take detailed notes in real-time during presentations, company meetings and calls 1-3 years of experience in the life sciences/biotech/healthcare or healthcare investments/finance industry, with experience in venture capital, public investing, basic, clinical, or regulatory roles at a biotech or pharmaceutical company, biotech or pharma business development, investment banking, equity research, or biotech consulting.(exceptional candidates coming from academia may be considered if demonstrate strong interest and at least some experience in investing, investment research)Please apply/send resume for a confidential review, consideration and additional details.",Algo de responsabilidad,Jornada completa,"Análisis, Investigación","Gestión de inversiones, Biotecnología",308,None,True,,1146,ACTIVELY_HIRING_COMPANY
305,2243913854,2020-11-06,"Coalition, Inc.",Data Engineer - Data Clusters,"Lisbon, Portugal","About Us Coalition’s Insurance and Cybersecurity offerings come together to provide a comprehensive shield from cyber risk. We believe the task of locking down every system and keeping up with every vulnerability is challenging and while being proactive is important, it’s not enough because breaches and other compromises happen, even to the vigilant. While we proactively help our customers understand active risks and shut them down, when all else fails, we are there for them financially and with services to help mitigate damage and come back stronger after an incident. Help us protect the world against cyber risk and give business owners a trusted support system and fighting chance. We have over 25,000 customers, ranging from small and mid-sized businesses to Fortune 500 companies. Founded in 2017, Coalition has raised $125M from a number of top tier global investment firms including Ribbit Capital, Greenoaks Capital, Valor Equity Partners, Felicis Ventures, and Vy Capital. Headquartered in San Francisco, Coalition’s team is distributed across more than 15 locations globally, including Austin, Washington DC, Denver, Canada and Portugal. Coalition Engineering Our culture is one of character, humility, responsibility, purpose, and authenticity. We are growing rapidly and that growth is enabled by strong teamwork, communication, and mentorship. We want people who are passionate about becoming experts in both the business and the technologies that support it. Our core platform is written mostly in Python with some services in Java and Go. We prefer to use the right tool for the job and make pragmatic decisions about how to scale and de-couple systems as we continue to grow. We’re looking for someone who can navigate a cloud environment (AWS) with many moving pieces and systems to help the team understand how they fit into the broader puzzle. Responsibilities Triage and prioritize application security vulnerabilities.Develop internal application security testing pipeline and review processes.Build and conduct secure coding training for all developers.Mentor and train engineers to build secure productsImplement automated, proactive security measures (e.g., SAST/DAST).Develop Secure SDLC process and communicate process to Engineering.Building Application security metrics Your Background At least 3-5 years of direct experience either working on or leading an application security team.Experience conducting application security reviews.Experience with building/measuring metrics and KPIs to track application security issuesExperience with source code repositories, CI/CD pipelines, and associated security tooling (e.g., GitHub, Drone, Buddy).Experience developing SDLC processes.Experience working with SAST/DAST and tools (e.g., Synopsys, Veracode, GitLab Secure, GitHub Advanced Security, etc.).Experience with threat modeling methodologies (e.g., STRIDE).Experience with Java, Go and Python secure coding assessments.Experience in API design and system architecture Bonus Points Experience in bug bounty managementTeaching experience Why Coalition? We are all here to build something we believe in and to make a company that will last. We’re also assembling a team of expert incident responders, threat and malware researchers, and security analysts to protect our customers before, during, and after a cyber incident. Our goal is to harness the power of technology with the safety of insurance, to provide the first holistic solution to cyber risk. Coalition's culture is one that strongly values humility, authenticity, and diversity. We want to work with people of different backgrounds and different paths in life, and we trust our team members to take responsibility, share ownership and work for one another. We are always looking for collaborative, inquisitive and dedicated individuals to join our team. Recent press releases: https://news.crunchbase.com/news/coalition-secures-90m-series-c-at-890m-valuation-to-grow-cyber-insurance-platform/https://www.forbes.com/sites/amyfeldman/2020/05/28/next-billion-dollar-startups-2020/ Coalition is proud to be an Equal Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Servicios y tecnologías de la información,2,None,False,,77,ACTIVELY_HIRING_COMPANY
306,2243940919,2020-11-06,Sophos,UX Researcher,United States,"Senior UX ResearcherThe Sophos UX organization is looking for a Senior UX Researcher to join our UX team. This position can be based in the UK for our Abingdon office, or in the US for our Burlington office, with remote consideration. Cybersecurity threats increase exponentially every day. IT security products have become as complex as the networks and devices they secure. More people with less training must protect more devices, systems, and networks in their enterprises, businesses, and homes in an increasingly complex world. Making the complex available to people is a UX issue.   The Senior UX Researcher will conduct primary and secondary research and generative and evaluative research across the full range of products at Sophos.  They will work closely with our team of UX designers and researcher as part of the UX team.  ResponsibilitiesPlan and execute qualitative and quantitative research to understand users’ needs and goals for using Sophos productsPlan and run evaluative testing sessions to identify and prioritize likely problems and blockers to adoption in product UXRun research and evaluation activities, observing and capturing insights and themesAnalyse findings and create reports from research activities, turning data into actionable insights for UX Design and Product Management teamsPresent research findings and recommendations to project stakeholdersCollaborate with Product Managers, Dev and the UX team to have an awareness and understanding of product roadmaps, and possible discovery areasWorking with remote team members across multiple time zones  SkillsAt least 8 years of corporate work as a UX research or UX evaluation person or as a UX designer who has carried out research or evaluation as part of their roleA degree in psychology, behavioral sciences, human factors or equivalent experienceExperience in design, computer science, related technical field or equivalent experience a plusHighly collaborative approach focused on finding solutions that can be implemented by product teamsExcellent interpersonal, communication, and teamwork skillsExperience with various methods including remote moderated/unmoderated testing, surveys, jobs-to-be-done, interviews, user observation, usability testing, concept validation.Demonstrated understanding of the strengths and shortcomings of different research methods, including when and how to apply them during the product development process.Experience writing discussion guides, moderating sessions, note taking, analysis, and writing reportsKeen interest and knowledge of UX principlesKnowledge and understanding of Personas and their use in research and evaluationCapable of deriving meaningful insight and actionable next steps from dataPassion for problem solving through user-centric designStrong verbal and written communication skillsOrganised, eager and fast learning – you do not need to have Cybersecurity experience, but you will learn and become very familiar with cybersecurity as part of your jobExperience of facilitating workshops including Design Thinking Workshops (nice to have)",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Software,44,None,True,,363,ACTIVELY_HIRING_COMPANY
307,2268030563,2020-10-18,"Everest Consultants, Inc.",Data Engineer (Remote work),"Sunnyvale, CA, US","Title: Data Engineer Duration: 3 Months Location: Remote  NOTE - Need to work on W-2 only (No 1099 or Subcontracting)  Description  Be part of Data Engineering team responsible for Data Analytics Platform servicing the business needs of the broader organization.  Qualifications  Bachelor's degree in Computer Engineering, or related discipline 3+ years relevant working with Redshift, SQL, Python, Airflow and AWS data technologies Understanding of data architecture concepts such as data modeling, metadata, workflow management, ETL/ELT, real-time streaming), data quality 3+ years of experience working with SQL Experience with setting up and operating data pipelines using Python or SQL 1+ years of experience working on AWS Exposure to open source and proprietary cloud data pipeline tools such as Airflow, and Glue Experience working with relational databases Experience with code management tools (e.g. Git, SVN) and DevOps tools (e.g. CICD) Great written and verbal communication skills Self-starter with the ability to work independently or as part of a project team Capability to conduct performance analysis, troubleshooting and remediation Everest Consultants is an equal opportunity employer and does not discriminate on the basis of race, color, religion, sex, national origin, age, disability, or any other characteristic protected by applicable local, state or federal civil right laws.",Sin experiencia,Contrato por obra,Tecnología de la información,Servicios financieros,3,None,False,,63,ACTIVELY_HIRING_COMPANY
308,2237188914,2020-11-03,Yields.io,Senior Data Scientist,Belgium,"Our companyChiron is Yields.io's award-winning platform for automated model validation and testing. The solution is used by both international investment banks as well as by regional financial institutions to increase the efficiency of model validation and generate regulatory compliant documentation. Apart from this software solution, we offer advice and implementation services to assist our clients through their model risk management journey. Yields.io has its headquarters in Belgium, is alumnus of the IMEC.iStart incubator program and is backed by investments from Volta Ventures (early-stage European VC) and Michel Akkermans (serial entrepreneur, private investor, and former CEO and chairman of Clear2Pay). YouWe are currently looking for a result-oriented data scientist who wants to work on concrete client projects related to model risk management. This will include both projects where you will create new techniques to detect model failure as well as projects where you will validate and monitor models to determine whether an existing algorithm works as expected.  As a data scientist you will interact intensively with the development team, both providing invaluable input related to feature requests as well as feedback on existing functionality. As a consequence you will be contributing to our model risk management platform tackling one of the greatest challenges in machine learning.  This position will include some travel to client sites. MustAt least 3 years of hands-on experience with the mainstream ML techniquesProficiency in Python as well as in the main analytics libraries (Keras, Tensorflow, scikit learn, ...)Master or PhD in an quantitative field (data science, mathematics, physics, ...)Fluency in EnglishExcellent verbal, written and presentation skills PlusExperience in quantitative software developmentExperience in model validation and/or quantitative financeFamiliarity with pyspark, spark ML/MLlibPositive and creative mindsetPragmatic & client focussed Application ProcessAfter an initial screening of your CV you will be invited to participate in a 2 hours assessment to solve a small machine learning problem in Python.Once the assessment is positively evaluated, you will be invited to a few short interviews.  Our offerWork with a world class team of senior developers and data scientists to solve one of the most important problems in machine learningOpportunity to significantly contribute to the growth strategy of our companyCompetitive base salary with an equity component",Algo de responsabilidad,Jornada completa,None,Servicios y tecnologías de la información,109,None,True,,353,ACTIVELY_HIRING_COMPANY
309,2251593918,2020-11-06,3Cubed Search,Data Scientist,United States,"Data Scientist - Remote (USA) We are looking for a driven Data Scientist to work with our client who is dedicated to improving global commerce. Their AI platform helps to fund and strengthen government institutions, disrupt transnational crime, and distribute the benefits of global commerce more broadly and inclusively. This is a business which employs and advances the latest machine learning and data engineering technologies to help tackle some of the central challenges of our time.  This is a company who, through artificial intelligence, are unlocking the power of global economic data to make trade safer, more efficient, and more profitable. They are building intelligence, which includes the world’s most comprehensive representation of global commerce activity. This data asset, composed of billions of records, covers more than 40% of cross-border transactions, corporate ownership registries in over 100 countries, the global movements of goods, illicit web activity, and more. Built on this foundation, their proprietary machine learning technologies and products are designed to help customers manage risk, automate otherwise labor-intensive investigations, and better manage cross-border flows.  We are looking for a talented Data Scientist to help build this vision. You’ll work closely with engineers on projects to analyze and observe world-scale datasets and write code and models that can scale to produce never before seen insights. This position can be worked remotely, or from the company headquarters location in NYC.  Responsibilities • Analyze global trade networks, using techniques from web/social/economic network analysis • Apply cutting edge classification, regression, and clustering techniques, including deep learning, to handle high dimensional feature and outcome distributions • Train your models across hundreds of millions to billions of observations • Work with data in English, Spanish, Portuguese, Chinese, Russian, Arabic, and more • Build performant models that deliver high quality results when applied to non-stationary and adversarial distributions • Use unsupervised and semi-supervised techniques in cases of low outcome-data availability • Work with engineers to integrate your models into robust and performant data pipelines • Opportunity to work with the top technical and domain experts on our advisory board, including Matt Jackson, Stanford professor and leading expert on economic networks • Collaborate with fellow engineers and data scientists across the organization  Requirements • B.S., M.S., or Ph.D. in an engineering or quantitative discipline, or equivalent work experience • 3+ years industry experience • Expertise in machine learning and classical statistical analysis • Experience with agile development practices and Git version control • Ability to evaluate solutions in terms of business impact in addition to traditional stats or ML criteria • You have the ability to take ownership and iterate on a project through completion • You care deeply about machine-learning excellence, clean code, and knowledge-sharing • You have strong written and verbal communication skills  Nice to have, but not required • Expertise in one or more of the following: natural language processing, deep learning, computer vision, or network analysis • Experience with relational and graph databases • Experience with docker and kubernetes • Experience in machine learning model deployment • Working knowledge of cloud services like AWS, Azure, or GCP  Technologies we love • Languages: Python, Go, Java • Tools: Docker, Git, Airflow, Ansible, Swagger/OpenAPI, Dask • Datastores: Postgres, Redshift, MySQL, Elasticsearch, Neo4j  Why it’s great to work here • We love to collaborate, and we win as a team!• We are committed to engineering excellence • We value personal and professional development • We learn from diverse backgrounds and perspectives • We impact the world, from enabling developing countries to identifying drug traffickers  We are an equal opportunity employer with a commitment to inclusion across race and ethnicity, gender, sexual orientation, age, religion, physical ability, veteran status, and national origin. We offer a comprehensive healthcare package and paid parental leave of 2 months for the primary caregiver and 1 month for the secondary caregiver For further information or to apply, please contact Lisa Darbyshire at lisa@3cubed.tech",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Software,116,None,True,lisa@3cubed.tech,349,ACTIVELY_HIRING_COMPANY
310,2253700866,2020-10-04,Basepair,Senior Bioinformatics Scientist (Remote),"New York City, NY, US","Basepair develops SaaS to manage, analyze and interpret next generation sequencing (NGS) data. Scientists and physicians working in molecular diagnostics, biopharma, assay development at top universities like Harvard, Stanford, NYU, UCSD, etc. use Basepair to make breakthrough medical discoveries and provide better medical care to patients. Founded by a scientist from Harvard Medical School, Basepair is driven by the mission to use technology to improve healthcare. Our team is analytical, fast-paced and informal.  We are funded by venture capital and NIH, and we are growing rapidly. We are looking for a technically skilled and detail-oriented scientist to join our bioinformatics team remotely. Your goal is to develop, validate and update best-in-class NGS pipelines. You will communicate with existing and prospective users to answer questions about our software, perform custom analyses, and help guide strategic scientific direction for Basepair. You will be the face of Basepair’s bioinformatics expertise, conducting webinars, publishing content, etc.  Requirements  Develop, validate and update best-practices pipelines for variant calling, gene expression, epigenetics, single cell RNA-Seq, etc. Have knowledge of public datasets and consortiums Perform custom bioinformatics analysis for users Conduct webinar, QnA, etc. to introduce NGS pipelines to bench scientists Write white papers and blogs Represent Basepair at conferences and meetings  What you will need for this position  Masters or PhD with 3+ years of experience in bioinformatics, computational biology or related field 2+ years of experience of building NGS pipelines 2+ years of Python programming, data visualization, ability to read and modify other people’s source code Proficiency in Linux, setting up servers, installing packages, bash scripting, etc. Ability to work independently, prioritize tasks and manage your time productively Excellent communication skills, including scientific writing   Additional Desired Qualifications  Experience with cloud computing (AWS), docker, etc Proficiency in R Experience with CWL, WDL Expertise with front end software development using JavaScript, e.g., React, d3.js, etc. Familiarity with molecular biology and NGS library preparation techniques Previous startup and remote work experience is a plus   Benefits  This is an opportunity to make a significant impact at an early stage startup. We’re a small team working closely together to make people’s lives better! Your voice will be heard and you will have the autonomy to set your vision. We strongly encourage ongoing learning to be the best in your position. We provide a competitive salary, meaningful equity, excellent healthcare and other benefits.  While half the team works out of our New York office, we are a remote-friendly company. We want to hire the best talent, and people who work at Basepair can live and work from anywhere they want.",Algo de responsabilidad,Jornada completa,Análisis,"Software, Investigación, Biotecnología",17,None,True,,92,None
311,2208994107,2020-10-15,Pinsent Masons,Data Engineer,United Kingdom,"DATA ENGINEER – UK BASED Role OverviewWe are currently recruiting for an Data Engineer to join our Information Technology team. This role will be based in any of our UK offices, to be agreed with the successful candidate. The Data Engineer will be involved in helping to define, build, and maintain a robust data platform and information architecture. You will be joining a team in the early stages of a large digital transformation focused on bringing improvements in data management practices to the firm.   Candidate OverviewWe are looking for an organised, highly motivated and enthusiastic individual who has the ability to work under pressure and adapt to new technology. Experience in using architecture frameworks such as TOGAF and data management frameworks such as DAMA. What can we offer you?Join a global, innovative and forward thinking firm:Access to training and development to refresh or enhance your current skillset:The opportunity to work agile:Competitive salary and benefits package, including 25 days holiday, private healthcare and contributory pension. Firm Introduction Pinsent Masons is an international law firm that ranks amongst the top 75 law firms globally, with a long-standing reputation for delivering high-quality legal advice rooted in its deep understanding of the sectors and geographies in which its clients operate. We know that our culture sets us apart, and with over 1,500 lawyers operating from 24 locations throughout the UK, Europe, Asia Pacific, Africa and the Middle East, it is at the heart of our success as a leading international law firm. Our core values are Approachable, Bold and Connected and as a firm we hold these in high regard. Personally and collectively, we live them every day and our firm is a better place for it. Pinsent Masons stands out in particular for its innovative approach to service delivery and in 2016 we were ranked among the five most Innovative Law Firms in Europe. For any queries or for a copy of the full job description then please contact our in-house recruiter Glenn Wilshaw. Please note we only accept CVs that are logged on the Recruitment portal. #LI-LINKEDIN Primary Location: GB-GB-BirminghamWork Locations: Birmingham - 19 Cornwall Street 19 Cornwall Street  Birmingham B3 2FFJob: Business OperationsOrganisation: Technology ServicesJob Posting: 15-Oct-20, 12:55:07 PM",Algo de responsabilidad,Jornada completa,Tecnología de la información,Servicios jurídicos,13,None,False,,205,ACTIVELY_HIRING_COMPANY
312,2211437274,2020-10-28,Prestige Staffing,Data Engineer,Atlanta Metropolitan Area,"Data Engineer Location: Remote We have a client seeking a Data Developer for a long term contract to perm. The client is in the franchised food service space and is growing exponentially year-over-year. This position is fully remote for the forseeable future. They key skill set for this position is expert knowledge in SQL, ETL/ELT. AWS, and overall database development. Our client is transitioning to have their IT in-house, which requires a lot of rebuilding and implementing new practice and procedures! 5+ years of strong SQL experience5+ years strong ETL / ELT experience2+ years of AWS knowledgeSnowflake experience is an added bonus",Intermedio,Contrato por obra,"Tecnología de la información, Ingeniería","Servicios y tecnologías de la información, Software",147,None,True,,467,ACTIVELY_HIRING_COMPANY
313,2181318595,2020-10-13,Which?,Researcher/Writer (Product Testing),"London, England Metropolitan Area","We're looking for a Researcher/Writer to join the Product Testing team on a fixed term basis. We've all been in the situation where we've invested time and money into purchasing a product only to be let down. That's where Which? steps in. We rigorously test the products and services you need so that we can tell you which you should choose - and which you should avoid. Our 800,000+ subscribers depend on us. And so we need you to give them the unbiased information they expect so that they can choose the right products the first time. What you'll be doing:This unique role needs someone who can organise top quality product research, can get to grips with the results and can then turn them into engaging print and online content. You'll design and commission robust research with external laboratories for a range of consumer products. This means that you'll need to be switched on and will really understand what consumers want to know - for example, will the battery in that new mobile phone last through the day or will the latest washing machine really get my clothes clean at 30C? You'll deliver the research that tells people what they need to know and truly affects what they buy.  You'll have an eye for a great story. Working with technical data you'll draw out what the information is saying and what consumers would be interested in. You will then use your exceptional writing skills to deliver content for our flagship magazine, Which?, and our website which.co.uk, including features, product reviews and news stories. You'll also get the chance to create a range of related website content, including photo galleries, graphics and videos. What is on offer?A supportive team structure, the tools to grow and develop and you can work every single day knowing that you're playing your part in making consumers as powerful as the organisations they deal with. Refer to our candidate for more information about our benefits package. What we are looking forYou'll have excellent project management and delivery skills that enable you to run multiple projects at the same time and to produce articles to tight deadlines.You'll have an understanding of different research techniques. And while you may not have conducted product tests in the past, your experience will help you to plan/commission research that will tell consumers what they need to know.You'll need excellent writing skills and a talent for turning complex information into clear, accessible language that's enjoyable to read.You'll be comfortable interpreting and working with complex large data sets in Excel. Please see the attached Performance Framework for further details on the role.We're not looking for the total package, we know it's a big ask, and we can support you in developing the full range of skills needed to succeed in this role. Let us know what makes you stand out from the crowd by sending us a covering letter and your CV.If this sounds like your ideal next role, then we want to hear from you!  At Which? we value diversity and we're committed to creating an inclusive culture where everyone is able to be themselves and to reach their full potential. We want to receive applications from all regardless of age, gender identity, disability, marriage or civil partnership, pregnancy or maternity, religion or belief, race or ethnic origin, sex, sexual orientation, transgender status, social economic background etc. We believe that a diverse workforce helps us to understand and create a positive impact for consumers. We want to ensure that everybody can apply and be part of our recruitment processes, and therefore when required we make reasonable adjustments to accommodate our candidates.",Algo de responsabilidad,Jornada completa,"Investigación, Redacción y revisión","Publicaciones, Gestión de organizaciones sin ánimo de lucro",269,None,False,,2481,ACTIVELY_HIRING_COMPANY
314,2211106222,2020-10-25,Mirania Data Systems,Web Researcher,India,We are looking for a Web Researcher to join our team and play an important role in the execution of our projects. We are a KPO (Knowledge Process Outsourcing) unit with clients spanning across different industries. Hence there is a lot of opportunity to learn and grow. Job Details-------------1) Part time2) Payment as per project complexity3) Flexible timing4) Oppurtunity to learn new skills and strengthen your own existing skills as you work on projects with a wide range of requirements and complexities from both National and International clients. We look forward to onboarding you if you are the right fit and strengthening our team.Please send in your resume to navinmirania@hotmail.com along with any queries you may have. We will look forward to hearing from you.,No corresponde,Media jornada,"Marketing, Relaciones públicas, Redacción y revisión",Servicios y tecnologías de la información,173,None,True,navinmirania@hotmail.com,665,JOB_SEEKER_QUALIFIED
315,2234207003,2020-11-02,Lawrence Harvey,Lead Computer Vision Scientist,United States,"Lead Data Scientist- Computer VisionUp to $200k + benefits + equity.Lawrence Harvey are currently partnered with a leading digital identify verification business, who use cutting edge Deep Learning technology to verify identities in real time. Due to heavy investment capital and a hugely successful 2020, they are looking to expand their research teams—specifically within Artificial Intelligence and Computer Vision. As a company, they have developed Machine Learning and Computer Vision algorithms that analyze huge amounts of different types of data, including but not limited to, social media, financial documents, human faces & other such documentation.If successful, you will be tasked with a number of responsibilities including: Leading all Machine Learning and Deep Learning efforts for the R&D team focusing specifically on image data.Will be leading collaboration with multiple business units, including product and engineering.Implement, optimize and deploy cutting edge computer-vision algorithms for document processing, facial recognition and other forms of verification.We are looking for a skillset similar to:Extensive Deep Learning background (4+ years).Strong academic background (PhD is preferred).A minimum of 4 years as a data scientist.PyTorch is the main library but will consider Tensorflow, Keras or CUDA.Experience with GPU.Experience deploying DL models to production.If this sounds like the kind of position you would like to be considered for, please get in touch.",Intermedio,Jornada completa,"Tecnología de la información, Ingeniería, Investigación",Servicios y tecnologías de la información,40,None,True,,216,ACTIVELY_HIRING_COMPANY
316,2256173912,2020-10-15,Huckleberry,Data Engineer,"San Francisco, CA, US","Data Engineer  San Francisco / New York / Remote Fulltime  About Huckleberry  Huckleberry is rebuilding small business insurance from the ground up. In a multi-trillion dollar industry where paper forms and fax machines still predominate, and customers are wasting countless hours navigating byzantine processes, we provide small business owners with the capability to manage all of their insurance needs through a single, elegant interface. Our team is rethinking every aspect of the experience, from pricing, to underwriting to claims.  We're backed by Tribe Capital, Uncork Capital, Crosslink Capital, e.ventures, Postmates CEO Bastian Lehman, Apartment List CEO John Kobs, and several others. We're looking for a Data Engineer to join our growing team of insurance innovators in San Francisco, CA. As an early member of the Huckleberry team, you will have full ownership of finding the best solutions to design, architect and implement across our stack. Our technology stack is built on Python/Node/Hapi/Postgres/React sitting on AWS. We write a lot of tests, use automated deployment, Github for code reviews, and Sketch/Invision for mockup prototyping.  Responsibilities  Work closely with product and engineering teams to identify important questions / processes that can be answered or improved with data. Define, improve, and maintain our data infrastructure and any related architecture. Drive the collection of new data and the refinement of existing data sources. Build tooling that can be used by other engineers to capture essential product-related data. Build tooling that can be used by product teams to analyze and evaluate business needs. Develop analytical solutions using machine learning / statistical modeling.   Requirements  3+ years of professional experience working with and analyzing large data sets to solve problems. Expert mastery of Python: scientific computing frameworks such as scipy, numpy, pandas, and/or scikit-learn: and tools such as jupyter notebooks. Experience with data workflow frameworks such as Airflow Experience with data processing frameworks such as Hadoop, MapReduce, and associated tools. Experience building ETL pipelines and integrating with APIs that use REST, SOAP, and other technologies. Familiarity with Node.js/JavaScript a plus. Understanding of trade-offs in database and infrastructure design choices. Strong commitment to quality designs, automated testing, and documentation. Good communication skills in English, both written and spoken. Sense of ownership and ability to drive issues and new ideas.  Why You'll Love Working at Huckleberry  Comprehensive medical, dental and vision insurance with 95% of premiums paid for by Huckleberry Free One Medical subscription Flexible Spending Account and 401k Commuter benefits Paid maternity and paternity leave Free daily lunch and a kitchen stocked with delicious snacks, drinks, and coffee Company-sponsored happy hours and outings",Sin experiencia,Jornada completa,Tecnología de la información,"Software, Internet, Seguros",14,None,False,,105,ACTIVELY_HIRING_COMPANY
317,2268577816,2020-11-08,Myticas Consulting ULC,BHJOB15656_15470 - Data Engineer (Remote),"Ottawa, Ontario, Canada","The recruitment team at Myticas Consulting is looking for an experienced Data Engineer who would be interested in a remote contract opportunity offered within the Ottawa, ON region. Security Clearance Required: Enhanced Reliability. Project Scope: IoT solution to ingest data from radio-spectrum analysis was built in Azure and needs to be migrated into AWS. This included some App migration, some containerization and some migration of R to Python. Qualifications: AWS is critical.Azure is a benefit.Knowledge of R and Python.Containerization are required. Skills: RPythonSparkSQLWarehousingLakehouseAWS Data Tools (EMR, Athena, Glue, S3)AWS App Dev (S3, Lambda, Step Functions)DockerC++",Intermedio,Contrato por obra,Tecnología de la información,"Servicios y tecnologías de la información, Software",41,None,True,,168,JOB_SEEKER_QUALIFIED
318,2274526908,2020-10-10,Shopify,"Senior Data Scientist - Finance (Remote, Americas)","Houston, TX, US","At Shopify, we build products that help entrepreneurs around the world start and grow their business. We’re the world’s fastest growing commerce platform with over 1 million merchants in more than 175 different countries, with solutions from point-of-sale and online commerce to financial, shipping logistics and marketing.  Data is a crucial part of Shopify’s mission to make commerce better for everyone. We organize and interpret petabytes of data to provide solutions for our merchants and stakeholders across the organization. From pipelines and schema design to machine learning products and decision support, data science at Shopify is a diverse role with many opportunities to positively impact our success.  Our data scientists focus on pushing products and the business forward, with a focus on solving important problems rather than specific tools.  Successful Candidates Will Have Experience With Building data models and conducts analysis to provide recommendations on investment and improve margins. Conducting research with internal and external data with statistics/causal inference techniques to provide recommendations on strategic decisions or understand impact from macro events. Generating time-series forecasts for financial planning and anomaly detection.Enforcing the service level agreement on critical data set and dashboards used across Finance for the purposes of analysis, disclosures and audits.   Your Responsibilities Proactively identify and champion projects that solve complex problems across multiple domainsPartner closely with product business leaders to influence business decisions with dataApply specialized skills and fundamental data science methods (e.g. regression, survival analysis, segmentation, experimentation, and machine learning when needed) to inform improvements to our businessDesign and implement end-to-end data pipelines: work closely with stakeholders to build instrumentation and define dimensional models, tables or schemas that support business processesBuild actionable KPIs, production-quality dashboards, informative deep dives, and scalable data productsInfluence leadership to drive more data-informed decisionsDefine and advance best practices within data science and product teams  You'll Need To Have Extensive experience with Python and SQLExperience with applied statistics and quantitative modeling (e.g. regression, survival analysis, segmentation, experimentation, and machine learning when needed) with both time-series and panel dataDemonstrated ability to translate analytical insights into clear recommendations and effectively communicate them to technical and non-technical stakeholdersCuriosity about the problem domain and an analytical approachStrong sense of ownership and growth mindset  If you’re interested in helping Shopify shape the future of commerce, click the “Apply now” button to submit your application.  Closing Date: November 6th , 2020  At Shopify, we are committed to building and fostering an environment where our employees feel included, valued, and heard. Our belief is that a strong commitment to diversity and inclusion enables us to truly make commerce better for everyone. We strongly encourage applications from Indigenous people, racialized people, people with disabilities, people from gender and sexually diverse communities and/or people with intersectional identities. Please take a look at our 2019 Sustainability Report to learn more about Shopify's commitments.  ↓  Interested, but not ready to apply?  Join the Shopify Talent Community for external candidates to learn more about Shopify by clicking here .",Algo de responsabilidad,Jornada completa,Otro,"Software, Internet, Servicios financieros",8,None,False,,63,COMPANY_RECRUIT
319,2275993419,2020-11-04,deepwatch,Data Scientist (remote),"Denver, CO, US","Description  Who We Are  deepwatch is redefining cybersecurity and is one of the fastest growing companies in the U.S. (Top 50 based on last year’s Inc5000). deepwatch serves an impressive list of Fortune 50 and Global 2000 companies as well as numerous mid-sized enterprises. We’ve established strategic partnerships with leading security vendors and serve as a trusted advisor to our customers. Our Core Values drive all aspects of the business and have been paramount to the company’s success and foster our dynamic, entrepreneurial workplace. At deepwatch, your colleagues are some of the most technically astute minds in cybersecurity, who are passionate, knowledgeable, and willing to provide mentorship and guidance at every opportunity.  deepwatch's innovative cloud SecOps platform and borderless SOC delivers data-driven managed security services while extending customers’ cybersecurity teams and proactively protecting their brand, reputation and digital assets. deepwatch's powerful analytics platform, led by 200+ experts, analyzes billions of events each month and is trusted by hundreds of leading global organizations to provide 24/7/365 managed security services. We have some of the coolest, most innovative IP in the industry and we’re rapidly expanding that.  If you have the passion, work ethic, winning attitude and competitive mindset to be at the forefront of the best entrepreneurial MSSP|MDR in the U.S., we want you on our team.  deepwatch Offers A highly collaborative environment with very bright minds and inquisitive thinkingAwesome benefits - we pay a significant portion of our employees’ medical and dental premiums (100% for the HDHP plan) and a very generous portion for dependentsFSA (medical and dependent) and HSA with employer contributionCompany paid Life Insurance, Short Term Disability and Long Term Disability401k retirement plan with employer matchPaid Time Off (PTO)10 Company HolidaysPaid time off for votingAs a fully remote company, we offer the responsible balancing of your time between work & lifeAll employees are paid a generous mobile phone and home internet allowanceApple productsAttractive referral bonus programCareer paths and the opportunity to do cool and different things as our growth continuesSignificant annual allowance per employee for Professional Development Data Scientist  The mission of the deepwatch Security Research team is to tease from massive data sets security outcomes that provide actionable security details to customers. Data Scientists at deepwatch will analyze terabytes of data with the objective of squeezing out as much security value for our customers as possible. deepwatch will use the techniques developed by the Data Science team to automate delivering outcomes before our Analyst teams engage. We are seeking those who want to use their data science skills to help deepwatch identify threats in traditional digital threat vectors as well as cutting edge technology stacks such as Cloud Native (Azure, AWS, GCP), Internet of Things (IoT), and Serverless applications!  Responsibilities Solving difficult data problems while embracing cyber security challenges with open armsGathering and processing data at scale, writing scripts and queries, and building and calling APIsVisualize threat signal data and uncover how bad actors use security vulnerabilities, malware, and patterns to spread across networks and drive analytic development to build libraries for persistent detectionDrive the development of Machine Learning use cases to detect malicious activity in customer environments with regular content updatesProvide documentation to Threat Hunt, Research and Analyst teams around data analytics and mathematical decisions, with actionable workflows for threat investigation of ML alertsEnsure data quality and normalization throughout all stages of acquisition and processingClean, analyze and select data to achieve goals that create desired security outcomes for deepwatch customersBuild models that elevate the customer experience and track value of security outcomes for deepwatch customers over timeCollaborate with colleagues from Product, Delivery, Content, and Threat Hunting teamsPresent proposals and results in a clear manner backed by data and coupled with actionable conclusions that drive analytics, content libraries, and automation outcomesWork with engineers to develop efficient data analysis and data modeling infrastructure  Requirements  Required Experience, Skills and Knowledge Bachelor's Degree with an emphasis in Data Science or related field such as Mathematics or Computer Science2+ years-experience with various data analysis and visualization toolsAWS/Azure/Google Cloud data engineering experienceProficiency in Python and other programming / scripting languagesExperience with various machine learning techniques and parameters that affect technique/model outputs and performanceDeep understanding of machine learning techniques and algorithms, such as Random Forests, Gradient Boosting, Ridge/Lasso, SVM, time series techniques et. al.Exceptional numerical and statistical ability, with excitement for applying analytics to client challenges and significant experience using analytic / database software and languages such as SAS, SQL, SPSS, R, Python, et. al.Experience with analytics programming languages (Python, Ruby, Shell) and automation tools (Ansible, Chef, Puppet etc.)Exemplified critical thinking and creative problem solving skillsCompetency with common data science toolkits, such as NumPy, pandas, sparkML, scikitLearn, et. al.Capable of leading and executing on data acquisition, cleansing, and storage for individual initiativesWilling to tackle big problems that have unknown solutions at the outsetStrong oral and written communication skills, including the ability to communicate effectively to non-technical audiencesTeam player with a passion for coaching colleagues and customers in the areas of data science  Preferred Experience, Skills And Knowledge Master's degree or PhD in relevant field(s) such as computer science, mathematics, or data scienceHistory of diving into data to discover hidden patterns and of conducting error/deviation analysisAbility to develop both experimental and analytical plans for data modeling processes, use of scaling baselines (trends)Strong ability to accurately determine cause and effect relationshipsUnderstands relevant statistical measures such as mathematical modeling, confidence intervals, significance of error measurements, development and evaluation data setsAn ability to work successfully across a globally distributed team and geographical boundaries to deliver joint initiatives Equal Opportunity Employer  deepwatch is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability status, marital status, sexual orientation, gender identity, genetic information, protected veteran status, or any other characteristic protected by law. In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Software, Seguridad del ordenador y de las redes",85,None,False,,430,None
320,2283749579,2020-11-06,CitySwift,Data Scientist / Optimisation Engineer,"Galway, IE","This is an exciting opportunity to be part of a brilliant team in a fast-paced, collaborative environment. You will have the chance to influence and shape our Product, Technology and Data Science strategy while working with billions of data points to solve real-world, measurable problems!  About CitySwift  CitySwift is a Cloud-native, specialist data engine for modern bus networks. We optimise urban bus networks using Big Data and Analytics. Ultimately, we improve the reliability of services while simultaneously reducing Operator costs, resulting in a win-win for both passengers and operators!  Our Company Values  Be Open & Honest Take Ownership & Finish it! Think like a Customer Alright is not OK! Be up for the challenge.   What You'll Do:  Build statistical and machine learning models to understand and predict various aspects of public transportation, including demand, run times and usage patterns to name a few. Conduct rigorous testing and evaluation of existing models, suggesting improvements and optimisations as well as exploring alternative approaches.  Conducting R&D and exploratory analysis into new avenues of interest, with an aim to better understand the problem to be solved and gain deeper understanding of the nuances of data driven public transport optimisation.    What you'll bring:   Proven experience of data science and machine learning applications in a variety of areas and solving different problems using a variety of techniques.  Solid grounding in statistics and with proven ability to relate statistical analysis and metrics to real world problems during product development.  Strong Python 3.x knowledge with continuous use of pandas, sci-kit learn, TensorFlow and stats models or any other model building packages. Strong SQL and data manipulation skills. Experience building neural networks using TensorFlow bespokely and using the estimator API.  Experience using cloud based platforms for data manipulation but also cloud based model training and hosted real time and batch predictions.   It would be great if you have:  Experience with large scale data pipeline for leveraging external sources eg. Apache beam Experience of model specific transformation and feature engineering pipelines such as sci-kit-learn pipeline or TFX.  Experience with both TF1.x and 2.x with detailed knowledge benefits of both.  Experience of model explain-ability techniques.  Experience developing routing based predictions or area specific demand   What we can offer you:  Opportunity to make your mark in a high growth Irish Tech Company The product is scaling, with constant engagement and feedback from users and clients to inform the development roadmap. Ideas are listened to and encouraged. Experts are allowed to make decisions Open, transparent culture where everyone is kept informed and committed to the company's future.  We hire the best so that everyone can learn from each other Office in City Centre location. Flexible hours and remote working opportunities Generous Healthcare  Bike to Work & Taxsaver commuter scheme Competitive compensation  Active social club where employees are encouraged to have fun together both inside and outside of work!",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información",Servicios y tecnologías de la información,15,None,False,,119,ACTIVELY_HIRING_COMPANY
321,2279984524,2020-11-05,Signify Health,Data Scientist,"Dallas, TX, US","Position Overview:  Reporting directly to the Director of Business Intelligence and Analytics, the Data Scientist position is responsible for designing, methodologies for data management and exploration, running statistical experiments in a methodical manner, and will regularly evaluate alternate models via theoretical approaches. This role will be responsible for fulfilling our internal departments, as well as external clients' needs from an analytics perspective and develop reporting to satisfy those needs. The Data Scientist's role is to transform data into knowledge that can be used to make rational decisions by:   Collecting and preparing data for analysis – Cleansing / Data Wrangling Creating models to evaluate the data – Statistical, Visual, Machine Learning Evaluating models and refine as needed – How well does it work and can we make it better? Delivering solutions based upon the model and communicating their value and use   Education/Licensing Requirements:    Bachelor's degree in Computer Science, Statistics, Applied Math or related field   Experience Requirements:   Extensive background in data mining and statistical analysis Experience with statistical programming languages such as Python, R, Excel (analytics) required 5+ years' practical experience with ETL, data processing, database usage/programming and data analytics Transforming and cleansing data Creating and interpreting statistics – numerically analyzing data Creating and interpreting visualizations – visually analyzing data Creating statistical models – using them for inference and prediction Experience with Microsoft SQL Server (2000+ versions of SQL Server, SSIS, SSRS, SSAS)   Duties and Responsibilities:   Leveraging the CRISP DM process, work in collaboration with management, business users, IT developers and Subject Matter Experts (SMEs) to transform data into knowledge that can be used to make rational decisions Must be able to understand business need and specify analytical/statistical requirements and implications, design, program, test, and field the results into a productive feedback cycle Research and develop statistical learning models for data analysis Implement new statistical or other mathematical methodologies as needed for specific models or analysis Keep up-to-date with latest technology trends Communicate results and ideas to key decision makers in a concise manner Investigate available data, identify and recommend best sources for building better models/reports for ultimately improving company results Comply with applicable legal requirements, standards, policies and procedures including, but not limited to the Compliance requirements and HIPAA   Essential Skills:   Fluently speak, read, and write English Strong work ethic, able to work both collaboratively, and independently without a lot of direct supervision, and solid problem-solving skills Excellent interpersonal skills Strong mathematical, analytical, and statistical skills Excellent pattern recognition and predictive modeling skills Excellent verbal and written communication skills Proven ability to prioritize and multi-task Advanced skills in MS Office Excellent analytical skills     Essential Characteristics:   Self-directed and organized Discrete/ability to maintain confidentiality Strong work ethic Team player Detail-oriented Sense of urgency Customer service orientation Ability to work under pressure Ability to work well independently Able to lift up to 20 lbs. unassisted Ability to take direction  About Us:  Signify Health is helping build the healthcare system we all want to experience by transforming the home into the healthcare hub. We coordinate care holistically across individuals' clinical, social, and behavioral needs so they can enjoy more healthy days at home. By building strong connections to primary care providers and community resources, we're able to close critical care and social gaps, as well as manage risk for individuals who need help the most. This leads to better outcomes and a better experience for everyone involved.  Our high-performance networks are powered by more than 9,000 mobile doctors and nurses covering every county in the U.S., 3,500 healthcare providers and facilities in value-based arrangements, and hundreds of community-based organizations. Signify's intelligent technology and decision-support services enable these resources to radically simplify care coordination for more than 1.5 million individuals each year while helping payers and providers more effectively implement value-based care programs.  To learn more about how we're driving outcomes and making healthcare work better, please visit us at www.signifyhealth.com.",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Software, Servicios financieros, Atención sanitaria y hospitalaria",60,None,False,,338,ACTIVELY_HIRING_COMPANY
322,2248348278,2020-10-28,Brightloom,Director of Data Science,"Seattle, WA, US","The Role:  As the Director of Data Science at Brightloom, you'll lead the data science team and partner across the organization to help grow our data science capabilities. You'll be taking business needs from product and engineering teams and creating a comprehensive data science strategy around them. From there, you help prioritize the work for the data science team, balancing the work for the team and helping the independent contributors be their best. You will heavily engage with the application engineering, data engineering, and data science technical leads to ensure that your data science strategies are operationalized effectively.  You're a person who loves helping others work together to do interesting data science. You can evangelize a data science idea to non-technical people, and you can deal with the realities of a complex business and figure out how to have data science contribute in a positive way. You enjoy leading data scientists so they can do strong work, and helping to elevate the data scientist's concerns when they raise them.  What you'll do:  Lead the data science team as their manager - helping devise projects, removing blockers, and engaging with independent contributors. You'll be hiring more data scientists and eventually hire managers to do this part of the job for you. Represent the data science discipline throughout the organization. You will have a powerful voice in the company and represent data scientists across different parts of the business. Partner across Brightloom engineering groups: evangelizing our culture of using data to measure, understand, and improve our product and features. Be a strong leader - you will give team members clear feedback that helps them grow and inspires thought leadership. You will lead by example, have compassion for everyone in the company and their challenges, and will take controversial directions when necessary. Be an expert in interpreting data and understanding its conclusions - your team will be creating lots of powerful insights and you will be finding the valuable implications of that data. Own the data science technical roadmap - take the business priorities from the product team and turn them into a set of projects the data science team will focus on delivering. Be involved in new product development - as the product team thinks of new ways to take customer feedback and create a better product, you'll be heavily involved with assessing what is feasible from a data science perspective.  About you:  Demonstrated experience building and developing a team Demonstrated experience putting a data science product into market, ideally in a startup Experience in the marketing, retail, or restaurant domain Foundational understanding of the data science ecosystem   About Us  At Brightloom (formerly eatsa), we are working to revolutionize restaurants through innovative technology and design. We are disrupting an industry worth $900 billion globally with partnerships in North America, Asia, and soon other continents.  Led by our CEO, industry veteran and former Starbucks and J.Crew executive Adam Brotman, our unique, world-class team combines software and hardware engineers, designers, and industry experts to push the boundaries on re-engineering every aspect of the restaurant experience.  We believe any restaurant brand should be able to engage customers digitally using a seamless combination of mobile, omni-channel ordering and loyalty offerings. Up until now, only a select few brands could afford, or knew how to put together a top-notch digital engagement and ordering platform. With key Starbucks technology components integrated into our platform, Brightloom will now allow any restaurant brand to create their own version of a world-class digital flywheel ecosystem. Brightloom's configurable technology suite combines convenience (digital ordering channels), personal connection (personalized marketing) and engagement (loyalty) for restaurant brands in today's new digital era.  What We Offer  Fun, creative and collaborative remote work environment  Competitive pay and equity/stock options Health, Dental & Vision Insurance Coverage Life Insurance, Short-Term Disability, Long-Term Disability Phone/Internet Reimbursement  Home Office Refresh Reimbursement  Employee Assistance Program Flexible Spending Account & Health Savings Account Flexible Time Off 401(k)  Brightloom is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability and protected veterans status or any other characteristic protected by law.",Director,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Software, Internet",40,None,False,,269,ACTIVELY_HIRING_COMPANY
323,2243132062,2020-10-01,BitSight,Security Vulnerability Researcher,"Boston, MA, US","You will be a member of the BitSight security data research team. The main goals of the team is to provide BitSight with subject matter expertise in cyber security, analyze and produce security data and prototype new features that can be added to the product. This role is focused primarily on the analysis of new vulnerabilities and supporting the threat research efforts.  Primary Duties:   Help BitSight maintain the most accurate and up-to-date global visibility on new vulnerabilities: Help BitSight maintain global visibility over the current threat landscape:   Operational Duties:   Keep up with newly published vulnerabilities: Understand the technical details of the published vulnerabilities as well as their real risk: Build scripts and software modules to verify the presence of vulnerabilities: Effectively communicate the vulnerability impact: Assist in threat research and analysis of malware-related network traffic: Reverse-engineer malware families: Reverse-engineer vulnerability patches in order to better understand certain vulnerabilities: Assist in analysing data from internet scanning tools in order to validate its accuracy: Assist in the development of tools to improve vulnerability or threat research.   Experience, Skills and Knowledge:   Fast learner and motivated. Must be particularly interested in cybersecurity: BSc or MSc is desirable: Comfortable working in Windows, OS X, Linux and Android environments: Technical knowledge of network protocols and security concepts: Comfortable with at least one programming language, ideally Python.   What we offer:   Great company - BitSight pioneered the market and the Security Rating is becoming increasingly important worldwide as the standard, Good work environment and perks: Very knowledgeable and helpful team:",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Internet",12,None,False,,71,ACTIVELY_HIRING_COMPANY
324,2242683737,2020-10-26,Guru (getguru.com),Senior Machine Learning Engineer,San Francisco Bay Area,"Overview: Guru is seeking an experienced Machine Learning Engineer to develop, improve, and deliver features powered by ML into our product. This is an awesome opportunity to maximize and grow your software engineering and machine learning skills alongside a team of creative, accomplished data scientists and engineers. To be successful you must be highly collaborative, excited about using ML to tackle real world problems, and have a commitment to show your grit. While we will always celebrate our successes, we embrace the journey by both persevering and learning from our setbacks. If this sounds like you, and you want to work with a diverse team that values all voices, please read on… At Guru your voice will be heard and respected. One of our core values is “Learn and Grow” as we seek to reflect on past projects to find opportunities to learn how we can better communicate and work more effectively as a team. We actively promote a healthy work life balance especially during the global pandemic as we realize for many life and work are intertwined more than ever. This job is not only about how well you develop: it’s about how you lend your positivity and presence, combined with your skill set to an energized environment and highly collaborative team. Strong sense of humor required, sarcasm detection skills a plus. Responsibilities:Productionize and deploy the ML models prototyped by our data scientists as well-tested Python-based servicesBuild, automate, maintain, and optimize our feature extraction and model training pipelinesCollaborate with ML engineers, data scientists, and architects to improve the architecture, scalability, stability, and performance of our ML platformDevelop processes, monitoring, and frameworks to ensure data and model qualityCollaborate on design and code reviews to ensure high quality software Requirements:5+ years of software engineering experience in Python/Scala/Java or similar programming languages to contribute to a Python code baseExperience architecting, building and deploying scalable ML systems into AWS cloud using ECS, ECR, Lambda, API Gateway, Sagemaker, DynamoDB, and S3Experience processing large amounts of data using technologies such as Apache Spark and EMRExperience working with Docker, CI/CD pipelines, and familiarity with infrastructure as code principlesProficient working with SQL, data warehouses, and relational data Preferred but not required:Experience with ScalaExperience with Natural Language Processing (NLP)Experience designing systems in microservices architectures Important:Guru believes embracing diverse experiences, backgrounds, and skill sets make both Guru and our customers stronger and smarter. Even if your experience and skill set doesn’t match the requirements perfectly, apply and tell us why you think you are a great candidate to tackle the responsibilities of this position! Benefits to you:Competitive salaryEmployee Stock Option PlanGenerous health, wellness, and commuter benefitsThe chance to contribute to an upbeat, fully engaged culture About Guru:Guru is a dynamic, fast growing start-up based in Philadelphia and San Francisco. Our mission is to reinvent the way people connect with meaningful information at work. Guru’s knowledge management solution provides customer-facing teams access to expert-verified information where they work and when they need it most. We believe in cultivating a welcoming, inclusive culture that encourages personal growth through working hard and having fun. Launched in September 2015, our vision is backed by an amazing group of investors including FirstMark Capital, Salesforce, Michael Dell, the Slack Fund, Emergence Capital, Thrive Capital and Accel. As we enter the next exciting stage of expansion, we're searching for passionate individuals to join our rapidly growing team. This is a full-time position located in Philadelphia, San Francisco, or Fully Remote. Re-location and/or Visa Sponsorship is not included in our hiring package. Applicants will need to be authorized to work in the US. All are welcome here. At Guru, being inclusive is very important to us. Regardless of race, age, ethnicity, sexual orientation, gender identification, or background. If you have any questions about the application process or need any accommodations, please contact: talent@getguru.com  We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información","Internet, Software, Servicios y tecnologías de la información",26,None,False,talent@getguru.com,268,ACTIVELY_HIRING_COMPANY
325,2220598642,2020-10-28,Tail Wind Informatics Corporation,Data Engineer,Greater Minneapolis-St. Paul Area,"Tail Wind is currently seeking candidates for a Data Engineering position. The position can be full time salaried with benefits, W2 Hourly with benefits or CTC hourly. Job Description:We’re seeking an experienced Data Engineer to assist with a legacy system project. The successful candidate will assist in building out a quality reporting capability for their client facing system. Experience with Master Data Management will be a plus. Required SkillsBachelor's degree in Computer Science or Information Technology preferredPower BIAzure StackDatabricksAzure Data FactoryLogic AppsAPI’sETLExcellent written and verbal interpersonal and communication skills Benefits 401k, Health Insurance, Dental Insurance, Long-Term Disability Insurance The Tail Wind Team: A healthy work-life balance.  We look for people that love what they do, want to learn, earn and enjoy life to the fullest. To learn more about this opportunity please select Apply Now. Thank you! Equal Opportunity Employer - No Agencies Please",Intermedio,Jornada completa,Tecnología de la información,Servicios y tecnologías de la información,66,None,True,,187,ACTIVELY_HIRING_COMPANY
326,2180218584,2020-10-13,Vivid Seats LLC,Sr. Data Engineer,"Chicago, Illinois, United States","The Opportunity:  As a Sr. Data Engineer, you will maintain a holistic view of the Vivid Seat’s data architecture with an understanding of how it relates to the systems that depend upon it. You’ll partner with engineering teams to create data models and assist in designing our transactional data stores. This includes designing and building data systems and automated processes for our underlying cloud infrastructure and deployment pipelines. You’ll mature operational stability of the data platform through best practices, automation and monitoring while staying up to date on new and emerging technologies, planning accordingly to incorporate valuable concepts to enhance our data schema and capabilities.  To be successful, you’ll need:  Expert knowledge of a relational database platform such as MySQL, Postgres, Oracle or SQL Server Experience in either modeling transaction or data warehousing with an interest in learning both methodologies ETL pipeline and tooling experience Coding and scripting experience using Java, Python or Bash Proficiency in working in a Linux environment Cloud experience with either GCP, AWS or Azure and experience running data platforms within a cloud environment A willingness to participating in an on-call rotation  Additional Experience of Interest:  Experience with configuration as code tools such as Ansible, Terraform etc. Experience with containerization such as Docker Experience with continuous integration, testing, and deployment using tools such as Jenkins  What We Offer:  Vivid Seats is the largest independent online ticket marketplace, sending tens of millions of fans to live events. Experiences Matter - which is why we continue to grow year over year. Working at Vivid Seats puts you front and center at the opportunity to scale our best in class platform that allows our fans to sit closer and experience more.   At Vivid Seats, you will have the opportunity to work with the flexibility and speed of a startup: while operating at massive, profitable scale. We keep our teams lean, allowing each employee direct accountability of creating a positive ticket buying experience. We are relentless and move quickly to release new features and content to our applications. Good ideas are heard and implemented, and hard work rewarded. Being a part of our team means having the ability to drive impact and own the innovation that connects our tens of millions of unique monthly users to the memorable experiences that only live events create.   We are passionate about creating memorable experiences for our fans and the best in class experience for our employees. Vivid Seats offers competitive compensation levels, individual and team-based bonus opportunities, 401K matching, a generous benefits package and Flex PTO policy plus a variety of workplace perks.  ﻿Location: 111 N Canal Suite #800  Chicago, IL 60606   This position will start remotely.",Intermedio,Jornada completa,Ingeniería,"Internet, Deportes, Entretenimiento",26,None,False,,144,ACTIVELY_HIRING_COMPANY
327,2225131274,2020-10-21,Octo Telematics,Actuarial Data Scientist,"Boston, Massachusetts, United States","Company Profile: Founded in 2002, Octo is today the Number 1 global provider of telematics and data analytics solutions for the auto insurance industry and, increasingly, a major player in Fleet management services, with world-class solutions to grow its core businesses – Insures and Intelligent Mobility – and to expand and provide innovative connected solutions in new industries and international markets. Octo’s vision is to connect the world of mobility through advanced analytics and IoT-driven services for a new era of Smart Telematics. Octo currently has 6 million connected users, holds the largest global database of telematics data, with more than 248 billion miles of driving data collected and over 464,000 crashes and insurance events analysed, and runs more than 10 car sharing services with more than 400,000 hires per month. Job Description: Reporting within the Data Analytics / Scoring Team, Actuary will be responsible for the development, maintenance and deployment of Octo’s Scoring services. The overall goal of the team is to develop Octo’s Analytics capabilities in order to contribute in sustaining and growing our business to achieve long-term success.  The Actuarial Data Scientist helps lead multiple projects simultaneously. On a typical assignment, the actuary would be responsible for: Participating as a subject matter expert with prospective clients. This includes, but is not limited to presenting Octo's analytical products and capabilities and responding to RFPs  Creating collateral regarding analytical products to support Sales and Marketing teams Speaking to external audience at industry and Octo events to drive broader brand awareness.   Participating on new client projects ensuring optimal implementation of analytics-based products  Continuously supporting the Account Managers (Customer Success Managers) in their interaction with the Clients when actuarial questions are asked Delivering updates to clients on their scores and analytics, including managing the standard reporting process Assisting with the development of required filing support and responding to questions posed by regulators during the DOI approval process  Proposing, defining and supporting research on new analytics ideas to increase and maximize the value added of Octo’s services for our Clients Supporting with the analysis and evaluation of new analytics ideas and defining business requirements  Contribute to the evolutionary development of algorithms to assess motor insurance risk and deliver feedback to drivers and insurance companies Research alternative statistical modelling methodologies Prototype new product features in conjunction with the product development team Provide operational analytics support to client delivery teams Build relationships internally and collaborate effectively on cross-functional teams Working with the analytics team to define and research answers to internal and external questions and requests Other relevant Actuary activities as required  Professional requirements:  BA/BS in Actuarial Science, Mathematics or related technical discipline Associate or Fellow of the Casualty Actuarial Society Experience with personal lines and commercial lines 5 + years combined of auto insurance pricing and US rate filing experience Experience constructing and understanding GLMS and other predictive models Experience in data analytics Experience working with SQL Experience of predictive modelling including feature engineering, feature selection, regression and clustering Experience in delivering insight via data visualization and providing recommendations based on analysis Familiar with Python, R or Spark Able to function in a complex, agile, fast-moving workplace and adapt to the changing environment. Strong analytical and problem-solving skills, ability to analyse data, understand trends, etc. Strong written, oral and presentations skills with demonstrated experience communicating information to executive management, prospects, clients and public groups  Languages: English Fluent, Italian is a plus, or second European language The position is a key role in the context of growth of the company and exposes to professional opportunities in terms of responsibilities and geographical span. The person will be characterized by a strong presence, self-motivation, analytical and critical thinking.  National and international travel.  Place of work:  Working from Home",Algo de responsabilidad,Jornada completa,"Análisis, Gestión de proyectos, Ventas","Servicios y tecnologías de la información, Telecomunicaciones",138,None,True,,626,ACTIVELY_HIRING_COMPANY
328,2220715226,2020-10-28,BMC Software,Remote Principal Data Scientist - Innovation Labs,"United, LA, US","Description And Requirements  From core to cloud to edge, BMC delivers the software and services that enable over 10,000 global customers, including 84% of the Forbes Global 100, to thrive in their ongoing evolution to an Autonomous Digital Enterprise.  Our Goal With Our Innovation Labs Team Is To Harness New Ideas, To Anticipate And Act On Market Changes By  The BMC Innovation Labs brings together customers, partners, and employees to accelerate the development of new and relevant solutions that create value.  Fostering innovation by creating spaces for experimentation  Advancing ideas that generate disruptive technologies  Accelerating prototyping and development of new capabilities   It is through this collaborative environment that we explore how new technologies can be leveraged to bring market differentiating value to customers through our next generation solutions. We help clients pivot from thinking digital to being digital at the core.  From big data analytics, to cognitive digital twins and data driven strategy consulting and startup acceleration we work to make our customers even more successful. Join us in our accelerated journey.  Job Summary  The Principal Data Scientist will deliver critical advanced analytics to support BMC’s Data Science practice and its adoption of Artificial Intelligence (AI) solutions. As the Senior Data Scientist, you will help to solve real-world business problems as a central member of the Data Science team by designing and building experimental frameworks and production-ready models using Machine Learning (ML), Deep Learning (DL), Natural Language Processing (NLP) and other robust advanced statistical learning techniques.  Job Responsibilities  You will be responsible for design and beginning-to-end execution of BMC Data Science projects including interpreting business need, munging/wrangling data, developing and validating predictive models, and deploying completed solutions  You will use advanced statistics, data mining, machine learning, and deep learning techniques to deliver data-driven insights for BMC project stakeholders  Work with internal teams and customers to understand challenges and create solutions, inform the business’ strategic direction and identify opportunities  Produce a range of data-driven visualizations (dashboards, reports, presentations) and provide insights relative to created data science products  Team with product managers and product owners to understand requirements and develop processes/tools to monitor data accuracy and business performance  Process, cleanse, and verify the integrity of data used for analysis  Work with software developers and architects to help operationalize models into production  In conjunction with data owners and department managers, develop data models and protocols for solutions that provide advanced, meaningful, and actionable business insights  Support the transfer of knowledge to team members as appropriate   Education & Licensure  Master’s or Bachelor’s degree in a highly quantitative field including Applied Math, Statistics, Computer Science, Bioinformatics, Operations Research, Economics or Engineering  5+ years’ experience in Data Science centric positions  Applicable work experience with proven advanced capabilities can be substituted for master’s degree (Bachelor’s degree minimum required)  Extensive experience in developing enterprise product systems, 5+ years software development in cloud computing, distributed systems, and Big Data, strong experience with containers and orchestration technologies such as Docker and Kubernetes.   Qualifications  Technical expertise with proven predictive modeling and machine learning skills  Knowledge of advanced statistical learning techniques and experience with applications  Experience working with complex data using advanced analytics techniques and software technologies to deliver and interpret valuable insights  Combination of deep technical skills along with business knowledge enough to interface with all domains and levels of the BMC organization  Experience using Python, R and Databricks  Experience using Machine Learning libraries, such as scikit-learn, caret, mlr, mllib  Experience with cloud technologies including Google Cloud, AWS and Azure  Strong SQL coding skills and the ability to manipulate data and draw insights from large datasets  Experience working effectively in a team-based environment  Excellent written and verbal communication skills  Proven track record of delivery and execution   It is the policy of BMC Software to afford equal opportunity for employment to all individuals regardless of race, color, age, national origin, physical or mental disability, history of disability, ancestry, citizenship status, political affiliation, religion, gender, transgender, gender identity, gender expression, marital status, status as a parent, sexual orientation, veteran status, genetic information or other factors prohibited by law, and to prohibit harassment or retaliation based on any of these factors. BMC never asks for payment from individuals seeking employment with the company.  If you need a reasonable accommodation for any part of the application and hiring process, visit the accommodation request page .   < Back to search results",No corresponde,Jornada completa,"Ingeniería, Tecnología de la información","Equipos informáticos, Software, Servicios y tecnologías de la información",27,None,False,,256,ACTIVELY_HIRING_COMPANY
329,2239753074,2020-11-03,RedHolt,Senior User Researcher,United States,"Our client is hiring a Senior User Researcher to play a crucial role in newly formed product teams focused on building and improving their digital experiences. As a senior member of the product team, you’ll collaborate with your peers in product management, UX and engineering and share responsibility for the entire team’s success.  Ideal Candidate You’ll be a seasoned user researcher who has extensive experience of designing and executing moderated/unmoderated/remote/in-person research to drive software development. You’ll be passionate about methods and models but pragmatic in their application. You’ll know how to combine qualitative and quantitative techniques to triangulate findings and build-on prior research.  You’ll demonstrate a thorough comprehension of the human-centered design process and feel very comfortable in both the ambiguous discovery phase of identifying the right problem to solve and the detailed work of shipping desirable products. You’ll understand how best to use research to understand what users need and how best to use research to evaluate how well an in-development or in market solution meets those needs.  You’ll be a natural collaborator and patient communicator who understands how to communicate complex concepts in consumable ways. Ideally, you’ll have experience of integrating research and design in the context of agile transformation. Experience of the practical application of techniques such as Jobs-To-Be-Done is a bonus.  Note that this role would suit an experienced user researcher who is now ready to largely let go of the day-to-day of research execution in favor of consulting, process development and coaching.  You will: • Collaborate identify research opportunities that act as a critical input into product planning, build and optimization • Have deep knowledge of research methods as they pertain to software development • Know when to use qualitative and when to use quantitative techniques individually and in combination to deliver timely and actionable insight • Partner with other user researchers to develop impactful research plans that effectively balance efficiency, quality and cost • Guide those plans as they are executed by a mix of internal resources and third-parties • Champion the value of user research and educate others in its potential and constraints • Explore the deployment of research techniques that may be new• Understand the importance of scaling user research and be willing to be part of that vision • Coach developers, designers, product managers and leaders so that they can contribute meaningfully to the commissioning and execution of research.  Key Responsibilities: • Guides research design and execution in a fast-pace agile environment • Handles multiple research projects • Helps generate process documents such as approaches, project plans, presentations and highlevel reports • Partners with the research operations team to balance competing demands and priorities and to develop and socialize best practices that enable the scaling of research • Effectively collaborates with cross-functional stakeholders • Communicates findings in a compelling and consumable way • Identifies opportunities to empower non-specialists to execute generic research tasks • Advocates for the growth of research • Identifies opportunities to optimize existing process, methods and tools • Advocates for the deployment of methods that are new • Navigates multiple stakeholder groups and influences others.  Preferred qualifications:• 8 years of experience in user research as it pertains to software development. • Bachelor’s or advanced degree in the social sciences, human computer interaction (HCI), human factors or a related field. • Schooled in “design thinking” or the human centered design process • Ability to effectively convey ideas and complex concepts • Relevant research experience with consumer applications in one of the following areas: insurance, financial services, startups and technology companies. • Exemplary ability to build positive, collaborative relationships across teams and functions. • Solid knowledge of and experience with agile development process. • Excellent verbal and written communication skills, including the ability to articulate design decisions based on value to the user and the business.",Algo de responsabilidad,Jornada completa,"Investigación, Ciencias","Banca, Servicios financieros, Seguros",30,None,True,,160,ACTIVELY_HIRING_COMPANY
330,2271846486,2020-11-04,New York Technology Partners,Data Engineer with Prometheus,United States,"We are sourcing for Data Engineer with Prometheus for Remote position. Please review the below detailed job description mention and let me know if you are interested. Position: Data Engineer with PrometheusLocation: Remote positionDuration: 10 Months  Job Description:Major change here on the SRE role with McDonald’s in regards to the skill set. I connected with the Director in this group and he’s not looking for Python skills, so please see the changes below/attached and update the search accordingly.  Primary SkillsExperience with Prometheus including setup of Prometheus for monitoring (setup of scrape configurations, recording rules, etc.)Understanding of PromQL and be able to write PromQL queriesUnderstanding different types of metrics used in Prometheus and their setup Experience with GrafanaExperience setting up Grafana dashboards and viz using the core set of Grafana visualizationsExperience using promql to get data for Grafana vizExperience with using variable in dashboardsExperience with Alerting in GrafanaUnix scripting experienceAWS EC2 experience  Secondary SkillsExperience developing Java Spring Boot Application for monitoringExperience with Spring boot including scheduler, micrometer, actuatorExperience with SQLExperience with time series data queryingExperience with Prometheus sdk for generating metricsDevOps with Jenkins",Intermedio,Contrato por obra,"Ingeniería, Tecnología de la información",Dotación y selección de personal,38,None,True,,141,ACTIVELY_HIRING_COMPANY
331,2190019271,2020-10-30,Planet121,AWS Data Engineer,New York City Metropolitan Area,"Planet121's global client needs an AWS Data Engineer to join them on a new 13 month month contract. They are looking for someone who is strong in either Scala or Python to help in the data migration efforts or a larger AWS transformation project.  The client is in New York City and work will be 100% remote. Candidates located in Eastern and Central Time are preferred.Those authorized to work in the US are encouraged to apply. Qualifications5 years of Data Engineer experience with Fortune 500 companiesHeavy data migration backgroundExpertise in either Scala or PythonExperience working with Terabytes and/or Petaytes of dataExperience with AWSExcellent communication and collaborative skills Additional InformationIf you are interested, please respond to this ad with an updated resume and a summary of your skills. We look forward to hearing from you soon.All your information will be kept confidential according to EEO guidelines.",Intermedio,Contrato por obra,Tecnología de la información,Dotación y selección de personal,198,None,True,,512,JOB_SEEKER_QUALIFIED
332,2251923745,2020-10-06,Proper,Sleep Data Scientist (Part-Time),"New York City, NY, US","Proper is a proud Equal Opportunity Employer – we recruit, train, compensate and promote our team members based on qualifications. We know how important it is not only to include, but to actively seek out a diversity of opinions and voices.  We want to hear from you regardless of your race, religion, national origin, sex, gender identity, sexual orientation, disability, age, veteran status, or any other applicable legally protected characteristics.  About Proper  Proper is on a mission to improve people's overall health and happiness through better sleep. We are the trusted expert that brings an integrated and personalized approach to sleep wellness. Our vision is to build a modern sleep wellness business grounded in truth and supported by the best in data, technology, and science.  About The Role  We are looking for a hands-on part-time Sleep Data Scientist to advance Proper's use of data, insights, and automation as we continue to build new evidence-backed and data-rich digital experiences for our customers. This role reports to CPO.  Responsibilities:  Lead Proper's early data science efforts, support user experiences for both sleep customers and sleep coaches Ingest, connect, and enrich time series sleep, behavioral, motivational, coaching, and outcomes data events into a unified data model Apply machine learning and artificial intelligence models to detect patterns that lead to improved sleep outcomes Smartly integrate with wearable (Apple Health, FitBit), audio recording, and self reported sleep data to allow customers maximum flexibility with how they monitor their sleep Create beautiful consumer-friendly data visualizations that encourage adherence to good behavior and sleep hygiene practices Empower Proper sleep coaches with automated insights to be more efficient and effective in helping their customers sleep better Support best-in-class consumer-first e-commerce experiences Think omni-channel (native app, mobile web, SMS) in the ingest and delivery of data products Define technical solutions with clarity on feasibility, timeline, and cost Design a technical architecture that supports rapid product iteration Understand and implement best practices for data protection and privacy  Preferred Qualifications:  5+ years data science experience 3+ years data engineering experience Deep experience with rich time series data  Deep experience with modern data science / statistical packages (TensorFlow, PyTorch) Experience with popular health / sleep tracking APIs (ex. Apple Health Kit - HKCategoryValueSleepAnalysis) Experience with data visualization / plotting library (D3.js, plotly) Prior experience supporting awesome consumer facing products Past experience in small, high growth startup environments Previous health-tech experience helpful (health tracking, coaching, fitness, weight loss, nutrition, therapy) Remote or NYC-area candidates",Sin experiencia,Media jornada,"Ingeniería, Tecnología de la información","Software, Internet, Sanidad, bienestar y ejercicio",22,None,False,,493,JOB_SEEKER_QUALIFIED
333,2215782611,2020-10-27,UST Global,Data Engineer - Spark,Poland,"UST Global is a leading digital technology company that provides advanced computing and digital services to large private and public enterprises around the world. Driven by a larger purpose of Transforming Lives and the philosophy of “few clients, more attention”, we bring in the intrepreneurial spirit that seeks the faster path to value in today’s digital economy. Our innovative technology services and pioneering social programs make us unique. UST Global believes in building long-lasting, strategic business relationships through agile and client-centric global engagement models that combines local experts & resources with cost, scale, and quality advantages of global operations. UST Global is actively recruiting for an experienced Data Engineer who will be working closely with our Customer and their team (100%) remotely. Overview of the role:        You will be part of a team of data engineers building pipelines from alternative data sets and performing most of the ETL that supports our community of data scientists. What do you need to have experience with?Primary Skills: Spark (PySpark), Python, Hadoop (Hive, HDFS), SQL Server dev skills.  • Strong Python, Spark, SQL skills • Strong knowledge of Linux  • Hadoop (Hortonworks / Cloudera) and Hive skills• Experience of developing enterprise grade ETL/data pipelines using Python and SQL• Understanding of data manipulation/wrangling techniques • Good relational database knowledge• Good understanding of data modelling • Software engineering practices (unit testing, version control, code review) • Experience using continuous integration tools (Jenkins, octopus) • Experience of using git • Good understanding of scrum and Kanban • Fluency in English are crucial as team is working for a Global Customer. For more details, please respond bysubmitting your updated CV and contact number for an immediate discussion andconsideration.",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Servicios y tecnologías de la información,35,None,True,,148,ACTIVELY_HIRING_COMPANY
334,2215542856,2020-10-27,Black Knight,Data Engineer,"Philadelphia, PA, US","Black Knight is the premier provider of integrated technology, services, data and analytics that lenders and servicers look to first to help successfully manage the entire loan life cycle. Our deep understanding of regulatory and compliance issues complements the knowledge, technology and solutions we offer to help our clients achieve their business goals. Black Knight offers leading software systems: data and analytics offerings: and information solutions that facilitate and automate many of the business processes across the mortgage life cycle.  JOB FAMILY DESCRIPTION    As a Data Engineer II for Black Knight's Innovation Lab, you will join a team of 15+ developers and product enthusiasts engineering a next generation Artificially Intelligent Virtual Assistant known as AIVA. AIVA works alongside operators, loan officers and lenders to make their jobs more efficient. Each quarter, she reads millions of documents and then summarizes significant data points for her colleagues to review. Although she's early career, she already has cut down certain manual tasks from 30 minutes to just 8 minutes! Our team employs leading-edge cloud computing technology and leverage Amazon Web Services to build AIVA's infrastructure. Her make-up is well beyond mainstream workflow automation/RPA. We're continuously training AIVA's lexicon to give her context what she's studying. We tinker with algorithms and build deep learning networks to fortify her skill sets as she reads through bank statements, pay stubs, W2s and more. Most importantly, we capitalize on large data sets from our enterprise clients so we can optimize our feature selection at scale. Each day we train AIVA so that she can save people from millions of hours of stare-and compare work. We know with AIVA in the workforce, she can free her colleagues' time, talent and imaginations to develop new skills, provide better service, and to become more engaged at work.   There is room for a range of skills. Some you already have and some you will quickly gain when you are here.   Agile (Scaled Agile Framework)Machine Learning ( Natural Language Processing ,Vision , Classification , Search)DevOps ( Infrastructure as Code , Continuous Integration and Continuous Delivery)Behavioral Driven DevelopmentDesign and ArchitectureCloud (AWS)Languages (Java , AngularJS , Python)GENERAL DUTIES & RESPONSIBILITIES    Participates in project meetings with other technical staff, business owners and subject matter experts.Designs scalable, highly available, fault tolerant and resilient data processing infrastructure, assembled from microservices in a Continuous Integration Continuous Delivery environment.Builds streaming and batch data extraction transformation and load processes using AWS Serverless technologies.Interacts with product managers and/or users to define system requirements and/or necessary modifications.Assesses and develops design requirements for the project and communicates in writing or in meetings with development team while assessing detailed specifications against design requirements.Develops and/or reviews development of test protocols for testing application before user acceptance.Reviews application in progress of development to ensure compliance with overall design parameters and corporate development standards.Verify stability, interoperability, portability, security, or scalability of system architecture.Monitor system operation to detect potential problems.Document design specifications, installation instructions, and other system-related information.Performs additional related duties as assigned.EDUCATIONAL GUIDELINES    A Bachelor's degree in Computer Engineering, Computer Science or other related discipline: or equivalent combination of education and experience that is required for the specific job level.  GENERAL KNOWLEDGE, SKILLS & ABILITIES    Experience building and optimizing 'big data' data pipelines, architectures and data setsExperience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvementAdvanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databasesExperience with build processes supporting data transformation, data structures, metadata, dependency and workload managementExperience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.Experience with big data tools such as Hadoop, Spark, Kafka, etc. strongly preferredExperience with relational SQL and NoSQL databases, including Postgres and Cassandra preferredExperience with data pipeline and workflow management tools such as Azkaban, Luigi, Airflow, etc.Experience with AWS cloud services: S3, Glue, Athena, Kinesis, DynamoDB, Sagemaker, EMR, RDS, Redshift a plusExperience with stream-processing systems such as Storm, Spark-Streaming, etc. a plusStrong analytic skills related to working with unstructured datasetsA successful history of manipulating, processing and extracting value from large disconnected datasetsWorking knowledge of message queuing, stream processing, and highly scalable 'big data' data storesExperience building production quality cloud products preferredExperience with AWS , DevOPs , CI/CD preferredKnowledge of financial services industry a plusKnowledge of banking practices, regulations and operations within the assigned line(s) of business a plusOutstanding verbal and written communication skills to technical and non-technical audiences of various levels in the organization (e.g., executive, management, individual contributors)Excellent analytical, decision-making, problem-solving, team, and time management skillsAbility to estimate work effort for project sub-plans or small projects and ensure the project is successfully completedPositive outlook, strong work ethic, and responsive to internal and external clients and contactsWillingly and successfully fulfills the role of teacher, mentor and coachJOB FAMILY LEVEL    Intermediate professional role. Proficient in at least two higher-level programming languages and knowledge of at least one systems development life cycle model. Understands the products, services, practices, regulations and operations associated with the assigned line of business. Conducts detailed analyses of all defined systems specifications for changes in systems requirements, business requirements or equipment configurations, and develops all levels of logic flow charts. Develops and prepares moderately complex computer programs, prepares program test data, tests and debugs programs. Documents all procedures used throughout the computer program when it is formally established. Receives general supervision and is competent in most phases of programming to work on own, and requires only some general direction for the balance of the activities. May assist and help train Entry-level software engineers. Typically requires five (5) or more years of software engineering work experience or an equivalent combination of education and experience.  Black Knight is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, disability, age, and protected veteran or military family status. Our employees' diversity is our strength, and when we embrace our differences, it makes us better and brighter. Black Knight's commitment to inclusion is at the core of who we are, and motivates us in how we do business each and every day.",Sin experiencia,Jornada completa,Tecnología de la información,Servicios y tecnologías de la información,78,None,False,,603,None
335,2181342362,2020-10-14,Ranker,Lead Data Engineer,United States,"We are currently looking for a full-time Lead Data Engineer to join our growing remote team. This is a great opportunity to work on a new product for a leading, high traffic site (over 60 million unique visits a month). Despite the immense traffic we generate, we do all this with a small, talented team of dedicated software engineers who love working with interesting, complex projects. As part of the team, you’ll be managing and improving our data and our data storage solutions. You will be using your creativity and knowledge to solve both technical and business problems. What’s in it for you:Work with modern storage technologiesCollaborate in a team environment, with a variety of developers across the United States and the world.Contribute directly to the technology, processes and methodology used to solve problems day-to-day.Who we believe will do great in this role:Great communication skills.Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databasesExperience building, documenting and optimizing ‘big data’ data pipelines, architectures and data sets.A successful history of manipulating, processing and extracting value from large disconnected datasetsSolid understanding of data storage technologies, including BigQuery, MySQL, MongoDB, and othersBonus points if you have:Expert level understanding of MySQL with an ability to find bottlenecks and optimize performanceExperience using and managing BigQueryExperience with ElasticSearch and RedisDevops skills, especially working with cloud providers such as Google Cloud and Kubernetes About Ranker/Watchworthy:Ranker, a Quantcast Top 50 site in the US, attracts more than 20 million monthly unique visitors worldwide and is the leader in fan-powered rankings on just about everything. Whatever the topic - TV, movies, video games, sports, brands, food, lifestyle - Ranker puts the vote into the hands of millions rather than a few critics to answer the questions we are most passionate about. Over 1 billion votes now power Ranker Insights, a treasure trove of psychographic correlation data that delivers personalized consumer recommendations (“if you like X, you’ll also like Y, Z”), and also audience insights to marketers, studios, and platforms seeking a deeper understanding of consumer tastes and preferences. Launched in 2020 and powered by Ranker Insights, Watchworthy is the only statistically relevant, crowd-sourced TV recommendation app available to consumers. Ranker made #187 on Deloitte’s 2019 Technology Fast 500 featuring the fastest growing companies in North America and Built In LA’s Top 50 Mid-Sized Companies To Work For in 2020. Headquartered in Los Angeles, Ranker also has offices in Chicago and NYC.",Intermedio,Jornada completa,"Ingeniería, Análisis, Ciencias","Internet, Medios de comunicación en línea, Entretenimiento",17,None,False,,127,JOB_SEEKER_QUALIFIED
336,2271223821,2020-11-03,ilegra,Senior Data Engineer,Brasil,"Somos uma empresa global de design, inovação e software. Resolvemos desafios com alegria e criatividade, combinando o poder da tecnologia com a paixão das pessoas. É essa soma que nos leva além.  E também impulsiona nossos clientes que são líderes globais: Whirlpool, Thomson Reuters, AGCO, Sompo, Movile, Bradesco, Fiat Chrysler e outros. Unimos a expertise e a experiência de uma equipe multidisciplinar capaz de impactar e gerar valor para o seu negócio. Conhecemos profundamente nossos clientes, o que nos permite trocar experiências e cocriar soluções. A paixão pelo que fazemos se transforma em resultados. Venha fazer parte de nosso time!! RESPONSABILIDADES E ATRIBUIÇÕESProgramar em linguagem Python, Scala ou JavaManter serviços analíticosAtender à contestações de clientesDepurar incidentes de serviços de dados(crashes) e corrigir falhas, se necessárioPlanejar capacidade de infraestrutura de dadosPropor melhorias de monitoramentoAcompanhar rotinas de manutenção(turnos noturnos/madrugadas) REQUISITOS E QUALIFICAÇÕESExperiência em SQL e ETLBom conhecimento em LinuxBons conhecimentos em Hadoop (Hortonworks, Cloudera, AWS, GCP ou Azure)Experiência com Spark INFORMAÇÕES ADICIONAISEstamos em formato de trabalho remoto, sem previsão de retorno, buscando manter nosso time protegido. Por isso, espere uma rotina de trabalho 100% remota, e uma integração com sua equipe neste formato também :) Não se preocupe: continuamos com muito calor humano e proximidade, mesmo distantes :)",Intermedio,Jornada completa,Tecnología de la información,Servicios y tecnologías de la información,18,None,False,,273,ACTIVELY_HIRING_COMPANY
337,2224720319,2020-10-29,Synergis Creative,Spark Data Engineer,"Mountain View, California, United States","Title: Spark Data Engineer Location: Remote Duration: 12 month contract (medical,dental, vision benefits offered) (Not available for sponsorship or C2C)  Our client is a deeply data-driven company with data driving not only business decisions butalso product features and directions. Their team is responsible for supporting one of the biggest in-house Hadoop/Spark infrastructure in Silicon Valley. They build infrastructure and tools to power thousands of AI engineers, data analytics, and software engineers within the company. They are also committed to being an early adopter and contributor to open source big data technologies,including Hadoop, Spark, and TensorFlow. They are looking for a data engineer with a focus on Hadoop and Spark to develop their Spark infrastructure and grow their Spark user groups. Your work will impact thousands of Spark users inside and outside the company. ResponsibilitiesPrepare training material and hold technical training sessions for internal Spark usersDeveloping Spark infrastructure, Spark user libraries and tooling to make direct impact to usersInteract with multiple groups on a daily basis to design data solutions and promote the best Spark practices among usersSolve production issues related to user Spark applications Basic QualificationsBS/MS in Computer Science or related technical discipline1+ years of relevant work experience in Spark and HadoopExcellent communication and presentation skillsGood understanding of Spark, Hadoop, HDFS, YARN, Hive technologiesGood understanding of distributed storage and computing systemsGood understanding of programming language like Java and ScalaGood understanding of scripting language like Shell and Python Preferred qualificationsGood understanding in Spark Core and Spark SQL engineExperience in building large scale applications with Spark SQLExperience in writing, analyzing, and debugging SQL queries using Hive and Spark SQLExperience with tuning large scale Spark jobsExperience in working with a data format on Hadoop/Spark like Avro, Orc, and ParquetExperience with Interactive Spark Notebooks (Jupyter Notebooks) SynergisCreative (creative.synergishr.com) is a specialized division of Synergis (www.synergishr.com)that serves the needs of leading creative firms, departments and agencies. Synergis Creative carefully matches creative and marketing talent to a full-time, contract or project positions. Synergis Creative's recruiters have been a driving force of the creative and marketing space for over six years. We draw from a wealth of experience with technology staffing, industry best practices and exceptional connections to match candidates with incredible opportunities. Synergis Creative is an Equal Opportunity/Affirmative Action employer",Intermedio,Contrato por obra,Análisis,Dotación y selección de personal,97,None,True,,273,ACTIVELY_HIRING_COMPANY
338,2207189148,2020-10-23,"Okta, Inc.",Staff Data Scientist for Risk Based Authentication (Remote Eligible),"San Francisco, CA, US","This is an opportunity to join our fast-growing Security Intelligence Platform team to develop cutting-edge risk-based authentication and authorization policies. We are looking for a Staff Level Data Scientist to build data models and use machine learning to solve business problems in security, authentication, and identity. The ideal candidate has experience building data models from complex systems, developing enterprise grade software in an object-oriented language, and experience or knowledge in security, authentication or identity.  Job Duties And Responsibilities  Build and own forecasting models that will identify risk associated with authentication such as anomalous activity Research new user behavior to discover patterns, find opportunities to improve detection Partner with product team to define requirements for successful model builds Work closely with engineering team and management to scope and plan engineering efforts Work with Infrastructure team on tooling requirements for big data Test-mindset development, design and code reviews   Minimum REQUIRED Knowledge, Skills, And Abilities  5+ years experience building data models as a Data Scientist Skilled in building data models and using machine learning algorithms for classification and regression Excellent grasp of software engineering fundamentals Advanced Python Development Expert knowledge of Tensorflow, Sagemaker or a similar machine learning platform   Additional Desired Knowledge, Skills, And Abilities  3+ years of software development experience in an object-oriented language building enterprise grade highly reliable, mission-critical software Experience with multi-factor authentication, security, or identity Experience with Java   Education And Training  B.S, M.S, or PhD in computer science, data science, machine learning, information retrieval, math, or equivalent work experience   Okta is an equal opportunity employer  Okta is rethinking the traditional work environment, providing our employees with the flexibility to be their most creative and successful versions of themselves, no matter where they are located. We enable a flexible approach to work, meaning for roles where it makes sense, you can work from the office, or from home, regardless of where you live. Okta invests in the best technologies and provides flexible benefits and collaborative work environments/experiences, empowering employees to work productively in a setting that best and uniquely suits their needs",No corresponde,Jornada completa,"Ingeniería, Tecnología de la información","Seguridad del ordenador y de las redes, Software, Servicios y tecnologías de la información",18,None,False,,231,ACTIVELY_HIRING_COMPANY
339,2185712302,2020-10-15,Dropbox,Data Engineer - Location Flexible,"Remote Lake, MN, US","Company Description Dropbox is now a Virtual First company, which means work outside of an office will be the primary experience for all employees. The location listed on the job description is simply so our jobs get picked up by job boards as they require a specific location. Being Virtual First means, location is flexible, so please feel free to apply to any position regardless of the location listed. Final location will be determined, by teams and individuals as the hiring process unfolds.    Dropbox is the world’s first smart workspace that helps people and teams focus on the work that matters. With more than 600 million registered users across 180 countries, we’re on a mission to design a more enlightened way of working. Dropbox is headquartered in San Francisco, CA, and has 12 offices around the world. Team Description Our Engineering team is working to simplify the way people work together. They’re building a family of products that handle over a billion files a day for people around the world. With our broad mission and massive scale, there are countless opportunities to make an impact.   Role Description   In this role you will build very large, scalable platforms using cutting edge data technologies. This is not a “maintain existing platform” or “make minor tweaks to current code base” kind of role. We are effectively building from the ground up and plan to leverage the most recent Big Data technologies. If you enjoy building new things without being constrained by technical debt, this is the job for you!  Responsibilities  You will help define company data assets (data model), spark, sparkSQL and hiveSQL jobs to populate data modelsYou will help define/design data integrations, data quality frameworks and design/evaluate open source/vendor tools for data lineageYou will work closely with Dropbox business units and engineering teams to develop strategy for long term Data Platform architecture  Requirements  BS or MS degree in Computer Science or a related technical field4+ years of Python or Java development experience4+ years of SQL experience (No-SQL experience is a plus)4+ years of experience with schema design and dimensional data modelingAbility in managing and communicating data warehouse plans to internal clients.Experience designing, building and maintaining data processing systemsExperience working with either a Map Reduce or a MPP system on any size/scale Benefits and Perks 100% company paid individual medical, dental, & vision insurance coverage401k + company matchMarket competitive total compensation packageFree Dropbox space for your friends and familyWellness ReimbursementGenerous vacation policy10 company paid holidaysVolunteer time off Company sponsored tech talks (technology and other relevant professional topics) Dropbox is an equal opportunity employer. We are a welcoming place for everyone, and we do our best to make sure all people feel supported and connected at work. A big part of that effort is our support for members and allies of internal groups like Asians at Dropbox, BlackDropboxers, Latinx, Pridebox (LGBTQ), Vets at Dropbox, Women at Dropbox, ATX Diversity (based in Austin, Texas) and the Dropbox Empowerment Network (based in Dublin, Ireland).",No corresponde,Jornada completa,Tecnología de la información,"Software, Servicios y tecnologías de la información, Internet",108,None,False,,534,COMPANY_RECRUIT
340,2235325194,2020-09-29,SysMind LLC,Natural Language Processing (NLP) Data Engineer - Remote,"Secaucus, NJ, US","Position  Natural Language Processing (NLP) Data Engineer  Duration  12+ Months  Work Experience  Minimum 8 years of experience as an Analytics Developer with and around 4 years of experience with NLPAI implementation experience.  3-5+ years' developing Machine learning based algorithms and models.  3-5+ years' experience with medical terminology (Hospital andor diagnostics industry experience)  3-5+ years' experience AWS cloud architecture  At least 2-3 implementation experience with NLP tools like AWS Comprehend, Linguamatics, cTakes or other NLP Tools is required.  Experience in data lake implementations with EMR a plus.  SYSMIND LLC is an Equal Employment Opportunity employer. All qualified applicants will receive consideration for employment without any discrimination. We promote and support a diverse workforce at all levels in the company. All job offers are contingent upon completion of a satisfactory background check and reference checks. Additionally passing the drug test may also be required. All contractors intending to work on SYSMIND's W2 are 'at will' employees.",Sin experiencia,Jornada completa,Tecnología de la información,Servicios y tecnologías de la información,8,None,False,,51,ACTIVELY_HIRING_COMPANY
341,2222489629,2020-10-29,Pipefy,Senior Data Engineer,Brazil,"Pipefy is searching for an experienced and energetic Data Engineer to help us continue growing at a steady pace.  Pipefy is the Lean Management platform. We help anyone take control of their daily work, in areas from employee onboarding to customer service to agile development. Our software puts the proven benefits of Lean Management within easy reach, including greater agility, improved efficiency, and higher quality outcomes. Since we started in 2015, Pipefy has helped thousands of do-ers around the world solve business problems on their own. Today, companies in over 150 countries use Pipefy, from startups to industry leaders such as Accenture, Visa, GE and Volvo. What You’ll Do: ● Administration/maintenance of ElasticSearch servers: ● Administration/maintenance of Redis and Memcached servers: ● Design, implement, test, deploy, and maintain stable, secure, and scalable data engineering solutions and pipelines in support of data and analytics projects, including integrating new sources of data into our data warehouses: ● Produce scalable, replicable code and engineering solution that help automate repetitive data management tasks: ● Help other DE staff troubleshoot their SQL, Python or other code. ● Work in Cloud environments (AWS, GCP): ● Train other DE staff on these skills,  What We Need You to Have: ● Customer requirement analysis: creation of MER: NoSQL databases (differentiation, applicability, study-case): ● Strong mastery on relational databases and SQL. Extract, Transform, and Load (ETL): ● Proficiency in Python or other object-oriented/object function scripting language like Scala, Java, C++, specially for data manipulation and analysis and ability to build, maintain and deploy processes with these tools:. ● Strong experience with big data tools, as Kafka, Hadoop, Spark, etc.: ● Strong experience with data pipeline and workflow management tools as Airflow, Azkaban, Luigi, etc.: ● Experience with stream-processing systems as Spark-Streaming, Storm, etc.: ● Cardinality: multiple relationships: PK, FKS, constraints column ● 1FN: 2FN: 3FN: 4FN ● DCL (GRANT, REVOKE): TCL (COMMIT, ROLLBACK, SAVE POINTS): Cursors: View: Functions: Triggers: Errors: ● ACID compliance: comparative relational modeling: ● Have installed/configured/administered at least 2 of the following databases: Redshift, DynamoDB, Redis, Memcached, MongoDB, Cassandra: ● Differentiate and exemplify the different market engines: column-based (ex. HBase), document (MongoDB), key-value (ex.: Redis), graph (ex.: Neo4J), MultiModel (CouchBase) ● Multiprogramming and competition: Blocks (Shared, Exclusive, Update, Intent, Schema, Bulk Update, Key-range): Dynamic Lock: Blocks Monitoring: Deadlocks: Timeout: Execution plan optimizer internals (including plan overlays): Compressed, Partitioned, INCLUDE and Stack indices ● Data Lake x Data Warehouse: Hadoop Ecosystem (interconnectivity from the tools): ● Degeneration dimension: MOLAP, ROLAP ou HOLAP: Slowly Changing Dimension: Junk dimension: transactional fact, fact through snapshot ● Basic experience with git for version control and Docker/docker-compose ● EC2: Compute Engine: Azure VM: S3: GCS: Blob Storage ● Postgres RDS: MySQL RDS: Aurora RDS ● Desirable knowledge in another On Premises or Cloud DBMS (MySQL, Cassandra, MongoDB or any other NoSQL): ● Optimization of the DBMS instance, optimization of DML processes, native replication, Log Shipping, and Problem Solving:  It Would be Awesome if You: ● Non-relational modeling oriented to Key Document-Value, Column Oriented, Graph Oriented, and Multi-Model ● 5FN: Boyce-Codd: FN Domain-Key (6FN): Denormalization techniques ● CROSS APPLY: binary objects: JSON/XML manipulation: Partitioned view: CTE: UDDT: Partitioning and distribution of tablespace (filegroups) ● Shared-nothing architecture: Eventual consistency: Lock-in: hybrid platform architecture ● Row-level security: dynamic data masking: logon triggers: LDAP integration ● Deployment of an end-to-end BigData platform (e.g. Streaming - HDFS - Hive - Spark/PySpark): MapReduce: ● Have worked on projects with more than 5 data marts: Semi-structured (JSON): Unstructured (logs web services): Data Vault Model ● Data pipeline with data stream: Transactional log reader implementation (Debezium, AlibabaCanal, etc). ● Redshift/Spectrum analysis: Athena: Key store DynamoDB: Memcache Redis: Stream Kinesis, ElasticSearch. ● SQL Data Warehouse: Cache Redis: Azure Cosmo DB: Data Factory ● BigTable: Spanner: Datastore: MemoryStore: Firebase ● Knowledge in database environment tuning, including: partitioning, indexing techniques, and statistics, solid knowledge in lock mechanisms, tablespaces, server counters analysis, event analysis, a solid background in execution plan analysis, troubleshooting (CPU, memory, io, concurrency).  What You’ll Get in Return: ● A fast-paced environment full of enormous challenges and the possibility to create a global brand. ● All the tools you might need to do great work (we’ll spare no expense to make you feel ready to overcome all these challenges). ● The chance to work at an ambitious company, alongside smart colleagues with entrepreneurial mindsets and world-class professional skills.",Intermedio,Jornada completa,Tecnología de la información,Software,13,None,False,,234,ACTIVELY_HIRING_COMPANY
342,2167653679,2020-11-04,"Torqata Data and Analytics, LLC",Senior Data Engineer,United States,"BCGDV is partnering with Torqata, an ATD intelligence company, to solve the replacement tire industry’s most pressing problems through data and analytics. We are a team of data-driven scientists, software engineers, and marketing experts with deep experience in supply chain, operations, logistics, revenue management and customer engagement.     Torqata’s powerful data platform and suite of analytics products has been designed to enable manufacturers, retailers and distributors to work smarter, more collaboratively and drive better results across the industry.     We are a data and analytics services and software start-up in the automotive and tire industry seeking to position itself as the premier provider of such services through increased visibility throughout the tire value chain and unified reconciliation of data across disparate sources such a point-of-sale data, aggregated inventory, OE production data, product information, sales forecasts, introduction of a Blockchain ecosystem, etc.     Position Summary  We are looking for an outstanding Data Engineer to work on developing cloud-based data infrastructure for the purpose of serving rich analytics to customers through SaaS products and other data-driven solutions. You will work on data ingestion pipelines (both real-time and batch), transformation, cleansing, analysis, monitoring, and other tasks within the Data Engineering team to design modern, large-scale data management systems. The individual will work in a highly collaborative environment across multiple teams.   In this role you will:   Work with data scientists, application developers, and data engineers to architect data pipelines to enable the development of machine learning models, data driven applications, and other analytical solutions for both internal consumption and external SaaS customers  Design table structure for proper level of normalization and performance to match use cases  Develop cloud-based systems for ingesting customer data across multiple sources in real time and via streaming processes  Perform RDBMS management tasks such as query optimization, DDL, view creation, permission management, index recommendation, etc.  Build ETL processes on jointly defined requirements for the data pipeline  Identify, analyze, and interpret trends or patterns in complex data sets  Translate insights into predictive power by assisting data scientists with feature engineering in Python  Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality  Support bug fixing and performance analysis along the data pipeline  Analyze and manage 3rd Party and other external data sets  Follow an agile development methodology      Qualifications   BS/MS degree in Computer Science, Engineering, Mathematics, Statistics or equivalent experience  4-6 years of experience working with data models, database design development, and data mining/cleaning deployed in a cloud environment  Strong experience with SQL, Python, and shell scripting  Experience working with at least one major cloud provider (GCP preferred but not required)  Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy  Understanding of the fundamentals of statistics and machine learning  Experience with database design and development  Experience with Unix-like systems  Experience working in start-up environment or organizations with an agile culture  Curious, driven, critical-thinking problem solver  Professional attitude and service orientation: superb team player",Intermedio,Jornada completa,Tecnología de la información,"Sector automovilístico, Servicios y tecnologías de la información",76,None,True,,232,ACTIVELY_HIRING_COMPANY
343,2197060085,2020-10-20,Hamilton Porter,Lead Data Engineer - 100% Remote,"Austin, Texas Metropolitan Area","Hamilton Porter is a recruiting firm that works with technology companies from across the United States to find and hire engineering talent on a full-time basis. We are happy to announce that one of our fastest growing client is actively looking to hire a Senior / Lead Data Engineer to their team. Our client is a leading marketing technology that operates at high scale and the movement of data between their systems and teams is at the heart of their sustained growth. For this Senior Data Engineer, we are particularly looking for someone that has a strong background in Airflow or Google Cloud Composer. This role can be worked 100% remotely. Please read on for more details! Responsibilities:The Senior Data Engineer will be a catalyst in helping to design, build, enhance, and optimize our ETL systems.Work with our Software Engineering, DevOps, and Data Science teams to facilitate accurate and efficient data pipelines existing between the key component of our infrastructureCreate ETL processes that combine data from all of our marketing channels to produce a universal user profile that can be used to power cross-channel decision-making engines and models.Work closely with Data Science in designing and building our Universal User Profiles that will power future models that drive decision across the companyWork with stakeholders including the Executive, Product, Development, and Data Science teams to assist with data-related technical issues and support their data infrastructure needsAssist with optimization of data-driven processes focusing on both performance and costPropose new additions to our Data Engineering and Data Science technology stacksIdentify, design, and implement internal process improvements including automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, and more Skills Required:Fluent in Python and comfortable with packages like NumPy and PandasExpertise in Apache Airflow (you will not be the Airflow admin, DevOps handles that)Advanced working knowledge of SQL, relational databases, and query tuning/optimizationFamiliarity with a variety of non-relational data stores including Data Warehouses, NoSQL Systems, and Data Lakes.Passionate about designing elegant ETL pipelines for big data systemsExpert analysis and troubleshooting skills as well as experience performing root cause analysis on internal and external data and processesExperience refining non-uniform or unstructured data into actionable data productsExperience with automated testing platforms and continuous integrationComfortable with cloud computing services and concepts (AWS preferred)Working knowledge of message queuing, stream processing, and highly scalable data stores. Compensation & PerksCompetitive Annual Base Salary: $130,000 - $160,000 (DOE)Paid Quarterly Bonus Program (approx 15% - 25% of base salary annually)Excellent Healthcare Benefits - 100% covered for employees & family membersGenerous PTO Plan with ability to work 100% remotely401k program, health & wellness programs, and much more! We are looking to interview and hire for this position ASAP ~ please apply today for consideration!",Intermedio,Jornada completa,"Tecnología de la información, Ingeniería","Software, Servicios y tecnologías de la información, Medios de comunicación en línea",68,None,True,,251,ACTIVELY_HIRING_COMPANY
344,2215719451,2020-10-26,Creative Circle,User Experience Researcher,"Austin, Texas, United States","Calling all UX Researchers with B2B experience! Our financial services client is seeking TWO UX Researchers for a 12-month contract near the Domain! The UX Researcher's primary focus will be to bring best practices on both the evaluative and generative side of research methodologies.  The UX Researcher's will highly collaborative and must be comfortable working across teams like product, UX design and content. The UX Researcher's will be asked to manage end-to-end user studies. REQUIRED:- 5-7 years as a UX Researcher- Experience conducting user interviews- The ability to present research problems and solutions to internal stakeholders and other leaders within the company- Past experience completing heuristic evaluation, surveys and competitive/ comparative analysis- The ability to A/B test, handle benchmarking and usability tests. SKILLS:- InVision- Sketch- Axure- MS PowerPoint or Keynote PREFERRED:- Experience working on survey designs and handling B2B user interviews- Any experience in FinTech or a highly regulated field! This is a 12-month contract with the possibility to extend. 40 hours/week. The team is currently working remotely but this role is intended to be onsite once it is deemed safe to do so.",Intermedio,Contrato por obra,Investigación,Banca,97,None,True,,485,ACTIVELY_HIRING_COMPANY
345,2268557657,2020-10-08,Beacon Biosignals,Senior Data Engineer,"Boston, MA, US","About The Role  Beacon Biosignals is seeking a talented engineer to help us ingest petabytes of EEG data and make it truly useful to the world.  About You  You've encountered the myriad idiosyncrasies inherent to storing, streaming, and analyzing large volumes of dense signal data (e.g. audio, video, domain-specific sensor data, etc.).  3NF is generally table stakes for any relational schema you design.  Migrations fill you with a sense of excitement rather than dread, because your data layer just leveled up. Besides, you automated away most minor migration-related pain points a long time ago anyway.  You don't have any particular need to work with a pure monolithic architecture or a pure microservices architecture. For you, characterizing service boundaries is an architectural design decision driven by resource profile, operational cost/benefit, and product need.  You have a tried-and-true workflow for debugging cross-service performance issues and selecting the layer of the stack that actually merits optimization.  You've witnessed some truly weird (un)structures in clinical data, but at the same time, you know from experience that designing The One True EMR is actually just falling down The One True Rabbit Hole.  You are as comfortable optimizing bare-metal custom GPU kernels as you are orchestrating robust networks of source-specific ingest pipelines.  You know from experience that a well-designed K8s cluster can provide an essential, unified ontology for resource/workflow orchestration, while a poorly designed K8s cluster can make developers reconsider getting into software development in the first place.  You're a reproducibility/containers nerd who turns data scientists into reproducibility/containers nerds.  You've tried just about every 'git but for dense models/data' solution out there.  You prefer open-source dependencies to closed-source dependencies because you have a compulsion to read the code that you're running.  You think Hasura is cool.",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Internet",None,None,False,,11,JOB_SEEKER_QUALIFIED
346,2218537998,2020-10-19,Q-tech,Front-end Developer (React) - Remoto,España,"100% remote position in zones where +/-1 hour zone from Spain.Visa permit is required. For one of our clients, a leading multinational B2C learning platform, we are looking for a Front-end Developer. They are in total +400 people, 35 of them working in IT Teams. Currently they are building new squads, so they need more talented people like you who can help them to continue growing their website/mobile. As a senior team member, you will collaborate with their cross-functional teams (including designers, product managers and data scientist) and software engineers (FE and BE) to tackle complex challenges and build their website and internal tools.  You will participate in all stages of the product life cycle. You will devise, define, guide and build new features in their website.  Technical requirements: ·       At least 4 years of experience in Javascript.·       Experience in modern frameworks such as React, Angular or Vue. They use React.·       You have deep knowledge in HTML5, CSS3, SASS, HAML and Styled-Component.·       You love working with BEM and Atomic Design methodologies.·       Experience in componentization and design systems.·       Experience in agile methodologies such as Scrum or Kanban.·       If possible, you have been working with remote teams. Personal requirements: ·       Good written and verbal communication skills in English.·       A can-do attitude!·       Team player skills.·       Modest, humble and sociable.  Nice to have:·       Experience in e-commerce or e-learning products.·       If possible, you have been working with remote and distributed teams.·       Good verbal communication skills in Spanish.",Intermedio,Jornada completa,Ingeniería,Servicios y tecnologías de la información,103,None,True,,476,JOB_SEEKER_QUALIFIED
347,2271847649,2020-10-09,Impira,"UX Researcher (Contract, 3-6 months)","San Francisco, CA, US","UX Researcher (Contract, 3-6 months) *Remote   About Impira  At Impira, we believe that technology can make the messy, monotonous, and complex melt away, creating space for meaningful work. And that's our mission: to make work meaningful.  Our culture emphasizes transparency, empathy, accountability, curiosity, and continuous improvement. We believe that people do their best work with autonomy, trust, and support from their colleagues, and we encourage collaboration across and within departments and geographies. Our leaders empower their teams by providing transparent context, rolling up their sleeves, and coaching for long-term success.  The Opportunity  Impira is building beautiful, powerful interfaces on top of its image and video data processing platform. Our goal is to expose the underlying machine learning and querying capabilities of our platform to non-technical users, enabling creative people to analyze visual information at scale. We're an early stage company. We have traction with both enterprise and self-service customers, but are not yet satisfied with our level of product/market fit. You will be integral to those efforts.  As a user experience researcher contracting with the team for 3-6 months, you'll be leading our efforts to understand our existing and potential customers. You will report to the CEO and collaborate with the product and go-to-market teams to help us drive product/market fit.  What you'll do:  Work with the CEO and product/go-to-market teams to define a handful of specific research initiatives conducted over a 3-6 month period.  Conduct research to help us define our customers, products, and positioning in the market.  Research end-customers and develop hypotheses about gaps both in the market and our product offering.  Design studies that address both user behavior and attitudes.  Generate insights that both fuel ideation and evaluate designs.  Conduct research using a wide variety of qualitative methods, subset of quantitative methods (i.e. surveys), and interpret analysis through the lens of UX, HCI, and social science. Work cross-functionally with design, product management, engineering, and go-to-market teams. Partner with engineers, analysts, and other technical roles to create and share research.  Adapt and lead research practices to meet team needs under the tight time frames of an early stage company.  Synthesize and communicate research findings to inform business decisions and build an in-depth understanding of our customers and market positioning.    What we are looking for:  6+ years of experience as a user experience researcher. Experience conducting B2B research. Proven track record presenting to and influencing stakeholders, from other researchers and designers to senior executive management. Command of a set of qualitative and user-centered design methods. Demonstrated ability to plan and conduct research in close collaboration with people in a variety of roles, including design, engineering, go-to-market and product management. Knowledge of quantitative, behavioral analysis, and statistical concepts. Experience with survey research (questionnaire design, sampling, analysis). Ability to ask, as well as answer, meaningful and impactful questions. The drive to explore and define research opportunities throughout the company. A startup-player with experience (either full time or contract) at a seed or Series A company with a track-record of defining product/market fit.  The ability to communicate is paramount.  An up-to-date portfolio that demonstrates past experience, with a focus on product/market fit and driving business outcomes.   --  Impira is headquartered in San Francisco and has raised Series B funding from top institutional investors and industry leaders. Our investors and advisors are hands-on and work closely with us to achieve our growth ambitions.  To all recruitment agencies: Impira does not accept agency resumes. Please do not forward resumes to Impira employees. Impira is not responsible for any fees related to unsolicited resumes and will not pay fees to any third-party agency or company that does not have a signed agreement with the Company.",Algo de responsabilidad,Contrato por obra,Tecnología de la información,"Servicios y tecnologías de la información, Software, Internet",6,None,False,,54,ACTIVELY_HIRING_COMPANY
348,2213035229,2020-10-26,Tanium,Data Engineer,"Emeryville, CA, US","Data Engineer  At Tanium, a Data Engineer in our Support Center, which delivers technical support to customers, fulfills a necessary role in our organization by interpreting data and using it to drive business improvement. This role will report to the Support Director.  What You’ll Do  Collect and interpret data from various sources Analyze complex data, looking for relevant trends Identify and measure improvements in KPIs Develop models to personalize interactions with business Collaborate with business partners to deliver high value and actionable business insights Partner with business groups and leadership on executive presentations which are based on data modeling which is used to drive the optimum business decisions Build data pipelines, dashboards and reports to support business partners   We’re Looking For Someone With  Education  BA/BS or equivalent experience required from the following: Computer Science, Engineering, Mathematics, Statistics, or Data Science    Experience And Skills  5+ years experience in data analytics Experience with a business intelligence solution such as Periscope or Power BI Experience with a CRM such as Salesforce.com Strong programming skills in at least one language such as Python, Java, or C++ Expert in Microsoft Excel and PowerPoint Has a deep understanding of data warehousing, data structures, and SQL Self-starter with ability to learn software applications with little direction Effective business communication skills Ability to match technologies to business goals Is very organized and analytical with the ability to create, manage, and prioritize projects   About Tanium  At Tanium, we empower the world’s largest organizations to manage and protect their mission-critical networks. There’s a reason why six of the top ten retailers, 12 of the top 15 US banks, and five of the US Armed Forces use Tanium. We provide lightning-fast capabilities at their fingertips to see everything and do anything across their computer networks – with unparalleled scale.  We pride ourselves on being unstoppable in the pursuit of our mission. We are diverse problem solvers driven to do the right thing and win as a team.  Join our team at tanium.com/careers/",Intermedio,Jornada completa,"Tecnología de la información, Atención al cliente, Ingeniería","Servicios y tecnologías de la información, Software, Servicios financieros",168,None,False,,1111,COMPANY_RECRUIT
349,2249318600,2020-11-05,AccelOne,Data Engineer,Argentina,"Google Cloud Data Engineer AccelOne is looking for a talented Google Professional Data Engineer with an advanced English level to be part of an important international project. Company Background AccelOne provides Outsourced IT / Software Development resources to companies in the US and Latin America from their HQ in Kirkland, WA with offices in Buenos Aires, Argentina. Our company was created and built by seasoned technology professionals and entrepreneurs from a foundation of respect, transparency, fluid communication, and accountability.  Project Overview AccelOne is looking for an experienced, talented, passionate, and hard-working person in order to be part of a great team of Data Engineers who lead the future of digital services and Big Data. Our client provides IT services through Consulting and Systems Integration, Managed Operations, and transactional services through Worldline. It is the European leader and global operator of the payment services industry. Summary Job Description Design data management processes with Google Cloud Platform servicesBuild, optimize and monitor systems that facilitate the exploitation of data.Ensuring that data is extracted, received, transformed, stored and accessible by the rest of the team.Build pipelines and test transformation processes of ingested dataBe aware of upload processes and solve incidentsPrepare and manage documentation, when requestedFocus on innovating new and better ways to create solutions that add value  Job Requirements Bachelor’s degree in Computer Science, Mathematics, or a related technical field or equivalent practical experience. Certification: o Minimum: Google Professional Cloud Architect  o Preferred: Google Professional Data Engineer, AWS Big Data Specialty 10+ years of direct experience working in Enterprise Data Warehouse technologies5+ years in a customer-facing role working with enterprise clientsExperience with implementing and/or maintaining technical solutions in visualized environmentsExperience in design, architecture, and implementation of Data warehouses, data pipelines, and flows.Experience with developing software code in one or more languages such as Java, Python, or SQL.Experience designing and deploying large scale distributed data processing systems with one or more technologies such as Oracle, MS SQL Server, MySQL, PostgreSQL, MongoDB, Cassandra, Redis, Redshift, Hadoop, Spark, HBase, Vertica, Netezza, Teradata, Tableau, Qlik, or MicroStrategy.Customer-facing migration experience, including service discovery, assessment, planning, execution, and operationsDemonstrated excellent communication, presentation, and problem-solving skills. Willingness to travel around 30% (Exempted) What we offer An opportunity to join a company that is growing rapidly and improving the way that software products are developed.A creative, flexible, fun, and challenging environment with international clients. A Competitive Salary.Remote positionEnglish classesThe opportunity to be exposed to the newest technologies (Blockchain & Cryptocurrency, Machine Learning and others).Corporate benefits with home appliances and electronic stores.Corporate discounts with Open English and NextU platforms.",Director,Contrato por obra,"Tecnología de la información, Estrategia/planificación","Software, Servicios y tecnologías de la información, Equipos informáticos",12,None,True,,122,ACTIVELY_HIRING_COMPANY
350,2193870389,2020-10-19,Eliassen Group,Data Engineer - SAS,"Ohio, United States","Data Engineer - SAS ETLCincinnati, OH﻿Our innovative and industry leading client is searching for an experienced Data Engineer to build out a Data Science based environment that will leverage modern data engineering concepts and technologies utilizing Spark, Python, SAS and SQL. The Data Engineer will work with SAS Data Integration Studio for ETL and SAS programming backgrounds are needed. The Data Engineer will develop new data pipelines for this scalable data solution that is analyzing financial data and streaming to the cloud. The Data Engineer should have expertise with data stitching, profiling, and pipelining large data sets in Agile software development environments. Duration: 6-12 Months+ Renewable ContractRate: $60.00/hr - $70.00/hr BOE C2C or W2 (Health, Dental, Vision, and 401k Matching) Requirements for the Data Engineer:5-7+ Years of Data Engineering experience in enterprise environments2+ years of SAS programming and SAS Data Integration Studio experienceExperience with Data Modeling, Profiling, Stitching, and PipeliningHands on experience with Spark, Python, and SQL Strong Cloud platform experience with AWS, Kafka, and NiFiModern Data Engineering and Agile methodology experienceData Engineering experience with Docker, Kubernetes, and Microservices is highly desired  For immediate consideration, please send updated MS Word resume to:    Keywords: Spark, PySpark, DataFrames, Data Engineer, Data Architecture, Data Architect, Python, SQL, R, SAS, AWS, Azure, Google Cloud Platform, GCP, Docker, Kubernetes, Data Pipeline, SAS, Data Integration Studio, SAS Programming",Intermedio,Jornada completa,Tecnología de la información,Dotación y selección de personal,56,None,True,,217,ACTIVELY_HIRING_COMPANY
351,2233000470,2020-10-23,APN Software Services Inc,Reverse Engineer (Vulnerability Researcher),United States,"Title: Vulnerability Researcher (DTJP00021272) Duration: 6-12 months Location: Austin, TX 78753 [Candidate may need to go onsite on occasion] Work Schedule: M-F standard 8-5. May have meetings in off hours. Job Description:Client's Security & Resiliency organization manages the security risk across all aspects of Client's business. We are currently experiencing incredible growth in order to meet the security needs of the world’s largest technology company. With team members located in over 15 countries, you will have an excellent opportunity to influence the security culture at Client's and further develop your career. Client is a worldwide provider of information technology services and business solutions to a broad range of clients. We seek men and women who share our values, thrive in a team environment, and recognize the importance of accountability: people who strive to exceed expectations to ensure our Clients' success. The ideal candidate will have exceptional hands-on vulnerability research skills, be a strong team player, and actively participate in a fast-paced and challenging global environment. Candidates must be able to work independently and demonstrate exceptional organizational and time management skills. Responsibilities:•          Responsible for discovering and exploiting vulnerabilities affecting Client's software and firmware•          Developing and maintaining tools to assist in vulnerability research and exploit development•          Participate in or work directly on, additional projects, assignments or initiatives as required•          Integrate information security controls into an environment to identify risks and reduce their impact•          Provides analysis of potential information security risks and recommend solutions•          Communicates information security procedures to the business•          Escalate issues to vendors, security team, and engineering through standard escalation processes Essential Requirements:•          Bachelor of Science in Computer Science, Computer Engineering, or Electrical Engineering or a related technical field or equivalent professional experience•          10+ years of Information Security experience•          5+ years direct or equivalent experience in areas of vulnerability research, exploit development, reverse engineering and fuzzing •          In-depth knowledge and experience with Windows Operating Systems Internals (Kernel, Registry, File system, Windows APIs)•          Knowledge of Windows development (C/C++/C#) user mode and kernel mode applications•          Experience in vulnerability research, exploit development, reverse engineering and kernel debugging•          Competency with any of the following tools: User and kernel-mode debuggers (WinDbg, OllyDbg/Immunity Debugger), IDA Pro, Hex-Rays, Visual Studio, Driver Verifier Desirable Requirements:•          Experienced programming using x86/x64 assembly C, C++, and Python (or a comparable scripting language)•          Familiar with the Metasploit framework•          Source code review for control flow and security flaws•          Have published security research or security bug•          Possess excellent communication skills in English, both written and verbal•          Excellent problem solving skills with the ability to diagnose and troubleshoot technical issues•          Customer-oriented with a strong interest in customer satisfaction Best,Kushal ShahAPN Software Service INCkushal@apninc.com",Intermedio,Contrato por obra,"Tecnología de la información, Otro, Investigación","Seguridad del ordenador y de las redes, Software, Seguridad e investigaciones",11,None,True,INCkushal@apninc.com,100,ACTIVELY_HIRING_COMPANY
352,2268735187,2020-11-02,Avanciers,Data Engineer,"Toronto, Ontario, Canada","Title: Data Engineer Location: Toronto, ON (Remote until the further notice) Experience: 8+ years  Job Description: Should have good experience in analyzing data and proposing solutions according to client needShould have experience in getting data from production to the test environment.Should have experience in hiding or masking production data before moving to other environment.Should be well aware of the data setup process.Must possess strong written and verbal communicationsExperience in Health domain will be an added advantage but not necessary.",Intermedio,Contrato por obra,"Ingeniería, Tecnología de la información",Servicios y tecnologías de la información,102,None,True,,431,ACTIVELY_HIRING_COMPANY
353,2183071083,2020-10-14,Slack,"Staff Data Engineer, Security",United States,"Staff Data Engineer, Security Our Security team supports the unwritten fourth tenet of Slack’s mission: make people’s working lives more secure. We’re serious about protecting our infrastructure, operations, and most importantly, our customers’ data. We take a systemic approach to security, and strive to ensure we provide low friction high-impact security across everything we do. As a member of the Slack Security Customer Protection team, you are the first line of detection of bad actors using Slack in unwanted and unexpected ways. As Slack’s data, number of customers, and features grow, protecting customers’ data from unwanted behaviors becomes an ever more important and complicated problem. This team develops tooling to tease out high-quality signals from all the noise and collaborates with analysts to detect unwanted behaviors, such as fraud and abuse, among others. Your work directly impacts the way millions of people, teams and businesses get things done. Slack's API and web backend is built using PHP/Hack, and our backend services are written in Java and Go. We use Airflow, Presto, Hive and Spark to interact with our data infrastructure. Slack has a positive, diverse, and supportive culture—we look for people who are curious, inventive, and work to be a little better every single day. In our work together we seek to be smart, humble, hardworking and, above all, collaborative. If this sounds like a good fit for you, why not say hello? What You Will Be Doing  You’ll own technical strategy to drive insightful and forward-looking approaches that go beyond the direct team and tackle larger open-ended problems.  You’ll participate in the strategic development of methods, techniques, and evaluation criteria for projects and programs Build and scale data systems that power batch and real-time data processing of hundreds of billions of records daily Partner with Data and Backend Engineering teams as well as Core platform and Features teams to understand and contribute to product and feature development that may impact our security model Partner with the Customer Experience team to capture requirements for new developments and understand their impact to customers Provide implementations to expose actionable data to internal and external partners.  What You Should Have  7+ years of experience working with data technologies that power analytics (e.g. Airflow, Hive, Spark, Presto, Kafka, Pinot, MySQL or similar technologies). You have a deep understanding of data processing (relational, key/value, document, columnar, graph). Experience working in a security or fraud & abuse functions. Have basic understanding of and interest in learning more about security engineering You are skilled at crafting and building robust backend data services (distributed systems, concurrency models, microservices) that distill actionable insights out of large amounts of input data. You possess expertise in high-level programming languages (e.g. Go, Java/Scala, Python). You are dedicated to code quality, automation and operational excellence: unit/integration/data quality tests, scripts, workflows. You can lead technical architecture discussions and help drive technical decisions within your team. You are a strong communicator. Explaining complex technical concepts to designers, support, and other engineers is no problem for you. You have a Bachelor's degree in Computer Science, Engineering or a related field, or equivalent training, fellowship, or work experience.  Slack is registered as an employer in many, but not all, states. If you are not located in or able to work from a state where Slack is registered, you will not be eligible for employment. Visa sponsorship may not be available in certain remote locations. Visa sponsorship is not available for candidates living outside the country of this position. Slack has transformed business communication. It’s the leading channel-based messaging platform, used by millions to align their teams, unify their systems, and drive their businesses forward. Only Slack offers a secure, enterprise-grade environment that can scale with the largest companies in the world. It is a new layer of the business technology stack where people can work together more effectively, connect all their other software tools and services, and find the information they need to do their best work. Slack is where work happens. Ensuring a diverse and inclusive workplace where we learn from each other is core to Slack’s values. We welcome people of different backgrounds, experiences, abilities and perspectives. We are an equal opportunity employer and a pleasant and supportive place to work. Come do the best work of your life here at Slack.",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Internet",24,None,False,,295,COMPANY_RECRUIT
354,2224785887,2020-10-30,McKesson,Outcomes Researcher,United States,"Be part of the team that’s poised to transform the fight against cancer. Backed by the strength of a Fortune 8 company, our entrepreneurial organization develops technologies used by the oncology community to deliver evidence-based, personalized care, as well as insights used by biopharma companies to accelerate drug development and support the entire treatment journey. Our work powers informed decision-making at every pivotal moment in oncology – from the treatment options presented to patients, to the operational considerations for oncology practices, to the design of clinical trials, to the commercial launch plans for new therapies. Position SummaryThis position reports into Manager, Clinical Programs and designs, analyzes, and reports health outcomes, pharmacoeconomic, and disease management information from real-world evidence studies. Provides hematology/oncology research and clinical analysis expertise to pharmaceutical manufacturers, physician and organization leadership. Conducts comparative effectiveness, pharmacoeconomic and health outcomes research. Supports and adheres company Code of Ethics and Business Standards. Works independently and under the supervision of research managers and directors. Key ResponsibilitiesWrites proposals, protocols, statistical analysis plansWorks with study sponsors to identify and refine study conceptsEstablishes effective timelines for completion of milestones and delivery of studiesCompletes regulatory and compliance documentsDesigns data requirements for studies based on feasibility estimates and available dataWorks with data from multiple sources (including electronic health records and claims)Researches and performs critical and statistical analysis of medical and scientific evidence as the basis for evaluation of cancer therapiesConducts and coordinates customer meetings to communicate study progress and resultsAnalyzes data to answer questions posed by internal and external stakeholdersFormats output of data analysis for customer readiness, including writing final reports and preparing presentationsPublishes research results as abstracts, posters, manuscriptsSolid oral and written communication skills. Position will require customer interaction either by phone or in person. Typical Minimum Requirements Typically requires 7+ years of relevant research/clinical/healthcare experienceMaster’s degree in Pharmacy, Public Health, Healthcare Economics or related clinical disciplinePharmD or Ph.D. preferred Must be authorized to work in the US.  Sponsorship is not available for this position Critical Skills 3-5 years’ experience in writing and completing clinical research studies requiredMust have experience navigating EHR and claims dataOutcomes research and pharmacoeconomic trainingHealthcare experience and knowledge of Real World data sources required: Oncology and Pharmaceutical/CRO experience strongly preferredProven success managing multiple projects simultaneously with multiple timelines and varied deliverablesMust be able to work collaboratively with cross-functional teams in a fast-paced matrix environmentProficient with Microsoft Word, PowerPoint and Excel and Webex/Microsoft Teams Physical RequirementsGeneral Office Demands Benefits & Company StatementMcKesson believes superior performance – individual and team – that helps us drive innovations and solutions to promote better health should be recognized and rewarded. We provide a competitive compensation program to attract, retain and motivate a high-performance workforce, and it’s flexible enough to meet the different needs of our diverse employee population.We are in the business of better health and we touch the lives of patients in virtually every aspect of healthcare. We partner with payers, hospitals, physician offices, pharmacies, pharmaceutical companies and others across the spectrum of care to build healthier organizations that deliver better care to patients in every setting. But we can’t do it without you. Every single McKesson employee contributes to our mission—whatever your title, whatever your role, you act as a catalyst in a chain of events that helps millions of people all over the globe. Talented, compassionate people are the future of our company—and of healthcare. At McKesson, you’ll collaborate on the products and solutions that help us carry out our mission to improve lives and advance healthcare. Working here is your opportunity to shape an industry that’s vital to us all. Equal OpportunityMcKesson is an equal opportunity and affirmative action employer – minorities/females/veterans/persons with disabilities. Qualified applicants will not be disqualified from consideration for employment based upon criminal history. Agency StatementNo agencies please",Intermedio,Jornada completa,Investigación,"Atención sanitaria y hospitalaria, Industria farmacéutica",23,None,False,,651,COMPANY_RECRUIT
355,2213064080,2020-10-26,Selby Jennings,Python/SQL Data Engineer - Elite Quant Hedge Fund (6-Month Contract),United States,"Python/SQL Data Engineer - 6-Month Contract with Elite Quant Hedge Fund - Urgent Hire One of the world's largest and most presitigious hedge funds are seeking Data Engineers in a contract capacity to build stable, productionalized data pipelines that support trading activities. You will contribute to building robust data pipelines that ingest over 30TB of data each day using Python/SQL. Additional responsibilities Include:• Working closely with business partners across the firm to understand their data needs• Working with engineers, researchers, and portfolio managers across the organization to onboard interesting new datasets• Extending and improving our data onboarding framework as needed You should possess the following qualifications:• Have at least a bachelor’s degree in a technical field• Have at least 2 years of full-time work experience as a Data or Software Engineer working in Python/SQL• Have experience building ETL pipelines",Algo de responsabilidad,Contrato por obra,"Ingeniería, Finanzas","Servicios financieros, Servicios y tecnologías de la información",128,None,True,,309,ACTIVELY_HIRING_COMPANY
356,2232843553,2020-11-02,Blackstone Talent Group,Senior Data Engineer (GCP),"San Ramon, California, United States","Referral Program: Not Interested but know someone!? We offer a $1000 Referral Bonus for anyone you refer that gets the project.  Position Details:Location: San Ramon, CA (remote)Type: 6 Month Contract to Hire (Full Time)Green Card, TN Visa, EAD, US Citizen are acceptable Looking for someone with Google Cloud Platform & Google BigQuery experience.  Blackstone Talent Group, an award-winning technology consulting and talent agency is seeking a Senior Data Warehouse Analyst to join our team at our client’s site in San Ramon. Key Responsibilities:·            Work closely with our operation team to create and track key metrics for our finance organization, and share informative actionable insights·            Improve existing process for warehouse operations·            Optimize capacity of warehouse·            Build dashboards, self-service tools, and ad hoc reports to analyze and present data associated with business operations, and strategic decision making·            Identify actionable insights, suggest recommendations, and influence the direction of the business by effectively communicating metrics and results to stakeholders.·            Partner with Data Engineering to develop our data infrastructure supporting BI needs·            Ability to work across multiple facets of a project and juggle multiple tasks at the same time. Key Skills:Create clean, reliable, and scalable “single-source-of-truth” data sets by partnering with business owners and engineering teams to address data issues in upstream systems.Perform data profiling on large, complex data sets and provide insights into data quality challenges.Build, maintain, and improve data models, dashboards, and data pipelinesExpert in building, deploying and maintaining data pipelines using open source tools i.e, Python, AirflowWork with business and engineering teams to drive the development of company’s data, reporting, and analytics platformsSkilled at writing optimized data extract queries in BigData systems (i.e., BigQuery, Hadoop, DOMO, Birst)Expert in data analysis, visualization, and communicationExperience creating dashboards/visualizations using Tableau, Business Object, PowerBI, Looker (or similar)Proficiency with SQL, and comfort with Python or any other scripting language Additional Qualifications:·           BS/MS in STEM or quantitative field (CS, Applied Statistics, Operations Research) or BS/MBA in Finance, Accounting, Economics, Business Analytics·           Required 5+ years of experience in data analysis role·           Experience working in a fast-paced agile environment.·           Experience working with enterprise systems and understanding of data design pattern differences between transactional systems and analytical data warehouses·           Experience with data analytics tools and languages (R, Python)·           Experience with commercial and emerging BI databases, technologies, and languages·           Knowledge of accounting principles, financial statements, and financial modeling·           Excellent problem-framing, problem solving and project mgmt. skills and ability to change direction quickly·           Experience with git and version control workflows·           Attention to detail and personal pride in work undertaken.·           Ability to self-start and self-direct work in an unstructured environment, comfortable dealing with ambiguity·           Strong communication skills, and ability to work with multiple stakeholders  EOE of Minorities/Females/Veterans/Disabilities",Intermedio,Contrato por obra,"Tecnología de la información, Ingeniería","Software, Servicios y tecnologías de la información, Seguridad del ordenador y de las redes",37,None,True,,202,ACTIVELY_HIRING_COMPANY
357,2203718248,2020-10-22,Simon Data,Senior Data Engineer (NYC OR Remote North America),United States,"About UsSimon Data was founded in 2015 by a team of successful serial entrepreneurs. We are an enterprise customer data platform that empowers marketers to create personalized data-driven experiences for the customers. We’re scrappy problem solvers who believe in tackling big challenges with disruptive thinking and giving our customers the support they need to deliver great next-generation experiences at scale.  Simon Data is a data-first customer experience orchestration platform, designed to disrupt the marketing technology and marketing cloud category. Simon’s platform empowers businesses to use enterprise-scale data and machine learning to power customer communications across every channel. Our unique approach allows brands to develop one-to-one relationships with their customers without building a bespoke in-house data infrastructure.  At Simon, we firmly believe that business success starts and ends with people. We all do our best work when we are surrounded by other friendly top performers who want to succeed together. This attitude is core to our values. When you trust your team, invest in their development, and give them ownership, great things happen. The RoleDoes your ideal job involve working with petabytes of data or constructing data pipes that operate over widely diverse industries? Are you passionate about how your work has a tangible impact on the bottom line for each of our clients? As a Senior Data Engineer at Simon, you’ll immediately dive into a system of multiple streaming and batch pipelines. You’ll use your readiness to seek complete solutions with a passion for building fault-tolerant and highly available systems. The Simon Data pipes are the backbone of our platform and critical to our clients’ success. You will play a pivotal role in our ability to sustainably and rapidly move the data that powers our platform to engage with hundreds of millions of customers -- sending over billions of messages annually. What You'll DoBuild, scale, and own data pipelines using batch and streaming tools like Python, Spark, Kinesis, Redshift, Snowflake, and Elasticsearch or using new technologies to achieve the desired outcomeArchitect and develop new data products for clients like new reporting capabilities or data transformation tooling Construct the platform and tools for our clients to self serve their data engineering needs on the Simon systemContribute to an ecosystem to address evolving requirements of scale!Develop expertise in profiling and debugging AWS services to define performant usage patternsCollaborate daily with a group of your peers, all of whom are passionate about quality, staying ahead of the curve, and continuous improvementParticipate in team-wide discussions ranging from architecture to developer efficiency to security Be a part of establishing our mark in Open Source Software as well as promoting and sharing it at conferences locally and nationwide QualificationsAt least 4 years of demonstrated ability crafting, deploying and owning several substantive data engineering or analysis projects with company-wide impactMinimum of 2 years proven experience working with various functional owners in your company (spanning product management, program management, as well as Dev/Tech Ops)Proficient in SQL and at least one mainstream programming language (Python, Java, Scala, C#, Ruby, etc.) Visa sponsorship for this role is currently not available. ﻿DiversityWe’re proud to be an equal opportunity employer open to all qualified applicants regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or expression, Veteran status, or any other legally protected status.",Intermedio,Jornada completa,"Tecnología de la información, Ingeniería",Software,16,None,False,,107,ACTIVELY_HIRING_COMPANY
358,2273362316,2020-11-04,Homeward,User Researcher,"Austin, TX, US","Remote (anywhere in U.S.)   We're seeking a User Researcher to help us build a simpler, more customer-centric home buying and selling experience in partnership with real estate agents.  Role location  This is a remote position and we're accepting applications from anywhere in the U.S. We also have an optional office in Austin you can use if you live here or come visit.  Our offering  We give homeowners the freedom to buy the home they want before selling their current one. Customers tell us about their home and financial situation, then we provide them with funds to confidently secure their next home with a competitive all-cash offer. This saves them stress from having to list their house without knowing where they're going next, and makes the process of buying and selling a home as easy and predictable as it should be.  About Us  Homeward was started in 2018 by Tim Heyl, a 10-year industry veteran and owner of one of the fastest growing agent teams in the U.S. We're passionate about our mission to empower home buyers and their agent partners to buy before they sell while making the entire experience more convenient and certain. We're growing fast in Texas, Colorado, and Georgia, and plan to expand across the U.S.  Homeward is backed by top-tier venture investors like Adams Street, Javelin, and LiveOak. We've raised over $25 million in equity and secured over $100 million in debt to buy homes for our customers. Our leadership team includes experts from the real estate, mortgage, and technology spaces.  Values  Golden Rule  'Treat others how you want to be treated.' We're building our company culture and customer experience with this as the guiding principle. It's a simple rule, but emphasizes that we don't prioritize money or growth over people.  Calm Focus  We don't chase every opportunity and rush from urgent task to urgent task. We relax, stay calm, and focus on our company-wide objectives. If something is out of scope, we say 'no'. If something feels rushed we slow down and think it through so we can avoid unnecessary rework later. We don't bombard each other with notifications expecting instant response times. We block off time for deep work so we can get into the flow and create solutions our customers love.  Cross Functional Collaboration  We look at our customers' experience wholistically and recognize that improving it requires support from multiple functions. Given this, we're excellent collaborators. No function is more important than another and we're eager to work as a team to solve our customers' toughest problems. We value strong internal alignment, and take pride in understanding our teammates' perspectives before expressing our own.  In this role, you will:  Report to our VP, Product and work closely with senior leadership to identify key research opportunities to inform and prioritize company initiatives. You'll join a small Product team and have a big impact on our company, developing research plans that affect our service & digital product development.  Partner with groups across the entire org from Operations to Marketing to Product & Engineering to develop appropriately rigorous and rapidly executed research opportunities. Spend most of your time listening to customer, partner agent, and internal team member feedback via any medium available - from cold calling customers or agents to surveys to long-term diary studies. You will pick the right modality and structure for the desired research outcome. Summarize and communicate your research insights to the broader organization and leadership team to continually develop a sense of user pain points, regular refinement of business processes, and ensure we're exceeding our customer & agent partners' expectations.  Create, maintain, and socialize important artifacts like monthly summaries, journey maps, and personas to align our organization on dimensions of our service & customers' experiences. Be exceptionally outcomes-focused to ensure we're always solving the most important problem.  Get up to speed on the residential real-estate industry and become well-versed in the home buying, home selling, and home valuation processes.  Build upon good research practices at Homeward and continue to help us adopt best practices.   What you'll bring:  You have a few years of research experience in a high-performance startup or technology company. You're collaborative and open to feedback. You're great at working as part of a team and love getting input on your research plans and research roadmap so you can continuously improve.  You're able to ship quickly and adjust your process to fit the needs of an early stage startup. You create high-quality research studies in short cycle times. You value shipping a good solution now over a great solution several weeks from now. You're interested in improving the complex, emotional process of buying and selling a home and making it the exciting milestone in people's lives that it deserves to be. Hands-on experience conducting a variety of research practices such as user interviews, user testing, and user surveying. Strong analytical skills and the ability to balance and interpret quantitative and qualitative feedback into synthesized, insightful summaries Demonstrable experience developing high-quality research artifacts for a variety of audiences. An educational background in the following or relevant work experience: Psychology, Human Computer Interaction, Cognitive Sciences, Design, or any discipline with a strong emphasis on qualitative and quantitative research methods   Nice to haves:  You have experience in the real estate space Knowledge of SQL-like querying language and ability to write some basic reporting needs for surveys Solid understanding of web analytics tools and strong quantitative analysis skills",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Banca, Servicios financieros, Bienes inmobiliarios",63,None,False,,392,ACTIVELY_HIRING_COMPANY
359,2246366152,2020-11-05,Gemography,Data Engineer (Remote),Morocco,"You will work on:Take ownership and responsibility of data produced by the data pipelines.Maintain and update ETL data pipelines as well as create new ones.Document, identify and automate common data and pipeline operations.Participate in standups/meetings and operate in a team environment with agile methodologies.Monitor the status of data pipelines and act correspondingly.Ensure data produced has the right format/quality and that associated metadata is properly documented. What we are looking for: Experience with data engineering, preferably in Python.You’re a fast learner, can contribute from day one as well as integrate and apply new concepts quickly.You take pride in what you create and passionate about getting the details right, even when no one's looking.You are able to weigh tradeoffs, articulate complex ideas, and have precision about what you know and don't know.You enjoy staying on top of tech trends and hacking new things.Proficiency in written and spoken English.  Bonus points if you have:Hands-on experience in SQL tuning, schema design or analytical programming.Familiar with Docker, Kubernetes, Airflow or similar technologies.A graduate degree in Computer Science or similar discipline. Benefits & PerksCompetitive salaries and performance bonuses.Your own Spotify Premium and Netflix accounts.24-days paid time-off (+ public holidays).Health insurance & pension. ImportantResume/cover letter are optional.The job role is fully remote (anywhere in Morocco). It's long term and comes with an indefinite period employment contract.",Intermedio,Jornada completa,Tecnología de la información,Internet,20,None,False,,193,JOB_SEEKER_QUALIFIED
360,2227370056,2020-10-30,Starbridge Partners,Senior Data Scientist,"Indianapolis, Indiana, United States","[EXCLUSIVE SEARCH] Title: Senior Data ScientistWhere: HQ in Downtown Indianapolis, IN (Remote Available)For: Well-funding AgTech StartupReports to: Chief Data Scientist *Must be eligible to work in the U.S. (i.e. no sponsorship or H1B transfers)* About our Client:Our client is a fast-growing AgTech startup that recently raised a large sum of funding to support growth objectives over the next 3+ years. With their differentiated business model that includes both a cloud-based, prescriptive analytics solution and 'high touch' operational advice, the company is cash-flow positive and has accumulated a backlog of clients.  Grown 300% this year and over 60 Employees. **Covid is not negatively impacting their sector**.  Your MissionThey are seeking a Senior Data Scientist to extract insights from the agronomic, soil and environmental data collected from customers. Your focus will be to develop quantitative solutions to help growers increase crop yields and reduce yield variation. ResponsibilitiesDevelop and help support new techniques to address quantitative problems in digital agriculture using large datasets. Data mining using state-of-the-art methods on large Spatio-temporal datasets derived from agricultural production systems.Extending data resources with third-party sources of information when needed.Proposing new ideas and novel solutions that do not follow conventional thinking or https://www.linkedin.com/redir/phishing-page?url=approaches%2eWork closely with software engineers to deploy solutions to problems in a production environmentConduct written and verbal presentations to share insights and recommendations to audiences of varying levels of technical sophistication.Establish procedures for the application of basic machine learning algorithms to agronomic and environmental data.  RequirementsRelevant Masters or Ph.D. in a quantitative field with a minimum of three years of professional work experienceStrong background in statistical methodology and the ability to infer causal relationshipsStrong hands-on proficiency with at least one data science programming language (R, Python, Julia)Experience with machine learning (ML) and artificial intelligence (AI) algorithms.Strong research track recordExperience in working with large-scale spatial and temporal dataExperience with data visualizationAbility to work in a fast-paced business environment.Experience with ArcGIS or other geographic information systems (GIS) platform is a PLUSAre a self-starter who can own complex projects from start to finish  Compensation / Benefits Competitive Base Salary + Performance Bonus Medical, Dental, Vision Insurance, 401K match, PTO, etc.",Intermedio,Jornada completa,"Investigación, Ingeniería, Ciencias","Agricultura, Servicio de información",60,None,True,,214,JOB_SEEKER_QUALIFIED
361,2224745057,2020-10-29,Kumu,Data Engineer,Philippines,"As Kumu's Data Engineer, you will be working alongside a growing team of engineers and data scientists, to help further rapidly scale the Kumu environment. The team needs a reliable member to help perform the following: Maintenance of existing data warehouse infrastructureDesign, build and deploy efficient pipelines to migrate data into and out of our data warehouse and do automated updates from those various data sourcesIntegrate with external data sources to pull data and dump into data warehouse - including API services, flat files, unstructured dataClean, transform and normalize data into the form needed by various stakeholders as preparation for more business-driven analysis- data scientists, data analysts & other department stakeholdersAssist in optimization of data operations in terms of efficiency and costEnsure a full-stakeholder approach in building big data solutions by coordinating with multiple cross-functional teams, including Product, Engineering and Business Intelligence Teams. Be a gatekeeper of our data and provide the necessary access only to the relevant stakeholders (data analysts, data scientists, business team etc.) for convenient data accessibility, but with strong data security.Documentation of technical specs of all the data infrastructure being used - data warehouse, pipelines, catalog, etc.Participate in code reviews of peer engineers and maintenance of code repositories We need you to have: Basic understanding of business metrics for app analyticsStrong communication skills to be able to coordinate between various stakeholdersBasic knowledge of architecture / pipeline diagrams and documentationStrong preferences for familiarity working with these types of data: Event streaming, Image / Video live streaming, Transactional, ECommerce Along with these:Strong programming knowledge in Python for developing ETL componentsStrong understanding of SQL for data analysis and table transformationsMulti-Cloud Platform Experiences - AWS, GCP or AzureExperience working with modern high performance analytical databases and computation engines like Spark, Flink, Presto, Synapse, BigQuery, Elasticsearch, Greenplum and othersExperience working with various data storage and object structures including, but not limited to structured SQL records, NoSQL documents and unstructured media files.",Intermedio,Jornada completa,"Tecnología de la información, Ingeniería","Servicios y tecnologías de la información, Medios de comunicación en línea, Software",25,None,True,,290,ACTIVELY_HIRING_COMPANY
362,2191796340,2020-10-19,Redapt Inc,"Value Engineer, Data Science","Seattle, Washington, United States","Working at Redapt means being a part of a fantastic team, working with the latest technologies, and having a direct impact on project success. We solve complex business problems, align stakeholders, develop a client’s data DNA, and deliver rapid ROI. If you love leading a team helping customers solve complex problems related to Business Intelligence, Advanced Analytics, and Data Science, we’d like to hear from you!We are looking for a versatile Value Engineer and Financial Data Scientist who can lead, sell, design, and implement modern architecture for a diverse set of customers and industries. The ideal candidate would have deep experience in designing high-value advanced analytics solutions utilizing popular analytical frameworks running on Azure, GCP, and AWS. This position will be responsible for leading customer conversations, creating and presenting project architecture, and leading delivery. The role will also be responsible for managing our portfolio of managed analytics and data science customers with targeted collaboration with CFOs and other finance leaders to create extreme value data initiatives and solutions. This position will directly own value generation, value monitoring & ROI reporting for our customers. Primary responsibilities include mentoring and leading other data science consultants, leading pre-sales workshops with finance and technology executives to uncover innovative ways to apply advanced analytics techniques to solve business problems in new ways. The role can be hands-on when necessary but should have the direct delivery experience to recommend technologies, solutions, and help troubleshoot. Responsibilities:Data Science Practice GrowthDrive growth through business development, resourcing, & quality delivery.Monitor business impact and value generation of analytics projects.Plan strategy for growth of practice capabilitiesHelp created go-to-market strategies around advanced AI and ML services and hardware.This role will be directly involved in the business development process, delivering customer demos to show the value of how data can drive business goals.Create proposals and SOWsWork closely with sales and other practice leaders to recommend strategies to grow our data science services.Manage full sales cycles, end-to-end, for high potential clientsEvaluate business impact and priority initiatives for our portfolio of managed analytics customers. Talent Leadership and Product OwnershipHelp with planning and staffing for data science projects.Provide support for project managers through developing tasks, estimates, and dependencies to meet expectations.Train the data science team on best practices and new technology initiatives.Anticipate the impact of new technologies and frameworks and help create compelling data science offerings to our clients.  RequirementsBackground in finance and accounting and knowledge of how to use data science techniques in operations to impact corporate financials8+ years of experience with advanced data science techniques, frameworks, libraries, and technologies including but not limited toTensorflow, KubeFlow, Python, R, Keras, NumPY, SciKit, PyTorch, Databricks, SQL.Experience with all aspects of Artificial Intelligence, Machine Learning, and Deep Learning.Working knowledge of DevOps processes (CI/CD) applied to data science and ML opsAdvanced Math or Data Science Degree.Ability to articulate concepts to people with a varying technical background This position can work remotely with some travel required as needed. Redapt is an equal opportunity employer. Applicants will not be discriminated against because of race, color, creed, sex, sexual orientation, gender identity or expression, age, religion, national origin, citizenship status, disability, ancestry, marital status, veteran status, medical condition, or any protected category prohibited by local, state or federal laws. All employment is decided on the basis of qualifications, merit, and business need.",Intermedio,Jornada completa,"Tecnología de la información, Consultoría",Servicios y tecnologías de la información,113,None,True,,423,ACTIVELY_HIRING_COMPANY
363,2197070439,2020-10-21,LogRhythm,Data Engineer III,United States,"About us:  LogRhythm is the pioneer in Next Generation SIEM and Threat Lifecycle ManagementTM (TLM) technology, empowering organizations on six continents to rapidly detect, respond to and neutralize damaging cyberthreats. Our TLM platform unifies leading-edge data lake technology, artificial intelligence and security analytics to serve as the foundation for the AI-enabled security operations center. We are consistently recognized as a leader in the security intelligence domain and have been placed in Gartner’s SIEM Magic Quadrant for 6 consecutive years. Who we are looking for:  The LogRhythm Data Science team is seeking a qualified Data Engineer III with the requisite experience and passion for designing, implementing and delivering data-driven analytics products to support our customers need for advanced cyber threat detection and mitigation. The qualified individual is an experienced engineer who has demonstrated expertise with modern, scalable and distributed analytics platforms in a highly collaborative engineering environment. Here’s an overview of the responsibilities & challenges ahead:  Leverage modern analytics stacks and cloud platforms to design, implement and maintain scalable infrastructure for ingesting, processing and persisting large volumes of batched and streaming data.Contribute to multiple production code bases in a continuous delivery (CI/CD) environment.Write, debug, maintain and constructively review code on a highly collaborative software engineering team.Develop production quality software for interacting with distributed data pipelines, data stores and data models.Leverage best practices regarding big data and scalable processing and storage infrastructure.Assume light on-call responsibilities to support monitoring and integrity of cloud-based production software product offering. Required Skills:  3+ years of experience with scalable data processing and storage technologies such asSpark, GCP Dataflow, GCP PubSub, Kafka, Flink, Elasticsearch4+ years of experience with PythonExperience with libraries such as pandas and numpy would be beneficial3+ years of experience with other programming languages such as Java or GolangExperience with SQL or pyspark would be beneficialExperience with deploying and leveraging cloud-based infrastructure in GCP/AWS/Azure preferably through automated means, Kubernetes and Docker experience would be usefulKnowledge of distributed computing fundamentals and the ability to design for scalability on Linux platformsExperience with standard development tooling such as Git, Jira, RallyExperience with agile development processes such as scrum or SAFe Valued Skills/Qualifications A bachelor’s degree in relevant technical field of Computer Science, Mathematics/Statistics, or similarly relevant engineering or computational discipline.Excellent communication skills and the ability to work collaborativelyData analytics/modeling experienceStrong mathematical/statistical analysis skills Workplace equality & inclusion are not just words or topics for LogRhythm, they are part of our core values, beliefs, and integral to our company culture. We hire the best of the best and do not discriminate based on race, gender, age, religion, sexual orientation, identity, or other personal factors. LogRhythm was built on the principals of innovation, dedication, creativity, and commitment. It is through these key areas we were able to grow as an equal and inclusive workplace, one where our employees feel respected and safe in.",Intermedio,Jornada completa,"Ingeniería, Gestión de productos, Otro",Software,7,None,False,,120,ACTIVELY_HIRING_COMPANY
364,2218851771,2020-10-28,Cavendish Professionals,Senior Data Scientist,Greater Munich Metropolitan Area,"Our client works on very challenging and exciting projects and are looking for a Senior Data Scientist Skills:(PhD or MS) preferably in computer science, engineering, mathematics or statistics2 years+ professional experience in advanced data analyticsKnowledge on Text AnalyticsExperience on NLP/AIYou speak fluent German and English Further Info:Location: MunichDuration: PermanentWorkload: Remote/Office Based If interested, please get in touch via contact details provided or click 'Apply' to forward an up to date copy of your CV.",Intermedio,Jornada completa,"Tecnología de la información, Consultoría",Dotación y selección de personal,82,None,True,,372,JOB_SEEKER_QUALIFIED
365,2283184772,2020-10-22,SubiHIS Consulting,Data Scientist,"Canberra, AU","* Applicants Must be Australian Citizens *  Overview  The National Skills Commission (NSC) is working to develop intelligence on Australia’s labour market, workforce changes and current and emerging skills needs. The NSC will drive long-term improvements across the skills system to bring together existing data and develop new capability in skills analysis, and improved data and advice on VET pricing and outcomes. The Commission provides high quality advice to the Minister for Employment, Skills, Small and Family Business on Australia’s labour market, future workforce changes and current and emerging skills needs. It uses new data sources and techniques such big data and machine learning, as well as more traditional economic and skills analysis.  Our Key Focus Areas Include   assessing the nature of labour market recovery determining skills shortages or surplus analysing the structural shifts that are occurring in the labour market identifying current, emerging and future skills needs.  Estimated start date  21-11-2020  Location of work  Australian Capital Territory New South Wales Northern Territory Queensland South Australia Tasmania Victoria Western Australia Offsite  Length of contract  30/06/2021  Contract extensions  Automatic 12 month extension if both parties are happy with the arrangement.  Selection criteria  Essential Criteria  Excellent communication skills, problem solving and analytical skills. Demonstrated experience in applying data science to meet the needs of business users, including understanding business requirements, articulating problem statements and developing criteria for suitable implementation of data science solutions. Demonstrated knowledge of appropriate techniques to explore, profile and cleanse data from a diverse range of sources and experience in presenting exploratory data analysis to non-technical stakeholders. Experience using Python, PySpark, R or SparkR programming languages through development environments including Databricks for developing supervised and unsupervised machine learning models, with a particular emphasis on Natural Language Processing. Demonstrated experience in using data science preferably for economic research, working with Australian Labour Market data such as ABS Quarterly Labour Force Survey and Census.  Desirable criteria  Experience with proof-of-concept development, preferably in Power BI or Shiny. Experience working with big, unstructured datasets. Knowledge of the Burning Glass dataset would be an advantage. Expertise in Agile methodology and a clear understanding of the ethical implications and governance of algorithms.   What To Submit  Please hit the 'Apply Now' If you are interested, you must include:  résumé responses to the selection criteria (up to 500 words per criteria) references (this can be included in their résumé)  This is a remote position.",Algo de responsabilidad,Contrato por obra,"Ingeniería, Tecnología de la información",Relaciones gubernamentales,None,None,False,,17,JOB_SEEKER_QUALIFIED
366,2231245147,2020-11-01,HOOKED,Machine Learning Engineer,"San Francisco, CA, US","We are looking for someone interested in applying the latest advances in ML to building cutting-edge entertainment experiences for our 40MM monthly users.  Here Are Some Example Projects  Create a recommendation system that provides personalized recommendations to users by leveraging the data generated by hundreds-of-millions of stories being read. The system must be fast, scalable and support testing different candidate recommendation algorithms.  For our top stories we work with actors to create audio versions of our story. For the rest of the catalog we have experimented with text-to-speech systems but have found the results more comical than convincing. Build open state-of-the-art TTS systems (wavenet etc) to create TTS system that takes into account semantic context. What emotion needs to be conveyed? Can we condition on this to guide the TTS system?  Hooked readers generate vast amounts of granular data when they read -- every tap is a data point. Can we use marry this behavioral information with automatic story analysis using NLP techniques to predict engagement on future stories?",Algo de responsabilidad,Jornada completa,Ingeniería,Software,144,None,False,,493,JOB_SEEKER_QUALIFIED
367,2197052864,2020-11-02,RJR Partners,Technical Recruiter,San Francisco Bay Area,"Our client, a boutique big data consulting firm, is looking for their first in-house technical Recruiter. This is a full-time, salaried position located in the United States.  The ideal candidate will be energetic, possess a strong work ethic, phenomenally organized, and has the agility to successfully operate in a fast-moving startup environment. The right candidate will enjoy managing their own time, going from creation to execution, learning new things and being recognized and given thanks for all of the contributions made.  Responsibilities:Develop and maintain a world-class recruiting and people operations functionLead recruiting initiatives end-to-end: maintain a best-in-class candidate experience, source and manage the talent pipeline, communicate with candidates and hiring teams to ensure delivery against goalsSource and maintain a bench of top-tier data scientist and data engineering candidatesOwn all aspects of the employee lifecycle, from offer letter generation to onboarding to offboardingManage and shape the company's organizational brand on recruiting outlets like LinkedIn, Glassdoor, company website, etc.Create and participate in initiatives that pertain to employee engagement and enhancing company culture Minimum Qualifications:BS/BA preferred2+ years experience in full-cycle recruiting & sourcingPrefer experience working in a startup environment or within an agency supporting startup clientsExperience working in a consulting firm a huge plusKnowledge of data engineering, analytics and data science industry What they Offer:Competitive salary and bonuses401 (k), Commuter plan, FSAFlexible PTO policy: work hard and take time off when you need itGenerous healthcare benefits with medical, dental and vision coverageWeekly team lunches and other social events (when it's safe again!)Convenient location in downtown San Francisco Office or remote work available",Algo de responsabilidad,Jornada completa,Recursos humanos,"Software, Consultoría de estrategia y operaciones",458,None,True,,914,ACTIVELY_HIRING_COMPANY
368,2266206851,2020-10-08,AnswerLab,(Remote - Major Metropolitan Cities) Qualitative UX Researcher,"San Francisco, CA, US","In response to COVID-19, AnswerLab has transitioned all its client work to remote studies. This role is expected to be 100% home-based with no travel needs in the foreseeable future (12-18 months). Our commitment to our team's health and safety takes priority. In fact, we immediately transitioned all of our in-person studies to remote work in the beginning of this year to ensure the well-being and security of our people, clients, participants and partners. We may return to in-person research in the future at which point this role may require up to 25% of travel.Why We're Saying Bye to In-Person Research in 2020Who We Are:We are a team of 130+ diverse insights experts who are passionate about solving UX challenges and creating experiences people love.AnswerLab is the leading UX Research firm in the US. We help powerful brands such as Amazon, Google, Facebook, FedEx, Wells Fargo, and Walmart bring a human-centered design process to every product launched. We focus on user experience research to understand what people see, do, think, and feel when using websites, mobile applications, voice interfaces, AR/VR, wearables, and other digital products. Our research studies are tailored to our clients' unique needs to provide clear, actionable recommendations that generate strategic business results.The secret to our success is no secret: It is the people who work here! We recruit only the most skilled and client-focused professionals to join our team. All are devoted to being at the forefront of the user experience industry. Our team is made up of smart, down-to-earth people who value a 'get it done' attitude as well as a good dose of humor during our work day. We empower them to do what they do best: lead impactful research studies from planning to analysis for the world's most innovative brands.Who You Are:You are a driven, ambitious and results-oriented individual who is deeply passionate about UX Research. You have 5+ years of hands-on experience moderating 1:1 usability studies on large scale websites/mobile devices, and you want to become a part of a team whose mission is to improve the digital world by creating experiences people love. You thrive in a home-based work environment, and you are comfortable conducting research remotely.Click here to learn more about the AnswerLab culture and why people choose to join our team.The Qualitative UX Researcher RoleAnswerLab is a growing user experience research firm that assists clients in measuring and improving the experience of their online customers. Example research methods include one-on-one usability studies (remote and in-person), eye-tracking, remote usability studies, online and in-person focus groups, mobile device testing, card sorting, ethnography, and quantitative benchmarking studies.Global market leaders select AnswerLab as their user experience research partner including Google, Amazon, Facebook, FedEx, Wells Fargo and Walmart.The qualified candidate will be responsible for:* Working with clients to understand business needs and to craft UX research solutions* Assisting in the development of screener surveys for identifying clients' target users* Monitoring the participant recruiting process* Developing moderator guides* Consulting with clients on the development of prototypes for testing* Managing technical setup for in-person labs* Moderating remote and in-person user experience research studies or conducting interviews in field* Analyzing the research findings* Developing PPT presentations to communicate findings and recommendations* Presenting to executives* Keeping projects on schedule and within scope and budget* Building a trusted advisor relationship with clients* Contributing to AnswerLab's knowledge library* Collaborating with colleagues to solve research challengesWe understand that outstanding candidates can come from a variety of backgrounds. While specific experience is important, we are ultimately looking for candidates who have the personal characteristics to thrive in a growing client-focused business.The qualified candidate will have experience in and meet most of the criteria listed below.* Leading consulting engagements with clients -- either in research specifically or with a management consulting firm that uses analytical data to support conclusions* 5+ years of hands-on experience moderating 1:1 usability studies, particularly on large scale websites, web-based applications or mobile devices* Experience in financial services preferred* Designing and writing discussion guides, screeners, test protocols, and final reports* Using online/remote usability tools (i.e. Zoom, WebEx, GoToMeeting, etc.)* Conducting presentations with senior-level business managers and executives* Working with the Internet and web-based tools* Demonstrated ability to 1) work independently and drive towards deadlines, 2) produce high-quality deliverables for clients, and 3) think creatively and solve problems.* Ability to engage with business and research managers in Fortune 500 companies.* Excellent communication skills and the ability to facilitate discussions* Ability to work in a fast-paced deadline-driven environment, manage competing priorities, and be an independent problem-solver* Presentation skills, including building PowerPoint presentations and presenting results and recommendations to clients* Undergraduate and/or advanced degree - preferably an educational background in Experimental Psychology, Cognitive Psychology, Human Factors, Human Computer Interaction, or other related discipline with a solid foundation in research-based design using both quantitative and qualitative methodsAnswerLab's Core Values:* Build trust* Provide amazing service* Support and Encourage Inclusivity* Jump in to help others* Handle change with flexibility* Innovate our products and processes* Figure it out and get it done* Make AnswerLab a great place to workPhysical Requirements:* Overtime may be required to meet project deadlines.* Sitting for extended periods of time.* Dexterity of hands and fingers to operate a computer keyboard, mouse, and other devices and objects.This is a full-time position.No staffing/recruiting agencies please.We are interested in every qualified candidate who is eligible to work in the United States, however, we are not able to sponsor visas.At AnswerLab, our mission is to create experiences people love. This means we strive to make our company a great place to work for people from all walks of life. Hiring people from a wide variety of backgrounds makes our company stronger and helps us achieve our mission.We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity and/or expression, status as a veteran, and basis of disability or any other federal, state or local protected class.",Director,Jornada completa,Tecnología de la información,Servicios y tecnologías de la información,6,None,False,,40,None
369,2248374055,2020-10-28,"Pachyderm, Inc.",Community Manager,"San Francisco, CA, US","The role  As the Community Manager at Pachyderm, you'll play a strategic role in helping grow Pachyderm's community outreach at multiple levels. You'll talk with our vibrant community of 2000+ members in Slack and our 100+ contributors on GitHub, while also deepening our ties with external AI/ML communities in Slack/Discord and on social media hotspots like Reddit, Twitter and LinkedIn.  We're looking for a true 'social butterfly,' someone who loves talking with others and putting others first. Are you the kind of person who loves connecting with new people? Do you have a fantastic memory for details? If a friend comes into town with their family are you the first one to put together a list of great restaurants for them to visit? Do you love bringing people together to learn and grow? Do you love to help find the answers people need fast?  If you also have a passion for artificial intelligence and machine learning (AI/ML), as well as other cutting edge technology, that's a big bonus. You don't need to be a data scientist or engineer, but you do need to be able to get along with technical folks. You'll need to have a lot of energy for the community and know enough to pass on questions and engage effectively. We're looking for someone who is going to stay focused on other people, even when it's not directly helping Pachyderm but simply growing interest in AI/ML around the world.  It's also terrific if you have some good technical aptitude, the ability to learn quickly and a desire to get stronger in the AI/ML space. But most importantly, if you're the person who loves to help people make broader and deeper connections online then you're the person we need.  Responsibilities  Build up a powerful and consistent presence in as many strong AI/ML communities as possible — Pachyderm Slack, Reddit, LinkedIn, MLOps, Discord/Slack. Help manage social media presence Assist with discovery with potential leads whenever possible. Help direct questions to the right people and answer questions yourself as your knowledge grows Think strategically about how to grow our communities using critical thinking and long term planning Help drive sales by working closely with sales to nurture and organically engage community members who's organizations might need Pachyderm's goods and services Help to create and organize events such as webinars, podcasts and coordinate with conferences and other potential partner's events and content Generate content like podcasts or interviews or articles with the help of the evangelism team   Requirements  A technical depth to the point where you understand the data science ecosystem, the basics of AI/ML, systems architectures for enterprises, including the kinds of architectures and applications people are building in this space Strong comfort with a broad range of social media platforms like Slack, Discord, Twitter, YouTube, LinkedIn, Reddit Ability to quickly adapt to any new social media technology and learn it fast Comfortable writing well and speaking Self-motivated, self-starter Able to work on multiple things at once Ability to manage your own task list with ease Ability to keep track of a lot of things happening at different speeds  Bonus  Bonus: If you have your own communities or a big presence on social media like YouTube that's a major bonus. We want someone who's already thinking about growing their own social media presence skillfully.  Second Bonus: If you have audio and video editing skills, as well as some design skills, those help to quickly create assets for our communities, especially podcasts and video content.",Algo de responsabilidad,Jornada completa,"Marketing, Relaciones públicas, Redacción y revisión",Software,35,None,False,,321,None
370,2238662665,2020-09-30,Third Republic - Recruitment Solutions for Digital Transformation,Data Engineer - AWS (Boston OR Dallas) Remote flex,"Boston, MA, US","Data Engineer - AWS (Boston OR Dallas) Remote flex - Boston  Who is hiring?  We are currently working with a leading company in the US that is working in the area of digital transformation for the cloud environment. It helps companies migrate to cloud environment from Azure, GCP or AWS. My client also works in big data, analytics and AI in the area of warehousing industries. They seek to hire a GCP Architects to work on infrastructure and application.  What will you be doing?  This is an excellent opportunity to work with cutting edge technologies on the client site for some of the most exciting projects in the analytics community!Great opportunity to work with other BI & Big Data professionals and learn from some of the top professionals in the cloud and data space. You will also be leading a team in an Agile environment team of junior to mid-level Big Data Engineers.  Requirements  Knowledge or experience with AWS (EMR, EC2, EC2, S3) Proven experience with Python and Java Experience with Scala Work with C++ is a plus Design and develop scalable code in a Big Data environment Work with Apache Hadoop Experience with Scoop, Flume, Oozie or Zookeeper Hands-on with Apache Hive and Apache Spark Benefits Full medical/health coverage  Amazing company culture! Remote flexibility when needed Why you shouldn’t miss this opportunity?  Data Science(Data Engineer),Amazon Redshift, Python, Spark",Sin experiencia,Contrato por obra,Tecnología de la información,"Servicios y tecnologías de la información, Software, Servicios financieros",5,None,False,,30,ACTIVELY_HIRING_COMPANY
371,2232746020,2020-10-23,Oxford Solutions Inc.,Senior Big Data Engineer,United States,"This is a remote job opportunity within the United States. ESSENTIAL DUTIESWriting, debugging, unit testing, and performance test code in the data access layerParticipate in code and design reviews in an Agile team environmentUtilize domain driven techniques and design patterns to build and contribute to technical design.Develop and maintain strong knowledge of implemented requirements and detailed application behaviors. REQUIREMENTSBachelor's Degree in Computer Science or related area required: Master's Degree preferred7+ years overall big data experience developing software using object-oriented or functional language experience7+ years working with open source Big Data technology stacks (Apache Nifi, Spark, Kafka, HBase, Hadoop/HDFS, Hive, Drill, Pig, etc.) or commercial open source Big Data technology stacks (Hortonworks, Cloudera, etc.)SQL experience3+ years of experience in:document databases (MongoDB, Accumulo, etc.)Agile development processescloud-based development and deliveryGit version control systemLinux operating environmentContinuous delivery technologies (Puppet, Chef, Ansible, Docker, Vagrant, etc.)Build automation and continuous integration tools (Maven, Jenkins, Bamboo, etc.)Agile process management tools (Atlassian Jira)Familiarity with test automation (Selenium, SoapUI, etc.) Remote - Senior Big Data Engineer - 21030",Intermedio,Jornada completa,Tecnología de la información,Software,31,None,True,,104,ACTIVELY_HIRING_COMPANY
372,2222518471,2020-10-21,PTC,Product Security Researcher,"Boston, MA, US","Job Description For Advertising Purposes  The responsibility of the Product Security Researcher is to lead offensive cybersecurity projects including the use of fuzzers, vulnerability research, exploit development, reverse-engineering, and red-teaming activities to ensure the security and safety of a variety of software products used in the area of industrial connectivity, Industrial IoT, and medical devices. This role requires substantial knowledge of state-of-the-art security principles, theories, and attacks, with lots of hands-on expectations.  The Product Security Researcher is the main subject matter expert for defensive cyber security techniques and best practices to ensure the security resiliency of all PTC products. The Product Security Researcher will help evangelize secure development practices.  To be successful in this role, the candidate must have a passion for security research, a minimum of 5 years of experience working as Product Security Researcher or similar role, 5-10 years of software development experience (preferably C/C++ and Java), and a formal Computer Science background. Candidates currently working as Product Security Researcher in the area of Industrial IoT, medical device software, or critical infrastructure software will be given preference.  The Product Security Researcher will report directly to the Chief Product Security Officer (CPSO).  The Product Security team is responsible for promoting, educating, and implementing product and application security throughout the development organization. As part of this architecture and research focused cross-segment team, advanced technical security skills, collaboration, and communication are key in driving security forward across multiple highly innovative and pivotal projects.  Your Day-To-Day: Research, develop and improve methods for Product threat identification, protection and correction in communication protocols used in Industrial IoT, Industrial Connectivity, and medical devices.Analyze the implementation of communication protocols used in Industrial IoT, industrial connectivity, and medical devices to identify behaviors, characteristics, risk factors, and potential threats.Stay abreast of public vulnerability reports, malware campaigns, and threat actors that may impact PTC products.Support penetration testing projects for Industrial IoT and Industrial Connectivity solutions.Conducts vulnerability research and develops impact analysis and mitigation strategy.Ability to develop proof-of-concept code to reproduce/triage security vulnerabilities.Contributes to critical product security incident response events.Provide cross-functional support to analyze and resolve key security vulnerabilities.Analyze/recommend strategy and direction to improve the security resiliency of PTC products.Maintain relationships with government, nonprofits, private sector, and research community.Participate in definition of product security standards, policy and processes.Conduct presentations in the area of cybersecurity to internal and external stakeholders.  Skills And Knowledge Deep understanding on how to protect applications against memory safety vulnerabilities.Broad computer science, systems, and networking background, including knowledge in cybersecurity, IP networking, and software development.Experience in conducting security testing for enterprise communication protocols and data exchange technologies, e.g.: OPC UA, AMQP, MQTT, Web Sockets, etc.Experience with exploit development using Python, Java and other programming languages.Experience with software vulnerability identification, exploit mitigation and binary analysis.Experience with networking communications and protocols.Experience with debuggers such as windbg, gdb, ollydbg.Experience with disassemblers such as IDA Pro or Binary Ninja.Experience in reverse engineering and reading assembly.Good understanding of cryptography primitives and cryptographic protocols.Previous experience conducting application penetration testing (Windows and Linux OS) using tools such as: Metasploit, Kali Linux, Burp Suite, etc.Knowledge of common security standards and best practices, such as NIST 800-53/800-160, ISO 270xx, CWE, CVSS, OWASP, MITRE ATT&CK , CERT Secure Coding Standards.Experience in security best practices for common authentication protocols (OpenID Connect, OAUTH, SAML, LDAP, KERBEROS, etc.).Proficiency in one or more programming languages: C/C++, JAVA, Python, etc.Good communication skills, both written and verbal.  Required Experience Minimum of 5 years software development experience, preferably C/C++, JAVA, and python.Preferred security certifications include: CSSLP, CISSP, OSCP, CEH.Good written and verbal communication skills.  Basic Qualifications Bachelor’s Degree in Computer Science or STEM related field.5 years working as Product Security Researcher or similar role.  PTC Company Description  About PTC (NASDAQ: PTC) PTC unleashes industrial innovation with award-winning, market-proven solutions that enable companies to differentiate their products and services, improve operational excellence, and increase workforce productivity. With PTC, and its partner ecosystem, manufacturers can capitalize on the promise of today’s new technology to drive digital transformation.  Why Join Us And Benefits Summary  When looking for a new job, we know you are looking for something that aligns with your values, passions, dreams, and lifestyle. Our team is passionate and committed. We are driven by innovation and value our work-life balance. Check out what it’s like to work at PTC at #lifeatPTC. We believe that diversity of experience and background leads to better ideas and a stronger company. We encourage everyone to bring their unique perspectives to our team. We take a holistic view of the employee experience and provide you with what you need to take care of your health, your wealth, your well-being, and your career. PTC benefits are among the most competitive in the industry. While your salary is the major component of your compensation, you also receive a competitive benefits package including:  Retirement Savings Plan with Company Match  Employee Stock Purchase Plan (ESPP)  Healthcare and Dental insurance  Paid Time Off and Sick Time  Birthday Day-off  Tuition Reimbursement (Canada, India, Israel, US)  Holiday Pay  Employee Referral Program  Management and Employee Training Development  Other Regional-specific Benefits All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status. Region The Americas Subregion North America PTC Org R&D - Research and Development Job Category Software Development Job Type Regular Full-Time",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Seguridad del ordenador y de las redes",2,None,False,,55,ACTIVELY_HIRING_COMPANY
373,2170080889,2020-11-02,EZ Texting,Lead Data Engineer,United States,"Who We Are:EZ Texting is the #1 text communications technology company delivering fast, easy, and effective solutions for businesses across a wide variety of industries. Dreamers first, we are at the forefront of revolutionizing the way businesses communicate with their customers and believe personal relationships can transform an organization’s ability to grow. Our employees are our greatest strength. We’re expanding quickly and scaling our teams to help accelerate growth while remaining committed to hiring exceptional, values-aligned talent. We have consistently been rated a Top 100 workplace and are committed to being a best-in-class employer for remote work — with benefits to match! We are open to hire in CA, NY, TX, OR, WA, TN, PA & GA, but welcome top applicants nationwide as we expand our operating boundaries. Role Overview: After our employees and culture, our data is our greatest asset. We extract valuable insights from our data to help our customers achieve their desired outcomes quickly and easily. Data Engineers are responsible for building the infrastructure and ELT processes to feed our data analysis needs. They work cross-functionally with stakeholders across the business to understand the questions we need to answer and the data required to support answering those questions. What You Do: Work closely with stakeholders to understand use cases and collaborate with analysts to build data models that deliver insights quickly and easily.Own the end-to-end data management and lifecycle processes.Create efficient and effective CI/CD processes that enable rapid development, deep visibility, high confidence through a multitude of tools like BigQuery and DBT.Develop core architecture of our data platform within GCP and advance data ingestion.Build data pipelines and ETL processes.  What You Bring: Expertise in SQL and at least one scripting language, preferably Python. Intuitive thinking of how to organize, normalize, and store complex data, enabling both ETL and end users.Passion for mapping and designing ingestion and transformation of data from multiple sources, creating a cohesive data asset.Expertise in cloud data warehousing tools (eg BigQuery or Snowflake) and ELT tools (eg Airflow, Google Compose, DataFlow, Fivetran, or DBT). Thrive on building modern, cloud-native data pipelines and operations, with an ELT philosophy.Excellent communication, empathetic with end users and internal customers.Focus on delivering outcomes and making an impact. What You Have:Bachelor’s degree in Computer Science, Computer Engineering or relevant field.5+ years experience in a similar role.Experience using workflow management engines (e.g. Airflow, Luigi, Prefect, Dagster, digdag.io, Google Cloud Composer, AWS Step Functions, Azure Data Factory, UC4, Control-M).Strong knowledge of data technologies and data modeling.Deep understanding of analytical data warehouses, like BigQuery and/or Snowflake.Hands-on experience implementing ETL (or ELT) best practices at scale.Hands-on experience with the following tools or technologies: BigQuery, Airflow, DBT.Experience publishing/consuming data to/from SaaS application APIs.Strong desire to collaborate asynchronously, with a focus on robust documentation.Process oriented approach, driven to iterate on existing processes or create new ones.Passion for stable and secure systems management practices.Ability to orchestrate and automate complex tasks.Proactive, grab-a-shovel and go-for-it attitude.Outstanding problem solving skills. Nice-to-have:Experience with Agile methodologies and DevOps principles.Experience with Terraform, Ansible, Java, Python and data modeling tools. What We Provide:Benefits available to EZ Texting team members include, but are not limited to:100% paid medical, vision, dental and life insurance for self (generous coverage for families)Stock options401(k) planPaid vacation and unlimited sick leavePaid parental leaveAnnual personalized learning reimbursementQuarterly wellness reimbursementRemote-work optimization benefits including:Monthly internet reimbursementMonthly flexible remote work stipend, including DoorDash subscriptionAnnual home office enhancement stipendDirect-billing ordering for supplies  ﻿EZ Texting is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.",Intermedio,Jornada completa,Tecnología de la información,Telecomunicaciones,96,None,True,,462,ACTIVELY_HIRING_COMPANY
374,2218845351,2020-10-28,phase2,Head of Data Engineering,Switzerland,"phase2 are supporting an early-stage data analytics startup leveraging artificial intelligence to redefine drug commercialisation in their search for their first Head of Data. The company alleviates hurdles faced by medical affairs and product launch teams through their journey from drug approval to commercialisation and is already being utilised by three of the world's largest pharmaceutical manufacturers. You will play a significant role growing an innovative data product utilising real-world text data at tera/peta bytes of scale. You will build, lead and mentor onsite and remote teams of data scientists and software engineers and collaborate closely with the CEO, CTO and COO to shape the planning and execution of all aspects of the product road map. Responsibilities will include:Partnering with the CTO and the engineering team to architect a scalable a data-oriented product Serving as the key source of knowledge of relevant applications, tools and large volume data solutions.Overseeing the full data cycle from collection, storage, management, analysis, ensuring quality to protection of data.Determining where cost efficiencies can be found and how to increase revenue based on insights derived from data. Your profileYou are an experienced Data Engineer or Data Scientist with prior leadership experience and you are able to effectively lead an interdisciplinary, distributed team. You possess excellent English communication skills and can leverage these skills to guide your team on complex technical solutions and results. You have completed a PhD/MSc in Computer Science or similar You're experienced leading teams of software engineers and/or data scientistsYou possess excellent project management skillsYou are an entrepreneurial thinker and are able to evaluate costs/benefits of solution alternatives both from technical and business perspectivesYou are curious and seek continuous improvementIdeally you will be experienced working on NLP challenges",Director,Jornada completa,"Tecnología de la información, Ingeniería","Software, Servicios y tecnologías de la información, Industria farmacéutica",105,None,True,,536,JOB_SEEKER_QUALIFIED
375,2198731658,2020-10-21,"Delphi-US, LLC",Business Intelligence Manager,"Manhattan, New York, United States","Open to 100% remote for right candidate. Must work East Coast hours. Us Citizens/ Greencards only, or no sponsorshp visas. Our client has an immediate requirement for a Business Intelligence Manager to support their team. This role supports data driven impacts working across multiple sects of our clients business. The selected candidate will work with traffic, subscriptions, advertising, and email data and have the opportunity to work in Python, R, Alteryx, Big Query SQL, Looker, PowerBI and more!  RoleClean, prepare and explain datasets, use advanced analytics to identify key trends, size up opportunities, and then work closely with business leaders to turn those opportunities into action.Work with the latest analytic tools to perform advanced analysis and discover insights.Create iterative and highly reproducible Python/R scripts to show ongoing improvement in data visuals and analytical techniques.   Partner closely with data scientist to extract learnings from latest prediction models.Potentially program manage key cross-functional data-science projects. Qualifications5+ years’ experience in a data analytics/data science role.Demonstrated comfort working autonomously in Python/R, particularly working with dataframes. Advanced SQL knowledgeDegree/Advanced degree in a technical/mathematical program preferred.Strong interpersonal and communication skills, experience building presentations. Passion for solving business problems via data insights.",Intermedio,Contrato por obra,Desarrollo empresarial,Servicios y tecnologías de la información,141,None,True,,461,ACTIVELY_HIRING_COMPANY
376,2226300022,2020-11-03,Meet,Senior Clinical Research Scientist,New York City Metropolitan Area,"An exciting opportunity has just emerged with a cutting-edge biotech focused on the development of innovative, novel therapies within Oncology and Hematology. My client is searching for an Associate Director/Senior Clinical Scientist to join their team!  The AD/Senior Clinical Scientist will work closely with medical directors, clinical operations, and the study teams to support the clinical development activities. This position will have the responsibility of contributing to the study team in clinical trial design, implementation, and execution of clinical trials! Responsibilities:·       Creating and authoring clinical sections of clinical study reports, protocols, regulatory agency reports, other regulatory documents.·       Monitoring of study execution and development planning for compounds assigned·       Preparation of clinical study report and protocol documents as well as other key documents (Investigator Brochures, internal or external presentations, regulatory submissions, SOP’s etc.)·       Interaction with internal and external stakeholders to support clinical trial objective including interaction with vendors, study sites, committees, and investigator meetings. Qualifications:·       Education requirement of RN, MS, PhD or PharmD, or equivalent. Advanced degree candidates preferred.·       5+ years in clinical research or drug development within oncology and hematology. ·       Experience in working in the pharmaceutical, biotech, or CRO industry. ·       A successful track record and understanding of the clinical research process from beginning to end of the product lifecycle. Contact Details:Full job description and company details are available upon application. This position is being dealt with by Kaitlyn Sumner at Meet. You can connect wither her directly at kaitlyn@peoplewithchemistry.com to discuss further and in confidence. You can find out more about Kaitlyn & Meet at www.peoplewithchemsitry.com",Director,Jornada completa,"Ciencias, Investigación","Industria farmacéutica, Biotecnología",36,None,True,kaitlyn@peoplewithchemistry.com,173,ACTIVELY_HIRING_COMPANY
377,2203212524,2020-10-13,National Collateral Management Services Limited,Data Scientist,"Gurgaon Sub-District, Haryana, India","The ideal candidate's favorite words are learning, data, scale, and agility. You will leverage your strong collaboration skills and ability to extract valuable insights from highly complex data sets to ask the right questions and find the right answers. Designation : Data Scientist Salary Grade : Assistant Manager/Deputy ManagerQualification: Postgraduate in Statistics/ Mathematics/ Applied Mathematics (Must be from a reputed Institution)Experience: Min 4 years (in Data modelling, analytics, and research) Deep understanding of predictive modeling, machine-learning, clustering and classification techniques, and algorithmsTechnical & soft skills: Evidence of expertise in data science, Sound Knowledge of econometric modelling with time series data, Proficiency and hands-on experience in statistical packages like R/Python, Advance level expertise in Microsoft suite (Excel with VBA, word, power-point, etc.), Expertise in optimization and scientific analysis of large data sets, Ability to communicate scientific results effectively, Strong Analytical skills, Attitude to learn, Team player, Manage time and work with strict deadlinesFamiliarity with Big Data frameworks and visualization tools (Cassandra, Hadoop, Spark, Tableau)ResponsibilitiesWill be handling Econometric/Mathematical modelling for agricultural production and its impact on commodity prices based on fundamental factors like weather, historical data, etc.a. Analyzing and quantifying productivity and production based on weather data and Agri-infrastructure (supervised & unsupervised statistical models, pattern recognition, correlation, seasonality analysis of time series data)b. Quantification of impact of identified production factors on pricec. Collecting and maintaining data related to all variables including weather parametersd. Analyzing historical price trends and arriving at fundamental factors influencing various commodity pricese. Developing dynamic econometric /mathematical models for price forecasting. (Multiple regression, time series analysis)f. Developing Price risk assessment models for commoditiesg. Developing market integration modelsh. Supporting research team with production and price estimatesLocation : Gurgaon",Sin experiencia,Jornada completa,"Ingeniería, Investigación, Tecnología de la información","Agricultura, Investigación de mercado, Investigación",1374,None,True,,3716,ACTIVELY_HIRING_COMPANY
378,2239746624,2020-11-03,Glocomms,Senior Data Engineer,"Menlo Park, California, United States","Senior Data EngineerSeries D Machine Learning Platform Tech A tech company based in Menlo Park, CA, their machine learning platform manages over 500,000 data sets per second. With a data science team that has doubled in size, the VP of Data Science is now looking towards expanding the data engineering team as well to create pipelines and infrastructure that can deploy machine learning models into production.  What you’ll do: Develop data infrastructure to ingest, sanitize and normalize a broad range of dataBuild infrastructure to help scale up, large-scale cloud-based machine learningDesign and develop streaming and IoT data pipelinesWhat we want from you: Experience building data pipelines from disparate sourcesHands-on experience building up working with python for automation and application developmentHands-on data modeling and data warehousingQualifications:Computer Science degree or related degree including Electrical and Computer EngineeringMinimum of 3 years’ experience",Intermedio,Jornada completa,Ingeniería,Software,56,None,True,,156,ACTIVELY_HIRING_COMPANY
379,2218908745,2020-10-23,BankMobile,Senior DevOps Data Engineer,Greater Philadelphia,"Position AccountabilityDesign, build, operate, and monitor our cloud data pipeline assets using the latest tools and techniques to enable rapid evaluation, deployment, and tuning of schema and data changes. Ensure the data pipeline infrastructure meets non-functional requirements such as scalability, performance, and reliability through effective architecture design and directing performance engineering efforts. Oversee cloud based relational databases and non-relational, time series data collections. Contribute to cross-team efforts requiring compiling data from telemetry, application logging, and application data to identify and investigate anomalous activity. This is a key role on the DevOps team that serves to connect our innovative digital banking product to the distinct business units with reliable, high-quality, insightful data. Expected Outcomes·       Cloud data pipelines are developed and supported in an efficient fashion to ensure large, complex data sets are effectively maintained and continuously augmented·       Manual processes around data delivery are identified so that automation can be designed and implemented for greater scalability and organizational efficiency·       Infrastructure is configured for optimal extraction, transform and loading of data from a wide variety of external sources·       Cloud-based analytics tools will make extensive use of our highly reliable data infrastructure to provide actionable insights into customer acquisition, product performance, fraud detection and other key business performance metrics·       Knowledge sharing is performed across all technology teams to increase business alignment, quality and efficiency·       Partners are satisfied with our level of professionalism and technical expertise·       Identify and deliver improvements to the SDLC in general - and the operations experience in particular - to ensure that the status quo is safe, high-quality, rapid releases.·       Document your work so that others can understand it. Position Responsibilities·       This is a hands-on systems engineering role that focuses on building and deploying data pipelines within our Azure environment with the express purpose of organizing our complex data effectively while ensuring data integrity and security·       Partner with the Data Architect to meet the functional needs of business operations, business product management, and disparate technical teams by delivering best-in-class data solutions·       Prepare, package, coordinate and implement production releases and fixes.·       Expert in Troubleshooting, Optimization and Performance tuning of SQL Server database server (Ex., Query Tuning, Server Tuning, Disk Performance Monitoring, Memory Pressure, CPU bottleneck etc.)·       DDL/DML expertise, Optimizing and Performance Tuning using execution plans, Profiler and Database Tuning adviser. ·       Troubleshoot application database connectivity, Azure SQL issues, query performance, disaster recovery and other issues in production and development.·       Experience in implementing High Availability & Disaster Recovery solutions using Always ON, Clustering, Replication, Mirroring and Log Shipping.·       Collaborate with business units to help define our data analytics strategy with the goal of building and driving adoption of a new unified business intelligence platform·       Continuously monitor our business for new opportunities to automate inefficient internal processes around data acquisition and availability·       Identify, assess, track and mitigate issues and risks at multiple levels within the organization·       Expert in Cloud-native computing (IaaS, PaaS, FaaS).·       Expert in DevOps practices and modern CI/CD tools and deployment models.·       Experience with Azure, or related cloud provider.·       Experience with SQL Server.·       Experience with PowerShell.·       Experience with C#/.NET.·       Experience operating Multi-Tenant SaaS systems. Experience Required·       Must have 5+ years of experience building and optimizing data pipelines, architectures and data sets within a cloud computing environment·       Technical experience with the following: MSSQL Server, Azure SQL, Microsoft Azure, Azure DevOps, Production Principal duties·       Cloud experience: Microsoft Azure Cloud, Azure SQL Database including installation, configuration, backup/restore, security, AD groups, managing resource groups, storage blobs.·       Must have advanced working SQL knowledge and experience working with both relational databases in a query authoring capacity as well as big data technologies such as No SQL and unstructured data store·       Must have expertise in DataOps techniques and modern cloud computing technologies, most importantly deep familiarity with the Azure stack·       Previous work experience partnering with data analytics teams to increase the effectiveness of internal business intelligence systems preferred·       Strong attention to detail including precise and effective customer communications and proven ability to manage multiple, competing priorities simultaneously·       Superior verbal and written communications skills and history of excellent team collaboration·       Provided 24x7 production support for SQL Server databases on standalone and Clustered Servers with sizes ranging from 100s of GB to 20+ TB to achieve maximum performance and uptime in production environment.·       Experience working as an Azure DevOps Automation Engineer for database deployment·       Establish best practices for databases, and ARM templates implemented for other environments.·       Create linked ARM templates and integrate with the Azure DevOps pipeline Hands-on, on the ground database guru who does the actual work Tech advisor and site engineer and point person for anything database.·       B.S. in Computer Science, Statistics, Informatics, Information Systems or other quantitative field preferred Experience with the following is a PLUS:Automation experience, ideation, creation, and execution of database automation – Terraform & Ansible.Experience in Installation, Configuration, Maintenance and Administration of Azure Data Explorer (ADX)Production support in a financial service setting.Front-line leader that can act as a player/coach that can provide lift to the engineering organization. About BankMobile:Established in 2015, BankMobile is a division of Customers Bank and America’s largest and fastest growing mobile-first bank offering checking and savings accounts. BankMobile provides an alternative banking experience to the traditional model and is focused on technology, innovation, easy-to-use products and education with the mission of being “customer-obsessed” and creating “customers for life.” The disruptive, multi-partner distribution model, known as “Bank-as-a-Service,” created by the executive team enables BankMobile to acquire customers at higher volumes and substantially lower expense than traditional banks. Its low-cost operating model enables it to provide low-cost banking services to low/middle-income Americans who have been left behind by the high-fee model of “traditional” banks. Today, BankMobile provides its “Bank-as-a-Service” platform to colleges and universities and currently serves nearly two million account-holders at 800 campuses (covering one out of every three students in the U.S.). BankMobile is operating as the digital banking division of Customers Bank, which is a Federal Reserve-regulated and FDIC-insured commercial bank. For more information, please visit www.bankmobile.com. BankMobile, a division of Customers Bank, will provide consideration for employment to qualified applicants without regard to their race, color, religion, national origin, sex, protected veteran status or disability. BankMobile, a division of Customers Bank. Member FDIC - Equal Housing Lender - All Rights Reserved",Intermedio,Jornada completa,Tecnología de la información,Servicios financieros,59,None,True,,238,ACTIVELY_HIRING_COMPANY
380,2211199703,2020-10-26,Ascent Global Security,Senior Cloud Security Researcher (REMOTE),United States,"We are seeking a Senior Cloud Security Researcher to join our world-renowned cyber security client. This is a home based, remote position. As a Senior Security Researcher, you will conduct advanced open security research in cloud environments, recreate data attacks and present your findings to ensure my client stays ahead of the competition. You will have the opportunity to work for a forward-thinking organisation, partnering with the top echelons of cyber security talent and will be exposed to a variety of innovative technologies and projects. You can expect unrivalled technical and career progression, along with the opportunity to conduct research and present at global conferences. What will help you:5+ years direct experience in areas of security research, cloud security architecture, malware analysisDeep understanding of cloud systems and security concepts5+ years of offensive pen testing experience OR 5+ years of IR and threat analysis experienceKnowledge of exploitation techniquesProficiency with reverse engineering tools The successful candidate will be offered an exceptional, premium salary and benefits package, including significant stock options. My client is interviewing immediately and looking to fill this position ASAP",Intermedio,Jornada completa,Tecnología de la información,Servicios y tecnologías de la información,28,None,True,,121,JOB_SEEKER_QUALIFIED
381,2278032228,2020-11-05,TRANSFORMIFY,Machine Learning Engineer,United Kingdom,"Quick Summary:Become a part of a revolutionary HRTech company that positively impacts the lives of people across the globe - we operate in more than 150 countries!We are dedicated to transforming the way businesses hire, manage and pay their external workforce of freelancers, consultants and independent contractors championing the use of AI and machine learning.You’ll be working alongside a small but passionate group of talented engineers, researchers, designers and business analystsYou'll get 22 days holidays, a pension and stock options after the first year. More about us:We are one of the fastest-growing, HRTech companies the UK, consistently being nominated and winning awards for our innovation in the industry, and a member of the Digital Skills * Jobs Coalition of the European Commission! Our goal is to provide solutions for our customers that are affordable, accessible and easy to use.Our Freelancer Management System is revolutionising the way businesses hire, manage and pay their external workforce from a single dashboard.Thanks to recently received Innovate UK Grant, we are seeking to expand our dynamic, proactive workforce with a similarly-minded mission-driven Machine Learning Engineer who is keen to challenge the status quo and make a differenceWe are an all-remote company and our vibrant, multicultural team is scattered across the globe.You will be paid a competitive salary, 22 days holiday allowance, stock options after the first year and pensionThis position is likely to remain fully remote. You can be based anywhere EU-WIDE and travel (expensed by us) to occasional team meet-ups.To join us, you need to be a UK citizen or have settled or pre-settled status in the UK. The Machine Learning Engineer (HRTech, Fintech) Role:As the Machine Learning Engineer you will be playing a pivotal mission-critical role, liaising with product managers and management in creating data models as well as designing, specifying and implementing algorithms based on models either defined by or in conjunction with the product and engineering team.You’ll write testable, complete and efficient codePlan and execute SDLCDesign, spec and implement AI/ML prototypes (including very early ones), microservices and systems/platforms in a similar wayDocument and maintain system functionality A bit about you:You must have demonstrable experience as a Software Engineer, preferably with an emphasis on Machine LearningExperience with PHP and SymfonyExperience with web technologies and developing for the web browserDesired but not essential- proven ability to write front-end code using libraries like React, Angular, Vue, Backbone.js, etc.Desired but not essential - experience with HrTech or FinTech company. You’ll be coming in as the first Machine Learning Engineer with a huge amount of opportunity to make a big impact from day one in a fast-paced environment.  Location: LondonDuration: PermanentSalary: up to £75,000 (there may be some movement for the right candidate) + package including Stock options after the first year Seniority LevelMid-Senior levelIndustryInformation Technology & ServicesEmployment TypeFull-timeJob FunctionsInformation TechnologyBase pay range£60,000/yr - £75,000/yr",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información",Recursos humanos,2,None,False,,27,JOB_SEEKER_QUALIFIED
382,2192284982,2020-10-19,Interos Inc,"Senior Data Engineer, Kafka",United States,"Interos, founded by Jennifer Bisceglie, is one of the most transformative technologically advanced platforms that powers the global economy supply chain. By using ML and big data, Interos aspires to dynamically and continuously map all of a company’s business relationships to multiple tiers of dependency on a global scale and endeavors to help customers understand risk in their multi-tier, global supply chains. The scope of this value proposition extends across a variety of different technology sectors including risk management, supply chain intelligence, financial intelligence and cyber-security. Interos has raised $26M in total funding from Venrock, led by Nick Beim, and Kleiner Perkins, led by Ted Schlein. We have 70+ employees and are poised to double in size by end of 2020. Our offices are headquartered in Arlington, VA and we have presence in Menlo Park, CA.We need an extraordinary team member who thrives as part of a fast-paced team and takes pride in their ability to succeed while delivering value to our customers. Be challenged by innovation and grow professionally by solving one of the most interesting challenges impacting businesses across the globe.  The Opportunity:Looking for expert technical leadership to help us design, build, and iterate our next generation platform. As someone who has successfully implemented a significant Kafka based machine learning or data analytics pipeline you can help us make the right choices and avoid mistakes as we build a scalable, reliable, and fully automated supply chain risk management system for our exponentially growing customer base. You will be working with a collaborative team of highly skilled and constantly learning software engineers and data scientists who value good ideas and the ability to create quality solutions.Essential Functions/duties:Lead Kafka topic topology designOwn Kafka message schema evolutionWrite Kafka producers and consumers in PythonGuide data and machine learning engineers on best practices regarding KafkaDesign and build near real-time data analytics pipelinesPitch in wherever needed to meet team goals and deliver a quality productMinimum Qualifications:Strong Python coding skillsReal world experience with production Kafka event streaming pipelineExperience with Kafka topic topology designExperience with Kafka streamsAbility to communicate clearly and willingness to share knowledge and collaborateMinimum years of relevant experience: 5+ years software engineering experienceMinimum education level: Bachelor’s Degree, Computer Science or related field or equivalentPreferred Qualifications:Comfortable working with Docker and KubernetesExperience with cloud services in general and AWS in particular BENEFITSComprehensive Health & Wellness package (Medical, Dental and Vision)10 Paid Holiday Days OffAccrued Paid Time Off (PTO)401(k) Employer MatchingStock OptionsCareer advancement opportunitiesCasual DressOn-site gym and dedicated Peloton room at headquartersCompany Events (Sports Games, Fitness Competitions, Birthday Celebrations, Contests, Happy Hours)Annual company partyEmployee Referral Program Interos is proud to be an Equal Opportunity Employer and will consider all qualified applicants without regard to race, color, age, religion, sex, sexual orientation, gender identity, genetic information, national origin, disability, protected veteran status or any other classification protected by law.If you are a candidate in need of assistance or an accommodation in the application process, please contact HR@interos.ai",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Software,7,None,False,HR@interos.ai,65,ACTIVELY_HIRING_COMPANY
383,2213085427,2020-10-27,"AvidXchange, Inc.",Senior UX Researcher,"North Carolina, United States","About AvidXchange AvidXchange is the industry leader in automating invoice and payment processes for mid-market businesses. Founded in the year 2000, AvidXchange processes over $140 billion transactions annually across its network of more than 600,000 suppliers, transforming the way 6,000 customers in North America pay their bills. AvidXchange is distinguished as a global fintech unicorn and one of the fastest growing technology companies in the U.S. with 1,400 employees supporting customers across seven office locations. Our employees live by our core values, including “Innovate to Change the Game”, “Passion about Customer Success”, “Win as a Team”, “Play to our Strengths”, and “Have a Blast”. We are on a mission to create something different at AvidXchange. Come join the team!            Job OverviewAs a Senior User Experience (UX) Researcher at AvidXchange, you will establish the methodology and set the tactical direction for all usability testing and research associated with assigned projects. This includes partnering closely with designers, product teammates, content writers and developers to deliver quality and timely research results and information to project teams in support of the design process. This role also manages the recruitment of research participants as well as key relationships with research vendors. This role works cross-functionally, fostering relationships with key partners at all levels across the enterprise. Job Responsibilities •      User Research – Lead, manage recruitment of users, and conduct various feedback sessions with customers. Plan, create, execute and analyze user research to fit into a UCD process. •      Evangelize the importance of bringing end users into the process early on, by way of observation, interviews, lo-fi or hi-fi testing.•      Create well-written deliverables that provide succinct, well-analyzed and actionable insights while articulating the findings through summary reports to convey iterative changes required to the user experience that benefit the end user.•      Utilize and facilitate remote moderated and unmoderated usability test platforms (usertesting.com, or similar) to rapidly turn around concurrent tests.•      Ability to conduct research and usability testing and synthesize those findings into actionable insights. Understand the specific pain points that the user faces at any time in their journey and work towards improving it with product teammates through requirements gatherings and prioritization of features based on research findings.•      Analyze and determine the appropriate research methodology and develop research/test plans to achieve stakeholder goals.•      Employ a variety of test methodologies such as Standard Usability Testing, Comparative Testing, Contextual Inquiry, Rapid Iterative Testing, Prototype Testing, Concept Validation, Card-Sorting, Benchmarking.•      Lead and Conduct research across multiple platforms, and cross-channel: desktop, tablet, mobile and native apps. Well versed in contextual inquiry research, such as diary studies and others to understand different user journeys through different products.•      Maintain cultural awareness of the design landscape and future trends. Proactively consume relevant content on them practice and processes of UX design.•      Look at the big picture, from UI to internal processes to user messaging.•      Create, improve and maintain complex user interface prototypes as required per project and product while contributing to promote and leverage our design system from a user research perspective.•      Complete user flows, process diagrams, company and user personas as required in the Discovery phase of each project.•      Mentor junior User Experience Researchers on the team. Educate the design team, product team, engineering team members and stakeholders on the benefits of user research and prototyping before implementation of a user experience design.  Required Education, Skills, and Qualification •      Minimum of 5-10 years of User Experience Research experience is required•      BS or MS in Interaction Design, Cognitive Sciences, HCI, or equivalent experience•      Portfolio of user interfaces or software UX design examples. User flows, research summaries, personas or process examples a must•      Demonstrable experience with a broad array of user research methodologies.•      A solid grasp of UCD, planning and conducting user research, interviews, surveys, A/B testing, user flows, personas, rapid prototyping, competitive analysis, heuristic evaluations, usability and accessibility concerns. Preferred Education, Skills, and Qualification Responsive design and mobile considerations.Experience in Axure, Sketch, Adobe software, InVision, UserTesting.com or equivalent experience.Great cross-functional collaborator!  Must be able to work with Designers, Developers, Writers, Customer Support, Researchers, Product Managers, and Product Marketers &Quality Assurance.Clear and effective verbal and written communication skills, problem-solving aptitude and demonstrates group presentation skillsAcute attention to detailBig picture thinking, with the ability to “get in the weeds”Strategic, analytical, and innovative thinking to address all aspects of custom software UX designAdaptable to competing demands and personally accountable.Passionate about representing the human perspective in design and have skills in bringing this passion to life for the teamSharp, analytical mind, creativity and the ability to work on multifunctional teams across the enterprise. Must be able to work with Designers, Developers, Writers, Customer Support, Researchers, Product Managers, and Product Marketers, Quality Assurance.Deliverables include research findings, personas, journey maps, workflows, and wireframes that communicate the UX strategy and findings and the reasoning behind it.Extensive experience in using UCD and UX design best practices to design solutions, and a deep understanding of mobile first and responsive design.Gain a deep understanding of business operations & industry practices to successfully aid in strategy, design, decision making and recommendations.Strong work ethic, clear and effective verbal and written communication skills.Aid and lead the UX team in the creation of UX research standards alongside UX management.Strong organizational and time management skills.Strategist at heart.A passion for solving problems and simplifying complex processes.",Intermedio,Jornada completa,Otro,Software,52,None,True,,203,ACTIVELY_HIRING_COMPANY
384,2242265172,2020-10-26,"Techaxis, Inc",Senior Data Scientist,United States,"Job Role:Data Scientist with Python Programming Skills who can develop insights from organizational data to drive supply chain performance. Requirements:    Must Haves:Hands on skills on Python and R programming languages to develop AI/ML based solutions to drive predictive models.Prior experience in working on Analytics tools like Power BI, Tableau etc. and have good skills in developing Analytics dashboard.Prior experience in Advanced Analytics strategy and end-to-end solution delivery using data science and analytics techniques on cloud computing platforms     Responsibilities:   Work closely with Customer Business SMEs for developing insights from Data using data scienceConceptualize, design, build and implement advanced analytics solutions in using AI/ML and data science techniquesWork closely with Customers for developing project plans and ensuring delivery consistent with the project estimates provided. Qualifications:    Bachelor's Degree or above   About Us: Techaxis is a US based firm which specializes in discovering, engaging and placing top talent globally, for full time or contract positions in leadership and mid to senior level positions for companies in the technology, healthcare, energy and education space.  Equal Opportunities Employers: Our clients provide equal opportunities to all its employees and all qualified applicants for employment, without regard to their race, caste, religion, colour, ancestry, marital status, sex, age, nationality, disability, and veteran status. Employees of our clients are treated with dignity and in accordance with their policy to maintain a work environment free of sexual harassment, whether physical, verbal, or psychological. Employee policies and practices are administered in a manner that would ensure that in all matters equal opportunity is provided to those eligible and the decisions are merit-based.",Intermedio,Jornada completa,"Tecnología de la información, Consultoría","Dotación y selección de personal, Servicios y tecnologías de la información",109,None,True,,324,ACTIVELY_HIRING_COMPANY
385,2184096851,2020-10-15,IMG systems,Big Data Engineer,"San Jose, California, United States","Position: Sr BigData EngineerLocation: Costa Mesa, CA // San Jose, CA Duration: 12+ Months Looking For Seniors. 10 + Years of experience. Requirements BS degree in computer science, computer engineering or equivalentProficient in Java, Spark, Kafka, Python, AWS Cloud technologiesMust have active current experience with Scala, Java, Python, Oracle, Cassandra, Hbase, Hive3+ years of experience across multiple Hadoop / Spark technologies such as Hadoop, MapReduce, HDFS, Cassandra, HBase, Hive, Flume, Sqoop, Spark, Kafka, Scala Familiarity with AWS scripting and automation Flair for data, schema, data model, how to bring efficiency in big data related life cycleMust be able to quickly understand technical and business requirements and can translate them into technical implementationsExperience with Agile Development methodologiesExperience with data ingestion and transformationSolid understanding of secure application development methodologies Experienced in developing microservices using spring framework is a plusUnderstanding of automated QA needs related to Big dataStrong object-oriented design and analysis skillsExcellent written and verbal communication skills Responsibilities Utilize your software engineering skills including Java, Spark, Python, Scala to Analyze disparate, complex systems and collaboratively design new products and servicesIntegrate new data sources and toolsImplement scalable and reliable distributed data replication strategiesAbility to mentor and provide direction in architecture and design to onsite/offshore developersCollaborate with other teams to design and develop and deploy data tools that support both operations and product use casesPerform analysis of large data sets using components from the Hadoop ecosystemOwn product features from the development, testing through to production deploymentEvaluate big data technologies and prototype solutions to improve our data processing architecture Automate everything",Intermedio,Contrato por obra,"Ingeniería, Tecnología de la información",Servicios y tecnologías de la información,75,None,True,,242,None
386,2257739193,2020-10-30,Sogeti,Data Engineer (tecnología Microsoft) - Python,Barcelona y alrededores,"Te gustaría pertenecer a una empresa comprometida con sus empleados y certificada con el sello Top Employer 2020 en España. En la actualidad queremos incorporar al equipo de Soluciones Microsoft a un/a Data Engineer, para un proyecto internacional, con un gran cliente del sector alimentación con sede principal en Dinamarca. El puesto por el momento es en remoto. Nuestras oficinas centrales están ubicadas en Barcelona ciudad (22@), donde tendrás la posibilidad de seguir desarrollando tu carrera profesional, contando con el apoyo de expertos en el área y excelente ambiente laboral! Es un proyecto end to end de configuración de un equipo de Devops para desarrollar y operar una plataforma de Big Data transversal a los diferentes departamentos y roles de la organización, para poder monitorizar y analizar un conjunto de datos de forma integral y fiable para toma de decisiones comerciales y operativas. Se trata de información de sus ventas a nivel europeo y campañas de marketing. El proyecto cubre todo el ciclo de vida del dato, desde la extracción del mismo a partir de diferentes fuentes mediante web scrapping, apuntando bases de datos estructurados y no etsructurados, hasta la distribución de informes de Power BI a los usuarios. Transformando, tratando y alojando los datos orientado al Data Warehousing. Volumen de datos ingestados: 12 Tera/año. Tecnologia utilizada en el proyecto: Phyton, Data Factory, Microsoft Azure SQL Database, Microsoft Azure DataLake, Microsoft Azure Storage (blob, table y Queue), Microsoft Azure Key Vault, Power BI (Premium), Analysis Services (SAS), Logic Apps, Dexio.io, MS Azure DevOps, MS Azure batch. No es un requisito indispensable aportar conocimiento las herramientas del Cloud Azure. ¿Que ofrecemos?- Remuneración competitiva según experiencia y valía.- Certificaciones oficiales de Microsoft a cargo de la compañía.- Tarjeta restaurante.- Flexibilidad horaria y teletrabajo (*según proyecto).- Tickets guardería.- 24 días de vacaciones laborables anuales más 2 días de asuntos propios.- 50% descuento en el seguro médico.- Plan de formación personalizado con cursos técnicos presenciales y e-learning además de programa de certificaciones a cargo de la empresa.- Curso de inglés online gratuito.- Seguro de vida y accidentes.- Buen ambiente de trabajo con la posibilidad de participar en actividades de Team building e iniciativas internas.- Desarrollar una carrera profesional en una multinacional líder en el sector de las nuevas tecnologías. Si estás buscando un entorno dinámico, multinacional, con grandes oportunidades de desarrollo y donde valores como la pasión por la tecnología, la innovación o el espíritu de equipo son parte de nuestro ADN, esta es tu oportunidad.",Algo de responsabilidad,Jornada completa,Tecnología de la información,Servicios y tecnologías de la información,102,None,True,,321,ACTIVELY_HIRING_COMPANY
387,2227382317,2020-10-30,PARKSIDE RECRUITMENT LIMITED,Data Engineer/Scientist(PHD),"London, England, United Kingdom","Our client at the heart of powering organisations with their enhanced Artificial Intelligence and as they enter into a new dimension of client development they are looking for the next generation of AI Data-Engineering and Science Researchers.analytically focused. Lead / play a key role in one or more of the followingDesign and implement sophisticated AI productsDesign and build AI related Engineering IPBuild end to end multi-component analytics solutions on premise or on cloud, including robust data pipelinesScale up AI algorithms/models to production / big data scaleEngineering component of critical AI projectsTypical background:MUST BE A PHD Student or qualified in Computer Science/Engineering/Software Engineering, Complex coding:Highly passionate about creating, building unique / out of the box toolsHands on expert /lead programmer, incl. experience in handling data in SQL or Spark (mandatory)Strong Technical architecture design and build skillsExperienced in building end to end solutions on premise or on cloudStrong knowledge of at least one of the cloud families from among - Azure, Google or AWSAbility to scale up algorithms to production / big data scale",No corresponde,Jornada completa,"Ingeniería, Investigación","Investigación, Servicios y tecnologías de la información",45,None,True,,169,ACTIVELY_HIRING_COMPANY
388,2215550439,2020-11-04,Cedrus Digital,Solutions Architect -Cloud,United States,"As a Lead, Data Scientist, you will…Extracts data from various data sources and performs exploratory data analysis, cleanses, wrangles, and transforms dataEmploys scaling & automation to data preparation techniquesIntroduces incremental improvements to data analysis, visualization, and presentation techniques to communicate discoveriesResearches relevant emerging empirical methods and quantitative toolsLeads innovative packaging and presentation of insights to business and broader analytics communityDevelops processes to automate and scale insights operationalizationLead a team of software engineers and application developers to develop automation solution for customers leveraging AI and Robotic Software We’d love to hear from people with:Expertise in several Modeling & Machine Learning Techniques (regression, tree models, survival analysis, cluster analysis, forecasting, anomaly detection, association rules, etc.)Expertise in several Data ETL (Teradata, Oracle, SQL, Python, Java, Ruby, Pig)Expertise in several Analytic Languages (R, SAS, SPSS, Stata)3 + years of experience in this disciplineTechnical LeadershipArchitectureSystem IntegrationStrong Inter-personal skills, Excellent Communication Skills, Great Leardership Skills",Intermedio,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software",119,None,True,,372,ACTIVELY_HIRING_COMPANY
389,2290358480,2020-10-14,Prima Assicurazioni,Big Data Engineer (Full Remote possibility),"Milano, IT","Description  We are looking for an experienced Big Data Engineer to join the IT department for the development and the maintance of every Prima system  Chi cerchiamo  You are our ideal candidate if you meet these requirements:  you developed and directly implemented data bases from tons of TB  the ETL pipelines are you bread and butter, the Data governance is your mantra  you are passionate about programming (better if functional), you care about code strength, cleanliness and testability  you have deep expertise on AWS Redshift/Athena, PostgreSQL, MySQL or similar products  you have an excellent knowledge of coding and data streaming systems, such as RabbitMQ, AWS SQS, Kafka, AWS Kinesis/Firehose or similar products  you have a good knowledge of workflow Management Systems, such as Luigi or Apache Airflow  you are not fossilized on a specific technology, because you are eager to experience and choose the 'right tool for the job'  you have a good knowledge of Git  Sarebbe fantastico se  In addition to the basic requirements, we will carefully evaluate these characteristics:  knowledge of more than one programming language (Python, Rust, Elixir, Scala, Go and so on)  knowledge of API REST and GraphQL  knowldege of AWS and Docker  knowledge of BI systems (such as Tableau, AWS Qucisight)  knowledge of distributive systems (CAP Theorem, Distributed Transactions and so on)  previous experience in an agile workplace using DevOps practices  excellent command of the english language  Come puoi aiutarci  The Speed and dynamism of our industry require us to make continuous and real time decisions, such as the price definition of an insurance cover or the fraud control of a claim reported. Almost all these decistions are automatically made by dynamic systems and AI engines that estimate the probability of future events and define the best possible actions for Prima and its costumers. These models, to be effective, need a large amount of high quality and high accessibility data.  Your goal will be to ensure the best performances made possibile by our technology, constantly evolving our platform of data warehousing and the ETL pipelines that feed it.  Specifically, You Will Take Care Of  design, development and implementation of the expansion of the data warehouse platform with a multi-country and multi-product perspective, focusing on its scalability and reliability  design of new ETL processes and refactoring of existing ones in order to improve their scalability and reliability  you will work close with the IT Team and also to Analytics, Pricing, Marketing and Finance Team, cooperating to the definition of the techincal specs and technical choices.  In order to continue our growth in a sustainable way we need to evolve our data warehouse platform in view of multi-country and multi-product, so as to support Analytics, Pricing, Marketing and Finance Team that base their work on manyTB of data we collected, our most valuable asset, the engine and the beating heart of our company!  Our technological stack is synonym of vanguard and includes the most relevant and advanced technologies. We pioneered in using Dockers: the entire system is on AWS: our microservices architecture allows to use the technology best suitable for us to face new challenges. We are among the few in Italy to offer services and projects developed using Elixisr and Rust. To ensure communications between services through API REST/GraphQL and RabbitMQ.  Tipologia contrattuale  Meal vouchers, trainging moments, team bulding events, latest generation hardware and devices: in Prima you will find everything you need to do your job at your best.  Salary and contract type will be evaluated during the interview, in order to offer an adequate pay to the real expertise and competence of every singole person. The employment is fulltime.  Our office is in Milan, in piazza Cordusio, but we also consider Full Remote hiring.",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Internet, Seguros",0,None,False,,2,None
390,2277590896,2020-10-11,Newsela,Data Engineer,"New York City, NY, US","The Role:   As the Data Engineer, you will be part of making insights accessible and timely by working closely with our data modelers to populate our data warehouse. In your daily work, you'll be responsible for working with another data engineer in optimizing data sourcing and transformation that create an efficient, effective data organization. You will focus on executing the data warehouse strategy to ensure resiliency, fault tolerance, and scalability, while also establishing best practices. You will also take a hands-on approach to collaborating with analysts and business intelligence to optimize the sourcing and consistency of KPIs, which will ultimately drive informed business decisions across the organization.  Why You'll Love This Role:   This is a rare opportunity to make an impact on how Newsela thinks about data during a critical time in the company's evolution. You will work closely with the Manager of Data Warehouse and other key stakeholders to optimize the most critical enterprise-wide KPIs that drive business growth and engagement. Using cutting-edge cloud technology, your work will combine deep analytics with analysis of user behavior, and will serve as the backbone of business intelligence and decision-making for Sales, Marketing, Product, and Customer Success. These insights will also be leveraged for C-level and Board reporting across Newsela. You will be joining a growing team of Data experts, and will help build the foundation for a product that's helping transform K-12 education.  Why We'll Love You:   You have 4+ years of demonstrated success in sourcing, transforming, and optimizing data from divergent sources. No management experience necessary but a passion for mentoring and learning leadership qualities is desirable. You are an expert in creating an ETL/ELT foundation leveraging best practices for continuous improvement, in addition to possessing expert SQL, DDL, and DML knowledge. You are highly skilled in scheduling, dependency management, and optimization. You are highly advanced with Python or other scripting languages in order to help data analysts and data scientists, among other partners, optimize data models. You will have an acute understanding of data warehouse modeling techniques and some experience using cloud-based data warehouse technologies. Through your work in data engineering, you have expanded and improved either the data warehouse set, utilization, and/or business performance. You do all this, while also contributing to an engaging data team culture  About Newsela:  One of the fastest growing tech companies in K-12 education, Newsela was founded on the principle that while every child learns differently, they all deserve a rich learning experience that ignites a love of learning. We built our platform based on learning science research to deliver the most engaging, authentic content to modernize how teaching happens in the classroom. Along with interactive assessments and tools, we provide teachers with digital content at five reading levels -- from +100 of the best sources -- that is relevant to the diverse backgrounds and interests of their students. Since we started in 2013, we've established a presence in 90% of U.S. K-12 schools and over 2.5M teachers and 37M students have registered with Newsela.",Sin experiencia,Jornada completa,Tecnología de la información,"Marketing y publicidad, Software, Internet",4,None,False,,34,ACTIVELY_HIRING_COMPANY
391,2175480892,2020-10-10,SecurityScorecard,Sr Data Engineer - Data Pipeline,Canada,"About SecurityScorecard:SecurityScorecard is an industry-leading cybersecurity company backed by Google, Sequoia, and Riverwood. Our mission is to make the world a safer place. We measure your and your vendors' cyber-health by assigning a security rating of 'A' through 'F' based on outside-in, non-intrusive data. Our Comprehensive security ratings, advanced data analytics, and actionable insights discover Third-Party Vulnerabilities & Security Gaps In Real-Time.Headquartered in NYC with over 200+ employees globally, raised over $110M USD, used by 1,000+ enterprise customers, and rating 1.5 million companies. We have created a new category of enterprise software, and our culture has helped us be recognized as one of the 10 hottest SaaS startups in NY for two years in a row.Our vision is to create a new language for companies and their partners to communicate, understand, and improve each other’s security posture. What you will do:As a Senior Software Engineer on the Data Pipeline Platform team, you will help us scale, support, and build the next-generation platform for our data pipelines. The team’s mission is to empower data scientists, software engineers, data engineers, and threat intelligence engineers to accelerate the ingestion of new data sources and present the data in a meaningful way to our clients.You will design and implement systems for ingesting, transforming, connecting, storing, and delivering data from a wide range of sources with varying levels of complexity and scale. Enable other engineers to deliver value rapidly with minimum duplication of effort. Automate the infrastructure supporting the data pipeline as code and deployments by improving CI/CD pipelines. Monitor, troubleshoot, and improve the data platform to maintain stability and optimal performance. Basic Qualifications:Bachelor's degree or higher in a quantitative/technical field such as Computer Science, Engineering, Math6+ years of data pipeline software development experienceExceptional skills in at least one high-level programming language (Scala, Java, Go, Python or equivalent)Actively using and a strong understanding of big data technologies such as Kafka, Spark, Storm, Apache Flink, Databricks toolkit, and CassandraExperience with Dataflow orchestration in Google Cloud Flow, Airflow, or ConductorExperience with AWS services including EMR, S3, Redshift, and RDSExcellent communication skills to collaborate with cross-functional partners and independently drive projects and decisionsPrevious experience working in distributed teams. We are a remote-first company!Located in the U.S. or Canada Benefits:We offer a competitive salary, a comprehensive benefits package including health and dental insurance, unlimited PTO, Maternity/Paternity leave, Tuition Reimbursements, and much more!  Additional Information:SecurityScorecard embraces diversity. We believe that our team is strengthened through hiring and retaining employees with diverse backgrounds, skillsets, ideas, and perspectives. We make hiring decisions based upon merit and do not discriminate based on race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status.",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Servicios y tecnologías de la información,23,None,False,,225,None
392,2006398368,2020-11-03,Omniscient Neurotechnology (o8t),Lead Support Engineer,"Sydney, New South Wales, Australia","Omniscient seeks an experienced, qualified Lead Support Engineer. Omniscient is looking for someone to enable the business to move beyond reactive bug fixing and into a more sustainable support workflow, encouraging active learning in response to technical issues as they arise. VISIONTo enable the world’s doctors to treat the brain health of billions through personalised clinical decision support SENIOR TEAM Dr Michael Sughrue | Co-Founder, Director & Chief Medical OfficerMike built one of the biggest neurosurgery practices in the US. With over 230 articles published in scientific journals and as a world authority in the field of Connectomics, Mike brings an unrivalled understanding of the brain to the business of practical clinical outcomes Dr Stephane Doyen | Co-Founder, Director & Chief Technology OfficerAs the Head Data Scientist with top-tier consultants, Oliver Wyman, combined with a PhD in neuroscience from Cambridge, Stephane is the ideal technical leader to develop our brain/machine-learning software Stephen Scheeler | CEO & Managing DirectorStephen headed up Facebook’s #5 market (ANZ) and was a pivotal figure in scaling Facebook from start up to US$500+ billion giant. Stephen brings the commercial software business leadership to execute our vision PRODUCTClinical decision support software that takes existing rsfMRI brain image, loaded via a web browser that de-identifies on-site, to the Cloud where, through 23 machine-learning steps, we return a functional map and detect anomalies of the patient’s brain in one hour. This allows neurosurgeons, neurologists, psychologists and psychiatrists to make more accurate diagnosis and personalised treatment plans for all brain-related disorders. TRACTIONBuilt our v1 software that provides brain mapping and anomaly detection (12 months, A$4.0m investment)Raised A$18.5m in seed fundingRecruiting high-calibre market development teams in US (#1 market, 4 staff) & China (#2 market 4 staff), and world-class software development, cloud computing, machine learning and business support teams in Sydney, Australia (16 staff)Hired leading Silicon Valley patent attorneys, Fish & Richardson, and secured two provisional patents to protect our IP. Successfully trialled our software in several world-leading brain medicine clinicsReceived commitments to deploy from world leading hospitals – e.g. Cambridge, Harvard, Johns Hopkins, MD Anderson, U Penn, Shanghai Mental, Shenzhen People’s, Beijing Tiantan, Suzhou University  KEY REQUIREMENTS Must have a Bachelors in Computer Science, Software Engineering, Math, Science or equivalentMust have 5+ years experience in leading software product support teams (preferably in medical technology industry): hands on building of organizational support capacity.Must be an expert in DICOM standardMust be proficient in using Python, Dockers and SSH and knowledge of networking protocolsMust be familiar with using Javascript and AWS softwareAbility to establish and maintain strong relationships within the organisationLanguage fluency in Mandarin & English RESPONSIBILITIES Developing procedures, work order instructions and technical artefacts related to supporting customersApplying deep issues analyses, including defining problems in technical terms to expedite the development team’s assessment and analysisProvide technical training and new product roll-out training to the support teamDeliver complex troubleshooting of installation problems and 2nd/3rd level support in providing customer issue resolutionsDetermine and guide development of the “field support” toolbox, enabling streamline remote/on-site debugging of client issues  ROLE This is a full-time role and will be remunerated at the market rate of the successful candidate based on their experience. Based on a successful trial period you would be offered an attractive Employee Share Option Plan. Reporting to Bryan Sin, Head of Product (based in North America).",Intermedio,Jornada completa,"Tecnología de la información, Gestión de productos, Atención al cliente","Servicios médicos, Software",57,None,True,,546,ACTIVELY_HIRING_COMPANY
393,2190025816,2020-10-16,Aegis Sciences Corporation,Research Scientist,"Nashville, Tennessee, United States","The Research Scientist is responsible for developing new methods and improving existing processes for the Aegis Laboratories. Essential Duties and Responsibilities:Lead, develop and validate new extraction and analytical methods Improve existing methods within the laboratoryIdentify technology needs and solutions using highly developed research skillsInteract with the appropriate experts across the organization to assess new or improved methodsIndependently design, coordinate, and conduct experiments for troubleshooting methodsAssist in mentoring R&D team members: serve as a resource for method development, validation and implementationTrain staff to understand the importance of method enhancements and/or new methodsProvides special training to technical staff membersAid in the documentation of cost of new or modified methodsPublish or present research data annually to internal or external audiences: mentor other TM interested in publishing or presenting  ﻿Successful Candidates Must Possess:A Ph.D. in Pharmaceutical, Analytical Chemistry, Medicinal Chemistry, or Toxicology Sciences requiredA minimum of two (2) years of relevant experience including the following are required:Leading, developing and validating novel extraction and analytical methods utilizing GC/MS, LC/MS/MS instrumentationIndependently designing, coordinating, and conducting method troubleshooting experimentsRegularly providing training for high-complexity analytical methods to technical staff and mentoring junior R&D Team MembersStatistical analysis and manuscript preparation highly desiredDemonstrated elevated degree of creative and innovative skills  Aegis Sciences Corporation is an Equal Opportunity Employer",Algo de responsabilidad,Jornada completa,"Investigación, Atención médica, Otro",Atención sanitaria y hospitalaria,84,None,True,,727,ACTIVELY_HIRING_COMPANY
394,2247000575,2020-10-02,Flashpoint,Data Engineer,"New York City, NY, US","Company Description:  Flashpoint is the globally trusted leader in risk intelligence for organizations that demand the fastest, most comprehensive coverage of threatening activity on the internet. From bolstering cyber and physical security, to detecting fraud and insider threats, Flashpoint partners with customers across the private and public sectors to help them rapidly identify threats and mitigate their most critical security risks. Flashpoint is backed by Georgian Partners, Greycroft Partners, TechOperators, K2 Intelligence, Jump Capital, Leaders Fund, Bloomberg Beta, and Cisco Investments. For more information, visit https://www.flashpoint-intel.com/ or follow us on Twitter at @FlashpointIntel  What we are looking for:  Our best engineers are collaborative and selfless. They enjoy writing code but they prioritize mentoring and supporting others. They leave code cleaner than when they found it but don't insist on particular patterns. They optimize for simplicity and readability. They are involved in the full lifecycle of software development: understanding the requirements, designing the solution, writing the code, testing the code, testing the integration, deploying it to production, and monitoring the deployment. They are fully engaged in the problem domain.  We see it as a prerequisite that candidates possess and demonstrate a desire to lead from the front in improving a supportive, empathetic team: we expect candidates to be trusted and beloved by their teammates such that they become technical and emotional anchors for the rest of the team and department.  What you will do:   Help build and maintain our data infrastructure. Become an expert in Apache Beam. Create observability tooling to help other teams debug, understand, and tune their big data jobs and pipelines. Assist and mentor other teams with building and managing their data pipelines. Write tools to automate data processes and deployments. Create maintainable, scalable code to address data needs Write empathetic documentation and runbooks to enable your team to be force multipliers for each other. Help bring in new technologies and develop innovative approaches to the data challenges we face. Apply your honesty, strong sense of morals and ethics, and sense of responsibility towards making Flashpoint and those around you smarter, stronger, and kinder. Identify opportunities for automation and drive process improvements.  What you will bring:   1 - 5 years experience contributing to production systems or other relevant experience. Experience with big data infrastructure. Proficient with Java or Scala. Solid foundation in computer science fundamentals from data structures and algorithms to high level design patterns. Excellent analytical, problem solving and technical skills. Demonstrated ability to learn and leverage new technologies. Experience with SQL schema design and data warehousing. Experience working with queuing systems and stream processing patterns. Basic understanding of privacy and security. An organized work ethic. A humble attitude and persistence to learn and to Get Stuff Done Right.  What else would be great:   Experience with public cloud data services, particularly Google Cloud Platform's. Experience with Spark, Hive, and/or Hadoop. Experience working with data science teams. Experience with automating infrastructure using leading cloud providers. Proficiency with Python.  Why Flashpoint is a Great Place to Work:   Diversity. Flashpoint is committed to fostering, cultivating and preserving a culture of diversity, inclusion, belonging, and equity. We recognize that diversity is key to achieving our vision. We believe that every person and their experiences contribute to building a work environment and a product that will change the world. Culture and Belonging. Our company's culture isn't something you join, it's something you build and shape, and each person's unique backgrounds and experiences contribute to who Flashpoint is and will become. You will have ample opportunities to connect with coworkers through various communication channels and company-funded events: dietary & allergy conscious catered lunches, book clubs, happy hours, committees and much more.  Benefits. We offer a competitive salary and benefits package, including unlimited PTO, 401(K), mental health and wellness benefits, commuter benefits, and generous parental leave policies. Perks. Flashpoint understands that personal wellness is one of the keys to a happy, healthy and productive work environment. That's why we also prioritize health and wellness perks like gym reimbursements and daily meditation, well-stocked kitchens, cool cultural initiatives and inclusive employee events. Career Growth. Flashpoint is invested in the growth of our team members and understands that frequent, two-way feedback is critical to that growth. We encourage regular one-on-ones with your manager, a regular schedule of performance reviews, learning and development opportunities, and guidance through formalized career paths: whether that be towards being a great manager, being a great individual contributor, or a lateral move to gain breadth of knowledge and experience.",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Internet",20,None,False,,112,ACTIVELY_HIRING_COMPANY
395,2201838625,2020-11-06,Idexcel,Data Engineer,"Sunnyvale, California, United States","Job Title: Data EngineerLocation: Sunnyvale, CA/RemoteDuration: 6+ months Note: Local to CA candidates preferred, would be completely remote. Description:Be part of Data Engineering team responsible for Data Analytics Platform servicing the business needs of the broader organization. Qualifications:• Bachelor’s degree in Computer Engineering, or related discipline.• 3+ years relevant working with Redshift, SQL, Python, Airflow and AWS data technologies.• Understanding of data architecture concepts such as data modeling, metadata, workflow management, ETL/ELT, real-time streaming), data quality.• 3+ years of experience working with SQL.• Experience with setting up and operating data pipelines using Python or SQL.• 1+ years of experience working on AWS.• Exposure to open source and proprietary cloud data pipeline tools such as Airflow, and Glue.• Experience working with relational databases.• Experience with code management tools (e.g. Git, SVN) and DevOps tools (e.g. CICD).• Great written and verbal communication skills.• Self-starter with the ability to work independently or as part of a project team.• Capability to conduct performance analysis, troubleshooting and remediation.",Algo de responsabilidad,Contrato por obra,Tecnología de la información,"Servicios y tecnologías de la información, Servicios financieros",330,None,True,,1000,ACTIVELY_HIRING_COMPANY
396,2184096851,2020-10-15,IMG systems,Big Data Engineer,"San Jose, California, United States","Position: Sr BigData EngineerLocation: Costa Mesa, CA // San Jose, CA Duration: 12+ Months Looking For Seniors. 10 + Years of experience. Requirements BS degree in computer science, computer engineering or equivalentProficient in Java, Spark, Kafka, Python, AWS Cloud technologiesMust have active current experience with Scala, Java, Python, Oracle, Cassandra, Hbase, Hive3+ years of experience across multiple Hadoop / Spark technologies such as Hadoop, MapReduce, HDFS, Cassandra, HBase, Hive, Flume, Sqoop, Spark, Kafka, Scala Familiarity with AWS scripting and automation Flair for data, schema, data model, how to bring efficiency in big data related life cycleMust be able to quickly understand technical and business requirements and can translate them into technical implementationsExperience with Agile Development methodologiesExperience with data ingestion and transformationSolid understanding of secure application development methodologies Experienced in developing microservices using spring framework is a plusUnderstanding of automated QA needs related to Big dataStrong object-oriented design and analysis skillsExcellent written and verbal communication skills Responsibilities Utilize your software engineering skills including Java, Spark, Python, Scala to Analyze disparate, complex systems and collaboratively design new products and servicesIntegrate new data sources and toolsImplement scalable and reliable distributed data replication strategiesAbility to mentor and provide direction in architecture and design to onsite/offshore developersCollaborate with other teams to design and develop and deploy data tools that support both operations and product use casesPerform analysis of large data sets using components from the Hadoop ecosystemOwn product features from the development, testing through to production deploymentEvaluate big data technologies and prototype solutions to improve our data processing architecture Automate everything",Intermedio,Contrato por obra,"Ingeniería, Tecnología de la información",Servicios y tecnologías de la información,75,None,True,,242,None
397,2200115126,2020-10-21,UnitedHealth Group,Big Data Engineer (100% telecommute),United States,"Combine two of the fastest-growing fields on the planet with a culture of performance, collaboration and opportunity and this is what you get. Leading edge technology in an industry that's improving the lives of millions. Here, innovation isn't about another gadget, it's about making health care data available wherever and whenever people need it, safely and reliably. There's no room for error. Join us and start doing your life's best work.(sm) You’ll enjoy the flexibility to telecommute* from anywhere within the U.S. as you take on some tough challenges. Primary Responsibilities:Design, code, test, document, and maintain high-quality and scalable Big Data solutionsDesign, develop and implement rules enginesResearch, evaluate, and deploy new tools, frameworks and patterns to build sustainable Big Data platformIdentify gaps and opportunities for improvement of existing solutionsDefine and develop APIs for integration with various data sources in the enterpriseAnalyze and define customer requirementsAssist in defining product technical architectureMake accurate development effort estimates to assist management in project and resource planningCreate prototypes, proof-of-concepts & design and code reviewsCollaborate with management, quality assurance, architecture, and other development teamsWrite technical documentation and participate in production supportKeep skills up to date through ongoing self-directed training The ideal candidate will be a self-starter who can learn things quickly who is enthusiastic, active, and eager to learn. You’ll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in. Required qualifications:Bachelor's degree9+ years of hands-on Software Development experience7+ years of development experience with Java or Scala, XML, Web Services5+ years of previous relational database experience4+ years of experience in Hadoop, MapReduce, HDFS, Spark, Streaming2+ years’ experience in at least one major cloud platform (Azure preferred)2+ years of experience in Kafka, streaming, NoSQL databases (Cassandra/Hbase preferred), Docker, KubernetesThorough understanding of service-oriented architecture (SOA) conceptsPrevious experience with Agile/SCRUM methodology/best practicesPrevious experience and successful track-record of learning new tools and technologies and leveraging these on integration and implementation projectsIf you need to enter a work site for any reason, you will be required to screen for symptoms using the ProtectWell mobile app, Interactive Voice Response (i.e., entering your symptoms via phone system) or similar UnitedHealth Group-approved symptom screener. When in a UnitedHealth Group building, employees are required to wear a mask in common areas. In addition, employees must comply with any state and local masking orders           Preferred Qualifications:Healthcare industry experienceFormal training and/or certification in any of the above-mentioned tools and technologiesAdvanced degree in a technical field Careers with Optum. Here's the idea. We built an entire organization around one giant objective: make health care work better for everyone. So when it comes to how we use the world's large accumulation of health-related information, or guide health and lifestyle choices or manage pharmacy benefits for millions, our first goal is to leap beyond the status quo and uncover new ways to serve. Optum, part of the UnitedHealth Group family of businesses, brings together some of the greatest minds and most advanced ideas on where health care has to go in order to reach its fullest potential. For you, that means working on high performance teams against sophisticated challenges that matter. Optum, incredible ideas in one incredible company and a singular opportunity to do your life's best work.(sm) *All Telecommuters will be required to adhere to UnitedHealth Group’s Telecommuter Policy",Intermedio,Jornada completa,"Atención médica, Otro",Atención sanitaria y hospitalaria,16,None,False,,234,ACTIVELY_HIRING_COMPANY
398,2208425108,2020-10-23,Dynata,Freelance Researcher,New York City Metropolitan Area,"POSITION SUMMARYDynata is looking an experienced freelance researcher who is passionate about uncovering and translating insights into impactful thought leadership content to power better decision-making. This position is open to remote hires as well as: USA (New York, NY) USA (Dallas, TX) USA (Shelton, CT) USA (Lehi, UT) USA (Maumee, OH). ESSENTIAL DUTIES AND RESPONSIBILITIES These include the following. Other duties may be assigned at the discretion of management in the context of the role. 1) Researcher to run research projects for Dynata’s marketing team, using Dynata’s online sample, to create content on a variety of topics which can be used for thought leadership and PR in global TV, news outlets, social media and for conference and webinar presentations. 2) Projects include:A quarterly Global Consumer Trends Report covering trends of interest across economic, society, technology, health, work life, the environment, spending habits and similar topics.A global weekly tracker focusing on COVID-19 and related issues8-10 ad hoc projects a year, mostly fast-turn studies of up to 10 questions which produce content on a current news topic. 3) Working at Dynata:You will be working as part of the marketing team, both directly with the head of marketing, and with marketing project managers, designers and copywriters.You will also work closely with a Dynata project manager who will set up the sample, field the study and be the liaison for survey programming, translation, data processing and creation of tables. 4) Span of work:The input to you is a marketing brief explaining the goal of the project, the topics to be covered, the likely storylines and some sample questions. The output from you is a written report covering the questions asked, by demographics such as country, income and generations – and a draft PowerPoint to be used in a presentation or webinar.We anticipate a time requirement of 2-3 days per week across the year, mainly concentrated during the Global Consumer Trends report periods each quarter. REQUIRED SKILLS & QUALIFICATIONSTo perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.  Education and Experience:5+ years of experience managing research projects on a variety of topics for demanding clients who often have tight timelines.Excellent writing and communication skillsExperience and confidence to understand the client’s brief, but also challenge it and advise on best research practices and best ways to execute it.Ability to work well across departments and manage project details effectivelyWillingness and ability to learn and use Dynata’s tools and platforms so they can be showcased effectively in the research results Specialized Skills:The ability to see the story in the data, tell the story effectively and help the marketing team translate it into powerful industry content to maintain Dynata’s position as a thought leader.Flexibility.Comfortable working with SPSS, creating questionnaires, writing tab specs and banner plans. Dynata is one of the world’s leading single providers of first-party data contributed by people who opt-in to member-based panels that the company manages and maintains. With a reach that encompasses 60+ million people globally and an extensive library of individual profile attributes collected through surveys, Dynata is the cornerstone for precise, trustworthy quality data. The company has built innovative data services and solutions around this core asset to bring the voice of the individual to the entire marketing spectrum, from market research to marketing and advertising. Dynata serves nearly 6,000 market research agencies, media and advertising agencies, consulting & investment firms and healthcare and corporate customers in the Americas, Europe, and Asia-Pacific.",Intermedio,Contrato por obra,"Investigación, Análisis, Tecnología de la información","Investigación de mercado, Servicio al consumidor, Marketing y publicidad",375,None,True,,2009,ACTIVELY_HIRING_COMPANY
399,2174485099,2020-10-12,Zego,Senior Data Engineer (London or UK Remote),United Kingdom,"Senior Data Engineer - London or Remote (in the UK) We are Zego, a global insurtech scale-up providing cover that creates possibilities. In an ever-changing world, insurance is struggling to keep up. Through the power of emerging technologies, we are creating fairer products designed for the 21st century. In 2019, we closed our series B funding round, raising $42M from top-tier investors that will fuel our growth into new territories and the expansion of our product portfolio. We were also listed in the Fintech 50 and placed number 7 in the Startups 100. More recently, we were accepted into the Tech Nation Future 50 2020 cohort and medium-sized and a Tech Company of the Year 2020 finalist - solidifying our place as one of the UK’s most exciting and influential tech companies. Overview of our Engineering Team: Zego puts technology first in its mission to define the future of the insurance industry. By focusing on our customers needs we're building the flexible and sustainable insurance products and services that they deserve. And we do that by empowering a diverse, resourceful, and creative team of world-class engineers that thrive on opportunity and innovation. Purpose of the Role: We are looking for a Data Engineer to help us build and improve a leading edge data analytics platform. Our core application is built on top of the Django web framework and hosted on Amazon Web Services. We typically use Python 3, Postgres, Celery, and whatever else we need to get the job done. We maintain both custom integrations (for ETL workloads) and use 3rd party tools (for ELT workloads) that are scheduled by Airflow, loaded into a Redshift cluster and modelled using Data Build Tool (DBT) and Looker (LookML). We're looking for people with a strong background in Python who are comfortable modelling data and writing performant SQL. As a Data Engineer at Zego you will have the opportunity to: Work on a large, critical data platform - learn how to develop and optimise raw data structures for high load transactional systems.Deep-dive into new and emerging technologies - we support a modern technology stack, utilising best-in-breed tools and advanced features of PostgreSQL, Redshift, AWS as well as working closely with our wider python engineering team.Have a real positive impact on the company, product, users and very importantly your colleagues as well. What you will be working on: You will assist in developing and maintaining our ETL and ELT pipelines.You will support the development and implementation of our ML models and experiments.You will help evolve the architecture of our data function to support our long term vision.You will contribute to code reviews and team discussions.You will take ownership of our reporting tools, both internal and for our partners.You will collaborate with product managers and across teams to bring new products and features to the market.You will help own product data in 'single source of truth' data platform, focusing on data structure, quality, usage and efficiency. What you will need to be successful in the Role: We are looking for somebody with a strong working knowledge of data architecture and development. You will either have past experience with tools like Docker, Airflow, Redshift, DBT or Looker. Or an interest in learning these, with the support of the team, is essential.We're looking for people with a commitment to building, nurturing, and iterating on an ever-evolving codebase. Other beneficial skills include: Familiarity with Kubernetes (EKS)Having experience building a Data Lake (on AWS)Having experience building highly available publish/subscribe messaging queue systems What's it like to work at Zego?Zego has a truly international and inclusive team, unified by great ideas and collaborative thoughtfulness. Our people are the most important part of our story and everyone plays an essential role in our journey. We look for people who have expertise, enthusiasm and who are motivated by change. There’s plenty of room to learn and grow, as part of our ongoing training programmes or directly from other experts. You’ll work alongside a talented group of people who respect each other's differences and seek to understand fresh perspectives.",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Seguros,22,None,False,,271,ACTIVELY_HIRING_COMPANY
400,2243719488,2020-10-01,Change Healthcare,Principal Data Scientist,"Seattle, WA, US","Transforming the future of healthcare isn’t something we take lightly. It takes teams of the best and the brightest, working together to make an impact.As one of the largest healthcare technology companies in the U.S., we are a catalyst to accelerate the journey toward improved lives and healthier communities.Here at Change Healthcare, we’re using our influence to drive positive changes across the industry, and we want motivated and passionate people like you to help us continue to bring new and innovative ideas to life.  If you’re ready to embrace your passion and do what you love with a company that’s committed to supporting your future, then you belong at Change Healthcare.Pursue purpose. Champion innovation. Earn trust. Be agile. Include all. Empower Your Future. Make a Difference.  Title  Principal AI Data Scientist   Overview Of Position  The Principal Data Scientist will be responsible for supporting Artificial Intelligence, Machine Learning, and Data Science solutions for Change Healthcare, reporting to an AI Data Science leader under the Chief AI Officer.  We’re looking for data scientists with a passion for artificial intelligence to help drive a new generation of data and machine learning enabled services and products to impact healthcare. You will enjoy working with a highly talented and diverse team of data scientists specializing in deep learning, active learning, and classical machine learning, one of the richest data sets in US healthcare, nearly limitless cloud compute resources including Spark clusters and GPUs, and the ability to see your insights turned into real products.  The ideal candidate will have a background in machine learning, have experience working with large data sets, and have some experience in building and deploying data-driven innovative AI solutions. You are focused on results, a self-starter, able to put the customer first, team first, and have demonstrated success in using data science to develop and deploy AI solutions with a focus on customer impact. You also are able to rapidly prototype new ideas and methods to deliver quality code that is testable and concise.  What will be my duties and responsibilities in this job? Use AI/ML technologies to innovate current Chang Healthcare operations. The tasks of innovation include, but not limited to: Smart revenue management, Intelligent payment platform, medical chart reading, code reading with noisy and incomplete OCR documents, Conversational AI to facilitate customer services and other healthcare related use casesWork closely with business and operations to understand the business requirements. To be able convert ambiguous requirements to mathematical AI models that can be trained and deployed to solve business problemsHave strong implementation skills to the proposed solutions and work closely with engineering team to create product pipelines that are scalable and flexibleWilling to work in an agile and fast-moving working environmentPassion for learning and innovating at new AI technologies that can facilitate future projects What are the requirements needed for this position? Ph.D. in Computer Science, Math, Physics, Engineering, Statistics, bioinformatics or other hardcore technical fields with profound mathematical training. Proficient in translating unstructured business problems into an abstract mathematical framework8+ years of experience in healthcare or medical industry with focus on AI technologiesFluency in one of the scripting languages, such as: Python, Scalar, PySpark and othersExperience with Spark, MapReduce and other big data processing tools is preferredFamiliar with both SQL and noSQL databases, ability to write efficient queries in SQL.Expertise in NLU/NLP, Conversational AIExpertise with one of the Deep Learning platforms, such as, TensorFlow, Pytorch, and KerasExpertise in Knowledge Graph and personalizationAbility to initiate and drive projects to completion with minimal guidanceThe ability to communicate the results of analyses in a clear and effective mannerFamiliar with AWS and its components, such as EMR, S3, EC2, SageMaker. or customer build AI Platform What other skills/experience would be helpful to have? Ph.D. with experiences on medical coding, medical chart reading, entity detection, and other reading comprehension using AI/NLP technologiesPh.D. with experience on big data processing in the areas of Revenue cycle management includes, but not limited to, risk management, payment accuracy, smart reconciliation, etc..Ph.D. with experiences on conversational AI technologies, such as AI model for intent detection, NER, dialog management and other related componentsExperience with medical ontologies, medical Knowledge Graph that links multiple entities, such as patients, providers, and payers. Possess the ability to run large scale inference on top of KG and generate business valuesExperience with medical image processing, diagnosis based on images and narratives using AI technologiesExceptional interpersonal and communication skills, including the ability to describe the logic and implications of a complex model to all types of partners (product managers, engineers, designers, senior executives)Possess impactful patents or scientific publications in the corresponding areas Strong capability to initiate and lead innovative research projects that have potential to revolutionize healthcare industry and generate business values What are the working conditions and physical requirements of this job?  General office demands  Join our team today where we are creating a better coordinated, increasingly collaborative, and more efficient healthcare system!   Equal Opportunity/Affirmative Action Statement   Change Healthcare is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, age, sex, sexual orientation, gender identity, genetic information, national origin, disability, or veteran status. To read more about employment discrimination protections under federal law, read EEO is the Law at https://www.eeoc.gov/employers/eeo-law-poster and the supplemental information at https://www.dol.gov/ofccp/regs/compliance/posters/pdf/OFCCP_EEO_Supplement_Final_JRF_QA_508c.pdf .  If you need a reasonable accommodation to assist with your application for employment, please contact us by sending an email to applyaccommodations@changehealthcare.com with 'Applicant requesting reasonable accommodation' as the subject. Resumes or CVs submitted to this email box will not be accepted.  Click here https://www.dol.gov/ofccp/pdf/pay-transp_%20English_formattedESQA508c.pdf to view our pay transparency nondiscrimination policy.  Change Healthcare maintains a drug free workplace and conducts pre-employment drug-testing, where applicable, in accordance with federal, state and local laws.",No corresponde,Jornada completa,"Ingeniería, Tecnología de la información",Servicios y tecnologías de la información,3,None,False,applyaccommodations@changehealthcare.com,50,ACTIVELY_HIRING_COMPANY
401,2221743893,2020-10-20,CrowdStrike,"Data Engineer with Python (Remote, ROU)","Bucharest, RO","At CrowdStrike we’re on a mission - to stop breaches. Our groundbreaking technology, services delivery, and intelligence gathering together with our innovations in machine learning and behavioral-based detection, allow our customers to not only defend themselves, but do so in a future-proof manner. We’ve earned numerous honors and top rankings for our technology, organization and people – clearly confirming our industry leadership and our special culture driving it. We also offer flexible work arrangements to help our people manage their personal and professional lives in a way that works for them. So if you’re ready to work on unrivaled technology where your desire to be part of a collaborative team is met with a laser-focused mission to stop breaches and protect people globally, let’s talk.  About The Role  We are looking to hire a Data Engineer for the Data Engineering team at CrowdStrike. The Data Engineering team operates within the Data Science organization, and provides the necessary infrastructure and automation for users to analyze and act on vast quantities of data effortlessly. The team has one of the most critical roles to play in ensuring our products are best-in-class in the industry. You will interact with product managers and other engineers in building both internal and external facing services.  The role is open for all candidates from Romania. We have colleagues from Brasov, Iasi, Cluj, Timisoara and Bucharest.  You will use Python and Golang. Don’t worry if you don’t know Golang, we will teach you!  Interviewing process: online  What You’ll Need BS degree in Computer Science or related field.5+ years of relevant work experience.Good knowledge of some (or all) of AWS, Python, Kafka, Spark, Airflow, Kubernetes, etc to build infrastructure that can ingest and analyze billions of events per day.Good knowledge of distributed system design and associated tradeoffs.Good knowledge of CI / CD and associated best practices.Familiarity with Docker-based development and orchestration.  Bonus points if you have… Created automated / scalable infrastructure and pipelines for teams in the past.Contributed to the open source community (GitHub, Stack Overflow, blogging). Prior experience with Spinnaker, Relational DBs, or KV Stores.Prior experience in the cybersecurity or intelligence fields.Golang experience  #Stack  Benefits Of Working At CrowdStrike Market leader in compensationComprehensive health benefitsWorking with the latest technologiesTraining budget (certifications, conferences)Flexible work hours and remote friendly environmentWellness programsStocked fridges, coffee, soda, and lots of treatsPeer recognitionInclusive culture focused on people, customers and innovationRegular team activities, including happy hours, community service events  We are committed to building an inclusive culture of belonging that not only embraces the diversity of our people but also reflects the diversity of the communities in which we work and the customers we serve. We know that the happiest and highest performing teams include people with diverse perspectives and ways of solving problems so we strive to attract and retain talent from all backgrounds and create workplaces where everyone feels empowered to bring their full, authentic selves to work.  CrowdStrike is an Equal Opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex including sexual orientation and gender identity, national origin, disability, protected veteran status, or any other characteristic protected by applicable federal, state, or local law.",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Servicios financieros",28,None,False,,364,ACTIVELY_HIRING_COMPANY
402,2226317649,2020-10-30,GalaxE.Solutions,Senior Data Engineer,"Detroit, Michigan, United States","ResponsibilitiesDesign and support the new and evolving sources of data being brought into the data warehouseWork closely with data architects and follow best practices for data management consumptionWork closely with business analysts to work through business requirements and develop processes to provide the needed data visibility via the data warehouse and reporting platformModel application layer and metadata designDesign and create automated applications and reporting solutionsWork closely with front-end developers to ensure data is being brought in and data integrity is being maintainedMonitor and troubleshoot performance issues on the data warehouse servers QualificationsProgramming experience in Python and C#Cloud-Native experience in AWS (Glue, S3, Redshift)Experience working with data integration and ETL tools Strong facilitation, requirements elicitation and data analysis skillsUnderstanding of current and emerging IT products, services, processes and methodologies",Intermedio,Jornada completa,Tecnología de la información,Servicios y tecnologías de la información,25,None,True,,105,ACTIVELY_HIRING_COMPANY
403,2271770740,2020-10-09,Pinnacol Assurance,Future Tech Opportunities,"Denver, CO, US","Pinnacol goes beyond providing Workers' Compensation insurance to Colorado businesses. We are a technology first company that believes in making a meaningful impact in workers' lives across Colorado in their most difficult moments by designing solutions that effectively help them get the care they need. We enable our policyholders to report a claim with a mobile first experience, all while providing insurance quotes to agents and new clients in 5 minutes or less through our award-winning app.  These customer-focused experiences are built on nimble platforms capable of using the latest and greatest technology available. Our Tech Stack includes:  Salesforce  React  Python  Gitlab  Google Cloud Platform   Cloud Functions, AppEngine and AppScript Pub/Sub BigQuery Cloud Composer (Apache Airflow) Cloud SQL (PostgreSQL) Storage Secrets Manager Kubernetes (GKE)  Hashicorp Terraform and Vault  This is about more than shiny code and sleek design. Pinnacol's culture sets us apart. We listen to our customers to create experiences with their insights in mind. We actively seek feedback from our injured workers and policyholders through surveys, focus groups, feature testing and research. It feels like family at Pinnacol. We do virtual team building and happy hours using Zoom and JackboxTV Games. We grow talent from within. There are opportunities for continued development and support for learning new skills, even those outside your current role. Our teams and leaders value collaboration and experimentation so we constantly learn how to do things better..  As one of the largest teams at Pinnacol, Information Services invests in a variety of opportunities for those who love tech. Pinnacol's charge is to 'Lead a revolution in caring' and our commitment to innovation and building cool stuff requires amazing talent. Here are a few of the roles we've recently hired:   Salesforce Engineer Data Engineer Data Scientist Machine Learning Engineer Natural Language Processing Engineer Database Engineer Cloud Architect ECM Administrator QA Engineer  Pinnacol has over 100 years of knowing and understanding Colorado workers and businesses. With a century of experience behind us, we're out to tackle the big problems that these individuals and communities face. By always asking 'What's next?', our agile and creative solutions keep us on the leading edge of creating better ways to care for and protect the people and businesses we serve.",No corresponde,Jornada completa,Otro,"Software, Seguros, Atención sanitaria y hospitalaria",None,None,False,,21,ACTIVELY_HIRING_COMPANY
404,2231886486,2020-11-02,FlatWorld.co,Technical Evangelist,United States,"US$100,000 – US$120,000 per year + Equity based on experience and fit. DAGsHub is a well-funded (US$3M) high growth startup, building a nextgen “GitHub for data scientists & machine learning engineers”. A thriving developer/user community is at the heart of our growth and business model and plays a critical role in our future success. We are looking for the first Developer Advocate / DevRel person to join our founding team and help us grow. We are building a home for data science collaboration – the field is rapidly developing, creating value and disrupting industries while still being chaotic. Now is the best time to create a place where data scientists can figure out how to work together. As one of the team’s first members, you will have a central role in shaping the company, its culture, its future, and its product. ** This is an outward-facing role and not a research one ** We provide everything data science teams need to manage their projects and collaborate. We transform well-established software practices into their natural equivalents in the data-science wild west and create new effective ways for data scientists to work together. Our product helps teams discover data science experiments & projects, understand the thought process behind experiments, reproduce results, and incorporate & review code and data changes and models. We believe this is the way to create the most vibrant collaborative data science community in the world! You willHelp us engage and expand our community of data scientists and machine learning engineers so that we can build the best tools for their workflow and enable Open Source Data Science to flourish.Be part of the founding team – have a ton of impact on our vision, understanding the community’s needs and prioritizing how it should be brought to life.Take ownership, responsibility, and pride in building and leading a community of data professionals. Accelerate the adoption of DAGsHub within the data science and machine learning community.Work on a wide variety of projects and tasks – no two days will be alike.Create or initiate collaborative data science projects that are valuable to the community or do social good, and show off how and why to use DAGsHub.Write great documentation, tutorials and blog posts, and give talks and lectures at events on a regular basis.Communicate directly with the DAGsHub community to enable and support them, gather feedback and generate insights into what really matters to them.Work with the rest of the team to improve the product and its adoption – understand the users, prioritize features and bugs, spread the word, research tech and business trends, think ten steps in advance to where the product should be going and how it can get there faster.Build relationships and partnerships with prominent researchers and organizations. You’d be a great fit if you ❤️Have very good (C1/C2) written and verbal EnglishAre curious and passionate about data science and MLOps – a tech geek at heartYou enjoy discussing data science technologies onlineGot 3+ years of experience as one of the following** Data scientist working on data science in production** Software developer with subject matter expertise in data science** Developer advocate with a passion for Data-Science** Technical product marketing(er) with a passion for Data-ScienceAre an experienced public speaker (meetups, conferences, etc)Have experience in writing tutorials, blog posts, docs, sample apps or other technical contentAre an outgoing person that enjoys interacting with new people and creating new connectionsYou have a growth mindset – our team really values learning and improving, and we seek out painful and inconvenient truths A fun person to work with! We are in this together for the long haul. Bonus points if you 🏆Launched a developer brand or product and grown a thriving communityCreated or maintained an Open Source projectBeen a community leader, responsible for scaling a developer communityActive social media accounts in a data-science / machine learning contextUsed a variety of data science ML tools, frameworks and environments such as Jupyter, RStudio, Tensorboard, Shap, DVC, MLflow, FastAIExperience with programming languages other than Python such as SQL and R and other tools and systems community members are likely to use such as Docker, Linux and BashPerksCompetitive equityVacation time-offHardwareStipends for a co-working space",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Servicios y tecnologías de la información,14,None,False,,166,JOB_SEEKER_QUALIFIED
405,2224684283,2020-10-21,Talener,Senior Data Engineer,"New York City, NY, US","Title: Senior Data Engineer  Location: REMOTE  Must Have Skills Fluent in PythonExtensive experience with Apache Airflow5-10+ years of professional experienceAdvanced knowledge of relational databasesCloud computing experience (AWS, Azure, GCP)Experience working with real time data pipelinesCI/CD  Pluses Experience with non-relational data storesAWSSnowflakeLooker  Salary Cap or Hourly Rate: Up to $160k, DOE  Benefits And Perks Competitive base salary + performance bonus (paid quarterly)Comprehensive health and dental benefits401k100% REMOTE  Client: Marketing and Advertising  Funding: Private  Additional Information: For additional information or to apply, please reach out to Bethany and barnold@talener.com.",Intermedio,Jornada completa,Tecnología de la información,Marketing y publicidad,42,None,True,barnold@talener.com.,150,ACTIVELY_HIRING_COMPANY
406,2279216893,2020-10-11,PSC Biotech Corporation,Data Scientist,"Pomona, CA, US","Who we are?  PSC Biotech is a leading Biotech Consultancy firm founded in 1996, headquartered in Pomona, California, USA, with global operations in Ireland, India, Singapore, Australia, and the US, serving 350 clients in more than 23 countries worldwide. We provide cloud-based software solutions for Quality Management and Regulatory Inspections, pharmaceuticals contract manufacturing professionals, and metrology services to our clients.  ‘Take your Career to a New Level’  PSC Biotech disrupts the conventional consultancy model by aligning our EVP as one of the unique selling points which include the opportunity to work with the most talented cohort of like-minded professionals operating in the Pharma/Biotech Industry. We offer a permanent contract of employment giving exposure to working in Top Pharmaceutical client sites in a diverse-cultural work setting.  Expertise/Requirements  We are looking for an experienced Data Scientist for our “PSC Software” Entity, this would be remote position. Details are as follows:  Bachelor’s or higher Degree in Computer Sciences or Data Science with an emphasis on data analysis and structures for machine learning, and artificial intelligence.  Additional experience in statistical modeling, computational biology/chemistry/physics, or mathematic modeling or other relevant areas is desirable.  Passionate about creating replicable, scalable systems around data and analytics. You think modularly and create robust, reusable patterns and components whenever possible Expertise and experience in engineering data pipelines using big data technologies on large scale data sets. Understand the Data Lifecycle and concepts such as lineage, governance and retention Conceptually familiar with AWS cloud resources (S3, EC2, RDS, etc.) Excels at taking vague requirements and crystallizing them into scalable data solutions. Operates independently, demonstrates excellence, and self learns new technologies and frameworks. Knowledge of United States Food and Drug Administration (FDA), European Medicines Agency (EMA) and other regulatory schema is a plus. Ability to communicate and work effectively with non-computer science personnel is a plus. Ability to work well under pressure to provide results in a short time-frame. PSC is seeking a highly responsive, goal-oriented individual who will bring significant energy and drive to lay the foundation for and help drive delivery of our next generation applications.  This is a remote position.",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Industria farmacéutica,3,None,False,,21,ACTIVELY_HIRING_COMPANY
407,2208737011,2020-10-15,Solita,Senior Computer Vision Engineer / Data Scientist (d/w/m),"Munich, Bavaria, Germany","Would you like to focus to enable fast change? How about working with modern, impactful technologies and skillful people making the change possible? We have enabled our clients to become data driven by implementing hundreds of data-driven solutions for large-scale Nordic companies and organizations. We have both automatized processes with the help of classical Machine Learning and Deep Learning, and helped companies to create new data-based services. The ideal candidate will have experience in both classic CV and Deep Learning techniques. Should be able to design creative solutions and communicate them well, and be responsible for writing quality code and supporting it in production. Other qualifications include:Strong practical experience with Image Pre-Processing/Classification and Object DetectionStrong practical experience with Deep Learning frameworks (Tensorflow or PyTorch) and modern Machine Learning techniquesDeep understanding in OpenCV libraryKnowledge of cloud infrastructures (Azure, AWS) is a plusPhD with a publication background is a plusEnglish is a must, fluent German is a big plusExperience in building production level ML/DL products is a double plus If you know how to apply OpenCV for automated image cropping, how to reduce background noise, and how to port Yolo to Tensorflow, you are already on the right side! If you are up to date with recent research in CV and worked on production level solutions (defect detection, medical image processing, etc.), do not wait any longer – we are eager to know you ASAP! Solita as a workplace – above average consultancySolita is a workplace, where you will always find a more knowledgeable multi-disciplinary peer to spar with. People join us to become a part of a diverse community of experienced professionals and continuous learners. And people stay for the same reason. At Solita our highly skilled experts are working together to help our clients in all industries, while still maintaining a start-up like, relaxed atmosphere and great culture! Our company culture is very important for us, and we value low hierarchy, independence and responsibility, impactful work, high technical skills and cool colleagues. Read more about what kind of company we are. All we have is in our people. We offer support for our people both in work and also when life happens. We care. Join us to make an impact that lasts!If you feel up to the challenge, contact us by sending us your application to careers@solita.fi. Your application won’t end in a mystery black box: We contact and communicate with all candidates openly. The application period will end on Sunday the 15th of November. We hope you will be able to work in our office in Munich. Interviews are held virtually in Teams. Read more about our interviews and onboarding.If you wish to have a chat with us before sending an application, please contact our AI Lead Oleg (oleg.gutyrchik@solita.fi). Advice for headhunters and agencies: We are not actively looking for new partners. Should you have any questions, please contact directly our Recruitment Director Kati (kati.kitti@solita.fi). ABOUT SOLITASolita is a workplace, where you will always find a more knowledgeable multi-disciplinary peer to spar with. People join us to become a part of a diverse community of experienced professionals and continuous learners. And people stay for the same reason.At Solita, everybody can feel comfortable to be themselves with all their perfections. We focus on changing the world, not people. Diversity in all forms is a strength, which we value highly. You will find an easy-going work culture, where you can be yourself.All we have is in our people. We offer support for our people both in work and also when life happens. We care.",Intermedio,Jornada completa,Tecnología de la información,Servicios y tecnologías de la información,153,None,False,"careers@solita.fi., oleg.gutyrchik@solita.fi, kati.kitti@solita.fi",721,ACTIVELY_HIRING_COMPANY
408,2248108394,2020-11-06,Apkudo,Data Engineer,"Baltimore, Maryland, United States","Position Title:Data Engineer/ETL - Fully Remote - Live/Work from anywhere in the U.S. Position Description:Are you engaged by data and by writing, enhancing, and debugging SQL and Python? Do you want to be a data pipeline expert and work closely with our data scientists to ingest massive amounts of data? If so, we need you! We are looking for a smart data minded person who is a master of our tech stack (e.g. Python, Pandas and similar libraries, PostgreSQL, AWS, Linux, Docker, etc.) to help us maintain, enhance, debug, evolve, and make a difference. Work remotely. Apply today! What you will do:Develop, enhance, and maintain data pipeline architectures capable of ingesting structured and unstructured data using both batch & streaming methods.Debug and improve SQL queries, fine tune AWS Postgres instances to enhance performance.Automate manual processes, optimize data delivery, and create/enhance data infrastructure for scaling.Optimize data custom extraction, transformation, and loading pipelines from multiple data sources.Assist internal and some external partners with data-related technical issues and support their data infrastructure needs.Develop code in Python to test AWS database design, automate processes and create ETL pipelines. What you will need:Bachelor's degree in Computer Science, Analytics or another applicable field is preferred (relevant experience may substitute for degree)6+ years of recent relevant data engineering experience requiredExperience building and optimizing data pipelines for acquisition and management of data including data security, data capture, data cataloging, & data classificationKnowledge of message queuing, stream processing and Change Data Capture mechanismsExperience with Python in ETL data solutions, PostgreSQL, and AWSAPI development (specifically to connect to SaaS solutions) desiredExperience with Ubuntu/Debian Linux, Docker/containers, Python data analytics packages such as Pandas What’s in it for you: Growth: Join one of the fastest growing companies in the sector where personal and professional growth are encouraged and expected!The Work: Work with cutting-edge technologies including robotics and forward-thinking customers who see and think ahead!The People: Work with other smart people who work well together and who appreciate both team and individual successes!The Compensation: Earn a competitive salary with an excellent benefits package!Remote First: “Remote-first” company with a flexible, friendly, productive work environment! Company Description:Apkudo is the developer of Hive, the platform for the management of the connected device supply chain. Through an applied combination of artificial intelligence, advanced analytics, and sophisticated automation, the Hive Platform manages the world of devices for all supply chain stakeholders by injecting intelligence and transparency throughout the entire device lifecycle: from design, development, and certification through to forward and reverse logistics. By balancing device velocity, quality, and precision across all supply chain processes, the Hive Platform significantly optimizes both device experiences and device value. We test, we certify, we verify, and we collect and provide data that helps businesses working with connected devices make and save money! Note: Apkudo is an Equal Opportunity employer. We are committed to diversity and inclusivity and to creating a culture where everyone feels respected and connected, no matter the location of their work. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law.",Intermedio,Jornada completa,Tecnología de la información,"Tecnología inalámbrica, Software, Internet",35,None,True,,139,ACTIVELY_HIRING_COMPANY
409,2213962605,2020-10-17,Vee,Data Scientist Intern (Remote),United States,"Position: Data Scientist Intern (REMOTE)Reports to: CTOLocation: Remote Are you passionate about exploring where, how, and why data can drive business decisions? Interested in how organizations use analytics and data to innovate, grow and transform? Driven to help establish, define, and evangelize how data science can help drive a strategy?  Company OverviewVee inspires people to align on Purpose so they can unlock their individual and collective human potential. We are an early stage startup poised for dramatic growth. We specialize in developing ways to drive greater strategic alignment to unlock enterprise innovation and growth. After spending considerable time exploring the need for better alignment models across diverse organizations, we have developed a framework and methodology based on insights from extensive research. We are building products to assess gaps and are offering our consulting services to help 21st century leaders develop and implement their organizational and people strategies, along with the capabilities required to operationalize their Purpose as they transform. Position OverviewJoin our fast-growing team! You will help drive intelligent, insightful, and predictive business results to help Vee and Vee’s clients drive value in the realms of people, purpose, and performance. You will help build Vee’s data capability and data strategy. General ResponsibilitiesResearch and develop statistical learning models for data analysisCollaborate with Data Engineering, People Science, business partners, and Chief Technology Officer to devise innovative and forward-thinking solutions for our clients’ needsKeep up-to-date with the latest technology trendsCommunicate results and ideas to key stakeholders at VeeImplement new statistical or other mathematical methodologies as needed for specific models or analysisOptimize joint efforts between Data Engineering, business partners, UX, and People Science teams at Vee to drive business resultsCore Experience & RequirementsMasters degree in Computer Science, Applied Statistics, Applied math, Data Science, or a related fieldPractical experience with multiple statistical languages (SAS, R, Pandas), data processing, database programming, and data analyticsSolid background in data mining and statistical analysisExperience with programming languages such as Python and RKnowledge of data visualization tools (e.g. Tableau)Strong collaboration skills - you partner well with others to solve problems and actively incorporate input from various sourcesExcellent oral and written communication skillsWorking with key stakeholders to drive business results ProfilePurpose is what drives you. Your passion for your work has led you here. You are ready to combine your experience with ours to help our client companies gain competitive advantage. You bring strong creative thinking skills in addition to superior communication skills, allowing you to develop creative solutions for any challenge that comes your way. You:Love what you do, love to be busy, and love to produce by being organized and methodicalWork with a sense of urgency and have a strong drive for resultsHave the resilience and agility to adapt quickly in a fast-paced environmentWork independently as well as collaboratively to stretch thinking into creative solutionsHave strong verbal and written communication skillsAre excited about and suited for a startup, where you’ll be wearing a few hatsAre smart and fun with an empathetic nature, which will add to our culture About VeeOur founders and team have deep expertise in branding, innovation, design, I/O psychology, organization design, digital & data product development, enterprise software and application development complemented by experience with clients ranging from emerging Silicon Valley unicorns to established leaders in government and the public and private sectors including American Express, Bank of America, BMW, Box, HP, Lowe’s, Mastercard, Microsoft, Nissan, Pepsico, Procter & Gamble, SAP and The Clorox Company, among others. For more information, check out our website in transition at https://www.letsvee.com/.",Prácticas,Prácticas,"Tecnología de la información, Análisis, Consultoría",Consultoría de estrategia y operaciones,431,None,False,,1991,ACTIVELY_HIRING_COMPANY
410,2186310720,2020-10-15,Passei Direto,Data Engineer,"Rio de Janeiro, Rio de Janeiro, Brasil","A posição de Data Engineer está em nosso time de Dados. O nosso maior desafio no momento é construir produtos que impactam a vida de milhões de estudantes. Essa pessoa será responsável por nos ajudar a fazer o melhor uso dos nossos dados para a tomada de decisões mais assertivas. 🧡 RESPONSABILIDADES E ATRIBUIÇÕESAqui na Passei Direto o aprendizado é constante. Contamos com a sua inquietude e colaboração para apoiar o time e suas principais responsabilidades serão: Arquitetar e construir estruturas para BI, análise e ciência de dados, integrando dados de nossas várias fontes de dados:Construir pipelines automatizados para processar e limpar dados:Ser um especialista em nossos conjuntos de dados, entendendo seus pontos fortes e fracos:Cuidar dos dados e métricas do PD, garantindo sua qualidade e visibilidade em toda a empresa:Trabalhar em colaboração com cientistas de dados em análises avançadas para imaginar e construir soluções criativas para questões desafiadoras, na maioria das vezes com uma linha de visão clara de seu trabalho até o impacto no mundo real:Trabalhar em projetos que abrangem várias áreas do PD (de Produto a Marketing e Conteúdo):Experimentar novas técnicas e ferramentas analíticas. REQUISITOS E QUALIFICAÇÕESAcreditamos que o nosso time nos ajuda a fortalecer a nossa cultura, transformando para melhor a forma que trabalhamos e nos relacionamos na empresa. Para essa oportunidade, estamos buscando um profissional com as competências abaixo: Ser muito bom em SQL e ter experiência com alguma linguagem de programação de alto nível (por exemplo, Python, R, Scala, Java):Ter experiência com uma variedade de técnicas de engenharia de dados (ou seja, modelagem de dados, ETL, Data Warehouse, Data Lake) e ferramentas (ou seja, Hadoop, Spark):Ser graduado em matemática, engenharia e/ou ciência da computação:Solucionar problemas de forma criativa, criando novas abordagens para alcançar resultados:Ser um entusiasta em aprender novas técnicas e tecnologias. INFORMAÇÕES ADICIONAISAlgumas tecnologias que usamos : AWS (EC2, S3, RDS, EMR, Glue, DMS, ECS):R, Python:MySQL:Spark. Local de trabalho: Botafogo, Rio de Janeiro - RJ, Brasil ou possibilidade de trabalho remoto.  Lembrando que, até dezembro de 2020, estamos todos remoto #FiqueEmCasa “Se te oferecem um lugar em um foguete, não pergunte qual é o assento, apenas embarque.” 🚀Sheryl Sandberg",Intermedio,Jornada completa,Tecnología de la información,Gestión educativa,127,None,True,,810,ACTIVELY_HIRING_COMPANY
411,2261283128,2020-10-06,"Logic20/20, Inc.","Data Engineer - Python, Databricks & Azure (Remote/Contract)","Seattle, WA, US","Description  Data Engineer - Python, Databricks & Azure (Remote/Contract)   About The Role. . .  In order to continue and accelerate our growth, we are looking for a Data Engineer with Cloud Solutions background to add to our Seattle, Washington-based team.  The engineer is responsible for building a large-scale data pipeline in cloud platform. This may involve in automation of manual processes to cloud environment. Candidate would direct the initiatives for creation of data sets. Delivering client value and ensuring high client satisfaction.  Core responsibilities for this position include, but are not limited to the following: Extracts data from various databasesPerform exploratory data analysis, cleanses, massages, and aggregates dataProductionize ETLs, schemas, and databasesEmploys scaling & automation to data preparation techniquesResearches relevant emerging tools and techniquesPossesses in-depth business knowledge in order to initiate and drive discussions with business partners to identify business issues needing analytic solutionsLeads innovative packaging and presentation of insights to business and broader analytics communityDevelops processes to automate and scale insights operationalizationEstablishes brand and team as subject matter experts in advanced analytics across departments.  Required Qualifications Experience with Azure Databricks and Spark preferredMinimum 5 years hands-on experience with PythonProficient in SQLKnowledgeable of relational database and ETL practicesExperienced in the software development lifecycleDemonstrated experience in a cloud-based computing environment such as AWS, Azure, or Google CloudBig data processing techniques, preferredCan work independently in ambiguous environment  About Logic20/20. . .   Logic20/20 is one of Seattle’s fastest-growing consulting firms. We hire remarkable people to create simple, efficient solutions for complex problems.  Although we make it look like magic, our success is due to our approach (methodical and structured) and the people we hire (smart, motivated, and team oriented). Together, these enable us to consistently exceed client expectations—and our reputation is growing.  For the past five years, we’ve placed in the top ten of Seattle Business magazine’s “Best Companies to Work For”. From engaged leadership and wide-ranging benefits to career mentorship and diverse internal opportunities, we pride ourselves on being one of the best companies to work with and work for.  We hire people that are self-motivated, comfortable conceiving strategies on the fly, and enjoy working individually and as part of a team. Our work is high-energy and demanding, but new hires will quickly feel at home among colleagues as friendly and focused as they are. We bring our best to every opportunity, driving change in industries across the West Coast. Join us and you can, too.",Sin experiencia,Contrato por obra,Tecnología de la información,"Marketing y publicidad, Servicios y tecnologías de la información, Software",0,None,False,,17,ACTIVELY_HIRING_COMPANY
412,2175449529,2020-11-05,Greylock,Founding Engineer (ML / DS),San Francisco Bay Area,"We're looking to build out the founding team of an upcoming AI-first investment of ours, which is still in incubation. While I can't give too many details out yet, it's an autoML company that is looking to create novel algorithms/models dealing with data sparsity issues in the enterprise. If you're an accomplished Data or Machine Learning Scientist and would like to work on a ground-floor opportunity where the modeling isn't 'out of the box', I'd like to hear from you. Please note: Due to the volume of applicants I typically receive, a follow-up email will not be sent unless a match is identified (sorry). On top of that, since this is a stealth opportunity with some fairly specific needs that I can't delineate in a job posting, we are going to appear to be highly selective in our applicant screening process. About me:I am a full-time, salaried employee of Greylock, and there are no fees associated with any of the work I do. My team provides free candidate referrals/introductions to all of our active investments (one of the many services we provide), and I'm always looking to add new people to our network of talent.",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información","Software, Servicios y tecnologías de la información, Internet",115,None,True,,486,COMPANY_RECRUIT
413,2272720010,2020-10-10,Amicus Recruitment,Senior Python Engineer / Fully Remote / £45k - £70k,"London, GB","Job DescriptionpPython Engineer / Fully Remote / £45k - £70k/p pDo you want to work for a company building out a Data management software to transform the Fintech business? We are proud to be working alongside an AI business who are transforming the way people invest their money. Whether it be personal, or business related, the company are building a real time data driven platform to help./p pFounded last year, they currently employ 10 individuals, with 5 in their current engineering team. As a Python Engineer, you will be joining a team of 3 Frontend Engineers, a hands-on CTO and will be working in very close sync with their Lead Data Scientist. In addition, they are looking to also bring on board 2x GoLang Engineers, 1 UX Designer and one DevOps Engineer therefore, they are really beginning to scale up the business over the next month. One of your key responsibilities will be to continue the growth and support the development of the companies Data Science sector. In addition, you will also be responsible for building on the API's functionalities, continue the growth of the organisations platform whilst providing sufficient support and maintenance./p pThey will allow you to work from there London office or work fully remotely from anywhere in Europe or on a similar time zone to the UK. They have a clear strategy and vision and using AI and work through tens of million / billions rows of data to revolutionise their sector./p pTo be considered you must have the following skill set:/p ul liOver 2 years' commercial experience coding in Python/li liPandas and NumPy would be good/li liTDD/li liAWS or cloud experience/li liExperience building Microservice Architecture/li liAny experience of open source databases like Postgres or NoSQL will be highly advantageous/li liA degree in Computer Science, Mathematics, Physics or similar would be useful/li /ul pThey are offering a great package with a salary between £45,000 - £70,000 plus good equity as well as the ability to work fully remotely indefinitely./p pIf you are interested then please click apply or send an email ./p pPython Engineer / Fully Remote / £45k - £70k/pimg src='",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Software,0,None,False,,21,JOB_SEEKER_QUALIFIED
414,2280931207,2020-11-06,Jefferson Wells USA,Data Engineer,"Ontario, CA","Think of your career as a project. Set a goal, detailing what you want to do and where you want to be working. Begin by researching your areas of interest, target companies, qualifications needed, etc. Discuss your strategy, your target employers and your plan to reach your goal with your recruiter. CONNECTING WITH A CAREER EXPERT IS HUMANLY POSSIBLE  We are currently looking for Data Engineer for an immediate contract in Toronto, ON.   Duration: 5 Months - with possibility of extension  Worksite: Remote  Description:  Docker experience is a mustOpenshift experienceThorough understanding of Kafka, producer / consumer / topic technologies and drive implementation of the technology Lead messaging modelling, persistent data modelling, normalization, transform, migrate, cleanse and all other aspects relating to dataUnderstand implications of data upstream and downstreamMake key decisions on technology and tools to implement from a data platform technology standpointAbility to innovate on the latest technologiesLead cloud hosted data persistence technologies for redundancy, resiliency, performance, maintenance and sizing     ManpowerGroup is an Equal Opportunity Employer (EOE/AA)",Intermedio,Contrato por obra,"Análisis, Tecnología de la información","Banca, Servicios y tecnologías de la información",20,None,True,,155,ACTIVELY_HIRING_COMPANY
415,2279991405,2020-10-11,Global Fishing Watch,Data Scientist,"Oakland, CA, US","General Summary  Global Fishing Watch (GFW) is an independent, international non-profit organization that advances the sustainability and stewardship of the ocean by offering, for free, data and near real-time tracking of commercial fishing activity.  GFW processes a global database of vessel GPS positions, several terabytes in size, and applies machine learning models that infer each vessel's type and size as well as when they are likely fishing. GFW is now developing new models, both on these GPS positions and on satellite imagery, to fully reveal activity in the world's oceans. These models include object detection from global feeds of satellite radar and optical imagery, and models that infer, based on vessel behavior, illegal activity and unreported catch. We believe that these new models have the potential to dramatically change the way we monitor and manage the world's oceans.  The Position  Forced labor in fisheries is increasingly recognized as a human rights crisis. Until recently, its extent was poorly understood and no tools existed for systematically detecting forced labor risk on individual fishing vessels on a global scale. Working closely with the GFW technical teams and GFW's research partners, the data scientist will refine our current vessel-level behavioral model to predict fishing vessels that have a higher risk of using forced labor and will develop new models. The position represents an exciting opportunity to apply modern ML to big data problems in a field where it has been little used to date. Unlike traditional supervised learning this problem is an example of 'positive-unlabeled (PU)' learning (because we don't know which vessels do not use forced labor), requiring less straightforward approaches and presenting interesting challenges. The existing model has been applied to a small training set, and working with global partners we are currently identifying additional labeled data. The successful candidate will refine the models as new data are acquired and subsequent model predictions will be tested in the field through our network of partners.  Skilled use of R or Python (current model is implemented in R) is needed, as is some experience with SQL and knowledge of machine learning techniques. A successful candidate does not need to demonstrate all of the skills required for this job, but does have to show an aptitude for learning such skills on the job. We have many successful data scientists who started with limited modeling experience. The ideal candidate will be excited about working with global data and will have a high aptitude for learning new techniques. Global Fishing Watch values working quickly, innovating, and working collaboratively. Our entire team works remotely, so the ideal candidate will be able to manage their own time and be effective with limited daily oversight. Finally, we are passionate about producing research and datasets that will make a difference in how we manage the world's oceans.  Job Requirements  Technical skills  Demonstrated skills with Python or R (with preference for R based on current model implementation) SQL experience Demonstrated abilities to process and interpret large datasets Knowledge of machine learning concepts and basic modeling   The Required Team And Communication Skills  Team player, willing to work, teach, learn with/to/from the GFW team Proactive mindset – enjoys and exhibits a high-degree of ownership of tasks and projects Comfortable working in a small but fast growing organization Excellent communication skills – in person, phone, and, most important, written Comfortable communicating with a wide range of individuals, including peers, juniors and senior level people, and government officials from multiple countries Intellectually curious, forward thinking, willing to suggest / try new technologies and creative approaches to problems Ability to work in a remote-only distributed team (in more than 5 different time zones)  Helpful skills, but can be learned on the job  Knowledge about marine science and human impacts on the ocean   Location: GFW has a distributed workforce, with employees all over the world. This position will require the successful candidate to work closely with team members based in California and Buenos Aires. Working from Asian or European time zones can be acceptable if the candidate is willing to work outside of normal business hours.  Responsible to: Research & Innovation Director  Salary or Compensation: Commensurate with experience. GFW offers pension/retirement, health and other benefits commensurate with similar level GFW employees in the country of employment.  Working Hours: GFW supports flexible working, so the pattern of hours may vary according to operational and personal needs. GFW works across different time zones and weekend work may be required on occasion. Periodic domestic and international travel will be required to meet with team members and for workshops. No overtime is payable.  Travel: Currently suspended due to COVID-19. In person team meetings may occur once every few months.  Holiday: Paid holiday/vacation commensurate with other, similar-level Global Fishing Watch employees/contracts in the country of employment.  Equal opportunities: GFW is an equal opportunities employer and commitment to this process is expected.",Sin experiencia,Contrato por obra,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Software, Investigación",None,None,False,,28,ACTIVELY_HIRING_COMPANY
416,2199827621,2020-10-22,InternPi,Data Scientist Intern,United States,"This internship opportunity is presented by InternPi, a premium internship placement service provider to college students and new graduates. Before you apply, please note there will be service fees charged to intern candidates upon successful internship placement. Please visit our website at www.InternPi.com for more details. Below is a remote unpaid internship opportunity from a company within our internship host employer network. Job Title: Data/Knowledge Scientist Internship Location: RemoteSalary: UnpaidStart Time: FlexibleTime Commitment: at least 2 months, minimum 15 hours/week during academic year  About Company: It is an artificial intelligence company founded in 2005 with 20+ employees globally. The company has developed a patented AI-enabled platform and provides evolutionary digital solutions to clients in various industries.  Internship Description: Intern can choose to work on one of the following programs:  FinTech Banking and Capital Markets: this program focuses on applying innovative AI and machine learning technologies to develop and refine a financial business solution, which analyzes comprehensive sets of server and container data generated for monitoring purpose (e.g., metrics, events, logs). In particular, technologies are leveraged in this program to: analyze collected data to identify trends: detect anomalies for operational support: predict future resources: allocate and add resources to meet operational needed: and visualize and analyze relationships across data elements and datasets. mHealth Business Solution: this program focuses on exploring IoT and AI technologies to assess and manage the overall health of the lymphatic system with a focus on Lymphedema conditions resulting from cancer treatment. The company’s product family includes a mHealth system that promotes precise lymphedema condition assessment among breast cancer survivors, as well as a real-time Lymphedema exercise tracking tool that used by patients and healthcare providers to monitor patients’ exercising.  ASD/ADHD Disease Management Solutions: this program focuses on exploring IoT and AI innovative technologies to develop an integrated behavior tracking/metering solution that help children with ADHD and/or ASD symptoms perform their day-to-day activities. The solution includes a combination of services aimed at helping children regulate and/or adjust their own behavior and helping parents and mental health specialists monitor its effectiveness.  Intern Responsibilities: ·       Coordinates research and analytic activities utilizing various data points (unstructured and structured) and employ programming to clean, massage, and organize the data.·       Mine and analyze data from company databases to drive optimization and improvement of product development. ·       Develop custom data models and algorithms to apply to data sets·       Develop processes and tools to monitor and analyze model performance and data accuracy·       Research and develop statistical learning models for data analysis·       Presenting information using data visualization techniques Candidate Qualifications:·       Bachelor’s in Computer Science, Engineering, or relevant field: or equivalent experience.·       Knowledge on the principles of machine learning, data mining and AI-driven analytics. ·       Experience with data analytics tools (e.g., Kibana), search engines, and ElasticSearch. ·       Experience with machine learning technologies including Python, SciKit-Learn, Pandas, TensorFlow, and Keras ML Libraries. ·       An understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc. ·       A drive to learn and master new technologies and techniques.",No corresponde,Prácticas,None,Dotación y selección de personal,163,None,False,,1061,ACTIVELY_HIRING_COMPANY
417,2232846806,2020-11-02,PRI Global,Lead Data Engineer,"St. Louis City County, Missouri, United States","Not a Typical Java full stack role is Java and Data engineer side roleAngular JS React JS Need exp in Data and ETLData injection and Data lining is a plusMicroservices Application is based on Angular JSTeam is Building automation projectBuilding Large scale data  Degree in Computer Science or related field - Strong foundation in algorithms, data structures and core computer science concepts. - Evidence of working with object-oriented development and design patterns. - Proficiency in multiple modern programming languages such as Java, Python, Ruby, Angular, Scala, etc. - Strong written and verbal English communications skills. - Strong analytical and excellent problem-solving skills. - Experience working in an Agile environment. - Experience with XP, TDD and BDD in the software development processes - Proficiency with cloud technologies (IaaS, PaaS, serverless technology, NoSQL databases), micro-service design, CI/CD, DevOps - Experience designing scalable fault tolerant platforms that are resilient to infrastructure failures - Experience with the strangulation pattern and anti-corruption layers to migrate monolithic systems into independent services - Expert in modern software design principles such as SOLID, DRY, and Single responsibility",Intermedio,Contrato por obra,"Ingeniería, Tecnología de la información",Servicios y tecnologías de la información,31,None,True,,134,ACTIVELY_HIRING_COMPANY
418,2181929866,2020-10-14,Doximity,Senior Data Engineer,United States,"Doximity is transforming the healthcare industry. Our mission is to help doctors be more productive, informed, and connected. As a software engineer focused on our data stack, you'll work within cross-functional delivery teams alongside other engineers, designers, and product managers in building software to help improve healthcare.  Our team brings a diverse set of technical and cultural backgrounds and we like to think pragmatically in choosing the tools most appropriate for the job at hand.   One of Doximity's core values is stretching ourselves. Even if you don't check off all the boxes below we encourage you to apply. Doximity is full of exceptional people that don't fit a mold, join us! About youYou have professional experience developing data processing, enrichment, transformation, and integration solutions.You are fluent in Python and SQL.You are no stranger to data warehousing and designing data models.You are foremost an engineer, making you passionate for high code quality, automated testing, design patterns, and other engineering best practices.You care deeply about the data being generated. You study the data and extract insights from it before you process it.You are user experience and product focused. You build solutions while thinking about the impact it has on our users and enhances the product.You are able to design data architecture that ensures solutions are fault tolerant, scaleable, and easy to iterate upon.You have the ability to self-manage, prioritize, and deliver functional solutions.You know your way around Git and AWS services.You agree that concise and effective written and verbal communication is a must for a successful team.You are able to maintain a minimum of 5 hours overlap with 9:30 to 5:30 PM Pacific time. Here's How You Will Make an ImpactCollaborate with product managers, data analysts, and machine learning engineers to develop pipelines and ETL tasks in order to facilitate the extraction of insights from data.Build, maintain, and scale data pipelines that empower Doximity’s products.Establish data architecture processes and practices that can be scheduled, automated, replicated and serve as standards for other teams to leverage.Spearhead, plan, and carry out the implementation of solutions while self-managing. About UsExplore our stackWe have over 350 private repositories in Github containing our pipelines, our own internal multi-functional tools, and open-source projectsWe have worked as a distributed team for a long time: we're currently about 65% distributedFind out more information on the Doximity engineering blogOur company core valuesOur recruiting processOur product development cycleOur on-boarding & mentorship process Benefits & PerksGenerous time off policyComprehensive benefits including medical, vision, dental, Life/ADD, 401k, flex spending accounts, commuter benefits, equipment budget, educational resources and conference accessFamily support and planning benefitsPre-IPO stock incentives.. and much more! For a full list, see our career page More info on DoximityWe’re thrilled to be named the Fastest Growing Company in the Bay Area, and one of Fast Company’s Most Innovative Companies. Joining Doximity means being part of an incredibly talented and humble team. We work on amazing products that over 70% of US doctors (and over one million healthcare professionals) use to make their busy lives a little easier. We’re driven by the goal of improving inefficiencies in our $3.5 trillion U.S. healthcare system and love creating technology that has a real, meaningful impact on people’s lives. To learn more about our team, culture, and users, check out our careers page, company blog, and engineering blog. We’re growing steadily, and there’s plenty of opportunities for you to make an impact. ﻿Doximity is proud to be an equal opportunity employer, and committed to providing employment opportunities regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex, gender, gender identity, gender expression, pregnancy, childbirth and breastfeeding, age, sexual orientation, military or veteran status, or any other protected classification. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law.",Intermedio,Jornada completa,Ingeniería,Software,55,None,False,,171,None
419,2203371537,2020-10-23,SADA,Senior Data Engineer,United States,"Join SADA as a Sr. Data Engineer! Your Mission  As a Sr. Data Engineer at SADA, you will work collaboratively with architects and other engineers to recommend, prototype, build and debug data infrastructures on Google Cloud Platform (GCP). You will have an opportunity to work on real-world data problems facing our customers today. Engagements vary from being purely consultative to requiring heavy hands-on work and cover a diverse array of domain areas, such as data migrations, data archival and disaster recovery, and big data analytics solutions requiring batch or streaming data pipelines, data lakes and data warehouses.  You will be expected to run point on whole projects, end-to-end, and to mentor less experienced Data Engineers. You will be recognized as an expert within the team and will build a reputation with Google and our customers. You will demonstrate repeated delivery of project architectures and critical components that other engineers demur to you for lack of expertise. You will also participate in early-stage opportunity qualification calls, as well as lead client-facing technical discussions for established projects.  Pathway to Success  #BeOneStepAhead: At SADA we are in the business of change. We are focused on leading-edge technology that is ever-evolving. We embrace change enthusiastically and encourage agility. This means that not only do our engineers know that change is inevitable, but they embrace this change to continuously expand their skills, preparing for future customer needs.  Your success starts by positively impacting the direction of a fast-growing practice with vision and passion. You will be measured quarterly by the breadth, magnitude, and quality of your contributions, your ability to estimate accurately, customer feedback at the close of projects, how well you collaborate with your peers, and the consultative polish you bring to customer interactions.  As you continue to execute successfully, we will build a customized development plan together that leads you through the engineering or management growth tracks.  Expectations Required Travel - 30% travel to customer sites, conferences, and other related events. Due to the COVID-19 pandemic, travel has been temporarily restricted.Customer Facing - You will interact with customers on a regular basis, sometimes daily, other times weekly/bi-weekly. Common touchpoints occur when qualifying potential opportunities, at project kickoff, throughout the engagement as progress is communicated, and at project close. You can expect to interact with a range of customer stakeholders, including engineers, technical project managers, and executives.Training - Ongoing with first-week orientation at HQ followed by a 90-day onboarding schedule. Details of the timeline can be shared. Job Requirements Required Credentials:Google Professional Data Engineer Certified or able to complete within the first 45 days of employment  Required Qualifications: Mastery in at least one of the following domain areas:Data warehouse modernization: building complete data warehouse solutions, including technical architectures, star/snowflake schema designs, infrastructure components, ETL/ELT pipelines, and reporting/analytic tools. Must have hands-on experience working with batch or streaming data processing software (such as Beam, Airflow, Hadoop, Spark, Hive).Data migration: migrating data stores to reliable and scalable cloud-based stores, including strategies for near zero-downtime. Backup, restore & disaster recovery: building production-grade data backup and restore, and disaster recovery solutions. Up to petabytes in scale. Experience writing software in one or more languages such as Python, Java, Scala, or GoExperience building production-grade data solutions (relational and NoSQL)Experience with systems monitoring/alerting, capacity planning and performance tuningExperience in technical consulting or customer-facing role Useful Qualifications:Experience working with Google Cloud data products (CloudSQL, Spanner, Cloud Storage, Pub/Sub, Dataflow, Dataproc, Bigtable, BigQuery, Dataprep, Composer, etc)Experience with IoT architectures and building real-time data streaming pipelinesExperience operationalizing machine learning models on large datasetsDemonstrated leadership and self-direction -- a willingness to teach others and learn new techniquesDemonstrated skills in selecting the right statistical tools given a data analysis problem About SADA Values: We built our core values on themes that internally compel us to deliver our best to our partners, our customers and to each other. Ensuring a diverse and inclusive workplace where we learn from each other is core to SADA’s values. We welcome people of different backgrounds, experiences, abilities and perspectives. We are an equal opportunity employer. Make them raveBe data drivenBe one step aheadBe a change agent Do the right thing Work with the best: SADA has been the largest partner in North America for GCP since 2016 and has been named the 2019 and 2018 Google Cloud Global Partner of the Year. SADA has also been awarded Best Place to Work by Inc. as well as LA Business Journal!  Benefits: Unlimited PTO, competitive and attractive compensation, performance-based bonuses, paid holidays, rich medical, dental, vision plans, life, short and long-term disability insurance, 401K with match, professional development reimbursement program as well as Google Certified training programs. Business Performance: SADA has been named to the INC 5000 Fastest-Growing Private Companies list for 12 years in a row garnering Honoree status. CRN has also named SADA on the Top 500 Global Solutions Providers for the past 5 years. The overall culture continues to evolve with engineering at its core: 3200+ projects completed, 3000+ customers served, 10K+ workloads and 25M+ users migrated to the cloud.",Intermedio,Jornada completa,"Tecnología de la información, Ingeniería, Consultoría","Servicios y tecnologías de la información, Consultoría de estrategia y operaciones, Servicio de información",9,None,False,,105,ACTIVELY_HIRING_COMPANY
420,2194340028,2020-10-20,Incedo Inc.,Data Engineer - AWS+PySpark,"Gurgaon, Haryana, India","Position Title - Data Engineer – AWS+PySpark Experience - 4 to 7YearsJob Location - Gurgaon  Responsibilities: Enable data query and analysis through different tools (Athena, Pig, Hive). Support transient/serverless processing capabilities. Optimize cost—design for scale up/scale down of compute needs to meet the performance thresholds. Solutions should scale to high volume, velocity and variety of data. Spark on EMR will be used as the ETL tool. Data cleansing, correlation, aggregation, change data capture, versioning will be as part of the EMR Spark data pipelines. AWS GLUE will be the central source of truth for metadata Data Security, Access Control and Compliance Enable adherence to Genentech’s own data policies and regulatory requirements. Encrypt data at rest and in motion using Key Management Service from AWS. Design role-based access control to data. Ensure logging and audit capabilities for all system- and user actions. Continuous Integration and Deployment Create CloudFormation/Terraform templates to enable deployments to multiple environments quickly and efficiently. Integrate with Jenkins/BitBucket to effect a robust CI/CD environment Understand Recovery Point Objective and Recovery Time Objective to formulate a DR plan for the environment. Configuration and management of AWS services including but not limited to EC2, S3, Cloudfront, RDS, Route 53, IAM, Cloudtrail, API Gateway, and more.",No corresponde,Jornada completa,"Ingeniería, Tecnología de la información, Consultoría",Servicios y tecnologías de la información,126,None,True,,528,ACTIVELY_HIRING_COMPANY
421,2220973245,2020-11-04,Scipher Medicine,Principal Data Scientist,"Waltham, Massachusetts, United States","The RoleThe Principal Data Scientist will lead the technical team to develop and apply state-of-the-art computational and statistical methods to deliver testable hypotheses and biological insights. What will I do? Drive to developing companies' platforms and algorithms in collaboration with the research team.Participate and lead components of the PRISM-RA and PRISM-UC data analysis projects.Work closely with Harvard Medical School and Northeastern University on Research Sponsored Agreement collaborations.Summarize and communicate results to project teams, provide intellectual input, and contribute to decision-making.Prepare and deliver scientific presentations for both internal and external usePresent the company’s scientific results at leading industry conferencesMaintain knowledge latest scientific and technology advancements in the fieldContribute to high-quality documents and scientific publicationsProvide regular updates to the technical teamManage each project within agreed upon timelinesMinimum Education and Qualifications PhD in Bioinformatics, Computational Biology, Biological Sciences, or relevant fields5 plus years of experience in bioinformatics, systems biology and statisticsBackground in working with gene expression dataSkilled in machine learning and statistical analysisProficiency in coding (R and python are preferable)Familiar and experienced in network medicine approaches is preferredAbility to establish and maintain effective working relationships with coworkers, managers and clientsAbility to laugh at yourselfAbility to work within a matrix team environmentStrong communication skills, both written and verbal To all recruitment agencies: Scipher Medicine does not accept agency resumes. Please do not forward resumes to our jobs alias, or Scipher Medicine employees. Scipher Medicine is not responsible for any fees related to unsolicited resumes.",Intermedio,Jornada completa,"Investigación, Atención médica, Gestión","Biotecnología, Industria farmacéutica, Investigación",13,None,False,,295,ACTIVELY_HIRING_COMPANY
422,2247054510,2020-10-02,Azlo,Senior Data Engineer,"Guadalajara, MX","About Azlo  Azlo is a new fintech company that helps business owners, entrepreneurs, and freelancers pay, get paid, and manage their money. Backed by BBVA, we're on a mission to transform small business banking.  Azlo is looking for a Senior Data Engineer to join our growing Data Engineering team. This role will be responsible for evolving and optimizing our data pipelines. A successful person in this position will be excited about, and comfortable with, defining, re-defining and implementing new data architectures to ensure optimal data delivery.  What You'll Do  Lead the technical effort of a data engineering scrum in the design of a Big Data infrastructure: collaborate and work closely with DevOps, utilizing state-of-the-art technologies and AWS.  Build and optimize big data solutions that successfully communicate with a variety of complex environments. Ensure streaming and batch ETL work is well-designed, scalable and the process provides real-time analytics capabilities. Monitor production tasks: ensure scheduled tasks are properly working.  Establish best practices so that Data Science work is maintainable and scalable.   What We're Looking For  5+ years of Data Engineering and leadership experience, working with different databases (both RDBMS and NOSQL), Big Data technologies, data integration and data management. Upper-Intermediate to Advanced English Proficiency: able to communicate confidently and effectively in a professional capacity with native speakers.  Prior experience with Spark and Hadoop ecosystems (HDFS, Hive, YARN) Prior experience with data cloud environments and specifically on demand managed Hadoop environments (EMR, Dataproc) Understanding of Agile methodologies and CI/CD tools such as git, Jenkins, Sonar, and Jira.  Prior experience with workflow management tools, such as Airflow, Oozie, Luigi or Azkaban. Prior experience with Software Design Patterns and TDD Proficiency in Python and/or scala.  Familiarity with ORC, Parquet, and Avro data storage formats. Innovative mindset - Problem-solving proclivity. Strength in both written and verbal communications within all levels of an organization. An entrepreneurial attitude and the ability to work in a fast-paced, flexible environment on multiple concurrent projects with a distributed team.  Technologies we like and use  Apache's Spark, Flink, Airflow and Hudi. Databricks' Delta Lake and MLFlow. Python, Scala and R. Tensorflow, Scikit-learn, Statsmodels, BigDL. Tableau, Shiny, Streamlit. Docker, kubernetes, git, AWS, MongoDB, Neo4j, Kafka streams. Microservice architecture, Pub/Sub, event-driven updates, functional programming.   What We Bring  High impact role in an early-stage fintech company. A passionate team with decades of experience in finance, tech, and startups. A mission to empower small business owners, and a mandate to do away with the old models of banking. Backing from a leading global bank with resources to support our growth.   Additional Details  The position is based in Mexico City.  Please submit your application/resume in English.  We are currently working remotely, but occasional travel may be needed in the future.",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Software, Internet, Servicios financieros",None,None,False,,27,ACTIVELY_HIRING_COMPANY
423,2234527085,2020-10-09,PokerStars,Big Data Engineer (BG remote),"Sofia, BG","The role Big Data Engineer We are looking for a Big Data Engineer to join our busy and dynamic team based in our Bulgaria service office!  Our tech teams work remotely within Bulgaria, occasionally you’ll need to come to the office in Sofia. Not often, but up to 4-5 times a month and of course, we’ll cover all related expenses. Working as a team is what makes us great and spending quality time together is essential for keeping us mission-aligned.  As part of our data platform team, you will be responsible for driving the design and development of core platform frameworks that enable the delivery and construction processes for the Data Management, Data Discovery and Analytics group, and using emerging big data technologies. You will be required to apply your depth of knowledge and expertise to all aspects of the software development lifecycle, as well as partner continuously with your different business partners daily to stay focused on common goals. Why we need you  You will develop real-time and batch processes using a wide range of technologies including  HadoopSparkFlinkStormHiveHbaseKafka You will efficiently translate architecture and low-level requirements to design and code using SQL and Java Big Data processing. You will perform optimizations on Big Data and investigation of job bottlenecks.  You will be responsible for the documentation, design, development of Hadoop applications and handle the installation, configuration, and support of Hadoop cluster nodes.  You will develop and maintain backend MapReduce, Tez, Storm, Flink applications. You will convert hard and complex techniques as well as functional requirements into detailed designs.  As a dedicated team member, you will propose best practices and standards: handover to the operations. You will test software prototypes and transfer them to the operational team. You will maintain data security and privacy across the data warehouse. You will be responsible for the management and deployment of HBase data structures. Who are we looking for  As a perfect candidate you have  Familiarity with Hadoop ecosystem and its components3+ years experience in streaming systems and processing big data volumesAbility to write reliable, manageable, and high-performance codeExpertise knowledge of Hdfs, Yarn, HBaseWorking experience in HQLExperience of writing Tez and MapReduce jobs and Kafka applicationsHands-on experience in programming languages, particularly Java, PythonAnalytical and problem-solving skills: the implementation of these skills in Big Data domainUnderstanding of data loading tools such as Flume, Sqoop etcWhat’s in it for you? Our experience-based salaries are competitive. Plus, there’s a discretionary annual performance bonus. And we provide advice and dedicated assistance to those moving to Bulgaria.  Your package will include  health and dental insurance for you, your partner and your children (if you all live at the same address)a personal interest allowance to let you learn something new or pursue a hobby1000 BGN as congratulations if you have a baby whilst you work for usin-house training and development to develop your skills, progressing your careerfree fresh fruit, snacks and drinks in the officecontribution towards your transportation and lunch expensesrelaxation areas around the office, including a PlayStation and Pool tablesports program and social events: including our sensational summer and Christmas partiesWhat happens next? If you're what we're looking for, we'll invite you for a short Zoom interview. And if that goes well, we'll organize a second, more in-depth technical interview. The Group PokerStars is part of Flutter Entertainment Plc, a global sports betting, gaming and entertainment provider headquartered in Dublin and part of FTSE 100 index of the London Stock Exchange, which brings together exceptional brands, products and businesses and a diverse global presence in a safe, responsible and ultimately sustainable way.  We are an equal opportunity employer that values diversity. We do not discriminate on any protected characteristic as defined by applicable law.  We will look to provide reasonable accommodation for applicants with disabilities to participate in the job application or interview process. If you need assistance, please contact talent@starsgroup.com .  Please note we cannot accept general applications: this inbox is just for providing support to those who need it.",No corresponde,Jornada completa,"Ingeniería, Tecnología de la información","Videojuegos, Apuestas y casinos, Medios de comunicación en línea",0,None,False,talent@starsgroup.com,31,ACTIVELY_HIRING_COMPANY
424,None,None,None,None,None,"Responsibilities   Aon is looking for a Vice President, Digital Forensics & Incident Response   As part of an industry-leading team, you will help empower results for our clients by delivering innovative and effective solutions supporting Digital Forensics & Incident Response. As a Vice President, you will report directly to the Managing Director and have direct reports which include entry level to mid-level colleagues. This role will start out virtual and when our local offices open back up, this candidate could be located near our Chicago, IL: New York, NY: Los Angeles, CA: Washington, DC: Dalls, TX: or Boston, MA office locations.   Your impact as a Vice President, DFIR   The Digital Forensics unit in Aon's Cyber Solutions is the heart of the firm's reactive cybersecurity consulting services. Our team works in many investigative and technical areas to help clients solve problems. Casework may include: the preservation and forensic analysis of operating systems: the collection of evidence from various devices and networks: document forgery analyses: user activity timelining: deletion, spoliation, and obstruction of justice analyses: IP theft investigation and remediation: interviews of technical staff: IoT device data analysis: online investigations: data analytics: client consultation: expert report writing: post-breach incident response: and more. Success as a member of the Digital Forensics team requires nimbleness and perspicacity. You are well-suited to thrive as a cybersecurity consultant when, at heart, you are a detective: you are a scientist: you are an advocate for the facts. You are a coder, a tinkerer, and a curious mind. You are a technical generalist and an expert witness. You solve puzzles. You are a translator of arcane technical scenarios and forensic artifacts into clear, compelling findings for legal, corporate, and government clients. You enjoy working in a challenging, ever-evolving, high-stakes consulting environment. You are as comfortable speaking in front of lawyers and executives as you are at a hackathon. You are self-sufficient at learning new technologies and can code up clever solutions to problems when adequate tools don't exist. You like working hard and helping clients find creative solutions to difficult and mission-critical technical problems. You thrive in a diverse, supportive workplace where everyone strives to improve their technical skills collaboratively.   As a Vice President, you will manage local and regional teams of experts in running high-stakes, high-profile investigations for our clients. You are expected to have mastery of the fundamentals of running cybersecurity investigations. You will apply your deep industry experience and thought leadership in cybersecurity to your casework and client management. You will work at the direction of a Managing Director or Executive Managing Director in the unit to scope, coordinate, oversee, and perform numerous client cases. You will publish and speak on relevant topics in our industry, drive the strategic direction of the firm, and help build Aon's Cyber Solutions service offerings. As a regional team leader, the quality of the Digital Forensics unit’s work and its continuing sterling reputation will rest with you.   Job Responsibilities:   Coordinate and perform the most complex forensic analyses handled by the firm. Provide top-of-the-industry expert testimony in trials, depositions, and other proceedings. Supervise local and regional Digital Forensics staff, including coordinating teams of experts, assuring stellar work product, conducting annual performance reviews, and mentoring cybersecurity experts. Work independently as technical lead for critical corporate, legal, and government clients on high-profile matters. Ensure that client matters are staffed adequately and efficiently and that deadlines are met. Produce high quality oral and written work product, presenting complex technical matters clearly and concisely. Form and articulate expert opinions based on analysis. Draft and conduct peer review of expert reports, affidavits, and other expert testimony. Maintain proficiency with industry standard tools and practices and seek opportunities to enhance depth and areas of proficiency. Seek opportunities to broaden expertise of the digital forensic examiners and staff through in house and outside training. Ensure the smooth functioning of the forensic laboratories under your direct supervision: foster teamwork, information sharing, and inter-office collaboration and consistency. Identify emerging cybersecurity opportunities and develop new strategic expertise and value propositions for the firm.\ Support and drive the strategic direction of the Digital Forensics unit.     You Bring Knowledge and Expertise   Required Experience:    8-10 years or more of sustained excellence in digital forensics, incident response, or applicable technical field. A demonstrable career in providing outstanding client service. Clarity in written and oral communication. Proven ability to excel and persuade as an expert witness. Three or more years managing technical teams on complex cybersecurity projects. GCFE, GCIH, CCE, EnCE or equivalent digital forensics / incident response certification. Deep experience with most common operating systems (Windows, macOS, Linux, iOS, Android) and their file systems (ext3/4, HFS+, APFS, NTFS, exFAT, etc.). Proficiency with industry-standard forensic toolsets, including X-Ways, EnCase, Axiom/IEF, Cellebrite, and FTK, and experience presenting findings derived from such tools in sworn testimony. Proficiency with database querying and analysis. Experience with cloud infrastructures for the enterprise, such as Amazon Web Services, G Suite, Office 365, and Azure. Strong work ethic. Even stronger analytic, quantitative, and creative problem-solving abilities. Confidence, humility, openness, kindness, and a commitment to learning and teaching others.     Education:   Bachelor’s degree or equivalent years of industry experience.    US-IND  We offer you  A competitive total rewards package, continuing education & training, and tremendous potential with a growing worldwide organization.     Our Colleague Experience:  From helping clients gain access to capital after natural disasters, to creating access to health care and retirement for millions, Aon colleagues empower results for our clients, communities, and each other every day.  They make a difference, work with the best, own their potential, and value one another.  This is the Aon Colleague Experience, defining what it means to work at Aon and realizing our vision of empowering human and economic possibility. To learn more visit Aon Colleague Experience.     About Aon:  Aon plc (NYSE:AON) is a leading global professional services firm providing a broad range of risk, retirement and health solutions. Our 50,000 colleagues in 120 countries empower results for clients by using proprietary data and analytics to deliver insights that reduce volatility and improve performance.  Aon provides  equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, creed, sex, sexual orientation, gender identity, national origin, age, disability, veteran, marital, or domestic partner status.  Aon is committed to a diverse workforce and is an affirmative action employer.  DISCLAIMER:  Nothing in this job description restricts management's right to assign or reassign duties and responsibilities to this job at any time.",Director,Jornada completa,"Consultoría, Tecnología de la información, Estrategia/planificación","Seguridad del ordenador y de las redes, Servicios y tecnologías de la información, Cumplimiento de la ley",16,None,False,,242,None
425,None,None,None,None,None,"An exciting San Diego Fitness startup who works on creating Artificial Intelligence app that tracks and swiftly showcases whatever the body needs. It is an app that measures a person's vitamin and mineral levels, along with additional wellness factors like hydration, lack of nutrition and even stress hormones. This company is transitioning into a period of growth and is looking to bring on a Senior Data Scientist. They have a remote friendly environment. In this role you will be responsible for leading the data science team to build thie core image analysis algorithm. In addition, a professional that can develop deep-learning and other machine learning models against image datasets to help their image analysis algorithm. The role is remote and the company is offering a competitive salary comensurate with experience level and qualifications. Candidates for this role are expected to have experience working with computer vision and deep learning models.Please feel free to reach out to J.Perez@x4technology.us if you think this role may be for you.",Intermedio,Jornada completa,Atención médica,"Sanidad, bienestar y ejercicio, Biotecnología, Atención a la salud mental",100,None,False,J.Perez@x4technology.us,316,None
426,None,None,None,None,None,Estamos buscando uma pessoa para atuar como Data Engineer em um projeto de inovação dos nossos produtos em tecnologia! Dá uma olhada em quais serão suas responsabilidades e quais requisitos precisa ter:  Suas principais responsabilidades serão:  Atuar na transferência de plataformas em SAS para Spark e/ou Python em ambientes Hadoop. Trabalhar boas práticas de direcionamento no Git e documentação de book no Confluence.   Conhecimentos necessários:  SAS Avançado: Git: Python: Spark: Scala: Git: Confluence:,Intermedio,Jornada completa,Tecnología de la información,Servicios y tecnologías de la información,8,None,False,,138,None
427,None,None,None,None,None,"Lead Data Engineer Work from Home - Utah Based Residents Preferred We are a Utah based company with customers on a global scale. Our products are tech-driven and our engineers are working on the IoT products we create. As the Lead Data Engineer you will help grow and mentor the Data team while staying closely involved with the day-to-day functions of the team. You will be reporting directly to the CTO on a team that is innovating the way people exercise. Requirements Experience leading and building a team of data engineersMinimum of 5+ years experience with SQL development demonstrating a mastery of use.5-8 years experience working with data in a variety of capacities – analyst, developer, reportdevelopmentHands-on experience with at SQL, SnowflakeExperience with ETL/ELT tools such as FiveTran and dbtDev-ops experience using GIT, developing, deploying code to productionProficient in working in Unix/Linux as well as Windows server environment Responsibilities Lead a team of data engineersUse an analytical, data-driven approach to drive a deep understanding of our business.Build data pipelines and data models that will empower engineers and analysts to make data-driven decisionsBuild data models to deliver insightful analyticsDeliver the highest standard in data integrityStrong analytical skills with ability to analyze and project sales, subscriber and engagement dataWork closely with analytics teams to develop comprehensive analytical reports to enable data-driven decisions to increase engagement and conversions of target customer segments. Must-Have Skills Passionate about learning new things and solving problems12 or more years of experience in software development and solution architectureSuperior written and communication skills with ability to interface with various groups such asproject team, and senior executivesStrong capability and extensive experience in developing and writing technical solutionsStrong organizational skills and the ability to independently execute work tasks in a rapidlychanging, fast-paced environment Key Technology Skills FiveTrandbtSnowflakeSegmentLooker PrincePerelson & Associates is an Equal Opportunity Employer and we do not discriminate against applicants due to race, color, religion, sex, national origin, age, disability, genetics, veteran status, or on the basis of disability or any other federal, state or local protected class. All applicants applying for U.S. job openings must be authorized to work in the United States.",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Sanidad, bienestar y ejercicio",38,None,False,,127,None
428,None,None,None,None,None,"About Cleo: At Cleo, we make a real impact by doing work that matters: helping families be their best at home and at work. Cleo is a family benefits platform that picks up where the healthcare system leaves off. We combine the expertise of our team of guides and specialists – parent and maternity coaches, doulas, lactation consultants, sleep experts, and more! – with a powerful technology platform that helps every working parent succeed as they grow both their families and their careers. Offered by over 100 leading employers, including global Fortune 500 leaders and industry innovators like Box, Chegg, Niantic, and Zenefits, and backed by NEA, Greylock and Felicis, we’re expanding our offerings and our team to meet the growing demand of employers, parents, and the healthcare sector and are looking for experienced and passionate team members like you to join us! Title: Sr. Data/ML Engineer Overview:As a Data & ML engineer at Cleo, you will lead and define our organization's approach and practices to managing our data, data discovery, and machine learning practice. You will play a critical role in advancing how we impact our members, personalize their experience as well as measure the outcomes of our impact. Cleo leverages our platform and provides the most impactful support at the right time to our new parents to support them in their journey of growing a family: and has an amazing opportunity to enhance it with the power of data and machine learning which this role would lead.  If you believe you can make an impact on our mission, we want you! Key Responsibilities:Build, maintain, and scale our ETL/data pipelines, warehouse analytics infrastructure and work hands-on, helping building workflows/tools and best practices where applicableParticipate in developing state-of-art machine learning solutions to address large scale healthcare problemsDesign and build pipelines that collect, preprocess, and deliver data to be used for business intelligence and data discoveryApply broad knowledge of technology options, technology platforms, design techniques and approaches across the data warehouse life cycle phases to design an integrated, quality solution to address the business requirements and ML roadmapWork closely with the data analyst to help build and identify the insights that will guide day-to-day operations, planning, and strategic decision-makingWrite production-ready software with fast and efficient algorithmsCollaborate with Product, Business, and Data Analyst/Science to prioritize and develop pragmatic solutions to high impact problems To be successful in this role you may have:3+years of experience in machine learning and data engineeringExperience building and optimizing ‘big data’ data pipelines, architectures and data setsHands-on experience with building out full end to end data architecture including ETL/data pipelines, data lake, and data warehouse in AWSStrong analytic skills related to working with unstructured datasetsStrong proficiency in one or more programming languages such as Python, Javascript, or C++Knowledge of machine learning frameworks such as Scikit-Learn, Keras, Tensorflow Experience working in production deployed end to end machine learning solutionsExperience with Natural Language Processing is desiredStrong communication and interpersonal skillsSkill at partnering cross-functionally across organizationAn eagerness to work in an ever-changing, fast-paced startup environment We don’t believe in perfection – we believe in passion, interest, and will – so don’t let a lack of experience or skill in one area listed above deter you from applying. We don’t believe in perfection – we believe in passion, interest, and will – so don’t let a lack of experience or skill in one area listed above deter you from applying. Cleo is proud to be an Equal Opportunity employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.",Intermedio,Jornada completa,Tecnología de la información,"Sanidad, bienestar y ejercicio",22,None,False,,267,None
429,None,None,None,None,None,"DescriptionWe seek a talented Senior UX Researcher to help radically enhance their web and mobile app experience by improving usability and intuitiveness in company products and platforms! Requirements:Sharing your expert knowledge with a design team that wants to develop their skills to be the best in the industryEvangelize user-centered design principles, standards, and best practices across user experiencesSolving problems and bringing business ideas to life, through sketching, research, wireframing, prototyping, designing, testing, and writing (multiple fidelities)Helping the team deliver valuable experiences to customers Qualifications:BA/BS degree in graphic design, communication design, human-computer interaction, or a related field, or equivalent practical experience7+ years’ work experience as a user experience designer or a similar role in a related fieldMUST HAVE's experience user personas, card sorting, journey mapping, wireframes, design navigation itemsExperience participating in the full product development lifecycle of the web, mobile, and/or software applicationsExperience in financial services or similar industries where the goal is to build simple user experience for complex tasksExperience working in cross-functional Product and Engineering teamsThe ability to understand customer needs, motivations, and behaviors and translate them into deliverable tasksExperience creating design artifacts such as (but not limited to), wireframes, user flows, user journey maps, design comps, prototypesWorking with and/or building Design SystemsEffective user research skills (user interviews, usability testing, recruiting, analysis)Good presentation and listening skills, ability to communicate user needs and design rationale to key partners outside of the design team (such as business, legal teams)Ability to manage time, prioritize design and research tasks, and work within deadlines with minimal supervisionIntellectual curiosity and hunger for continuous learning in the industryOptional experience in Agile, Design Thinking, Lean UX or Lean Start-up methodsYou have a powerful impulse to improve existing user experience, invent new experiences, and perform better than company competition  Benefits:Competitive payComprehensive health, vision, and dental coverage20 days paid vacation plus company-wide holidaysAbility to work remotely bar 1-2 days per month onsite meetings in New York CityCompany computer hardware of your choice and a generous contribution to your remote officeVirtual trivia and field tripsGenerous stock options",Intermedio,Jornada completa,Diseño,"Internet, Marketing y publicidad, Medios de comunicación en línea",173,None,False,,810,None
430,None,None,None,None,None,"Senior Machine Learning Engineer (MLOps, Kubeflow, Cloud Computing) We are looking for a Senior Machine Learning Engineer (MLOps, Kubeflow, Cloud Computing) to join a well-funded quantum computing startup (> $60M Series B) whose vision is to break through the global market with their unique cloud software that combines a powerful platform and quantum algorithm libraries to deliver real-world solutions across a full range of classical and quantum technologies. Headquartered in Boston, MA [2nd office in Canada], this company has conducted state-of-the-art research centered around delivering solutions for optimization, simulation & modeling, as well as machine learning across various industries. As a Senior MLOps Engineer, you will work very closely alongside a world-class team of quantum computing experts (collectively > 36,000 citations in the Quantum Computing domain) daily, aiding in the development and optimization of the company's novel quantum workflow platform. The ideal candidate will have experience working with cutting-edge machine learning techniques/frameworks (TensorFlow, reinforcement learning, etc.), hands-on knowledge of model development and deployment into production, and preferably experience working with MLOps pipelines (Kubeflow, guild.ai, etc.). What we can offer a Senior Machine Learning Engineer:·        A chance to develop a 'first-of-its-kind' quantum workflow platform alongside world-renowned quantum computing and software engineering experts·        A collaborative team and culture that looks after talent, cultivate success and celebrates accomplishments as a team·        Intellectual challenges that you would not experience in most companies.·        Competitive salaries, equity and benefits packages Key Skills: Machine Learning (ML), Deep Learning, Reinforcement Learning, TensorFlow, PyTorch, Keras, Machine Learning Operations (MLOps), Kubeflow, guild.ai, Guild AI, AirFlow, MLflow, ML Flow, SaaS, Software as a Service, Cloud Computing, Amazon Web Services (AWS), Google Cloud Platform (GCP), Azure, Model Deployment, Test-Driven Development (TDD), Big Data, Hadoop, Spark, Dask, MapReduce, DevOps, Docker, Kubernetes, Containerization, CI/CD, Jenkins",Intermedio,Jornada completa,"Tecnología de la información, Ingeniería","Software, Servicios y tecnologías de la información",975,None,False,,2322,None
431,None,None,None,None,None,"Title: UX ResearcherLocation: Permanent RemoteJD:Indicate education, experience and any additional traits required to be successful in the role.Experience:·       5+ years experience in Interactive Product Design and User Experience·        Extensive experience in advocating for the observed customer experience and bringing the customer to the forefront of design solutions.·        Design Research and/or Interactive agency experience preferred·        Candidates must be able to show proven experience and understanding current and emerging methods for design research and the externalization of consumer patterns·        Experience in media or retail industry preferred·        Proven ability to work cross-functionally in a multi-function organization·        Relationships within technology and digital media industry·        Proven ability to work cross-functionally in a multi-function and globally based organization·        Extensive experience in design thinking methods and the design of experiments.",Algo de responsabilidad,Contrato por obra,Tecnología de la información,Dotación y selección de personal,24,None,False,,151,None
432,None,None,None,None,None,"Replica is an enterprise data platform that delivers critical insights about the built environment. With better data, human-context and an intuitive design, Replica helps public and private sectors make informed, effective, and responsive decisions. By showing how people live, move and work, we contextualize hard choices, allowing our clients to see around corners and understand the trade-offs surrounding their decisions. Whether for a city planner increasing public transit to underserved neighborhoods or for a grocery chain evaluating where to open a new location, Replica's insights lets clients make more informed, people-centered decisions.  We spun out of Alphabet in 2019 when we secured series A funding from venture firms such as Innovation Endeavors, Firebrand Ventures, and Revolution's Rise of the Rest Seed Fund. Today, we are a team of :30 employees with offices in San Francisco, CA and Overland Park, KS.  We value our customers, believe in being resourceful, and work in service of each other to scale our product. As we build our team, we are committed to pursuing and bringing together a diverse workforce and creating an environment of inclusion. We value our differences and we encourage all to apply. We are committed to equal opportunity regardless of race, color, ancestry, religion, gender, gender identity, parental or pregnancy status, national origin, sexual orientation, age, citizenship, marital status, disability, Veteran status, or any other status protected by the laws or regulations in the locations where we operate.  The Team  Replica's engineering and research team consists of industrial veterans from Google, Uber, Lyft, Dropbox, as well as academic researchers from top research institutes that push the frontier of movement analysis forward. The team is heavily mission-driven, with deep technical expertise on big data processing at scale, production software engineering micro-services, and domain knowledge in the field of movement patterns.  The Role  As our engineering team grows, we are looking for a geo data software engineer working on geo data related data pipelines and data products. As an early member on the team, you will balance speed and quality as you build out new features for our customers.  You will collaborate with engineers, design, research and development, and customers to enable additional methods of querying and create valuable data visualizations for every customer. More specifically, here's what you can expect to do in the role:  Work closely with the customer success team to fully understand their needs and respond quickly to their feedback. Own the process and automation for data intake, QA and data delivery. Identify gaps and invent processes, automated scripts, and tools to efficiently carry out geo data processing tasks in a scalable fashion. Establish testing strategy and best practices. Add logging, observability, and notification for data workflows. Actively contribute to company culture by mentoring engineers, contributing to documentation, and actively collaborating with cross-functional groups.  Technologies: Python, PostGIS, geopandas, Big Query, Java, Python, JTS, Cron.   Minimum Requirements  5+ years of experience working with geo-data engineering projects. 3+ years as a software engineer. Efficiency with automation and tooling languages like python to build reusable components/tools. Proven experience working with data pipelines at scale and knowledge of common big data frameworks, such as hadoop/bigquery. Experience with common geo format (e.g., geojson, geodatabases like postgresql/postgis).  What We Value  Empathy. You are curious and eager to learn more about our users and understand their needs.  Balance. You weigh speed and quality carefully and understand the tradeoffs.  A collaborative approach to problem solving. You've worked with cross functional teams before and you enjoy the process.  Active participation. You jump in and actively engage with the team and customers to build products people use.  Ability to navigate ambiguity. Things get blurry, but you persevere to find clarity and communicate effectively with your teammates to ensure clarity for all. Passion. You are driven to improve the quality of life in urban environments.   Benefits  Our people! We work as a team and are excited to contribute to city planning.  Competitive salary based on experience and potential for impact. Equity at an early stage startup. Health benefits including medical, dental, vision, and HSA option.  401k account + employer contribution. Offices in San Francisco, CA, Overland Park, KS, and remote. Flexible PTO.  If you don't think you meet all of the criteria above, but still are interested in the job, please apply. Nobody checks every box, and we're looking for someone excited to join the team.",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Internet",0,None,False,,41,None
433,None,None,None,None,None,"Responsibilities: • Participate in the search strategy development• Conduct mapping, market, competitive intelligence, internet, and LinkedIn research• Identify search outreach targets (organizations, potential referral sources, and prospective  candidates• Develop outreach target lists• Create search status reports and other reports for clients• Assist with document editing  Experience/Competencies: • A bachelor’s degree • Five plus years of related professional experience• Hands-on experience involving market or prospect research• Highly developed analytical abilities, critical thinking, and problem-solving skills• Familiarity with LinkedIn and online databases/tools• Project management • Strong work ethic, sense of customer service, and responsiveness• Previous experience recruiting or executive search is a plus",Algo de responsabilidad,Contrato por obra,Investigación,"Recursos humanos, Formación profesional y capacitación, Dotación y selección de personal",27,None,False,,136,None
434,None,None,None,None,None,"Vacature van CodeGuild, locatie Utrecht.  Vacancy: Data Engineer Utrecht (Remote)  Does it seem cool to you to have a direct impact on making the world more sustainable?What do you think about working for a tech scale up that raised almost 10 million last year?Would you like to work in very skilled engineering team with one of the brightest minds from the region?Do you enjoy working on complex technical challenges with technologies such as: Python, Spark, Airflow & AWS? Don't wait any longer, because you don't get such an opportunity every day!  Your employer: Well-funded tech scale up has a major impact on making the world more sustainable!  Sometimes there are companies that have remained under the radar for a long time and the moment everyone knows them you think, I wished I have been there when they were a bit smaller. Well here is your chance. This Silicon Valley tech scale up is working hard to make the world substantially more sustainable with bleeding edge technology. We don't see companies like this very often in the region.  The goal is clear here, focus on an industry where the most impact can be made to make the world a more sustainable and green place. Hire the brightest minds from the region and focus on such a technically complex domain and you will enter areas where engineers have hardly been. This is exactly what they have done here, good results have been achieved and thus many millions in funding have been raised to further shape this. And not without result, because they work here for impressive customers such as Google Nest and the biggest EV company!  The organization has its origins here in the Netherlands, so their development hub is also located in the heart of Utrecht. You will work in a very flat and transparent organizational culture. As an engineer you have a lot of freedom and confidence here. For example, the organization has embraced remote working and you can completely determine your working hours yourself and days off are not counted here.  Your role: Data Engineer Utrecht (Remote)  In your role as Data Engineer Utrecht you will work in a highly skilled and experienced team of Data Engineers and Data Scientists. Of course you will also collaborate with other developers like backend & front-end. You and your team will focus various big data challenges around their high available and distributed systems/platform.  So the key project for now are very challenging because you and your team will develop a new Data Lake from scratch. Currently the company has developed other solutions, but as the company is rapidly growing a new data lake is needed.  Also improving current but building new data pipelines will be important. On the roadmap there is a plan for building a brand new Machine Learning forecasting pipeline, which had hardly been done before like the want it. So working here means working on the edge what has been done with technology.  What is being asked?  A technical Bachelor or Master, such as Computer Science or A.IAt least 2 years of Data Engineering experienceSoftware Development experience is a plusExperience with PythonExperience with Spark en/of PySparkExperience with AWS and/or Terraform is a plusExperience with Kotlin, Java and/or Scala is a plusExperience with Elasticsearch is a plusWhat's is being offered?  Salary between € 50.000 and € 75.000 based on knowledge and experienceStock options between € 20.000 and € 30.000The possibility to work 32, 36 or 40 hours & to allocate hours completely freelyBoth remote and office work possible25 vacation days, but these are not trackedLaptop of your choiceHave you always wanted to work for a very well-funded tech scale up that builds products for a sustainable world?     Respond via the form below or send your CV to Serge Warbout, via s.via de button 'Solliciteer nu' op deze pagina.  5cd8a0b9cc68f9ffa4c9253553278a55",Sin experiencia,Jornada completa,Ingeniería,"Construcción, Ingeniería industrial o mecánica, Ingeniería civil",14,None,False,,93,None
435,None,None,None,None,None,"Headspace is looking for a Senior Data Scientist, reporting into the Director of Data Science and Analytics.   We are seeking a talented and experienced senior data scientist to deliver impactful insights to teams across the business. Working closely with the director of data science and analytics, the senior data scientist will develop models to solve business problems and improve the member experience. The individual will have the opportunity to inspire and mentor additional members of the team in all things data-related. A successful candidate will be technically strong, proficient in communicating results to a range of audiences, and excited to share their knowledge with other team members  Location: This role is open to remote employees in select US states: California, New York, Florida, Georgia, Texas, Maryland + Washington DC, North Carolina and Washington.  About The Senior Data Scientist Role At Headspace Train, test, and tune machine learning models for a variety of problems across the businessManage all aspects of data science projects from start to finish, including early conversations with stakeholders and presenting results to executivesWork with the Director of Data Science & Analytics to pave the way for actionable data science in a high-growth, mission-driven organizationIdentify opportunities to apply data science and machine learning towards unaddressed business problems, or to improve existing aspects our data science infrastructureThis role will be a pillar of Headspace’s core strategy moving forward to emphasize and leverage data science throughout the business  What You’ve Accomplished Bachelor degree in computer science, statistics, applied mathematics, or any scientific or computational degree, Masters/Ph.D. preferred5+ years of experience developing machine learning models and putting them into production5+ years delivering analytical insights to stakeholdersExperience managing data science projects from conception to completionExperience with user behavior, mobile app, and subscription business a plusDeep understanding of statistics, experimental design, and machine learning algorithmsCommitment to using best practices in data scienceStrong programming skills in Python, experience with pySpark is a plusStrong SQL skills, experience with AWS services a plusStrong ability to communicate complex ideas and results to both technical and non-technical audiences  How We Feel About Diversity & Inclusion  Headspace is committed to bringing together humans from different backgrounds and perspectives, providing employees with a safe and welcoming work environment free of discrimination and harassment. We strive to create a diverse & inclusive environment where everyone can thrive, feel a sense of belonging, and do impactful work together. As an equal opportunity employer, we prohibit any unlawful discrimination against a job applicant on the basis of their race, color, religion, gender, gender identity, gender expression, sexual orientation, national origin, family or parental status, disability*, age, veteran status, or any other status protected by the laws or regulations in the locations where we operate. We respect the laws enforced by the EEOC and are dedicated to going above and beyond in fostering diversity across our workplace.  Applicants with disabilities may be entitled to reasonable accommodation under the terms of the Americans with Disabilities Act and certain state or local laws. A reasonable accommodation is a change in the way things are normally done which will ensure an equal employment opportunity without imposing undue hardship on Headspace.  Please inform our Talent team if you need any assistance completing any forms or to otherwise participate in the application process.  How To Get Started  If you’re excited by the idea of seeing yourself in this role at Headspace, please apply with your CV and a cover letter that best expresses your interest and unique qualifications.",Algo de responsabilidad,Jornada completa,Otro,"Servicios y tecnologías de la información, Software, Internet",41,None,False,,384,None
436,None,None,None,None,None,"DescriptionData EngineerMeow Wolf Inc.Status: Full-timeDivision: Attraction OpsSub-Division: AdministrationDepartment: Core ServicesWork Location: RemoteReports to: Director, Digital OpsProject Hire: NoJob Description:Meow Wolf is seeking a data engineer to join a cross-functional team that is building new and amazing enhancements to Meow Wolf’s customer experiences. This is a highly technical position that will require a good breadth of web technology and database experience, and a relentless drive to innovate. We are building next-generation products and experiences that integrate cutting edge technology into the broader Meow Wolf ecosystem and we need someone who is passionate about bringing these new experiences to life while remaining flexible to change and incorporating new learnings along the way. Job Responsibilities:Participate in Requirements Gathering: work with key department leads and our product manager to understand department-level data needs for data flowsBuild and maintain critical data ETLs leveraging best-practices in security and data fidelityMaintain and optimize our data warehouse (Big Query)Plan and architect new data flows for our current and future data gapsSupport Operations: triage alerts channeled to you and remediate as necessaryTechnical Documentation: create clear, simple, and comprehensive documentation for data flows and ETLsCoordinate releases with DevOps, leverage Github issues, and manage pull requests for the data projectsReasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. Required Qualifications:3+ years of experience in Python. Having built ETLs in Python is a huge advantageExtensive experience working with REST-based APIsStrong analytical thinking and problem-solving skills with the ability to navigate highly complex and ambiguous situationsAdaptable, enterprising, and willing to take ownershipA high-quality bar: just-enough documentation, unit testing, code reviews, test automation, continuous integration & deploymentA preference for Agile development methodologiesGreat communication skills - ability to think creatively and adapt the message to the audienceDesired Qualifications:The following are not required but are pluses:DockerGoogle Cloud PlatformGithub / GitflowAgile / ScrumWork Environment and Physical DemandsTo perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed must be representative of the knowledge, skills, minimum education, training, licensure, experience, and/or ability required.Work Environment: The position will be in an office space and have the option to work remotely.Physical Demands: There are no physical demands for this position.The employee will comply with company and OSHA standard workplace safety protocols. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. Work ScheduleThis is a full-time position, and hours of work and days are Monday through Friday, 9 a.m. to 5 p.m. or 10 a.m. to 6 p.m. Occasional evening and weekend work may be required as job duties demand. Supervisor ResponsibilitiesThis position does not require supervisory responsibility TravelTravel is not required for this position. Other DutiesPlease note this job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee for this job. Duties, responsibilities and activities may change at any time with or without notice. Apply View All JobsPowered by  Privacy Policy",Algo de responsabilidad,Jornada completa,"Ingeniería, Otro",Entretenimiento,25,None,False,,201,None
437,None,None,None,None,None,"w2 only. Accepted work statuses: USC, GC, OPT, CPT, H4 Location: Remote, Charlotte, NCDuration: 12 months Responsibilities & Duties:The Data Science Consultant will be responsible for forming and maintaining strategic relationships within and between business units through proactive engagement, consultation and project leadership in the area of advanced analytics including: advanced analysis, data exploration, data mining, data visualization, reporting, and dash-boarding.The incumbent will need to work with groups across the enterprise to ensure that these efforts are successful through expert planning, guidance, advice, and execution. Frame Problems with Stakeholders: Ability to research and construct problem frames in order to understand the analysis context and scope that will provide timely, useful results.Work in Project Teams: Ability to participate in multidisciplinary analytics project teams.Interview Subject Matter Experts: Ability to plan and conduct individual interviews with experts to gain valid information and data needed for analysis.Elicit Information from Groups: Ability to plan and conduct group elicitation sessions with committees or other working groups to develop and assess alternatives, uncertainties, and value and risk preferences. Desired Qualifications:Masters degree in analytics-related fieldPossesses a working knowledge of statistics, programming and predictive modeling.Possesses code writing abilities in languages like Python and SQL (Structured Query Language).Familiar with Big Data technologies such as HDFS, Hive, Pig, Spark.Experience with Cloud technologies such as AWS and Azure.Experienced developing models with artificial neural network architectures such as TensorFlow and PyTorch.Experience developing Natural Language Processing solutions and/or Computer Vision solutions.",Intermedio,Contrato por obra,"Ingeniería, Tecnología de la información",Servicios y tecnologías de la información,41,None,False,,162,None
438,None,None,None,None,None,"Holiday bonus·       410K match·       Unlimited vacation·       Standard holidays off - Paid·       Some of the best health, optical and dentalbenefits out there·       Wellness contribution·       Free products Title: Principal Data EngineerLocation: RemoteType: Direct hire Description: Seeking a Principal Data Engineer for a direct hire position. The position reports to the Director of Global Data Engineering and participates in a collaborative team environment. The company is migrating from Datastage ETL to Redshift / Matillion. Looking for a candidate to contribute to the strategy and development of the Enterprise Data and Analytics Platforms. Mentoring is a key component of this role. Required Skills:1) Expertise in data engineering / data movement in a Big Data anvironment.2) Matillion ETL3) Redshift4) Python5) Lead / Principal level",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Servicios y tecnologías de la información,17,None,False,,78,None
439,None,None,None,None,None,"Join a team of passionate thought leaders in a dynamic and collaborative environment! New Signature's Data & AI team is growing fast and we're looking for our next Azure Data Engineer to join us.  Role Description  What's the story?  As we continue to scale we're looking for the market's best Azure Data & AI specialists to help us grow our business' fastest growing practice, AppDev & Data. You'll be working with the industry's biggest players, delivering innovative greenfield Data Platform builds, Data Integration programmes and implementing bespoke High-Level Data Architectural designs.  Who we're looking for:  Strong experience using Azure Data components  (ADFv2 , Azure SQL DB, Azure SQL Datawarehouse, Azure Data Lake, Azure Databricks ...) Specific focus Azure Databricks or Databricks platform Excellent knowlegdge of Apache Spark ecosystem (SPARK 2.3x) Databricks Delta Lake  Strong Python programming  Build distributed in-memory applications using PySpark  Spark APIs - RDD, Datasets & Dataframes  Knowledge of C# highly desirable Experience with Power BI Agile methodolgy experience essential CI/CD, Azure DevOps experience, highly desirable  Why do people like working here?  Remote working Flexible hours  Who are New Signature?  We are a Microsoft house, born in the Cloud. The 2017 Acquisition of Paradigm Systems & Dot Net Solutions by New Signature accelerated a suite of capabilities to support the world's most prestigious and recognisable brands, helping them to become digital organisations powered by the Cloud.  We have over 500 people across the UK, US, Canada, South Africa, the Philippines and Australia, with our UK office growing over 70% YoY and headcount more than tripling.  How has this been possible?  Our values of being Generous, Authentic, Innovative and most importantly, Human, has enabled a unique approach to provide outstanding customer experiences, drive transformational results for clients across all company sizes & successfully deliver pioneering solutions that challenge the status quo. We've quickly established ourselves as a recognized expert at the forefront of Microsoft's technology stack with exceptional services to empower our customers, colleagues, and community.  Join us today and be part of the success story!  OUR CORE VALUES  Our employees are driven by our values and know that they make a positive difference every time that they help a customer to solve their challenges. Our focus on delivering great customer experiences empowers our people to build rewarding relationships that contribute to our positive work environment. You can learn more about our culture here:  New Signature Culture  Human  We use our hearts and minds to collaborate for success.  We harness technology to drive business, but we never let that replace our human connections. We use our hearts and minds to collaborate for success and instill confidence in our customers through relationships forged from trust.  Generous  We are giving and respectful.  With our efforts to always be generous, we elevate our service level with empathetic and considerate communications and actions. We always find a way to support our customers and colleagues by giving of our time and talent and equally respecting the time and talent of others.  Authentic  We tell it as it is, with positive intent.  Being authentic helps to nurture our strong and trusted relationships. We are honest, transparent, and reliable. When you partner with New Signature, you are partnering with a group of purposeful, outcome-driven and results-oriented professionals.  Innovative  We push the boundaries at the intersection of people, process and technology.  For us, there are no limit to our dreams. We continually innovate and push boundaries at the intersection of people, process, and technology to bring our customers and colleagues the best solutions first.  EQUAL EMPLOYMENT OPPORTUNITY  As a Global Cloud Transformation Consultancy business, New Signature understands diversity and inclusion in the workplace brings benefits to our customers, our business and most importantly, our people. We are committed to being an inclusive employer and we provide equal employment opportunities to all employees and applicants for employment.  New Signature prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other factors protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including all aspects of the recruiting and employment life-cycle at New Signature.  EMPLOYMENT ELIGIBILITY  New Signature requires candidates to prove eligibility to work in the UK. Offered candidates may be asked to complete a background check as permitted by applicable employment regulations. Depending on the requirements of the job, these record checks may include any or all of the following education verification, employment verification, drug screening, and criminal record check.",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Servicios financieros",12,None,False,,56,None
440,None,None,None,None,None,"User Researcher - Remote (UX/Agile) - London  £50k  My client, an award-winning Media House is looking for a creative and driven User Researcher to join their friendly team.  This role is based predominantly at home for now and some travel to London is needed once they return to a new normal  What will the role involve?  Planning and executing user research studies throughout the design and development lifecycle, from early strategic direction through post-release validation.  Employing a wide range of research methods, including generative design research and contextual inquiry, participatory design workshops, interviews, formative and summative usability studies, and quantitative methods, such as surveys and data analytics.  Developing and using relationships across the company to understand existing research and insights and identify impactful research questions, and collaborate on end-to-end research that looks across the customer journey.  Leading workshops with cross-functional teams to ensure that findings and insights are translated into actionable product goals and direction.  Sharing customer insights with the broader organisation in creative ways to increase customer empathy, including posters, immersion rooms, blog posts, and workshops.  Iterating and improving the processes within the user research community at Reach.  Who are we looking for?  Experience in research You will have a strong track record of qualitative research leading to results impacting product/UX strategy and development. You will have worked closely with quantitative experts and knows how to blend this with qualitative research to synthesise actionable insights. You will possess an up-to-date toolkit of research methods and the experience and savvy to know when to be lean and scrappy and when to be rigorous. The ability to collaborate with a wide set of stakeholders including UX and UI designers, product managers, and software developers.  It would be great if you had the following, although not essential:  Familiarity with the news and media industries. Experience researching multichannel experiences. Familiarity with Lean UX and Lean Research methodologies. Experience with agile software development. Experience identifying and implementing process improvements for research teams. A passion for Accessibility and Inclusive Design  Important Information: We endeavour to process your personal data in a fair and transparent manner. In applying for this role, Additional Resources will be acting in your best interest and may contact you in relation to the role, either by email, phone or text message. For more information see our Privacy Policy on our website. It is important you are aware of your individual rights and the provisions the company has put in place to protect your data. If you would like further information on the policy or GDPR please contact us.  Additional Resources Ltd is an Employment Business and an Employment Agency as defined within The Conduct of Employment Agencies - Employment Businesses Regulations 2003",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Dotación y selección de personal, Servicios financieros, Atención sanitaria y hospitalaria",8,None,False,,30,None
441,None,None,None,None,None,"Job Title: Product Data AnalystHourly Rate: $50 - $55.17hr. W2 ONLYLocation: Remote (FOR NOW) - MUST be willing to RELOCATE to: Menlo Park, CASeattle, WANYCLength: 6 month contract (opportunity for extensions up to 2 years)   Day 2 Day:A large networking company in Menlo Park, Seattle, and NYC is looking for 8 Product Data Analysts to join their Marketplace/ECommerce data science group. A strong candidate will have a background within Product Analytics or Data Science to help derive insights from large sets of data. Strong SQL skills are required with a knowledge of product insights. Strong product sense is important and this resource should be able to identify the Health, growth, and engagement of an application. As well as have a background in experimentation - A/b testing to test new features being implemented onto the web/mobile platform. These data scientist contractors will be working with their team to code, generate insights, and make recommendations about the product to their teams.   Must Haves: 3+ years experience in Data Analytics/Data Science and product analytics. - Fluency in SQL. - Ability to communicate the results of analyses in a clear and effective manner with product and leadership teams - Good understanding of statistics A/B testing (e.g., hypothesis testing, regressions). - Ability to understand Feature implementation on a Web/Mobile product",Intermedio,Contrato por obra,Tecnología de la información,"Marketing y publicidad, Venta al por menor",306,None,False,,1060,None
442,2220569564,2020-10-28,Mindoula,Data Engineer,"Silver Spring, Maryland, United States","About UsMindoula is a next-generation behavioral health management company that delivers tech-enabled, team-based 24/7/365 behavioral health support across the continuum of care. We are building the best population health management and analytics platform by using the latest technologies in big data and data science. Also, we are developing a comprehensive platform to address the needs of pre and post hospital care for large populations.We are currently seeking to fill in multiple roles in technology and data to help build great technology helping Mindoula to grow faster. About YouWe are looking for a talented data engineer who is well versed with SQL, database optimization, data processing platforms & analytics. Responsibilities:Be part of the data team, collaborate with product and engineering teams in developing the data required to support the functionality and new features of our platforms.Manage ingestion process of various input data sources (healthcare, claims data etc) and develop/maintain the common schema to store the healthcare information of members.Manage tools and processes to process the data to derive key insights and analytics to power the intelligence of our platform.Must be self-driven and a quick learner.Requires strong problem-solving, analytical and communication skills.Healthcare data experience is a plus. Technologies:Data Platforms: Spark, Python/Scala.Strong SQL experience.Databases: Postgres, Microsoft SQL ServerHosting: Microsoft AzureTools: Github, CircleCI, CodeClimate Requirements:Minimum 3 years of experience in positionHealthcare experience with managing claims data Compensation:Competitive salary.Generous benefitsThis position is open to both as an employee or as a contractor/consultant.",Intermedio,Jornada completa,Tecnología de la información,Atención sanitaria y hospitalaria,208,None,True,,487,ACTIVELY_HIRING_COMPANY
443,2228688020,2020-10-22,Realogy Holdings Corp.,Talent Researcher - Remote,"Madison, NJ, US","Job Description  Location information The ideal candidate will be located within a commutable distance of our Madison, NJ office. This role will be remote through year-end.  Summary Of The Role  You’re inquisitive, insightful and analytical. As the new Talent Researcher, you will focus on strategically building a robust talent pipeline by conducting in-depth talent and market research and utilizing data-driven sourcing strategies. Whether you are leveraging our business intelligence or managing our referral network data to find hidden talent, you’re able to effectively assess and match the right person, for the right job, right now and for the future.  To Succeed In This Role, You Will  Your responsibilities  Research and provide business intelligence and market data to support talent acquisition and planning practices.  Work to improve upon existing talent acquisition and planning processes and develop innovative talent and market data strategies.  Partner with recruiters and other team members to research, data mine and build creative strategies around sourcing and attracting the best talent for complex, hard to fill roles.  Effectively leverage all of our talent planning sourcing tools to build a more qualified talent pipeline.  Utilize direct and indirect sourcing techniques, including complex internet searches, social/professional networking, diversity resources and competitor research, and effectively assess talent to build a strong network of passive candidates.  Recommend and drive improvements to build talent pipelines and execute on research, referral generation, hiring events and data sourcing campaigns.  Proactively and independently identify, screen and qualify candidates through research, sourcing, networking, and detailed assessment using behavioral-based interviewing.   Who You Are  To succeed in this role, you are someone who:  Is a data guru and keeps abreast of trends and new ways of doing things in talent research  Operates confidently with minimal supervision and responds positively when it is provided  Looks ahead to identify potential roadblocks or diversions and acts to avoid them or to limit their impact  Willingly takes on new ideas and ways of doing things: sees them as opportunities rather than challenges   Qualifications  Bachelor’s degree in business, human resources, I/O psychology or related area preferred. Master’s degree a plus.  Experience in market/research intelligence  Advanced analytical skills and extensive experience working with large data sets  Data and systems savviness- extensive experience using people-related tools and systems  Experience synthesizing talent market data and insights to influence decisions within hiring stakeholders and cross functional teams  Experience in managing and prioritizing multiple strategic technical searches, projects and key stakeholder relationships  Demonstrated experience sourcing and assessing Technology and/or Sales talent  1-3 years of experience with passive recruiting techniques, including utilizing LinkedIn and other social networks for talent. Ability to think outside the box for targeted selection and creative sourcing  Advanced skills with Microsoft Office suite and applicant   Our Commitment to Diversity   At Realogy, diversity fuels success – for our company and for our employees. We strive to be the preferred company for diverse talent, committed to creating an inclusive environment that encourages everyone to succeed. We pursue talent – strategic thinkers who are eager to innovate, focused on execution and accountable for results. We value diversity – respecting backgrounds, cultures, perspectives. You’ll find our commitment to diversity reflected in our achievements:  Forbes 2020 Best Employers for Diversity.  Recognized on the 2020 Human Rights Campaign Corporate Equality Index .  Recognized for gender diversity on our board of directors by Executive Women of New Jersey and Women’s Forum of New York.  First residential real estate company to endorse the Equality Act and fully support H.R. 1447 amending the Fair Housing Act to include LGBTQ+ as protected classes.  With diversity, we succeed together. We hope you’ll join us.  Employment Type Full-time  Company  Realogy Holdings Corp  About Us  Realogy is a global provider of real estate services with a singular mission: We serve agents. This strategy is aimed at growing the base of high-performing independent sales agents at our company-owned and franchisee brokerages, providing services to make them more productive and their businesses more profitable.  While you won’t see our name on For Sale signs, you will see those of our industry-leading brands: Better Homes and Gardens Real Estate, Century 21, Citi Habitats, Climb Real Estate, Coldwell Banker Real Estate, Corcoran, ERA Franchise Systems and Sotheby’s International Realty to name just a few. Our four business units work together to provide a full-service solution to meet the needs of agents and their homebuying clients, from the initial listing until the keys are turned over.  Realogy was recently designated a Great Place to Work® for the second consecutive year, recognizing the company’s commitment to providing meaningful work and an environment where employees can grow and succeed. Realogy has 16,600 offices and approximately 302,000 affiliated brokers and agents worldwide. We’re the leader in residential real estate sales, with $6.1 billion in revenue in 2018, nearly 1.4 million real estate transactions and approximately 16 percent of market share of the U.S. residential real estate market. We’re there to serve agents who help people find and buy houses, move, and finance their dream. EEO Statement EOE AA M/F/Vet/Disability",Algo de responsabilidad,Jornada completa,"Investigación, Análisis, Tecnología de la información","Servicios y tecnologías de la información, Software, Servicios financieros",55,None,False,,809,COMPANY_RECRUIT
444,2219301826,2020-11-05,Irvine Technology Corporation,Senior Data Engineer - Apache Spark,"98109, Seattle, Washington, United States","Senior Data Engineer - Apache SparkCurrently remote through 3/2021Then will need to be onsite in Seattle, Wa IMMEDIATE NEED for a Senior Data Engineer. You will get the oppportunity to deliver large-scale, critical, and complex data architecture, storage, and pipelines for internal clients within this World Class Financial Services Organization. Great salary, incredible Health and Retirement benefits at this premier organization. Responsibilities:Build large-scale distributed data processing systems, data lakes, and optimize for both computational and storage efficiency on cloud platforms like AWS.Design, implement and automate data pipelines sourcing data from internal and external systems, transforming the data for the optimal needs of various systems.Design data schema and operate cloud-based data warehouses and SQL/NoSQL/temporal database systems.Develop batch and streaming pipelines using technologies including Apache Spark and Kafka.Own the design, development and maintenance of ongoing metrics, reports, analyses, dashboards, etc. to drive key business decisions.Monitor and troubleshoot operational or data issues in the data pipelines.Drive architectural plans and implementation for future data storage, ETL, reporting, and analytic solutions.Provide insightful code reviews, receive code reviews constructively and take ownership of outcomes (“you ship it, you own it”), working very efficiently and routinely deliver the right things in the front-end UI area.              Qualifications:BS in Computer Science or related field, or an equivalent in relevant work experience.Experience implementing big data processing technology: Hadoop, Apache Spark, Kafka, etc.5+ years of Coding proficiency in at least one modern programming language (Scala, Python, or Java).Experience writing and optimizing advanced SQL queries in a business environment with large-scale, complex datasets.3+ year’s experience in cloud-first design, preferably AWS (S3, Kurbernetes, dynamic autoscaling, etc.).Experience in data architecture, databases (e.g., SQL Server, Oracle, PostgreSQL), SQL and DDD/ER/ORM design. Experience with NoSQL databases such as graph databases, wide column stores, etc.) are a plus.Interest and curiosity in emerging technologies on the web like GraphQL, web assembly, MLaaS etcKnowledge of software engineering practices & best practices for the software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations. Please send your resume to Marc Rodriguez, Senior Technical Recruiter for immediate consideration. Let us help you secure an interview! You can also connect with Marc Rodriguez on Linkedin: https://www.linkedin.com/in/technicalrecruiter/ ﻿ABOUT USIrvine Technology Corporation (ITC) is a leading provider of technology and staffing solutions for IT, Security, Engineering, and Interactive Design disciplines servicing startups to enterprise clients, nationally. We pride ourselves in the ability to introduce you to our intimate network of business and technology leaders – bringing you opportunity coupled with personal growth, and professional development!  Join us. Let us catapult your career! Irvine Technology Corporation provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, Irvine Technology Corporation complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities.",Intermedio,Jornada completa,Tecnología de la información,Servicios financieros,40,None,True,,148,ACTIVELY_HIRING_COMPANY
445,2224723015,2020-11-03,Airvet,Data Engineer,United States,"Airvet Data Engineer This is an exciting opportunity to join a sharp, entrepreneurial team and have a real impact. We are seeking a talented Data Engineer who has a passion for using data to help the company make informed decisions. As a data engineer, you will collaborate with various departments and help them make data-driven decisions. You will be working with engineers and business to  Airvet is a fast-growing start-up in Los Angeles that just closed a $14m series A round. Our telemedicine platform enables veterinary practices to provide complete care to their clients. Our unique product offers solutions to both businesses and pet parents. During these unprecedented times, Airvet has continued to grow and thrive by helping practices offer new and creative ways to continue to provide care to clients. Join our team and help us continue to grow, adapt and thrive. What You’ll Need3+ years experience in Python.Must be very proficient with SQL.Must have experience with Airflow.Must have experience with Looker and lookml.AWS knowledge of EC2, Redshift. Nice to haveIntegration experience with Stripe.Integration experience Salesforce.Integration experience Quickbooks.Integration experience Amplitude or similar. What You’ll DoDesign, build and maintain ETL pipelines.Work with the stakeholders to extract  Why We Want to Hire YouYou have an insatiable need to learn about new tools and languages and love to build. It’s not your first rodeo. You’ve thrive in a fast-paced environment with changing priorities. You get the customer and the business. You want to do more than just build but really understand who you are building for and the benefits you are providing to the customer.",Sin experiencia,Jornada completa,Tecnología de la información,Veterinaria,204,None,True,,686,JOB_SEEKER_QUALIFIED
446,2275946442,2020-11-04,DDI | Development Dimensions International,Data Engineer,United States,"The Data Engineer will help design, build, and support our data and insights enablement solutions in the cloud. As part of an Agile solutions team, they will work to implement purpose-built data solutions for our internal and external stakeholders.ResponsibilitiesWork with a team to design, implement, and document best practices for data in the cloud.Collaborate on the strategy of new cloud data stores and migration of existing data.Be an advocate for quality and security through data quality and accuracy validation and while using security best practices.Work collaboratively our product owners to understand requirements and business problems: to propose and develop solutions that enable effective decision-making through analytics and support insights that will drive our business growth.Support our cloud data platforms as part of an agile team.Preferred Qualifications1+ years’ experience working with Azure DatalakeExperience with modern data platforms, such as Databricks, Synapse, Snowflake, etc.Experience with Git and Azure DevOps, JSON.Scripting languages: Python, PowerShell.Experience working with data visualization tool – Power BI, Tableau, etc.Interest in designing and implementing data management, querying, and storage systems.Ability to build data sets and data pipelines.Experience in software engineering with full stack .NET development experience.Experience with JavaScript frameworks - Angular, React.Experience with Microsoft SQL Server.Experience working in Azure.Strong Written and verbal communication skills.",Intermedio,Jornada completa,Tecnología de la información,Recursos humanos,70,None,True,,242,ACTIVELY_HIRING_COMPANY
447,2258245842,2020-10-30,DISYS,AWS Big Data Engineer,"Tampa, Florida, United States","DISYS is currently looking for an AWS Big Data Engineer for a REMOTE contract to hire position. The AWS Big Data Engineer will design and develop data pipelines using AWS Big Data tools and services and other modern data technologies. In this role, AWS Big Data Engineer will play a crucial part in shaping the future big data and analytics initiatives for many customers for years to come! The position is 100% remote.  Candidates must be able to work without visa sponsorship currently and in the future. No Corp to Corp will be considered. Job Description for the AWS Big Data Engineer:Build end-to-end big data pipelines on AWS, including:Ingestion/replication from traditional on-prem RDBMS (e.g. Oracle, MS SQL Server, IBM DB2, MySQL, Postgres) to AWSStreaming ingestion with Kinesis Streams, Kinesis Firehose, and Kinesis AnalyticsChange Data Capture (CDC) logic and partitioningETL and Analytics with AWS Glue, Glue Streaming, EMR, Spark, Presto, Athena, Flink, Python, PySparkRefactoring of existing RDBMS scripts (e.g. PL/SQL. T-SQL, PL/pgSQL) to PySpark jobsBuildout of data warehouse and published data sets using RedShift, Aurora, RDS, ElasticSearchPython scripting with AWS Lambda Requirements the AWS Big Data Engineer MUST have:Must have experience building end to end pipelines on AWS.3+ years of experience in software development with Python2+ years of development experience with Spark/PySpark, Pandas3+ years of database development experience with RDBMS, including development of stored procedures2+ years of ETL development experience2+ years of hands-on data engineering on AWS, including S3, Kinesis, Glue, Athena, RDS/Aurora, RedShiftAWS Solutions Architect Professional and Data Analytics Specialty (formerly Big Data Specialty) Certifications are a plusA Bachelor’s Degree from an accredited college in Computer Science or equivalent experienceExcellent communication skills",Intermedio,Contrato por obra,"Tecnología de la información, Ingeniería, Diseño",Servicios y tecnologías de la información,47,None,True,,168,ACTIVELY_HIRING_COMPANY
448,2275505460,2020-11-04,Healthgrades,Machine Learning Engineer,United States,"Healthgrades is focused on providing trusted information that helps consumers and providers make meaningful connections. As a Machine Learning Engineer, you will be building the future of Healthgrades’ data science solutions, enabling health systems, hospitals and providers to better reach the right consumers. The Healthgrades enterprise data platform will enable health systems to create a holistic patient view, eliminate data silos, and improve patient experience. This enterprise platform will bring together once disparate data into a single platform, breaking down data silos and making data more useful across an entire organization. The Healthgrades data platform will also serve as the underlying data management solution for powering Healthgrades CRM and other customer experience execution systems while enabling health systems to reach beyond traditional efforts to improve and manage patient experience and patient engagement. If you are a technologist and your idea of fun is to play with the latest technology, while delivering a world-class product designed from scratch, you will fit right in. What You Will Do:Work with a team of Data Scientists and Engineers to create products that will directly affect the mission of HealthgradesDevelop models in cutting-edge machine learning frameworksDevelop data pipeline features to process incoming healthcare information quickly and reliablyReview other team members' code for correctness and qualityWrite automated scripts that power a continuous delivery pipelineRemove roadblocks to development through collaboration, communication, and creative solution recommendationsRecommend and drive development best practices and continuous integration and delivery as part of a forward-thinking, agile organization What You Will Bring:5+ years of experience in Python or ScalaProficiency with Apache Spark or DatabricksExperience developing data pipelines or ETLsStrong understanding of SQL, relational databases, columnar data warehouses, and data modelingStrong knowledge of GitFamiliarity with MLFlow or similar tool.Familiarity with Docker.Ability to instrument basic automation and CI/CDAble to build base-line models with Tensorflow, Pytorch, or other machine learning frameworks.A bias towards self-education of new technologies, techniques and methodsTest-and-learn mentality – you pivot quickly when an approach is not successful Why Healthgrades?At Healthgrades, we recognize that our people drive our greatest achievements. We are passionate about maintaining a fulfilling, rewarding and high-energy work environment while setting the stage for your continued success.Meaningful Work – empowering consumers with data to make the right decisions for themselves and their familiesChanging the Game - evolving, dynamic culture with career advancement opportunitiesCommunity Builders- participating in local charity organizations and wellness initiativesRobust Perks – generous PTO, 401k contributions, tuition assistance, entertainment discounts & more!",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Atención sanitaria y hospitalaria,136,None,True,,528,ACTIVELY_HIRING_COMPANY
449,2273490475,2020-10-20,Sapp Brothers Petroleum,Researcher - Fleet Sales (Remote Position),"Omaha, NE, US","Researcher -- Fleet Sales  *Remote Position*  Sapp Bros., Inc., a growing chain of travel centers, is looking for Researcher to join our Fleet Sales team. At Sapp Bros., Inc. our mission is to treat every customer as 'our guest' by providing a",Algo de responsabilidad,Jornada completa,"Gestión, Manufactura","Restaurantes, Alimentación y bebidas, Venta al por menor",2,None,False,,18,JOB_SEEKER_QUALIFIED
450,2176240945,2020-10-12,iFit,Data Engineer (Remote),"Logan, Utah, United States","At iFit, we do remote teams right. Join a great company that is growing fast and with the right work/life balance. iFit empowers people to change their lives and achieve sustainable, healthy results. iFit's focus is to connect everybody to everything fitness. We believe a healthy lifestyle should be fun, so we constantly push the limits to bring our customers state-of-the-art products that will help them in every aspect of their lives. SummaryAs a Data Engineer, you will take on big data challenges in order to deliver insightful analytics. You will build data pipelines and data models that will empower engineers and analysts to make data-driven decisions and deliver a deep understanding of the business. Your attention to detail will provide the stakeholders with the highest standard in data integrity.  Essential Duties and ResponsibilitiesUse an analytical, data-driven approach to drive a deep understanding of our business.Build data pipelines and data models that will empower engineers and analysts to make data-driven decisionsBuild data models to deliver insightful analytics Deliver the highest standard in data integrityStrong analytical skills with ability to analyze and project sales, subscriber, and engagement data. Performs competitive analysis, reviews industry information for current trends and opportunities. Works closely with analytics teams to develop comprehensive analytical reports to enable data-driven decisions to increase engagement and conversions of target customer segments.  QualificationsExperience in business intelligence, analytics, or an equivalent analyst position with experience in SQL and an additional object-oriented programming language (e.g., Python, Java).High level of expertise in data modeling.Effective problem solving and analytical skills. Ability to manage multiple projects and report simultaneously across different stakeholders.Structured thinking with ability to easily break down ambiguous problems and propose impactful data modeling designs.Attention to detail and effective verbal/written communication skills. Education and/or Experience Bachelor’s degree in Engineering, Computer Science, Statistics, Economics, Mathematics, Finance, a related quantitative field, or equivalent practical experience.2-6 years of experience in consulting, business intelligence, analytics, or an equivalent analyst position with experience in SQL and Python. Language Skills Ability to effectively and accurately present information to customers, coworkers, and managers. Reasoning Ability Ability to define problems, collect data, establish facts, and draw valid conclusions.  Physical Demands The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. While performing the duties, the employee is regularly required to sit and talk or hear. The employee is frequently required to stand and walk. The employee must occasionally lift and/or move up to 25 pounds. Specific vision abilities required by this job include vision, and color vision. Work Environment The work environment characteristics described here are representative of those an employee encounters while performing the essential functions of this job. The noise level in the work environment is usually moderate. Typical office environment. About us We're a group of talented designers, developers, marketers, and sales associates that are part of the larger, 2,000+ ICON Health & Fitness corporation. We have the flexibility and feel of a startup company with the security and benefits you would find in a broader corporate environment. iFit is comprised of both on-site and remote employees. We are headquartered in Logan, UT and you are welcome to work from the office or mostly anywhere else in the US (there are a few exceptions). We are very experienced and comfortable working in a remote-friendly environment. We currently use Slack, Zoom, and Google to keep our communication alive and engaged!  Perks Excellent health, vision, dental insurance 401k match Excellent PTOMacBook Pro and external monitorA cell phone of your choice + monthly phone plan Free piece of fitness equipment of your choiceSemi-annual team meet-ups Continuing education opportunitiesHighly competitive salary and compensation packageYearly performance/pay evaluation  stackoverflow.com/jobs/companies/ifit#tech-stack-itemshttps://www.ifit.com/aboutus  List of states we are able to hire in: AR, AK, AZ, CA CO, CT, FL, GA, ID, IL, IN, KS, MA, MI, MD, MN, MO, NC, NH, NJ, OH, OR, PA, SC, TN, TX, UT, VA, WA, WI.",Intermedio,Jornada completa,"Análisis, Finanzas, Estrategia/planificación","Sanidad, bienestar y ejercicio",185,None,False,,775,ACTIVELY_HIRING_COMPANY
451,2000008427,2020-11-05,Conjoint.ly,Quantitative Market Researcher,Argentina,"Conjoint.ly is on a mission to automate market research. We offer quantitative research services to big and small companies (mostly in USA and Europe). Through automation, we slash costs and increase speed for our clients, but maintain a human connection and high research quality. As we grow (in number of products that we offer and in clients’ awareness of us), we are looking for a junior to mid-level market researcher to join our team on a remote basis. This job wins over working for a normal market research firm for the following reasons:We aim not to do the same thing twice. If it needs to be repeated, we must automate it.We are recognised as experts in the research methods that we do and clients will listen to your advice.You will have opportunities for professional growth as fast as our operations grow. Your role will not be limited to a single area and will include:Research on projects commissioned by clients. As a key client contact, you will support them from proposal to delivery of results on some of the most complex and interesting custom projectsCustomer support and advice: Helping our users do the best market research on our platform, including consulting them via email and over the phoneProduct development: Preparing documentation, algorithms, and other materials. Requirements:A strong interest in quantitative market researchBachelor's degree or equivalentExcellent skills in statistics. For example, you must be able to write code in R (preferred) or PythonNative or near-native profeciency in both English and Spanish Preferred skills:Experience at a market research agency or in-house data science or insights function, using common market research methodsSeveral years of experience in Excel. Being able to make a client-friendly customised models Application process will consist of the following stages:Apply on LinkedInWe will contact you for two or three interview roundsYou will be invited for IQ tests, practical tasks in Excel and other softwareReference checks Please contact us for any questions about the role. This is a remote, suitable for someone based in Latin America, reporting to a U.S.-based research manager.",Algo de responsabilidad,Jornada completa,"Marketing, Ventas",Investigación de mercado,322,None,True,,1685,None
452,2239304077,2020-09-30,1872 Consulting,Senior Data Engineer - 100% Remote,"San Francisco, CA, US","Sr. Data Engineer Remote (USA Only)  Responsibilities  Design systems that reliably and efficiently provide interactive query performance on large amounts of multi-modal data Build systems that handle scale Build the infrastructure required for optimal extraction, transformation, and loading of data from a variety of data sources using SQL and AWS 'big data' technologies Collect, parse, analyze, and visualize large sets of data Turn data into insights Create data tools for analytics and data scientist team members that assist them in building and optimizing our product   Qualifications  Experience with large-scale data and query optimization techniques Experience with ETL to data warehouse systems Experience with AWS cloud services: EC2, RDS, Redshift, AuroraExpert in SQL, NoSQL, and RDBMS Knowledge in multiple scripting languages (e.g. Python) Knowledge of cloud, distributed systems, and stream-processing systems Passionate about learning new technologies and solving hard problems in a fast-paced environment  The ideal fit...  Has a Computer Science degree Has 5+ years experience in SaaS development environments Is a 'student of the game' and thrives on new challenges Enjoys learning from teammates, and isn't afraid to teach others at the same time Sees the glass half-full. This is a new industry space...your vision could make all the difference! Wants to make a lasting impact and lifelong connections, this is not just another paycheck",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Servicios financieros",3,None,False,,36,ACTIVELY_HIRING_COMPANY
453,2252625429,2020-10-29,Compado GmbH,(Senior) Data Engineer (m/f/x),Germany,"We are a proud Remote Working Employer! To be considered in our hiring process it is necessary that you send us your informative CV and mention your favorite out-of-office workplace. Compado helps high-profile consumer brands, such as Hello Fresh, Parship and Babbel, to achieve outstanding growth by sending thousands of users - who are ready to buy - to their websites. In recent years Compado has become one of the market leaders in commercial decision products. Being one of the heavy-weight influencers of consumer journeys. We went ​fully remote ​and are spearheading the Remote Working movement within Germany. With Compado you can work from everywhere! About our Data Team'We are a young and international team of data engineers and data scientists, with wide ranging responsibilities and cutting edge projects. Our core responsibility is ensuring data quality and data availability, ranging from raw data, to novel data sources, to synthesising data into data marts that are ready for visualization and reporting. Furthermore, we own and initialize machine learning / data science projects, such as automatic ranking, semantic grouping, text translation, and image classification. Maintaining an open and goal-oriented culture at Compado helps us to foster our own initiatives and ideas, as we believe those produce the best results in the end. Are you someone with a lot of Data Engineering experience who loves to come up with novel solutions? Does this sound like an environment you could thrive in? Then you might be a perfect fit for our team!' Role & ResponsibilitiesAs a fast-growing company, our data and data sources are constantly expanding. Being able to come up with scalable and efficient solutions to provide data for downstream use is a core part of your responsibilitiesResponsible for managing a large part of our data pipelineCommunicate with different stakeholders to understand their data related needs,Independently develop new parts of our data infrastructure from scratch, tailored to the company’s needsYou are a mentor to our Junior / Trainee Data Engineers,You can assist our Data Scientists on any Data Engineering topicEnvision and shape our infrastructure to take it to the next level RequirementsA master’s or PhD in a technical field (e.g. Computer Science, Mathematics)At least 3 Years of Data Engineering experienceExtensive knowledge of SQL and Database Management and architectureStrong coding skills in Python and knowing your way around APIsExperience with Amazon Web Services (Redshift, s3, Lambda, Sagemaker, Glue, EMR etc.)Experience with Apache Airflow (or a similar workflow management platform)Familiarity with KubernetesFamiliarity with Tableau (or a similar data visualization tool)Not required but is a big plus: Knowing your way around DevOps and any experience related to Machine Learning / Data Science Why Compado?Attractive salary package, depending on your profileLead a “work from everywhere” lifestyle with an optional office in the heart of BerlinWork in a highly innovative culture, constantly striking new and refreshing paths, withemphasis on New Work and Remote Working as well as environmental consciousnessHighly international and ambitious teams.  Please submit your application to Susan (HR Manager) at sw@compado.com. We are looking forward meeting our future Data Engineer!",No corresponde,Jornada completa,"Análisis, Finanzas, Estrategia/planificación",Internet,117,None,True,sw@compado.com.,399,ACTIVELY_HIRING_COMPANY
454,2222407169,2020-10-29,Publicis Sapient,Senior Data Engineer,United States,"| Data Engineering | Seize The Moment | Publicis Sapient is looking for Data Engineers from the Sr. Associate level up through the Directors level. You will join a team of high level technologists to produce Cutting-edge Enterprise scale solutions for our clients. Working with the latest Data technologies in the industry, you will be instrumental to our mission of helping and supporting the world. Your Impact:Lead, design, develop and deliver large-scale data systems, data processing and data transformation projects.Combine your technical expertise and problem-solving passion to work closely with clients, turning complex ideas into end-to-end solutions that transform our clients’ businessDeploy, manage and audit best practices for clients’ products.Actively participate in overall engagement from strategy, assessment, migration and implementation.Execute technical feasibility assessments and project estimates for moving databases and data processing.Mentor, help and grow junior team members. Your Skills & Experience:Demonstrated experience designing, implementing and supporting enterprise-grade technical solutions for meeting complex data requirements.Strong and innovative approach to problem-solving and creating solutions.Advanced experience with data modeling, table design and mapping business needs to data structures.Experience designing and building data marts, warehouses and customer profiles databases. Set Yourself Apart With:Knowledge of cloud-based big data architectures.Experience with Data Lake, SQL data warehouse and Cosmos DB.Experience using Data Management Gateway and storage options.Cloud expereince in AWS, Azure or GCP. Hands on experince with some of the following  i.     Java- Intellij/Eclispe/JDK1.8/Sparkii.     Scala- Intellij/Eclipse/Sparkiii.     Python- Pycharm, Anaconda, Jupyter Notebook/Pyspark/python 3.7 Benefits of Working For Publicis Sapient :One of the best cultures in the industryFlexible vacation policy: time is not limited, allocated, or accrued15 paid holidays throughout the yearGenerous parental leave and new parent transition programTuition reimbursementCorporate gift matching program",Intermedio,Jornada completa,Tecnología de la información,Servicios y tecnologías de la información,35,None,True,,124,COMPANY_RECRUIT
455,2232899749,2020-11-03,Stott and May,Senior Data Engineer - Azure,"Broomfield, Colorado, United States","Senior Data Engineer required to develop, test and maintain data pipelines and related architecture within the Azure platform. This position will be helping the organization to make decisions faster across all facets of the business. You will work both independently and alongside a team of 5 to help facilitate the usage of more sophisticated analytics/data science throughout the organization. To be considered you will be able to demonstrate an understanding of data modeling, including dimensional modeling (Kimball) and tabular (columnar) modeling. You will develop ETL/ELT processes and patterns to efficiently move data using batch processing. Your background will include around 5 years of experience with ANSI-SQL, proficiency in Python, Pandas and/or PySpark. The client uses PowerBI on the front end to display data, so experience here would be beneficial. Knowledge of MS Azure is a must, SAP would be beneficial and experience with Snowflake, or similar columnar database, would be highly advantageous. ETL/ELT tools such as Data Factory, Data Bricks or similar is also required. If this sounds like a technical environment that is familiar to you please return your resume immediately for a prompt response. This role can be worked entirely remotely, or onsite in Colorado. This set up can be continued post-Covid. This role comes with a competitive salary as well as a generous benefits package. Client is keen to interview now. Please submit your resume for a prompt response.",Intermedio,Jornada completa,"Tecnología de la información, Análisis, Ingeniería","Industria textil y moda, Artículos de consumo",32,None,True,,119,ACTIVELY_HIRING_COMPANY
456,2256647919,2020-10-05,Camden Kelly Corporation,Data Engineer – Own 8+ TB of Data and Get 2-3 Remote Days,"Irvine, CA, US","As an analytical person, you’re all about getting into the nitty-gritty numbers. Would you love to take ownership of 8+ TB of data? Would you love to work from home 2-3 days a week (which adds up to 104-156 days a year)? If so, you’re sure to love this Data Engineer opportunity. Support an awesome internal development need that is already well versed in working with data but needs a little extra expertise to offset the work they’re currently handling. To do well here, you’ll need experience with Hadoop or Spark, MongoDB, AWS, ElasticSearch, and SQL 2012. If you have all of that you’ll be showered with great perks like stock options & flextime while you own all of the company’s data and work closely with a SQL Database & Cloud AWS services. If you’re knowledgeable, confident, and eager to be a part of a fun team you’re in the right place!  The easiest part of this job: When you work from home half of the week every week, you’ll save so much time & money, avoid a ton of stress, and get the work-life balance you’ve always craved.  The hardest part of this job: If you don’t have sufficient data expertise and AWS skills this won’t be the right job for you.  Get ready to take ownership of 8+ TB of data while enhancing your work-life balance by working home 2-3 days a week, every week in this Data Engineer position. Don’t miss out!  What’s in it for you?   Competitive Salary Medical Dental Optical Stock Options Flextime Remote Days 3 Weeks PTO Paid Holidays What You’ll Be Doing  Work closely with a SQL Database and Cloud AWS services Own all of the company’s data and support internal development Handle 8+ TB of data in real time and utilize your DBA skills on the backend Serve as the data expert in a Development team to offset some of the Developers’ workload What You Need  Hadoop or Spark MongoDB AWS ElasticSearch SQL 2012 - - - - -- - - - - - - - - -  About Camden Kelly  Camden Kelly specializes in connecting qualified IT professionals with awesome opportunities at great companies in the Southern California area. Whether you’re a jobseeker looking for new opportunities or an employer looking to hire the best IT talent in the area, Camden Kelly is your go-to IT recruiting firm. Why work with us? It’s simple: our staff is full of career oriented people just like you, and they will treat you how they expect to be treated.  At Camden Kelly, our values make us different than the competition. We are the proud recipients of the Best and Brightest award for 2016 and 2017. We believe in being honest, accountable, ethical, and reliable. We strive everyday to be better than we were yesterday, and to be better tomorrow than today. We’re not competing against other firms: we’re competing against ourselves.  Visit http://camdenkelly.com/jobs to explore opportunities in your area, and while you’re at it follow us on Twitter (https://twitter.com/camdenkellycorp)and Linkedin (http://www.linkedin.com/company/3279780), like us on Facebook (https://www.facebook.com/camdenkellycorp) and join our circle on Google+ (https://plus.google.com/u/0/106722962279155885960) to stay up-to-date with current jobs, industry news and job hunting resources. Also feel free to contact us directly at irvine@camdenkelly.com or 949-333-0057.",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Internet",3,None,False,irvine@camdenkelly.com,30,ACTIVELY_HIRING_COMPANY
457,2257684135,2020-10-21,ICTerGezocht.nl,Data Engineer (Remote) | Salary up to € 75.000 + 30K Shares | Utrecht | CodeGuild,"Utrecht, NL","Vacature van CodeGuild, locatie Utrecht.  Vacancy: Data Engineer Utrecht (Remote)  Does it seem cool to you to have a direct impact on making the world more sustainable?What do you think about working for a tech scale up that raised almost 10 million last year?Would you like to work in very skilled engineering team with one of the brightest minds from the region?Do you enjoy working on complex technical challenges with technologies such as: Python, Spark, Airflow & AWS? Don't wait any longer, because you don't get such an opportunity every day!  Your employer: Well-funded tech scale up has a major impact on making the world more sustainable!  Sometimes there are companies that have remained under the radar for a long time and the moment everyone knows them you think, I wished I have been there when they were a bit smaller. Well here is your chance. This Silicon Valley tech scale up is working hard to make the world substantially more sustainable with bleeding edge technology. We don't see companies like this very often in the region.  The goal is clear here, focus on an industry where the most impact can be made to make the world a more sustainable and green place. Hire the brightest minds from the region and focus on such a technically complex domain and you will enter areas where engineers have hardly been. This is exactly what they have done here, good results have been achieved and thus many millions in funding have been raised to further shape this. And not without result, because they work here for impressive customers such as Google Nest and the biggest EV company!  The organization has its origins here in the Netherlands, so their development hub is also located in the heart of Utrecht. You will work in a very flat and transparent organizational culture. As an engineer you have a lot of freedom and confidence here. For example, the organization has embraced remote working and you can completely determine your working hours yourself and days off are not counted here.  Your role: Data Engineer Utrecht (Remote)  In your role as Data Engineer Utrecht you will work in a highly skilled and experienced team of Data Engineers and Data Scientists. Of course you will also collaborate with other developers like backend & front-end. You and your team will focus various big data challenges around their high available and distributed systems/platform.  So the key project for now are very challenging because you and your team will develop a new Data Lake from scratch. Currently the company has developed other solutions, but as the company is rapidly growing a new data lake is needed.  Also improving current but building new data pipelines will be important. On the roadmap there is a plan for building a brand new Machine Learning forecasting pipeline, which had hardly been done before like the want it. So working here means working on the edge what has been done with technology.  What is being asked?  A technical Bachelor or Master, such as Computer Science or A.IAt least 2 years of Data Engineering experienceSoftware Development experience is a plusExperience with PythonExperience with Spark en/of PySparkExperience with AWS and/or Terraform is a plusExperience with Kotlin, Java and/or Scala is a plusExperience with Elasticsearch is a plusWhat's is being offered?  Salary between € 50.000 and € 75.000 based on knowledge and experienceStock options between € 20.000 and € 30.000The possibility to work 32, 36 or 40 hours & to allocate hours completely freelyBoth remote and office work possible25 vacation days, but these are not trackedLaptop of your choiceHave you always wanted to work for a very well-funded tech scale up that builds products for a sustainable world?     Respond via the form below or send your CV to Serge Warbout, via s.via de button 'Solliciteer nu' op deze pagina.  5cd8a0b9cc68f9ffa4c9253553278a55",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Seguridad del ordenador y de las redes",20,None,False,,136,JOB_SEEKER_QUALIFIED
458,2176211934,2020-10-12,inspHIRE Talent Solutions,Remote Sr. Data Scientist (SAS & Python expertise) - Contract,United States,"3 - 4 month project with possible extension: Remote After many years on the SAS platform, our client is in the process of migrating 70-80 solutions/artifacts to Python and Google Cloud Platform (GCP).Current state is SAS and Hadoop for data wrangling, exploration, profiling, attribution, and modeling.Amongst other tasks, you will help our client's team of data scientists migrate from SAS to a Python and R based platform. You will help them develop the best approach and tools to use to speed up the migration activity. Work with the existing SAS owners/users to understand current process (reverse engineer) and develop the right approach to move the solution from SAS to Python/GCP.Other tasks include developing some of the new solutions in Python on GCP.Ideal candidate is SAS developer who has transitioned to Data Sciences (Python). Required skills:Expert/senior advisor who can guide team in developing the best approach to migrate off of SAS and into the GCP environment.Excellent communication and customer service skills: team player.3+ years SAS3+ years as a Data Scientist3+ years Python1+ years Cloud (Google Cloud Platform/GCP is preferred) Preferred skills:HadoopFinancial Services *** CANDIDATES MUST BE EMPLOYABLE AS W2 CONSULTANTS. NO C2C, 3RD PARTIES, VISA SPONSORSHIP/TRANSFER ***",Intermedio,Contrato por obra,Tecnología de la información,"Servicios financieros, Software",74,None,True,,330,JOB_SEEKER_QUALIFIED
459,2166038042,2020-10-07,IronNet Cybersecurity,Principal Cyber Data Engineer (Remote/Virtual),"New York City, NY, US","Description  What’s your mission?  IronNet’s mission is simple: To deliver the power of collective cybersecurity to defend companies, sectors, and nations. For decades, companies have been defending against cyber attacks on their own while adversaries have been organizing themselves into sophisticated hacker networks … until now, with IronNet Collective Defense. In 2014, General (Ret) Keith Alexander, former Commander U.S. Cyber Command, launched IronNet to strengthen cybersecurity defense against highly sophisticated adversaries, across all borders and sectors.  In response to cyber adversaries who increasingly collaborate for collective offense, leading organizations in our critical infrastructure are using collective defense strategies and solutions to meet these powerful and ever-changing threats. We believe that collective defense is our collective responsibility and we are leading the charge.  The Opportunity  IronNet’s Analytics team is responsible for building behavioral analytics and event correlation code for our NDR and collective defense products. The team focuses on developing cost effective cloud solutions that are distributed and highly scalable, processing large volumes of events.  We are looking for a senior or principal level Cloud Data Engineer with focus on data pipelines and development of SaaS solutions to join the team.  To be successful in this role, you must be able to . . . Use AWS to provide microservices architectures that are highly reliable, redundant and scalableInterface data transformation, enrichment, and machine learning algorithms to cloud storage and messaging infrastructureUse modern programming languages (Python, Scala, Java, Golang, etc) to develop continuously integrated and deployed production software Architect horizontally scalable analytics and data processing pipelinesTurn proof of concept architectures into production environmentsShare knowledge and assist others in understanding technical topics You may be the person we need if your background aligns with the following . . . Proven experience as a Data Engineer, Machine Learning Engineer, Software Engineer, Cloud Engineer or similar role.Demonstrable expertise in a modern programming language(s) (Python, Scala, Java, Golang, etc.).Experience with SaaS architectures and delivering production software.Experience with Kafka, Spark, and other scalable data frameworks.Experience with cybersecurity event processing including high-volume ETL and analytics.Possess strong analytical, technical, and problem-solving skills.  Personal Profile Passion for championing projects from concept to delivery to customer.Competitive spirit: willingness and ability to “sell” your solution during collaborative team discussions.Desire to be the best and prove it every day.Eagerness to learn and improve your own skills and to make those around you better.Highly attentive to detail and a focus on improving the code base and quality of our tests.Commitment and aptitude to proactively find solutions to ambiguous opportunities.Bring a unique skill set or elevate the results of the teams you are a part of. Recognition & Awards  IronNet is recognized as a representative vendor in Gartner’s “Market Guide for Network Detection and Response (NDR)”, and Forrester recently named IronNet a representative vendor in its “Now Tech: Network Analytic and Visibility, Q2, 2020” research.  Recent Awards  CRN Emerging Vendors Fortress Cyber Security Hot 150 Cybersecurity Companies Fortress Cyber Security EMA Vendor To Watch CRN Security100  More About IronNet  IronNet delivers unmatched collective cyber threat detection for enterprise on-premise, cloud, and hybrid networks. We do this through the application of advanced behavioral analytics, AI, and machine learning techniques. Our team combines the tradecraft knowledge of the best offensive and defensive cyber operators in the world with world-class mathematicians and data scientists to engineer solutions that empower companies to defend against advanced threats.  Our founder and Co-CEO, General (Ret) Keith Alexander, is a recognized cybersecurity innovator and a frequent speaker about current cyberthreats and effective defenses. We have a leadership team with deep government and commercial cyber experience, and the company is advised by a board of esteemed security and venture investment professionals, including Jan Tighe Retired Vice Admiral, Former Deputy Chief of Naval Operations for Information Warfare and Director, Naval Intelligence, US Navy: and Jack Keane Chairman, Institute for the Study of War, Retired Four-Star General, Former Vice Chief of Staff, US Army.  Benefits Of Working At IronNet  IronNet strives to provide and takes pride in being able to offer comprehensive, essential and affordable benefits for our employees and their families. We offer an unlimited PTO plan, 401(k) match as well as Medical, Dental, Vision, and Disability Insurance.  All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, or protected veteran status, or any other legally protected basis, in accordance with applicable law.  Follow us on LinkedIn",Algo de responsabilidad,Jornada completa,Ingeniería,"Servicios y tecnologías de la información, Software, Seguridad del ordenador y de las redes",2,None,False,,12,None
460,2281987092,2020-10-17,Mach49,UX Designer/Researcher,"Tokyo, JP","We are seeking a creative problem solver that understands human-centered design, user research, usability testing, persona creation, and design thinking methods to join our team.  The Role   To help client teams conceive, test, and build new disruptive products by combining work from multiple disciplines: User Research, Design, Usability, and Design Thinking.  The process begins with Customer Development Research, moves through the brainstorming process, and continues with rapid product iteration. Each 12-week incubation is focused on helping project teams define a product concept, vision, and roadmap that global enterprises can build a business around. The UX Designer/Researcher helps keep the customer in the center throughout the incubation process.  Experience  You will bring knowledge of applying design thinking methods in the service of conceiving, validating and building products, including:  User Research: you will bring solid skills in conducting interviews, note-taking, deriving insight and clearly presenting findings. Over time, you will master script creation, scenario development, qualitative test strategy and persona development. UX: you will understand Information Architecture and methods for organizing complex and diverse types of content, and methods for visualizing the customer context, customer journeys etc. UI: you will be able to wireframe and prototype at various levels of fidelity Visual Design: you will bring a good understanding of visual hierarchy, grid systems, and typography  Presentation design: you will be able to design compelling presentations and pitch decks that tell stories, communicating boldly and clearly  You will have fluency in the following design programs:  – Adobe Creative Cloud  – Sketch  – Balsamiq  – Invision  – Keynote/Powerpoint/Google Slides  Qualifications And Characteristics  Bilingual: Fluent in Japanese and English Up to 2+ years of work experience Degree from an accredited university or college in Design and/or User Experience, or equivalent training/work experience A curious mind and the ability to naturally make connections between diverse fields and industries  The ability to work quickly and efficiently in a very fast-paced, multi-task, collaborative environment A positive attitude, resilience, comfort with ambiguity and the ability to contribute to strong team dynamics Clear and persuasive written and oral communication style Politically savvy when working with clients, skilled at knowing when to lead versus when to collaborate Comfort learning and working within the current Mach49 Experience Research process  Ability to work effectively with a range of different organizations and people at all levels Previous start-up experience a plus Willing to be flexible and work when the work is needed, sometimes at odd hours (there are lots of peaks and valleys during an incubation)  Prior experience of remote working is a plus   Please submit your resume and a portfolio link via the application below.",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Internet, Consultoría de estrategia y operaciones",3,None,False,,39,ACTIVELY_HIRING_COMPANY
461,2220734295,2020-10-28,HiLabs Inc.,Spark/Big Data  Engineer (2-5 years of experience),United States,"About HiLabs•   We dream audaciously big and build everything on BIGDATA.•   We are solving a real problem in healthcare, related to data errors.•   We believe in work hard party harder culture.•   We are a well-funded, and are growing rapidly (at the rate of 25% every quarter) - a perfect time to get on board! HILABS (www.hilabs.com) is a health data analytics company with product offerings to healthcare payers and providers in the united states. The company was spun out of Yale University a few years ago. The TeamWe are an innovation-centric team of people who work hard to develop radically differentiated technologies. In our team, we draw strength from healthcare delivery experts (data-savvy cardiologists at Harvard), data science geeks (from top tech schools of the world), and former healthcare CIOs (of CMS, Anthem, and Aetna) to develop and execute a growth strategy with a 360-degree view. The RoleWe are seeking a highly motivated Spark / Big Data Developer. Teaming up with architects, scrum masters, leads, managers and directors, you will work in an Agile environment to make the data on our Big Data Platform accessible for the needs of our clients through Atomic Models and Analytical Data Stores. In this role, you will coordinate with a variety of data scientists and business stakeholders to elicit and translate high level business requirements into detailed system requirements. You will participate in the entire software development lifecycle by writing and executing test plans, finding solutions to issues during development and after deployment. You should be intellectually curious, have a solutions-oriented attitude and enjoy learning new tools and techniques. Basic Qualifications: At least two years of experience with SQL and Java or Scala Experience with manipulating and transforming data Exposure to NoSQL databases, Spark and the Hadoop Ecosystem (MapReduce, Oozie, Hive, Pig) Strong critical thinking, decision making, and problem-solving skills Excellent verbal/written communication skills, including communicating technical issues to non-technical audiences Bachelor’s degree in a computer related field or equivalent from a top technical institute required Preferred Qualifications: Experience in designing efficient and robust ETL/ELT workflows, schedulers, and event-based triggers Experience with Spark core and Spark SQLExperience as a Big Data Developer Exposure to Data Mining, Data Engineering and Data Modeling",Algo de responsabilidad,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Software",70,None,True,,255,ACTIVELY_HIRING_COMPANY
462,2192286491,2020-10-19,Associated Bank,Data Engineer Senior - Data Warehouse - Oracle/Snowflake,"Milwaukee, WI, US","Associated Bank is an equal opportunity employer committed to creating a diverse workforce. We support a work environment where colleagues are respected and given the opportunity to perform to their fullest potential. We consider all qualified applicants without regard to race, religion, color, sex, national origin, age, sexual orientation, gender identity, disability or veteran status, among other factors. Applicants with a disability who need assistance applying for a position with Associated Bank are asked to email: careers@associatedbank.com   Job Summary  The Data Engineer Senior is responsible for ingesting, transforming, and preparing data for consumption by our various lines of business. This will include designing complex data solutions, working with business lines to understand needs, documenting, building, and testing the solutions. This will require ETL (Extract, Transform, Load) development and data analysis skills using SQL and/or scripting tools. Incumbent will collaborate with other teams in Operations & Technology, including Software Engineering, Enterprise Architecture, and Infrastructure teams as well as our support teams. The Data Engineer Senior will assist the Data Architects in developing standards and best practices across the team. The role will ensure proper handoffs to the DataOps team to ensure proper support and maintainability, as well as be available for support remediation and troubleshooting. Position will be responsible for building and maintaining our advanced analytics capabilities (Artificial Intelligence and Machine Learning) as well as mentor other Data Engineers on our team.  Job Accountabilities   Develop and maintain advanced analytics capabilities (Artificial Intelligence and Machine Learning). Ingest, transform, and prepare data for consumption by our various lines of business. Work with the lines of business on reporting, data visualizations and overall data consumption. Mentor Data Engineers and team members. Collaborate with other teams in Operations & Technology, including Software Engineering, Enterprise Architecture, and Infrastructure teams as well as our support teams. Manage the handoffs to DataOps team to ensure proper support and maintainability, as well as be available for support remediation and troubleshooting. Create standards and best practices.   Education   Bachelor's Degree or equivalent combination of education and experience Mathematics, Computer Science, MIS, Data Science, Analytics, or related. Required Experience 5-7 years ETL/ELT experience (SSIS, Informatica, DataStage, etc). Experience working with complex structured, semi-structured, and unstructured data. Expert SQL knowledge and analytical skills. Exposure to modern data/analytics architecture (Big Data, Cloud, etc.). AI/Machine Learning advanced analytics tools (Python, R, etc). Required   Compliance Statement  Fully complies with all applicable enterprise policies and procedures. Acts in compliance with all applicable laws and regulations as outlined in training materials, including but not limited to Bank Secrecy Act. Responsible for reporting suspicious activity to Financial Intelligence. Responsible to report all customer complaints as prescribed and procedure violations to management or HR. Responsible to report ethical concerns as needed to Associated’s anonymous Ethics Hotline.  Associated Bank is committed to working diligently with any colleague who needs an accommodation perform the essential functions of the job. Please contact the Leaves & Accommodations office to request an accommodation.",Intermedio,Jornada completa,"Análisis, Tecnología de la información","Banca, Servicios y tecnologías de la información",33,None,False,careers@associatedbank.com,219,ACTIVELY_HIRING_COMPANY
463,2232928999,2020-10-23,WorldLink US,Sr. Data Engineer,Dallas-Fort Worth Metroplex,"TITLE: Lead Data Scientist, Machine Learning POSITION TYPE: Fulltime LOCATION: Dallas, TX WHO we’re looking for: We are expanding our efforts into complementary data technologies for decision support in areas that capitalize on intelligent applications enabled with computational learning. Our interests are in enabling intelligent applications and corresponding computation learning processing on large and low latent data sets with elastic cloud architecture techniques on premise. To that end, this role will engage with team counterparts in exploring and deploying technologies for engineering features and creating algorithms that result in models incorporated into intelligent applications. Application use cases are expected to focus on core aspects of our business such as risk management and customer experience. Responsibility also includes coding, testing, and documentation of new or modified scalable analytic data systems including automation for deployment and monitoring. This role participates along with team counterparts to architect an end-to-end framework developed on a group of core data technologies. Other aspects of the role include developing standards and processes for computational learning projects and initiatives. Role and Responsibilities: Evaluate, research, experiment with computational learning technologies in a lab to keep pace with industry innovation while assessing business impact and viability for use cases associated with efforts in handWork with statisticians, data engineers, application developers, and related groups to inform on and showcase capabilities of emerging technologies and to enable the adoption of these new technologies, computational learning and associated algorithmsWork closely with statisticians, data engineers, application developers, other IT counterparts, and business partners to develop, integrate and deploy computational learning as part of applicationsCode, test, deploy, monitor, document and troubleshoot computational learning processing and associated automationEducate and develop system engineers on distributed systems engineering so as to enable future data science and practicePerform other duties as assignedConform with all company policies and procedures QualificationsKnowledgeExcellent knowledge of Linux, AIX, or other Unix flavorsExperience with recent computational learning technologies such TensorFlow, Caffe, Torch, Neon, SystemML, or TheanoExperience with directed analytic graph processing using Beam, Nifi, Flink, and/or SamzaExperience with messaging technologies such as Kafka, RabbitMQ, ZeroMQ, or MQTTExperience with high dimensional visualization using t-SNE or PCA or other related technologies such as AyasdiWorking knowledge of cloud based computational learning technologies such as Google Cloud Machine Learning, Microsoft Azure Machine Learning, or IBM WatsonWorking knowledge of Rasa, Spacey/Prodigy, NLTK, Standford CoreNLP, ELMo, and other natural language understanding and processing frameworks and modeling SkillsDemonstrated strong track record on delivering computational learning based solutions that solve complex analytical problems using quantitative approaches that are a blend of analytical, mathematical and technical skillsExcellent written and verbal communication skillsExperienced with solution development, deployment, and/or administration of distributed computational learning and/or analysis systems such as Spark, H2O, SAS Grid, Tensorflow or Hadoop EducationHigh School Diploma or equivalent requiredMaster’s Degree in operations research, applied statistics, data mining, machine learning, physics or related quantitative discipline required Experience2-4 years hands-on experience with NoSQL data stores such as MongoDB, Cassandra, HBase, Riak or other technologies that embed NoSQL such as MarkLogic or Lily Enterprise required3-5 years data science experience required5-7 years software engineering in languages to include Java, SAS, and Python required5-7 years hands-on experience with SQL databases and Business Intelligence tools such as Oracle, DB2, Postrges, MySQL, SAS, Cognos, Oracle BI Enterprise Edition, SAP BusinessObjects, or Tableau required WHAT you should know: Our success begins and ends with our people. We embrace diverse perspectives and value unique human experiences. We are proud to be an equal opportunity employer that celebrates the diversity of the communities where we live and do business. Applicants for our positions are considered without regard to race, ethnicity, national origin, sex, sexual orientation, gender identity or expression, age, disability, religion, military or veteran status, or any other characteristics protected by law. This job description is designed to cover the main responsibilities and duties of the role but is not designed to be a comprehensive list of all. WorldLink is an Equal Opportunity Employer and considers applicants for all positions without regard to factors including race, color, religion or belief, sex, age, national origin, citizenship status, marital status, military/veteran status, genetic information, sexual orientation, gender identity, physical or mental disability or any other characteristic protected by applicable laws. People with disabilities who need assistance with any part of the application process should contact us",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Servicios financieros",35,None,True,,161,ACTIVELY_HIRING_COMPANY
464,2256177952,2020-10-05,TapRecruit,Data Engineer,"New York City, NY, US","We know that what you say (and how you say it) matters, which is why we've built the most advanced online editor for job descriptions there is. Our customers (hiring teams at BuzzFeed, Oscar Health, Levi's, and many more) use our editor to write job descriptions that are welcoming to all qualified candidates. The result is a more fair and representative hiring process for candidates across the globe. Check it out: TapRecruit.co/smart-editor  We are looking for an experienced Backend Software Engineer to help us develop data products that help recruiting teams understand and benchmark their talent pipelines and processes. You'll work within the Data team, reporting to our Head of Data Science.  You will:  Build scalable data pipelines that integrate multiple data sources (both internal and external APIs).Generate fault-resistant data extraction and transformation processes with monitoring.Prototyping data products and productionalizing data modelsImprove engineering standards by developing internal tools that will be used by the data and engineering teamsWrite code that is maintainable and includes relevant tests. Maintain and advocate for these standards through code review within the data and engineering teams. This is a remote job and available to all candidates with work privileges currently residing in the United States.  You have:  4+ years of experience building large-scale software applications with PythonExpert-level understanding of SQL and common relational database systemsExcellent debugging and data flow optimization skillsExperience querying and setting up NoSQL databases (ElasticSearch, MongoDB)Familiarity with containerized development workflowsDesirable: Experience deploying data pipelines through AWS Our benefits:  Comprehensive healthcare plansFlexible PTO policy401k retirement planCommuter benefitsRemote-friendly team and open to more flexible work arrangements TapRecruit is a small but mighty team with a big mission of democratizing opportunity for all qualified candidates. Our founders are located in New York but we're building a team of experienced engineers, linguists and scientists from across the USA.  We care deeply about fairness (it's our mission) so you can be ensured that your application will never be judged based on your religious belief, age, color, race, creed, marital status, gender, sexual orientation, political affiliation, ethnic origin, family status or disability.",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Internet",7,None,False,,84,None
465,2198887213,2020-10-21,Harvey Nash Group,Sr. Data Engineer,"Moonachie, New Jersey, United States","Title: Jr. Data EngineerLocation: Remote (NY/ NJ)Type: Fulltime/ Perm Position  MUST EXPERIENCE:Skillset musts: Spark ETL (they use Databricks on Apache Spark) + Python developent (not basic python scripting, but full-stack touching both web applications and back-end web services), Azure (using) or AWS Background: Candidate should have experience on ML projects (Not a ML engineer) but has worked on models moving into production and come from a CS/mathematics education  PURPOSE OF POSITION:The ideal candidate will be working in our mixed technology environment to deliver data products providing decision support for business and customers. As part of a highly collaborative team, the role will interact with technical and business resources within and outside of IT organization. The ideal candidate is a committed, creative, self-motivated technologist who is interested in practicing current skills and learning new ones. TASKS AND RESPONSIBILITIES: The following duties are essential to the successful and satisfactory performance of this job. Other duties may be assigned. Build new micro-services, libraries, and features that form the platform to support cognitive analytic productsDesign and develop batch jobs, web applications and web servicesDeploy scalable machine learning models to productionCommunicate technical concepts and solutions in a clear fashion that business stakeholders and other developers can understand and collaborateWork with app dev and QA teams for testing and improvement if neededAbility to scope work and provide proper estimateFamiliarity with SDLC and agile methodologies and tools such as TFS, Git, SCRUMStay current with the latest in cognitive analytics and explore new tools and features if necessary MINIMUM EDUCATION:Bachelor’s degree in related field MINIMUM EXPERIENCE:5+ years of experience with strong python development skills2+ years in building python data engineering platforms for data science or data analytic groups2+ years of web development experience with strong java script skills KNOWLEDGE, SKILLS, ABILITIES:Experience with consuming data from streaming platforms like Kafka.Strong relational and non-relational data base experienceExperience with on-premise data products deployed using containers (Docker, Kubernetes)Experience with Azure or AWS PaaS and SaaSBachelor's degree from an accredited institutionSystem and networking fundamentalsML Modeling is plusExhibit and practice courteous, ethical and professional behavior while interacting with both internal and external customersAct in a collaborative, team-oriented environment focused on common goals to achieve mutually beneficial results EMAIL: Farhana.Shaik@harveynashusa.com",Intermedio,Jornada completa,"Tecnología de la información, Ingeniería",Industria aeroespacial y aviación,51,None,True,Farhana.Shaik@harveynashusa.com,181,ACTIVELY_HIRING_COMPANY
466,2207176149,2020-10-23,Progressive Insurance,Data Scientist - Machine Learning Engineer Lead - Remote,"Village of Mayfield, OH, US","As a machine learning engineer, you’ll use machine learning, data engineering and languages like Python to develop platform solutions to solve technical and operational problems. You’ll solve problems with techniques you may need to research, learn and create. You’ll use your strong technical and communication skills, as well as proven experience in developing and deploying machine learning to take projects into production. Remote work allowed.  Must-have Qualifications Master's degree or higher with quantitative focus in Econometrics, Statistics, Operations Research, Computer Science or related field (e.g. Mathematics) and a minimum of one year of relevant experience in Statistical/Quantitative Modeling and/or Machine Learning tools (R, Python, etc) and in using various database tools (e.g. Hadoop, SQL) processing large volumes of structured and unstructured dataInstead of the above, Bachelor's degree with quantitative focus in Econometrics, Statistics, Operations Research, Computer Science or related field (e.g. Mathematics) and two years of relevant experience listed in above bulletInstead of a degree, a minimum of seven years of relevant experience listed in above bullets  Preferred Skills Skilled in Linux, Bash & highly proficient in PythonUnderstanding of time and space complexity of Data Science algorithmsFoundation in computer science, software engineering, and system architectureKnowledge of differences in the SDLC for machine learning driven productsAbility to configure, deploy, and manage cloud resources, using infrastructure as code (for example, Terraform)  Benefits Gainshare bonus up to 40% of your eligible earnings: Progressive rewards each of us with an annual bonus based on company performance401(k) with dollar-for-dollar company match up to 6%Diverse, inclusive and welcoming culture with Employee Resource GroupsCareer development and tuition assistanceOnsite gym and healthcare at large locationsWellness programs to help you maintain a better quality of lifeMedical, dental and vision, including free preventive care  Sponsorship for work authorization for foreign national candidates is not available for this position.  Equal Opportunity Employer    Job  Business Analysis  Primary Location  United States-Ohio-Mayfield Village  Schedule  Full-time  Employee Status  Regular  Work From Home  No",No corresponde,Jornada completa,Otro,"Servicios y tecnologías de la información, Seguros, Servicios financieros",45,None,False,,298,COMPANY_RECRUIT
467,2193849284,2020-10-19,The Mirillion Group,AI & ML Team Lead,"Montreal, Quebec, Canada","We are seeking, for one of our clients, a Bilingual Data Science lead to work on developing statistical, machine learning, AI and applied mathematical models. You will Understand the client’s business goals, design, and develop analytic approaches and data products tailored to their needs. Work as a team lead with a diverse team of data scientists and data engineers. Act as a mentor for the team, own projects, be positioned as a Subject Matter Expert, and be hands-on building and improving models and performing analysis.Establish high standards and share knowledge in performance, scalability, enterprise system architecture, and engineering best practicesExtending prototypes into fully functional, polished solutions ready for internal useWork cross-functionally with other parts of the organization, including IS teams, and business, as well as the broader data science org, to build a coherent roadmap for the incoming projectsReport to the R&D Manager and work closely with various business lines. Qualifications  MS or PhD-level math, statistics, operations research, engineering, computer science or econometrics.Bilingual (French & English) 5+ years of quantitative experience Experience in leading a team (or as a principal data scientist)Strong Experience with one or more of the following: Natural Language Processing, text understanding, classification, pattern recognition, recommendation systems, targeting systems, ranking systems or similarExperience leading and mentoring people, preferably in a formal capacity, and want to continue to grow this competencyProficiency with Deep Learning packages such as Tensorflow, Keras and PyTorchExposure to distributed computing frameworks (e.g. Hadoop, Spark) as well as SQL, NoSQL and graph databasesExperience in working with business, product and other technical teams",Intermedio,Contrato por obra,"Tecnología de la información, Consultoría, Atención al cliente","Aeronáutica/Aviación, Banca, Servicios y tecnologías de la información",143,None,True,,723,ACTIVELY_HIRING_COMPANY
468,2283280902,2020-11-06,Experis,Data Collection Researcher,"Mountain View, CA, US","Data Collection Administrator   4 month contract (with potential for extension/conversion)  Sunnyvale, CA / Remote (must be local)     We are seeking a highly motivated Data Collection Admin for a 4 month contract role with a leading client in Sunnyvale, CA. Data Collection Admin will need to learn quickly and execute procedures accurately and capture and document any needed information associated to data collection processes and data management systems. The Data Admin will work closely with participants, engineering team, and operations to provide data and analytical support for Data Collection initiatives, root cause investigation of defects, and will provide support to insure compliance requirements.     REQUIRED SKILLS  - 2+ years of experience in customer service, technical support, project management, machine learning, or related field  - Fluent in writing and speaking English  - Experience using MS Office, Excel, Mac OS.  - Proven ability to work productively and efficiently in an independent setting  - Proven ability to clearly communicate with managers and associates at all levels  - Troubleshoot and triage any technical issues during the collections and report as needed  - Ability to work in field locations as needed  - Ability to travel domestically and/or internationally  - Able to work flexible schedule including evenings and/or weekends  - Comfortable working in a fast paced, highly collaborative, dynamic work environment  - A good sense of humor, a positive attitude, and great team work skills  - Demonstrated proactive behavior in addressing issues and problems  - Willingness to roll up your sleeves to get stuff done and to accept re-prioritization as necessary     PREFERRED SKILLS  - Hands-on experience with one-on-one session moderation with participants  - Experience in research  - Python, bash, or other programming language  - Lift 30-40 lbs. of boxes when needed, with or without reasonable accommodation  - Excellent communication, interpersonal and problem solving skills  - Experience using Confluence, Wiki tools, Jira.  - Strong organizational skills and ability to multitask effectively in fast paced, highly collaborative, and dynamic work environment  - Ability to follow through, work independently, and take ownership of assigned responsibilities  - Experience working with prototype assets  - Practical knowledge of machine learning processing needs and trade-offs  - Has own transportation   Desired Skills and Experience  - 2+ years of experience in customer service, technical support, project management, machine learning, or related field - Fluent in writing and speaking English - Experience using MS Office, Excel, Mac OS. - Proven ability to work productively and efficiently in an independent setting - Proven ability to clearly communicate with managers and associates at all levels - Troubleshoot and triage any technical issues during the collections and report as needed - Ability to work in field locations as needed - Ability to travel domestically and/or internationally - Able to work flexible schedule including evenings and/or weekends - Comfortable working in a fast paced, highly collaborative, dynamic work environment - A good sense of humor, a positive attitude, and great team work skills - Demonstrated proactive behavior in addressing issues and problems - Willingness to roll up your sleeves to get stuff done and to accept re-prioritization as necessary  PREFERRED SKILLS - Hands-on experience with one-on-one session moderation with participants - Experience in research - Python, bash, or other programming language - Lift 30-40 lbs. of boxes when needed, with or without reasonable accommodation - Excellent communication, interpersonal and problem solving skills - Experience using Confluence, Wiki tools, Jira. - Strong organizational skills and ability to multitask effectively in fast paced, highly collaborative, and dynamic work environment - Ability to follow through, work independently, and take ownership of assigned responsibilities - Experience working with prototype assets - Practical knowledge of machine learning processing needs and trade-offs - Has own transportation       ManpowerGroup is an Equal Opportunity Employer (EOE/AA)",Intermedio,Contrato por obra,Tecnología de la información,Electrónica de consumo,6,None,False,,129,ACTIVELY_HIRING_COMPANY
469,2291148332,2020-10-14,Heap,Principal Data Scientist,"San Francisco, CA, US","Heap is built on a rich dataset of product activity, encompassing hundreds of billions of events across thousands of websites. We've automated the process of capturing user behavior, and now we're now building the next generation of tools to help clients understand and take action on their data.  In this role, you'll research, develop, and productize advanced features for Heap's product analytics platform. These features will guide users' attention towards 'unknown unknowns' in their data, suggest the right questions to ask, and otherwise decrease the barriers to insights. This is an opportunity to scale your data science knowledge across hundreds of companies: instead of discovering important business insights for one company at a time, here you can turn your knowledge into a product that helps thousands of product managers at once.  You'll iterate quickly on challenging and interesting technical problems. How can we turn an autocaptured dataset of millions of events into quantifiable insights? How can we automatically identify frustrating aspects of a customer's product? How can we help our clients avoid overfitting, and protect them from being fooled by confounding factors?  As Heap's second data scientist, you'll work directly with our CTO and alongside an expert data scientist and engineer on a fast-moving team. As you develop these methods, you'll partner directly with our clients to test your approaches on a variety of datasets. This project is central to Heap's future strategy and to our continued success as the leading product analytics platform.  What you will be doing:   Research and develop novel product features. You'll be solving challenging technical and statistical problems that automate insights for Heap users.  Test prototypes with clients. You'll pair directly with clients to understand their data and business problems, in order to test methods and product features in practice.  Productize and scale. You'll partner with our engineers, designers, and product managers to turn new ideas into practical and statistically rigorous features in the Heap product.  Level up Heap's data science capabilities. We're developing data science as a core competency of Heap. As an early and senior member of the team, you'll help build and scale our technical infrastructure and lead an initiative that's key to the company's long-term strategy.  What we're looking for:    4+ years of professional experience as a data scientist Expertise in either R or Python. You're fluent in transforming, modeling, and visualizing data to solve a variety of problems. Comfortable in SQL. Experience with data warehouses such as Snowflake, Redshift or BigQuery is a plus. Experienced with statistics and machine learning. You're familiar with dangers like overfitting, confounding factors, and multiple hypothesis testing, and you're well-versed in statistical methods for handling such risks. Practical: you care about finding effective and robust approaches that can be scaled into products, not about using the newest and shiniest technologies.  An advanced degree (PhD, MS) in a quantitative field is optional but preferred. Strong communication skills: able to collaborate with technical, nontechnical and external stakeholders, including presenting conclusions to clients. You prefer rapid iteration, and have an interest in proving out ideas and making decisions in as fast a loop as possible. You can have a lot of fun playing with data.  People are what make Heap awesome. Regardless of age, education, ethnicity, gender, sexual orientation, or any personal characteristics, we want everyone to feel welcome. We are committed to building a diverse and inclusive equal opportunity workplace everyone can call home.  Heap has raised $95M in funding from NEA, Y Combinator, Menlo Ventures, SVAngel, Sam Altman, Garry Tan, Alexis Ohanian, Harj Taggar, Ram Shriram, and others. We offer plenty of awesome benefits, and we were named #1 on Glassdoor's Best Places to Work (SMB). We'd love to hear from you!",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Marketing y publicidad, Software, Internet",0,None,False,,1,None
470,2181330671,2020-10-13,Panasonic North America,Lead Innovation Researcher,"Denver, CO, US","Panasonic – Lead Innovation Researcher  Every moment of every day, people all over the world turn to Panasonic to make their lives simpler, more enjoyable, more productive and more secure. Since our founding almost a century ago, we’ve been committed to improving peoples’ lives and making the world a better place–one customer, one business, one innovative leap at a time. Come join our journey.   Click here to learn more about how Panasonic is creating a better life, a better world.   Watch this video to see how our employees are shaping the technologies that move us.  What You’ll Get To Do  You will conduct market research studies to identify and understand emerging transportation markets, being vigilant to new business opportunities. You will gather, analyze, and present actionable consumer, market, and competitor insights to a wide variety of stakeholders. Your work will shape the strategic direction of our business by providing strategic recommendations that inform our marketing, business strategy, and product development decisions. This position will report to the Vice President of NextLab. Independently conceive, lead, and conduct qualitative studies that drive strategic and tactical marketing, business, and product decisionsCreate clear and compelling market research storylines that are strategically sound and emotionally provocative to inform business strategy, the development of product roadmaps, enhance marketing efforts, drive engineering efforts, and provide early warning for strategic course correctionsDevelop a deep understanding of the transportation landscape including, but not limited to, products, markets, competitors, etc., and develop frameworks to synthesize this understanding into insights for the business, e.g. segmentation models, competitive analysis, etc.Lead innovation and design workshops with cross-functional partners to convert insights into action.Develop comprehensive research plans designed to explore, and subsequently validate, business or product opportunities.Identify and explore white space opportunities in the connected mobility space.  What You’ll Bring  Education & Experience: A Bachelor’s Degree in Market Research, Psychology, Social Science, or related field (bonus for a Master’s or PhD):Extensive years of experience conducting market research in a technology-related field:Proficiency in conducting end-to-end research studies:Demonstrated ability to influence product priorities and roadmap/strategy decisions:Expert-level understanding, and experience with, using leading-edge qualitative research methodologies and technologies to deliver consumer and market insights:Expert-level proficiency of both qualitative and quantitative methodologies and when/how to use them:Experience mentoring and coaching cross-functional team members:Market research, consumer insights, or related experience in either a supplier-side or client-side environment with a strong consumer focus:Experience conducting B2B market research a plus:Experience leading workshops that convert insights to action:Experience with Design Thinking:Experience managing vendors relationships a plus:Expert in methodological design (including approach, protocol, survey/questionnaire and output/deliverables)Demonstrated ability to forge strong relationships across an organization to align insights to each line of business and ensure research projects meet today and future business needs.It would be a bonus if you understand and are able to implement the “Jobs to be Done” framework to articulate opportunities and business strategies within existing customers and future ones, grounded in data and insights  Competencies Excellent analytical, decision-making, project management, written/verbal communication, and presentation skills:Strong business acumen:Self-starter—always looking for opportunities to improve something and will jump in to fix things without being asked:An expert storyteller with the ability to influence business decisions:An independent, strategic, and creative thinker who is a strong team player (no job is too small or too large) and willing to take on additional responsibilities as necessary:Flourishes in ambiguity:Exceptional interpersonal and communication skills:Ability to think both analytically and creatively—balance left and right brain—people person as well as data person.  Other Requirements Majority of team sits in Denver, Colorado. Will consider remote candidates.Travel for research post-Covid up to 35%.  What We Offer Competitive compensation packageComprehensive benefitsPet InsurancePaid Parental Care LeaveEmployee Referral ProgramEducational AssistanceFlexible Work ProgramVolunteer time OffCasual Dress CodeTotal Well Being Program Panasonic is proud to be an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender identity, sex, sexual orientation, national origin, disability status, protected veteran status, and any other characteristic protected by law or company policy. All qualified individuals are required to perform the essential functions of the job with or without reasonable accommodation. Pre-employment drug testing is required for safety sensitive positions or as may otherwise be required by contract or law. Due to the high volume of responses, we will only be able to respond to candidates of interest. All candidates must have valid authorization to work in the U.S. Thank you for your interest in Panasonic Corporation of North America.",Algo de responsabilidad,Jornada completa,"Investigación, Análisis, Tecnología de la información","Servicios y tecnologías de la información, Software, Servicios financieros",95,None,False,,920,ACTIVELY_HIRING_COMPANY
471,2246374163,2020-11-05,ThoughtRiver,Senior Data Scientist,United Kingdom,"We're looking for an experienced and collaborative Data Scientist who has made NLP their professional and/or personal mission. This is a fantastic and unique opportunity for a pragmatic individual who enjoys solving complex challenges to work with a talented team of Engineers and add an enormous amount of value to our business. We're currently supporting all our employees through Covid-19 and encouraging remote working: this role will be based remotely until we're advised it's safe to return to the Cambridge office and at that point we will require this person to travel to the office for collaboration. About UsThoughtRiver, the market leader in intelligent legal pre-screening, is disrupting legal services by enabling lawyers to review contracts quickly using behavioural analytics, machine learning and data visualization. Our product encompasses leading-edge AI technology, an innovative legal ontology and one of the world’s largest legal intelligence data sets. We recently announced a successful $10m Series A investment round and are ambitiously scaling. We have been named by Business Insider as one of the Top 15 European AI start-up companies, with a rapidly expanding global client list. Your Mission Design ways to enhance and expand the capabilities of “Fathom”, the brain behind our software.Drive Natural Language Processing and Machine Learning projects from concept to fruition, taking into account any competing forces and necessary trade-offs.Devise and apply novel approaches to interpret legal documents.Recommend relevant research, best practices, and their application to the product and legal domain.Recommend annotation, modelling, and evaluation approaches for a wide range of supervised and unsupervised problems.Work closely with Legal Experts and Product Owners to identify complex areas to interpret and methodologies to tackle them. Drive to extract maximum value from our large corpus of legal data. What You'll Need To SucceedYou will have a strong background in this field, with proven commercial experience working in a related field.Interest in the application and domain - solving a challenge to generate real value.A pragmatic mind with strong problem-solving skills.Utilisation of the latest techniques available and relish collaboration with specialists: we partner with in both academia and AI-focussed businessesTechnical experience neededEssentialNLPMachine learningPythonDesirable experienceLinguisticsUnsupervised learningGraph technologies (networkx etc.)Experience with defining and working with ontologiesRelation extractionLanguage modellingTest-driven developmentDockerStatistics Why You'll Love Working Here Competitive salaryCompany pension scheme25 days annual leaveA collaborative, supportive, and dynamic work culture: you’ll work with people who demand the bestIn-depth training and one-to-one support as you build your career at ThoughtRiver and map out your professional goalA regular programme of fantastic team-building and social activities to foster a collaborative spiritEnvironmentally conscious and serious about climate change: we're committed to completely removing our impact on the environment by October 2021 We Are An Equal Opportunities EmployerWe commit to creating an inclusive environment that enables everyone to perform at their best, where we recognise the rights of all individuals to mutual respect and where there is an unbiased acceptance of others.  Our policies and practices aim to promote an environment that is free from all forms of unlawful or unfair discrimination and values the diversity of all people. At the heart of our policy, we seek to treat people fairly and with dignity and respect.",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Software, Internet",36,None,True,,153,ACTIVELY_HIRING_COMPANY
472,2166041433,2020-10-27,The Adecco Group,Senior Data Engineer (Permanently Remote-US),United States,"Grow your career with The Adecco Group, the world’s leading provider of recruiting and career services. SUMMARY: The Senior Data Engineer is responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. Experienced data pipeline builder and data wrangler that optimizes data systems and building them from the ground up. Supports our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. Acts as a mentor to less seasoned Data Engineers. ESSENTIAL DUTIES & RESPONSIBILITIES:Creates and maintains optimal data pipeline architecture.Assembles large, complex data sets that meet functional and non-functional business requirements.Identifies, designs and implements internal process improvements, automates manual processes, optimizes data delivery and re-designs infrastructure for greater scalability, etc.Builds the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and relevant Azure technologies like Data Factory, Databricks, and similar.Builds analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.Works with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.Keeps our data separated and secure across national boundaries through multiple data centers and regions.Creates data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.Works with data and analytics experts to strive for greater functionality in our data systems.Participating in special projects and performs other duties as assigned. MINIMUM EDUCATION & EXPERIENCE REQUIREMENTS:Bachelor’s degree in Computer Science, Statistics, Informatics, Information Systems or a related field plus five (5) years minimum experience in Data Engineering, business intelligence, data analytics or supply chain management required. MBA or graduate degree in a related field preferred.Minimum ten (10) years of experience in related ETL or data warehousing role required. KNOWLEDGE, SKILLS & ABILITIES REQUIREMENTS:Advanced working SQL knowledge and proven experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.Demonstrated experience in building and maintaining reliable and scalable ETL on big data platforms.Solid working knowledge of Scala, Python and R.Thorough knowledge of building and optimizing data pipelines, architectures and data sets.Ability to perform root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.Strong analytic skills related to working with unstructured datasets.Build processes supporting data transformation, data structures, metadata, dependency and workload management.A successful history of manipulating, processing and extracting value from large disconnected datasets.Working knowledge of message queuing, stream processing, and highly scalable data stores.Strong project management and organizational skills.Ability to support and work with cross-functional teams in a dynamic environment.Ability to take responsibility for assignments and report on progress with minimal oversight. COMPANY OVERVIEW: Adecco Group North America, through an impressive portfolio of staffing industry leading brands including Accounting Principals, Adecco General Staffing, Adia, Ajilon, Entegee, Lee Hecht Harrison, Modis, Paladin, Parker+Lynch, Pontoon, Special Counsel and Soliant is the world’s leading provider of Human Resources solutions. We are the workforce experts delivering staffing and career service solutions to organizations and individuals across all industries. Collectively we harness the power of some of the greatest talent in the world. That talent and expertise allows us to do business globally and act locally with deep knowledge in niche areas. Every day, we have more than 100,000 associates on assignment, 30,000 colleagues working internally to support more than 10,000 clients in the United States and Canada. Ensuring our business units are prepared to deliver outstanding service to our associates and clients, the Adecco Group North America team provides a strong infrastructure through our corporate and shared services teams. Equal Opportunity Employer Minorities/Women/Veterans/DisabledThe Company will consider for employment qualified applicants with arrest and conviction record",Intermedio,Jornada completa,"Tecnología de la información, Análisis, Cadena de abastecimiento","Servicio de información, Servicios y tecnologías de la información, Logística y cadena de suministro",68,None,False,,468,ACTIVELY_HIRING_COMPANY
473,2232889268,2020-11-03,HashiCorp,Senior Data Engineer - Cloud Services,"New Orleans, LA, US","About HashiCorp  HashiCorp is a fast-growing startup that solves development, operations, and security challenges in infrastructure so organizations can focus on business-critical tasks. We build products to give organizations a consistent way to manage their move to cloud-based IT infrastructures for running their applications. Our products enable companies large and small to mix and match AWS, Microsoft Azure, Google Cloud, and other clouds as well as on-premises environments, easing their ability to deliver new applications for their business.  Engineering at HashiCorp is largely a remote team. While prior experience working remotely isn't required, we are looking for team members who perform well given a high level of independence and autonomy.  Our Team  Cloud Services is an exciting team delivering HashiCorp products as managed services. We work across the company, and with multiple cloud partners, to make using HashiCorp products simple for our customers. We’re a small, but rapidly growing team, making a huge impact.  This Position  Location: Remote  As part of the Cloud Services organization, you’ll be a key part of a newly formed team tasked with building out our Analytics capabilities. This position plays a key role in data collection, processing, and reporting, analytics projects, and influencing key stakeholders with critical insights.  This is a chance to make a large impact across the team and company, by exposing data on our customers and the runtime information of our tools.  In This Role, You Can Expect To  Develop, construct, test, and maintain our Analytics platform. Discover opportunities for data acquisition. Develop data set processes for data modeling, mining and production. Recommend ways to improve data reliability, efficiency and quality. Contribute to the design and implementation of large-scale systems. Interface directly with internal teams, users, and HashiCorp customers. Work with multiple cloud platforms such as AWS, GCP, and Azure. Work with HashiCorp products such as Terraform, Consul, Vault, and Nomad.   You May Be a Good Fit If  You have built or operated a real time analytics pipeline at scale Have experience with tools similar to Segment, Looker, Heap, RedShift, RDS. You are familiar with microservice architectures, and ideally, have seen them in operation at a global scale. You have prior experience working in high performance distributed systems: while we strive to hire at a variety of experience levels, this particular opening is not well-suited for recent graduates. You are able to knowledgeably discuss design and performance tradeoffs in complex systems.   About The Application Process  Please note, as communication is a critical aspect of how we work, a cover letter is a great way to provide a sample of how you communicate. In your cover letter, describe why you're interested in working at HashiCorp, and what draws you to this role in particular.  HashiCorp embraces diversity and equal opportunity. We are committed to building a team that represents a variety of backgrounds, perspectives, and skills. We believe the more inclusive we are, the better our company will be.",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Internet",2,None,False,,13,COMPANY_RECRUIT
474,2170985160,2020-10-30,iMerit Technology,Account Development Representative,"Austin, Texas, United States","We’re looking for an Account Development Representative (ADR) to join our Sales team. As an ADR at iMerit, you will play a key role in building out the lead generation engine that supports our fast-growing business. Your primary focus will be booking appointments for the Sales team via cold calling, cold emailing, and attending conferences on behalf of the company. To be successful in this role, you will:BE A HUNTER: Research our space and our target accounts, engage with prospects via telephone/email/social, creatively initiate conversations, schedule meetings with the right people at the right companiesBE SCRAPPY: You find a way to get things done no matter what, customize useful sales materials (presentations, one-pagers, case studies), learn from mistakes, won’t make excusesBE A PROBLEM SOLVER: Have a consultative approach, deeply understand client needs/business goals, connect the dots on how iMerit will deliver customized solutions to solve unique client problems, handle and overcome prospect objections verbally and via emailBE A TEAM PLAYER: Work cross-functionally with SDR, Sales, and Marketing teams to ensure campaign success, ask for help when needed, help others when ableBE A SELF-STARTER: Tackle new markets and opportunities with a great sense of urgency while having little direction and training, update all prospect interactions and statuses in Salesforce to ensure efficient lead management, take initiative – when you see something needs to be done you do itBE AN INFLUENCER: Lead by example, show a high level of work ethic, add to the company culture, deliver measurable results Required Experience/Skills:1-2 years experience in a Sales or lead generation role (cold calling)Ability to work interculturally and in a distributed teamInterest and openness to travel (up to 50%)Self-directed learner and hands-on problem solverComfortable working with data and complicated technologiesDesire to research market trends, technology, and concepts, in Artificial Intelligence/Machine Learning/Data Science Ideal Candidate Traits/Experience:Proven track record of reaching/exceeding sales goalsExperience working with an international teamExperience working with remote teamsPrior work history with crowdsourcing/outsourcingInterest in social impactBasic knowledge of Microsoft Office, Google suite, and Salesforce About You:Able to get along with everyone (can carry a conversation with a CEO, data scientist, homeless person)Curious by nature – eager to learnPassionateCompetitiveEXCELLENT verbal and written skillsValue teamwork but able to fly soloHave a track record of thriving in a self-starting environment leveraging your drive, creativity, and intellectOutstanding organizational and time management skills Proving yourself in this position has a clear career path upward within the Sales Org and can also lead to other opportunities within other departments in the organization. If you're confident you have what it takes and are ready to roll up your sleeves, we would love to meet you!",Algo de responsabilidad,Jornada completa,"Ventas, Desarrollo empresarial",Servicios y tecnologías de la información,120,None,True,,398,ACTIVELY_HIRING_COMPANY
475,2210781893,2020-10-24,Perficient,Lead Data Scientist,United States,"OverviewAt Perficient, you’ll deliver mission-critical technology and business solutions to Fortune 500 companies and some of the most recognized brands on the planet. And you’ll do it with cutting-edge technologies, thanks to our close partnerships with the world’s biggest vendors. Our network of offices across North America, as well as locations in India and China, will give you the opportunity to spread your wings, too.We’re proud to be publicly recognized as a “Top Workplace” year after year. This is due, in no small part, to our entrepreneurial attitude and collaborative spirit that sets us apart and keeps our colleagues impassioned, driven, and fulfilled.Perficient currently has a career opportunity for a Lead Data Scientist.Job OverviewThe role of the Lead Data Scientist is for individuals passionate about identifying and delivering the right Business solution for each client using AI/ML. Our Data Scientists are keen to understand our customer needs, processes, and pain point to determine the success factors and evaluation criteria that will be needed to measure the effectiveness of an ML model.The Lead Data Scientist will be involved in the strategic planning of an engagement or helping the client make decisions about their future AI/ML roadmap and vision. Once the project as begun, the Lead Data Scientist will be responsible for the execution of our established methodology, worked with the customer and/or the team's data engineer to identify data ingestion and transformation needs, exploration of the data and reporting findings, modeling, and evaluation of training iterations. It is a key part of the role to be able to explain in non-technical terms the chosen modeling approach and findings from data exploration or training results.The Lead Data Scientist will work with Senior Project Managers to assist with daily operations exercising time management, communication, and collaboration in a fast-paced environment to ensure the successful delivery of projects. The Lead Data Scientist will interface with Perficient technical and business delivery personnel, as well as vendors and customers on a regular basis. May mentor junior data scientists.ResponsibilitiesUse your machine learning (ML) expertise to research and recommend the best approaches to provide technology and business solutions by utilizing statistical/ mathematical methods (classification, time-series analysis, regression, statistical inference, …) or deep learning techniques.Perform exploratory data analyses, generate and test working hypotheses, prepare and analyze historical data, and identify patterns.Work directly with clients and stakeholders to present and explain the key techniques and major results generated using non-technical language: understand client feedback and be able to accommodate back into the model through programming or additional feature engineering.Come up with innovative, repeatable, business use cases for real-world recommendation techniques, and quickly develop prototypes to test these use cases.Utilize a diverse array of technologies, tools, and cloud services as needed, to deliver insights, such as Microsoft Azure.Translate customer pain points, needs, and requirements into creative ML solutions.Help define the automated AI/ML pipeline for both training and runtime predictions.Assist in the development of guidelines, best practices, and knowledge sharing documentationAbility to deliver on schedule and communicate effectively to ensure alignment between operations and technology.Ability to educate customers on project goals and solutions and set realistic expectations. Qualifications5+ years of professional business and data analysis or engineering experience, with strong relationship management and project execution experience.Minimum 2 years of consulting experience or a similar customer-facing role.Proven track record in working with large and complex datasets, developing ML models, supporting data pipelines in a production environment.Experience working in an Agile environmentUnderstanding of iterative development methodologiesStrong knowledge and understanding of current ML technologies & platforms and real-world applications of ML in the enterprise.Knowledge of current technologies and ML frameworks (TensorFlow, PyTorch, sklearn, keras,…)Hands-on experience in data engineering/processing frameworks (databricks, spark, dataflow, …)Experience with the MLOps framework (Kubeflow, MLFlow, airflow, …) a big plus.Skilled ability to obtain, understand, and respond strategically to client needs.Highly detail-oriented, well organized, and able to coordinate multiple projects simultaneously.Strong analytical, problem-solving, and conflict resolution skills.Energetic, motivated, service-oriented, and be able to multi-task.Proven track record of delivering on time, on budget, and meeting client commitments.Excellent listening, oral, and written communication skills.Excellent facilitation, presentation, and reporting skills.Strong interpersonal and teamwork skills.Flexible to new situations and challenges.Flexibility to travel up to 50 percent. Preferred Skills And EducationMaster’s Degree in Data Science, Mathematics, Statistics, or Computer Science or related major.Current and active AI/ML Certification in majors cloud platform (AWS, Azure, GCP, IBM) a big plus.Experience working in a professional services company, consulting firm, or agency. Perficient full-time employees receive complete and competitive benefits. We offer a collaborative work environment, competitive compensation, generous work/life opportunities, and an outstanding benefits package that includes paid time off plus holidays. In addition, all colleagues are eligible for a number of rewards and recognition programs including billable bonus opportunities. Encouraging a healthy work/life balance and providing our colleagues with great benefits are just part of what makes Perficient a great place to work.More About PerficientPerficient is the leading digital transformation consulting firm serving Global 2000 and enterprise customers throughout North America. With unparalleled information technology, management consulting, and creative capabilities, Perficient and its Perficient Digital agency deliver vision, execution, and value with outstanding digital experience, business optimization, and industry solutions.Our work enables clients to improve productivity and competitiveness: grow and strengthen relationships with customers, suppliers, and partners: and reduce costs. Perficient's professionals serve clients from a network of offices across North America and offshore locations in India and China. Traded on the Nasdaq Global Select Market, Perficient is a member of the Russell 2000 index and the S&P SmallCap 600 index.Perficient is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national, origin, disability status, protected veteran status, or any other characteristic protected by law. Disclaimer:  The above statements are not intended to be a complete statement of job content, rather to act as a guide to the essential functions performed by the employee assigned to this classification. Management retains the discretion to add or change the duties of the position at any time.",Intermedio,Jornada completa,"Otro, Tecnología de la información","Servicios y tecnologías de la información, Software",72,None,True,,352,ACTIVELY_HIRING_COMPANY
476,2206267426,2020-10-14,HuntSource,Senior Big Data Engineer,Atlanta Metropolitan Area,"Senior Big Data Engineer  100% Remote Compensation: base salary up to $160,000 DOE plus bonus and excellent benefits. Total comp approx.. $185,000 to $195,000 Immediate permanent opportunity for an experienced Data Architect. In this role, you will contribute to new, innovative data strategies. You will work with data first architecture while driving efforts to build out scalable, and efficient solutions to flow data from production systems into a data lake. This opportunity requires strong experience in EMR execution environment, Apache Spark and Python. Requirements for an experienced Senior Big Data Engineer:﻿EMR execution environment in Spark5+ years of software engineering experience using Python, and/or Java and Scala, with at least 5 years experience in a data focused roleExposure to transforming large data sets using Spark, Hadoop, Kafka, and/or related technologiesStrong knowledge and experience with AWS RDS, Glue, EMR, Redshift, Athena, and LakeFormation.Strong knowledge of data lake, data warehousing, and ETL/ELT concepts For immediate consideration please send an updated resume to Jaymes: jnowicki@huntsource.io",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Servicios y tecnologías de la información,47,None,True,jnowicki@huntsource.io,172,ACTIVELY_HIRING_COMPANY
477,2247060067,2020-10-09,PetDesk,Sr. Data Engineer,"San Diego, CA, US","About The Role  PetDesk provides an industry leading app and reminder platform that allows pet care providers to better communicate with pet parents. In order to maintain the most up-to-date information from pet care providers to millions of pet parents, the team developed a robust customer data sync technology. Now, we are excited to grow our Integrations Systems team to enhance and expand these data sync services within our ecosystem of partners.  The primary responsibility of this role will be to improve and modernize our back-end customer data sync technology, using best practices and the latest cloud-based technology, to meet the demands of our growing customer base. This also includes building and maintaining data systems to support future integrations and analytics. The ideal candidate is comfortable with a variety of tools and systems including AWS and Serverless, SQL and MPP databases, .NET/C# and Python, as well as 3rd party data services.  Apply if you're excited to:  Design, develop, and implement customer data workflows and background data processing jobs. Modernize an evolving data integration platform in the cloud using distributed systems, serverless components, and parallel processing, to enable downstream application integrations. Automate data synchronization processes and work with modern data (ETL) process scheduling tools (Apache Airflow), supporting complex source to target mappings. Provide and maintain a reliable infrastructure for delivery, storage, and processing of large data sets and databases (MPP, Postgres, SQL, etc.).   About You  Proficient with SQL and query optimization (ideally MS SQL and/or PostgreSQL). Excellent grasp of OOP concepts, preferably using Python and/or C#. Well-oriented with cloud platforms, particularly Amazon Web Services. Experience with API design, data modeling, and best practices for supporting related systems. A data automation mindset, with a focus on building reusable back-end components designed to scale with increased data volume and complexity. Best case scenario: experience with veterinary (or medical) practice management data/integrations!   Benefits & Perks  PetDesk is a Remote First organization, ensuring our culture, infrastructure, and ecosystem supports team members participation in critical decisions and information sharing, regardless of location. Benefits and perks include Medical/Dental/Vision/Life plans, flexible time off, 401(k), and paid parental leave. We also look forward to one day re-opening our dog friendly, Banker's Hill/Downtown San Diego location with a gorgeous view of the San Diego Bay!  About Us  PetDesk, an industry leader in Veterinary client communication software, has helped over 2,000 veterinary practices streamline business with simple software solutions that help pet parents stay current and pet care providers stay connected. The PetDesk Experience has garnered 2M App users and counting with a 5-Star Capterra rating through powerful features, including a 5-Star Rated Pet Health Mobile App and industry-leading customer support. The 150,000 reviews across the App/Google store speak for themselves.  Founded in 2013 and headquartered in San Diego, CA, PetDesk secured a Series-B Investment of $12M from Silicon Valley based Peakspan Capital in Dec. 2018. PetDesk employs nearly 70 team members and proudly supports a gender balanced workforce. We celebrate diversity and are committed to creating an inclusive environment for all employees. The more inclusive we are, the better our work will be.  Our mission is to engage pet parents in their pets' health through a deeper relationship with their pet care providers.  PetDesk is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. The more inclusive we are, the better our work will be.  Please, no external recruiters—candidate profiles submitted from external recruiting agencies will not be considered.  Notice at Collection to Applicants Residing in California Depending on your location, the California Consumer Privacy Act (CCPA) may regulate the way we manage the data of job applicants. Our full notice outlining how your data will be processed as part of the application procedure for application locations is available at this link.By submitting your application, you are agreeing to our use and processing of your data as required.",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Internet",None,None,False,,34,ACTIVELY_HIRING_COMPANY
478,2159760687,2020-10-26,InfoVision Inc.,Sr Data Engineer / Sr Big Data Engineer,"Henrico, Virginia, United States",Job Description: Main Skills:• 9+ years of IT industry experience• Apache Spark• Spark Streaming• Snowflake• Apache Kafka• Scala• AWS Amazon Web Services• Python,Intermedio,Contrato por obra,"Ingeniería, Tecnología de la información",Servicios y tecnologías de la información,88,None,True,,308,ACTIVELY_HIRING_COMPANY
479,2284728178,2020-11-07,Sub-K IMPACT Solutions Ltd,Data Scientist,"Hyderabad, Telangana, India","Job ProfileWe are looking for a Data Scientist to help us gain useful insights out of raw data. Data Scientist responsibilities include building analytics models. You should have a strong problem-solving ability and a knack for statistical analysis. If you’re also able to align our data products with our business goals, we’d like to meet you. Your ultimate goal will be to help improve our products and business decisions by making the most out of our data ﻿ResponsibilitiesPart of team of data scientists, machine learning engineers and big data specialistsDo data mining and collection proceduresEnsure data quality and integrityInterpret and analyze data problemsConceive, plan and prioritize data projectsBuild analytic systems and predictive modelsTest performance of data-driven productsVisualize data and create reportsExperiment with new models and techniquesAlign data projects with organizational goals RequirementsProven experience of 2-4 years as a Data Scientist or similar role in financial institutionGood understanding of machine learning, deep learning, reinforcement learningKnowledge of AWS cloud data managementA knack for statistical analysis and predictive modelingGood knowledge of R (EDA, ML, DL), Python (ML, DL, GPU)Extensive experience with SQL and NoSQL databasesExperience with SPSS ModelerExposure to Big Data ProcessingDecision Trees, Clustering, Support Vector Machines, Dimensionality Reduction algorithms, Ensemble algorithms, Regression models, Hidden Markov modelsExposure to frameworks & Libraries like Pytorch, TensorflowetcExposure to conversational AI/ NLP (preferred) USP of role Opportunity to work ongroundbreaking ideas which impact millions of households Interested?Send in your credentialsat earliest toradhadevi.a@subk.co.in and CC to divyanshu.anand@subk.co.in",Sin experiencia,Jornada completa,Tecnología de la información,Servicios financieros,171,None,True,"toradhadevi.a@subk.co.in, divyanshu.anand@subk.co.in",541,ACTIVELY_HIRING_COMPANY
480,2261389150,2020-10-06,Beat,Senior Data Engineer,"Athens, GR","About Us  Beat is one of the most exciting companies to ever come out of the ride-hailing space. One city at a time, all across the globe we make transportation affordable, convenient, and safe for everyone. We also help hundreds of thousands of people earn extra income as drivers.  Today we are the fastest-growing ride-hailing service in Latin America. But serving millions of rides every day pales in comparison to what lies ahead. Our plans for expansion are limitless. Our stellar engineering team operates across a number of European capitals where, right now, some of the world's most ambitious and talented engineers are changing how cities will move in the future.  Beat is currently available in Greece, Peru, Chile, Colombia, Mexico and Argentina.  About The Role  Data is at the heart of this effort and is an essential ingredient in Beat's aggressive growth plan and vision for the future. We're currently transitioning to a microservices architecture which requires novel solutions when it comes to ingestion and leverage of the data from different sources.  As a member of our team, you will help tackle some of the most fundamental data-driven challenges we face and your work will impact the entire Beat experience.  Our remote workforce works East Europe Timezone hours (10am - 6pm) and therefore we will need you to be located within UTC to UTC+3 to reasonably overlap with your team members' work schedule. With the various tools and communication technologies we're using, you'll feel connected to your team. You always have the option to travel to our headquarters for meetings, events, and team bonding—or you can join virtually. Whatever works best for you and your work style.  What you'll be doing:  Work closely with Data and Platform engineers for the design, development, enhancement and support of real-time data ingestion solutions. Develop the core libraries and tools that support data engineers across different teams. Develop components that will analyse, process and react to operational feeds in near real-time. Be agile both within and across teams, democratizing access to data for anyone within the organization.  What you need to have:  Bachelor's or Master's degree in Computer Science or in a related Engineering field. Higher degrees are highly appreciated. Experience building and running large-scale real-time and batch data pipelines. Experience coding using both Object-Oriented and Functional Programming principles on top of the JVM. Good understanding of the way distributed storage and processing systems work.  What is good to have:  Familiarity with the Apache Hadoop stack (YARN, HDFS, MapReduce and Hive). Hands-on experience with Apache Spark. Familiarity with ETL processes and industry best practices. Experience in developing with Scala. Familiarity with distributed messaging systems, preferably Apache Kafka. Hands-on experience with streaming technologies such as Spark Streaming, Apache Flink or Kafka Streams. Exposure to Kubernetes. Knowledge of relational databases and NoSQL technologies.  What's in it for you:  Competitive salary package Flexible working hours High tech equipment and top line tools A great opportunity to grow and work with the most amazing people in the industry Being part of an environment that gives engineers large goals, autonomy, mentoring and creates incredible opportunities both for you and the company  Please note that you will be working as contractor.  As part of our dedication to the diversity of our workforce, Beat is committed to Equal Employment Opportunity without regard for race, color, national origin, ethnicity, gender, disability, sexual orientation, gender identity, or religion.",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Marketing y publicidad, Software, Internet",4,None,False,,55,ACTIVELY_HIRING_COMPANY
481,2199898267,2020-10-22,Costain Group PLC,Azure Data Engineer,United Kingdom,"About Us:Our vision is to be the UK’s leading smart infrastructure solutions company. We will achieve this by focusing on blue chip clients whose major spending plans are underpinned by strategic national needs, regulatory commitments, legislation or essential performance requirements.  We offer our clients leading edge solutions that are digitally optimised through the following five services which cover the whole lifecycle of their assets: future-shaping strategic consultancy: consultancy and advisory: digital technology solutions: asset optimisation and complex programme delivery. Our culture and values underpin everything we do. Our Digital Team is growing rapidly and we are looking for individuals to join our DevOps Team as Data Engineers. Costain prides itself with creating a space that promotes creativity and the ability to think outside the box and believe this role is a truely exciting opportunity for a Data Engineer (SQL Azure/Data Factory/PowerBI and PowerApps) in search of a new challenge, who embraces new technology and tools and want to work alongside data architects and development engineers in a forward thinking Agile team.  About You:You will have a particular passion and expertise for Microsoft's SQL Azure / Data Factory / PowerBi / PowerApps platforms and want the opportunity to play a pivotal part in architecting, developing, managing and supporting Costain's Enterprise Data Warehouse. Essential experience required for the Data Engineer (SQL Azure/Data Factory/PowerBI and PowerApps) includes:Strong background in Data Engineering and Architecture.Strong understanding of Microsoft SQL Server, Azure, PowerApps and Power BI.Strong familiality of the Azure DevOps toolsetProven track record of implementing end-to-end data solutions and ELT/ETL pipeline development skills.Maintain and optimize the Data Warehouse and Data Lake / Data Brick solutions to maximize performance.Experience working with solutions in the Cloud specifically Microsoft's Azure platform.Strong SQL experience both within the SQL Azure space and on prem.Good documentation experience.Ability to communicate well with key stakeholders and non-technical audiences. Desirable experience required for the role includes:Experience in leading data engineering projects.Experience working with large-scale data environments in a data engineering role.Microsoft Azure related Certifications.Experience working in the Construction/Infrastructure space.Create apps and implement dashboards within the PowerApp and Power BI spaceExperience with AWS. A demonstrable track record in a similar role is a necessity for this role.  Benefits of Working for Us:We listened to our employees so our Core Benefits are funded by us and include a Group Pension Scheme, Employee Assistance Programme, Life Assurance, Income Protection and funded membership to a Professional Institute. In addition to this we also offer a Private Healthcare Scheme, Private Dental Scheme, Cycle to Work, Volunteering Days and Save as You Earn Scheme.  Diversity & InclusionAt Costain we aim to be an accessible, diverse and inclusive organisation to continue to meet our customers’ needs. We will be industry leading in our approach and people from all backgrounds will be proud to work for Costain. Our goal is to have a workforce that is representative of society.  We are proud to be a Times Top 50 Employer of Women and a Stonewall Diversity Champion.",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Ingeniería civil, Servicios y tecnologías de la información",19,None,False,,161,ACTIVELY_HIRING_COMPANY
482,2279731834,2020-11-05,Solas IT Recruitment,SSIS Data Engineer Specialist – Contract (work from home),"London, England, United Kingdom","SSIS Data Engineer Specialist – Contract (work from home) The SQL Data Engineer will be required to develop, implement and document data systems that provide technical solutions to meet specifications and business requirements. The SQL Data Engineer will be required to work on the Development of two frameworks using SSIS:To perform ‘continuous’ data validation of data within the enterprise data platformTo communicate with message queueing software to communicate changes to specific data sets within the platform Responsibilities: Specifically:Developing and maintaining current state documentation and deliverables for data solutions.Maintain existing and new data solutions to ensure that they continue to meet user needs. ﻿Requirements:Expert level SSIS SkillsAdvanced SQL server development skillsAbility to solve problems in a generic, rather than situation specific mannerBachelors Degree in Computer Science or other related degree: or experience of such kind and amount as to provide a comparable background.Experience with relational SQL and NoSQL databases: experience with SQL Server, Oracle, and/or MongoDB preferred.Experience building data transformations, data structures, and data pipelines.Experience with data integration tools.Experience with object-oriented/object function scripting languages.Demonstrated organizational, analytical, and interpersonal skills.Ability to manage tasks independently and take ownership of responsibilities.",Intermedio,Contrato por obra,"Ingeniería, Tecnología de la información","Dotación y selección de personal, Telecomunicaciones, Interconexión en red",46,None,True,,134,JOB_SEEKER_QUALIFIED
483,2258251338,2020-10-05,Flo Europe,UX researcher,"Moscow, RU","We are ready to consider remote applicants for this role, in any European time zone. Occasional business trips to our EU hubs will be required.  Requirements:   At least 3 years of work experience as a UX Researcher: Experience with both qual and quant methodologies: Experience with conducting in-person interviews and unmoderated remote user testing: Understanding of agile product development process: Good documentation and communication skills: Proficiency in English – comfortable working on a day to day basis. Passion for uncovering user insights and translating findings into product improvements: Quick learner that enjoys tackling a large variety of problems: Attention to details and commitment to quality:   Responsibilities:   Design and conduct user research studies, including remote and in-person UX studies, surveys for existing and future products Autonomously manage all aspects of user research for a given project from start to finish Communicate user research findings to cross-disciplinary teams",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Internet",5,None,False,,86,None
484,2207123583,2020-10-23,Bose Corporation,Senior Data Scientist,"Boston, Massachusetts, United States","Bose Sr Data Scientist   Are you passionate about applying data science to real business and customer needs? Would you like to use your data science skills to help our customers do more, feel more, and be more?At Bose, we aim to bring products into the world that people truly love, and we don’t stop until the details are just right. Data science, machine learning, and analytics are a crucial part of this mission.  These capabilities fuel the creation of new and innovative products in consumer electronics and wellness, help us to bring the right products to the right customers, and allow us to astonish customers with carefully crafted and personalized experiences. We are looking for a data scientist for our growing “AI for Business” team. The mission of this team is to develop world-class AI, data science, machine learning, and related solutions to extract insights from data for driving business and customer value. We provide data science expertise and partner with teams across the company, including sales, marketing, supply chain, and finance organizations. Our outcomes include optimized pricing, accurate demand forecasting, improved customer service, personalized recommendations, optimized digital experiences, and more.  Responsibilities: Engage with business partners and stakeholders to understand business problems and translate them into data science solutions.Coordinate data science, data engineering, and data governance resources to achieve business outcomes.Guide and contribute to the end-to-end development and deployment of predictive and prescriptive models for marketing, sales, finance, supply chain, and other business applications.Explore large datasets using modeling, analysis, and visualization techniques.Apply frequentist and Bayesian statistical inference tools to experimental and observational data.Communicate results, analyses, and methodologies to technical and non-technical stakeholders.Mentor junior data science colleagues.  Preferred skills and experiences: 7+ years of experience applying data science, AI/machine learning, and analytics techniques to business problems2+ years of experience leading data science projects or teamsExcellent strategic thinking, communication, collaboration, and problem-solving skillsExperience solving real-world problems with data at IoT scale using tools such as SQL, Spark, and PythonExperience with and understanding of project management tools and principlesExperience deploying machine learning models in enterprise systemsStrong programming background with experience using PythonStrong understanding of machine learning and statistical inference (including frequentist and Bayesian) concepts and techniques Education: Our group consists of B.S, M.S. and Ph.D. level backgrounds with members holding degrees in Data Science, Machine Learning, Computer Science, Business Analytics and Statistics. A similar educational background is preferred.",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Electrónica de consumo,63,None,False,,564,ACTIVELY_HIRING_COMPANY
485,2241534675,2020-11-05,VanderHouwen,Data Engineer,United States,"Job Description Job ID# 48038 **This position can be done 100% remote from anywhere in the United States but the candidate must be willing to work PST hours. Sorry, sponsorship is not available for this position.**  Data EngineerOur client is Looking for a data expert to improve the depth and accuracy of our database and collaborate on search and recommendation tools for our community. This will be their first dedicated data hire, you’ll work directly with the CTO to drive data improvement projects, manage data pipelines, and find ways for us to best put their data to good use.  We’re looking for people who:Are great communicators — Effective communication is key to how they work. They value patience and empathy in our product planning, support, and day-to-day relations.Work well both collaboratively and independently —They come together to pair on tricky problems and architecture, then dive deep on individual tasks.Are ready to learn and share knowledge — Everyone comes to our company with their own set of skills and experiences. Cross-training, code review, mentorship, and curiosity all help us build better products. Potential Pojects:Evolve and maintain data processing pipelines, combining public, private, and user-contributed data.Use natural language processing to extract relevant highlights and amenity information from campground review text.Coordinate manual data review and improvement projects using internal staff, community crowdsourcing, or mechanical turk.Make use of photo geotags and computer vision (via Amazon Rekognition / GCP Vision AI) to infer information about campground amenities.Improve techniques for matching and deduplication between multiple data sources.Import public data on national and state parks, forests, and recreation areas to provide a better search experience. Qualifications4+ years of professional experience in data engineering, data science, software development, or related field.Strong backend programming skills in one or more languages.Experience creating and maintaining data ETL pipelines or other complex data import systems.Fluency with SQL and relational schema design.A friendly working relationship with CSVs. PreferredAdvanced degree in math, statistics, computer science, information science, or related field.Experience working with geospatial datasets and GIS analysis.Experience applying machine learning techniques to real world problems.Familiarity with Elasticsearch.",Intermedio,Jornada completa,Tecnología de la información,Software,59,None,True,,166,ACTIVELY_HIRING_COMPANY
486,2197050949,2020-10-20,Tata Consultancy Services,BI DATA ENGINEER AWS/Azure,"São Paulo, São Paulo, Brazil","• Knowledge in Cloud Services (AWS/Azure) data applications building and data pipelines creation/curation is mandatory• Database/Data Warehouse (e.g. AWS Redshift, SQLDW, Oracle, Postgres). Previous experience with Stored Procedures and UDF’s is mandatory:• Multidimensional modeling (Star Schema and Snowflake) is mandatory:• Data Cleansing /Data Quality concepts knowledge is mandatory:• Basic Salesforce platform knowledge is mandatory:  • Arm Treasure Data (Customer Data Platform) is a strong plus:• Master Data concepts knowledge is a strong plus:• Knowledge in Python language is a plus • Knowledge in Cloud Services (AWS/Azure) data applications building and data pipelines creation/curation is mandatory • Database/Data Warehouse (e.g. AWS Redshift, SQLDW, Oracle, Postgres). Previous experience with Stored Procedures and UDF’s is mandatory:• Multidimensional modeling (Star Schema and Snowflake) is mandatory:• Data Cleansing /Data Quality concepts knowledge is mandatory:• Basic Salesforce platform knowledge is mandatory:• Arm Treasure Data (Customer Data Platform) is a strong plus:• Master Data concepts knowledge is a strong plus:• Knowledge in Python language is a plus    ·        Data Engineer, AWS, Azure, Database, Data Warehouse, Data Cleansing /Data Quality, Cloud Services",Algo de responsabilidad,Jornada completa,Tecnología de la información,Servicios y tecnologías de la información,59,None,True,,269,COMPANY_RECRUIT
487,2220524669,2020-10-28,Willis Towers Watson,Actuarial Data Scientist Internship,"Milan, IT","The Business: Insurance Consulting and Technology (ICT)   Our sophisticated approach to risk helps clients free up capital. We work in close concert with investors, reinsurers, and insurers to manage the equation between risk and return.  Using techniques and software solutions to help clients measure and manage risk and capital, grow revenue and create a competitive advantage.  Role: Actuarial Data Scientist Internship  The Actuarial Data Scientist Internship works under the direction of a Director, Senior Consultant or Consultant to organize, input and update data in actuarial models. Effectively communicate with project teams to meet or exceed internal expectations. Ensure that projects are on time and meet WTW’s standards of excellence.   Aptitudes y experiencia deseadas The Requirements:         Actuarial Science, Mathematical Engineer /Mathematics or related discipline degree level Intellectual curiosity to Actuarial Science reserving & pricing (P&C) Knowledge of Data Mining, Machine Learning: Intellectual curiosity to Python, R, SQL, Bash, Delphi, Big Data: Hadoop, MapReduce, Spark  Intellectual curiosity to deliver insightful analysis to tight deadlines Excellent communications skills Fluent spoken and written English C1 Level Formatting work correctly and professionally Reviewing work to ensure accuracy Ability to handle and process confidential information with complete discretion Proactively requesting additional work Committed to quality: continuously works to achieve the highest quality standards   Location: Milan   “Belonging to protected category as per Law 68/99 is the preferred lane”  “We are committed to equal employment opportunities at Willis Towers Watson”   The Company     Willis Towers Watson is a leading global advisory, broking and solutions company that helps clients around the world turn risk into a path for growth. With roots dating to 1828, Willis Towers Watson has 40,000 employees serving more than 140 countries. We design and deliver solutions that manage risk, optimize benefits, cultivate talent, and expand the power of capital to protect and strengthen institutions and individuals. Our unique perspective allows us to see the critical intersections between talent, assets and ideas – the dynamic formula that drives business performance. Together, we unlock potential. Learn more at willistowerswatson.com.  Willis Towers Watson is an equal opportunity employer:  Willis Towers Watson believes that effectively managing a diverse workforce is vital to our business strategy. We have an obligation to our organization, ourselves and our clients to hire and develop the best people we can find. We will continually review our policies and practices to ensure that all areas of the employment process (including recruiting, hiring, work assignments, compensation, benefits, promotions, transfers, company-sponsored development programs and overall workplace experience) are free from discriminatory practices. We are committed to equal employment opportunities at Willis Towers Watson.       Unsolicited Contact: Any unsolicited resumes/candidate profiles submitted through our web site or to personal e-mail accounts of employees of Willis Towers Watson are considered property of Willis Towers Watson and are not subject to payment of agency fees. In order to be an authorized Recruitment Agency/Search Firm for Willis Towers Watson, any such agency must have an existing formal written agreement signed by an authorized Willis Towers Watson recruiter and an active working relationship with the organization. Resumes must be submitted according to our candidate submission process, which includes being actively engaged on the particular search. Likewise, for our authorized Recruitment Agencies/Search Firms, if the candidate submission process is not followed, no agency fees will be paid by Willis Towers Watson. Willis Towers Watson is an equal opportunity employer.",Prácticas,Jornada completa,"Análisis, Consultoría, Tecnología de la información","Consultoría de estrategia y operaciones, Seguros",209,None,False,,1478,ACTIVELY_HIRING_COMPANY
488,2242567005,2020-10-26,Materialize,Software Engineering Manager,United States,"Materialize is the first true SQL streaming database. Materialize lets users build applications and experiences with millisecond-level latency for real-time data, using simple SQL queries. Our work builds on top of Timely Dataflow and Differential Dataflow, both created by our co-founder Frank McSherry, a world-leading computer scientist with decades of award-winning research in all aspects of data. Our aim is simply building something that works, in a space where most products simply do not. About the role: At Materialize, engineering management means serving your team of engineers to create an environment that allows them to effectively work and evolve. Because the team has a mix of backgrounds and geographic locations, this role requires a balance of execution, adaptability, and empathy. As an engineering manager at Materialize, you will report to our Head of Engineering, Cuong Do. Cuong has led teams of engineers at Cockroach Labs, started and led Dropbox NY, and was a founding systems engineer at YouTube, later managing YouTube's product engineering organization. You will also work closely with Frank McSherry, Materialize's Chief Scientist and Co-founder. Frank was a driving force behind Naiad and created Timely Dataflow and Differential Dataflow. Materialize currently has 12 engineers. Most of our engineers are in New York City, but we have engineers in every North American time zone. With effective engineering leadership and infrastructure in place, we could double in size over the next year and will continue to grow well beyond that. You will contribute to the product and technology strategy for your group. You will be responsible for the delivery of the products being built. In addition, you will contribute to the development and growth of the overall engineering organization.You will:Serve your team through coaching, mentoring, and management.Start as a software engineer on the team for 1-3 months, to develop close working relationships with our software engineers.Partner with recruiting to create a hiring plan and source, screen, interview, and close engineering candidates.Work with cross-functional stakeholders to ensure sustainable, effective delivery.Work with tech leads to develop technical roadmaps and manage code quality.Foster a culture of execution, quality, and inclusivity.Grow the technical expertise and careers of your team members.Develop the essential processes and structure needed to consistently deliver.Requirements:2+ years of experience at a startup managing engineering teams of distributed systems and infrastructure engineers.Experience managing a distributed team.Substantial hands-on engineering experience with one or more of the following: distributed systems, databases, and data infrastructure.Strong written and verbal communication skills.Ability to adapt to different development methodologies.Ability to create a sufficient amount of process to help the team make progress.Experience working cross-functionally with product management, sales, and marketing.B.S. degree in Computer Science, or equivalent experience.Bonus points for:Significant experience using SQL databases, Kafka, and other data infrastructure.Background in creating data infrastructure, such as databases.Experience building high performance, high availability systems.Experience working on a cloud product.M.S. or Ph.D. in Computer Science.Experience managing a remote-first team. As an early engineering manager at Materialize, you will lead part of our skilled engineering team. You'll help create the structure that will enable sustainable engineering growth. We are gearing up for growth, and you could be part of what makes that growth possible. Especially strong remote candidates will be considered. Such candidates will have significant experience leading distributed teams and a demonstrated ability to work with engineers with different levels and backgrounds. Working at Materialize * 100% covered health insurance for you and all your dependents* 401k* Flexible working hours* 4 weeks of vacation* Competitive equity package We understand it takes a diverse team of highly intelligent, passionate, curious, and creative people to develop the exceptional product we are building. Our dynamic team has incredible perspectives to share, just as we know you do, and we take great pride in being an equal opportunity employer.",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Software,45,None,False,,281,COMPANY_RECRUIT
489,2188702391,2020-10-16,"Neuronetics, Inc.",Clinical Research Scientist,United States,"Neuronetics is a commercial stage medical technology company focused on designing and marketing products that improve the quality of life for patients who suffer from psychiatric disorders. NeuroStar Advanced Therapy is the leading transcranial magnetic stimulation (TMS) device, and was the first TMS device designed for clinical use for the treatment of patients with Major Depressive Disorder. We are passionate about transforming patients’ lives and the practices of our physician customers. Treating depression at the source....One magnetic pulse at a time. The Clinical Research Scientist will be a representative of Strategic Clinical Development and will be responsible for supporting clinical strategy including development of New Indications, initial clinical study protocol synopsis drafts and pilot studies. He/She will review and analyze clinical publications and TrakStar data for technical content to support new indication submissions. This employee will become an expert on the medical literature for the science of transcranial magnetic stimulation, including existing standard of care for both medical device and pharmacologic treatment, pertinent regulatory guidances and will be able to summarize for strategic planning and company knowledge.  This role is based at our headquarters in Malvern, PA. Primary Responsibilities:Work with Dir Strategic Clinical Development on strategies for each indication submission.Perform retrospective analysis on published clinical data.Review competitor 510K submissions and publications for substantial equivalence data.Work with the Clinical Data Analyst to define search queries for supporting data.Work with the Clinical Data Analyst to develop analytics to support the 510K submission. Support development and author documents for 510K submissions. Become expert on clinical literature regarding TMS, psychiatric, neurologic and potentially other conditions, and current standard of careSummarize and adapt clinical study protocols and papers associated with key objectivesSummarize key papers and review with key medical and other company personnelSummarize papers associated with related studies for backgroundUnderstand related preclinical research results and conclusions, as needed Provide direct investigator/HCP interaction pilot study development as needed.Provide support for Outcomes Registry activities, Clinical Evaluation Reports and other related activities, as requested.Clinical report writing including clinical progress and other clinical reportsInterface with statistician to ensure adequate data handling and statistical analysis, as neededWrite departmental procedures and assist in training efforts, as neededParticipate in special projects as needed Travel up to 15%, as required Qualifications:Bachelor of Science: 5+ years in Clinical Research, Biological Research or related positionExperience with clinical research, summarizing of medical literature, medical deviceExcellent computing, project management software, presentation, excel, other skillsExcellent written and verbal communication skillsAbility to multi-taskAbility to work on cross functional teams",Intermedio,Jornada completa,"Investigación, Análisis, Ciencias","Servicios médicos, Industria farmacéutica",38,None,False,,375,ACTIVELY_HIRING_COMPANY
490,2265219012,2020-10-07,DeepL,"Senior Data Engineer - Language Data - Köln, Paderborn oder remote (m/w/d)","Köln, DE","DeepL...  ist das bekannteste KI-Unternehmen in Deutschland. Wir entwickeln neuronale Netze, die Menschen beim Umgang mit Sprache unterstützen. Mit dem DeepL Übersetzer haben wir die international beste Computerübersetzung auf den Markt gebracht und stellen sie für jeden im Internet kostenlos zur Verfügung. In den nächsten Jahren möchten wir DeepL zum weltweit führenden Unternehmen für Sprachtechnologie ausbauen.  Unser Ziel ist es, Sprachbarrieren zu überwinden und Kulturen einander näherzubringen.   Was unterscheidet uns von anderen Unternehmen?  DeepL (früher Linguee) wurde von Entwicklern und Forschern gegründet. Die Entwicklung neuer spannender Produkte steht bei uns im Vordergrund, deswegen verwenden wir viel Zeit für die aktive Forschung an den aktuellsten Themen. Wir verstehen die Herausforderungen bei der Entwicklung neuer Produkte und versuchen diesen mit einer agilen und dynamischen Arbeitsweise zu begegnen. Unsere Arbeitskultur ist sehr offen, denn wir wollen, dass sich unsere Mitarbeiter*innen wohlfühlen. In unserer täglichen Arbeit setzen wir moderne Technologien ein - nicht nur um Texte zu übersetzen, sondern auch um die weltweit besten Wörterbücher zu schaffen oder andere sprachliche Probleme zu lösen.  Wenn wir von DeepL oder Linguee als Arbeitgeber erzählen, reagieren viele Leute sehr positiv darauf. Weil sie sich über die offenen, kostenlosen Dienste und Apps schon häufig gefreut haben. Und wir freuen uns, dass wir helfen, Sprachbarrieren zu verkleinern.  Arbeite, wo immer Du möchtest  Du kannst entscheiden, ob Du zu Hause arbeiten möchtest oder im Büro. Unsere Arbeitsweise ist ganz darauf ausgelegt, dass Du ein fester Bestandteil des Teams wirst, egal wo Du arbeitest. Daher suchen wir deutschlandweit nach herausragenden Mitarbeiter*innen.  Was machst Du zukünftig bei DeepL?  Damit unsere Übersetzungs-Technologie die Feinheiten der menschlichen Sprache lernen kann, benötigen wir enorme Mengen an linguistischen Daten. Du ergänzt ein kleines Team, welches sich um die Beschaffung, Filterung, Aufbereitung und Qualitätsbewertung dieser Daten kümmert. Dabei benutzt, verbesserst und erweiterst Du unsere Pipeline und orchestrierst Hunderte von Servern - sowohl auf dedizierter Hardware als auch in der Cloud.  >>>  Deine Aufgaben  Du entwickelst, wartest und erweiterst die Infrastruktur für die Beschaffung und Verarbeitung unserer linguistischen DatenDabei stellst Du sicher, dass der Code und die Architektur performant, zuverlässig und gleichzeitig gut wartbar istDu löst auftretende Probleme und sorgst dafür, dass wir immer den Überblick behaltenZusammen mit den Researchern findest Du performante Lösungen für neue linguistische Fragestellungen Was wir Dir bieten  Interessante Probleme: Programmierung und Forschung auf höchstem NiveauEin kleines, effektives und extrem gutes Team mit viel Vertrauen und sehr kurzen Entscheidungswegen. Die Entscheider sind bei uns selbst EntwicklerFokus auf hoher QualitätViel Entwicklungspotential in einem der zukunftsträchtigsten Bereiche: in der Zukunft wird KI eine große Rolle in unserem Leben spielenArbeit an einem Produkt, das bereits jetzt mehr als 100 Millionen Menschen nutzenEine sinnvolle Arbeit: Wir reißen weltweit Sprachbarrieren ein und bringen damit verschiedene Kulturen einander näherEin schönes Büro in Köln oder Paderborn (oder eine vergleichbare Ausstattung für Dein Homeoffice) und viel Flexibilität Was Du mitbringen solltest  Mehrjährige Programmiererfahrung in C++ und PythonKenntnisse in anderen Programmiersprachen sind vorteilhaftErfahrung mit der verteilten Verarbeitung von großen DatenmengenErfahrung mit Amazon AWS (oder anderen Cloud-Umgebungen) und der automatisierten Verwaltung von Rechnern (z.B. mit Ansible) sind vorteilhaftVerständnis für AlgorithmikSpaß daran, auch schwierige Probleme zu lösenViel Interesse an neuen Dingen, beispielsweise neuen Programmiersprachen, neuen APIs, neuen Technologien bei maschinellem Lernen, ...Sehr gute Deutsch- sowie gute Englischkenntnisse, Kenntnisse in anderen Sprachen sind vorteilhaftErfahrung und viel Eigeninitiative bei der Programmierung verschiedenster Projekte Wir freuen uns auf Deine Bewerbung!",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Internet",2,None,False,,25,JOB_SEEKER_QUALIFIED
491,2285848415,2020-10-13,Sept Lieues,Data Engineer - Possibilité Remote,"Paris, FR","L'ENTREPRISE  Entreprise leader européen sur le marché de la data électorale qui développe des outils afin de comprendre et convaincre l'opinion à un niveau local.   LE POSTE / LES MISSIONS  Le data engineer participera à la mise en place et l'enrichissement du pipeline du traitement de donnée. Intégrant une équipe pluridisciplinaire (produit/dev/data) dans le but de développer les produits. Les missions sont les suivantes :  Travail en collaboration avec les data-scientist afin de mettre en production de manière robuste et scalable des algorithmes de NLP et de machine learning Conception, Implémentation et automatisation en Python Contribution à la conception et implémentation d'une architecture de traitement et de stockage des données performante et résiliante Aide à l'architecture des données afin qu'elles soient exploitable par l'équipe tech-product Participation à la mise en place de l'infrastructure cloud 80% Conception et implémentation python / data 20% Infra / devops   PROFIL RECHERCHÉ  Bac +5 ou équivalent en informatique. Vous avez un minimum de 2 ans d'expérience professionnelle avec idéalement une première expérience de Data Engineer sur des architectures complexes. Vous avez déjà travailler sur des problématiques de traitement de gros volumes de données (architecture de données, collecte, transformation...)  Vos Compétences Techniques Sont Les Suivantes  Python et son écosystème Conception et implémentation de micro-services / API Expérience sur des use-cases qui impliquent la manipulation de donnée non structurée  Base de données Optimisation et performances BDD relationnelles Les + :  Connaissances en Infra / DevOps Conception et implémentation de systèmes de collecte de donnée (scraper/crawlers) Architecture Serverless",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Internet, Dotación y selección de personal",None,None,False,,6,JOB_SEEKER_QUALIFIED
492,2211917527,2020-09-30,HomeLight,Data Engineer,"San Francisco, CA, US","Who We Are  HomeLight is a venture-backed technology startup revolutionizing the $1 trillion real estate industry. Our mission is simple – we empower people to make smarter decisions during one of life's most important moments: buying or selling their home.  HomeLight's technology analyzes millions of home transactions to determine which agent or cash buyer is right for you. We also offer innovative financing and closing solutions, creating an end-to-end real estate experience that's simple, certain, and satisfying.  We pride ourselves on our company culture – but don't just take it from us. We've been recognized as a best place to work by Forbes, Inc. Magazine, and the San Francisco Business Times. Our team breaks barriers every day while staying committed to HomeLight's goals and core values, which is a crucial element to our shared success.  What You'll Do Here:  We are building our Data Engineering team to tackle HomeLight's diverse, data challenges. This position is an excellent opportunity for an engineer that wants to own the development, optimization, and operation of our data pipeline, which collects, processes, and distributes data to a suite of HomeLight products and teams. You will provide mission-critical data to both our algorithms and internal users, refining our product and identifying new markets. Some projects you will work on:  Optimize and execute on requests to pull, analyze, interpret and visualize data Partner with team leaders across the organization to build out and iterate on team, and individual performance metrics Optimize our data release processes, and partner with team leads to iterate on and improve existing data pipelines. Design and develop systems that ingest and transform our data streams using the latest tools. Design, build, and integrate new cutting edge databases and data warehouses, develop new data schemas and figure out new innovative ways of storing and representing our data. Research, architect, build, and test robust, highly available and massively scalable systems, software, and services.  You Have:  3+ years of Python and ETL experience, preferably Airflow Experience writing and executing complex SQL queries Experience building data pipelines and ETL design (implementation and maintenance) Scrum/Agile software development process.  Bonus points for:  Expertise with Ruby on Rails. Familiarity with AWS, Elasticsearch, Ruby/Rails, Django, Heroku Experience setting up and managing internal API services. Experience working on a small team, ideally at a startup. Familiarity with the Amazon AWS ecosystem  Let's chat!   Send your resume and a brief note about why you'd be a good fit to jobs@homelight.com. No formal cover letters, please. We look forward to meeting you!",Sin experiencia,Jornada completa,Tecnología de la información,"Software, Internet, Servicios financieros",14,None,False,jobs@homelight.com.,87,ACTIVELY_HIRING_COMPANY
493,2291268919,2020-10-14,Hired Recruiters,Data Scientist - Analytics (Up to $125k + 100% Remote Option),"San Francisco, CA, US","Outschool's mission is to inspire kids to love learning. We believe the best way to do that is by linking learning to kids’ interests, connecting them with others who share those interests, and giving them the autonomy to pick their own path. We provide small group classes that meet over live video chat where learners are connected with teachers and classmates who share their interests. These classes are offered through our marketplace and conducted on our remote learning platform.  We're an experienced team with past accomplishments at Airbnb, Square, Apple, Uber, Udemy, Amazon, Google, and many startups. We came together because we wanted to make a difference in education, and saw the opportunity to empower learners, teachers, and parents. Now, in the face of mass school closures, our product and expertise has become central to many more families and organizations than ever before. Our business is growing explosively and as of July, 400,000 learners have taken more than over 1.3M class hours. We've already doubled our team so far this year to keep up with growth. As well as growing our business, we're committed to access and impact so we founded outschool.org to offer $1M in financial assistance to families in need. We're Series A stage, have raised $22M in funding and are profitable.  Data plays an important role in how we make decisions at Outschool. As our second full-time Data team member, you’ll have an opportunity to work cross-functionally with teammates from Operations, Product, Marketing, and other internal teams as they tackle a variety of challenges and opportunities. You’ll help shape Outschool’s strategy by sharing key insights, digging into some of our most pressing problems, and finding creative ways to use data to improve our products and services.  Responsibilities  Partner with teammates across the org to translate data into insights and actions Define and monitor key company-wide success metrics and OKRs Use visualization, reporting and other tools to improve how our team accesses and interprets datasets Create models to identify important segmentations and predict outcomes in specific subdomains  Build data tools that help us scale manual processes  Prototype new data-driven features that increase value for our learners, families, and teachers    Qualifications  3+ years of experience in a data science or analytics role Expert-level SQL skills and proficient in Python or R programming Prior experience working with data visualization tools (eg Mode, Looker, Tableau, Metabase) Bachelor’s degree in a quantitative field (eg Math, Economics, Statistics, CS, Engineering) Strong interpersonal skills and motivated by impact    Outschool is an equal opportunity employer. We view diversity as a moral imperative and a competitive advantage. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. We plan and structure our interviews to directly assess skills and experience.            Aptitudes y experiencia deseadas           Data Scientist",Intermedio,Jornada completa,"Análisis, Ingeniería",Software,0,None,False,,1,JOB_SEEKER_QUALIFIED
494,2277602597,2020-10-11,Slice,"Senior Data Scientist, Machine Learning (Belfast, UK)","Belfast, GB","Pizza is at the heart of our communities. From birthday parties to gameday potlucks, life's special moments are bettered by the craftsmanship and tradition found behind local pizzerias' counters. We're here to make sure these iconic small businesses serve our communities for generations to come by giving them the digital tools and services commonly found at big chains. Can you imagine what a small mom and pop pizza shop could achieve with the resources of Domino's?  In this role, you will be one of the founding members of the Machine Learning Data Science team for our leading marketplace technology company. You will develop and implement machine learning algorithms and personalisation products from scratch that directly impact our customers. You will be partnering closely with our Product, Engineering and Business stakeholders to open up new opportunities and accelerate the growth of the business. Your strong foundations in mathematics, statistics and machine learning and exceptional communication and leadership skills will bring unique insights into our strategy. Your passion for solving problems and sense of urgency will fuel the success of the team.  We are open to applications from UK candidates who are interested in working on a permanent remote basis.   What you'll do:  Develop ML models to derive insights on customer behaviour and inform product opportunities and strategy. Partner with Product teams on developing product roadmaps and leveraging ML techniques to curate a better user experience and drive business results. Work with Engineering teams to build the infrastructure and processes to productionise and iterate ML models. Collaborate with other Data teams on solidifying the data foundation of Slice, including event logging, experimentation, data modelling etc.  What we're looking for:  Essentials:  Graduate degree in Computer Science, Mathematics, Operations Research or equivalent quantitative fields.  3+ years of industry experience in Machine Learning or Data Science using mainstream languages such as Python, Spark etc. Experience in partnering with product and engineering teams in developing production-level code to deliver ML-backed product features. A fun and positive approach to your work, and treat others well. Excellent problem solving, analytical and organisational skills. Strong communication skills.  Desirable:  Familiarity with programming languages such as Java, C++ etc. Experience in search and recommendation product a plus. PhD preferred.  Interested?  We operate like a startup, so being self-motivated, curious, and flexible is a good start. You prefer to come up with your own solutions to problems but are not afraid to ask for help. You enjoy making suggestions for how to improve our product and business, no matter the department. You're the kind of person who roots for the underdog. And lastly, this job will probably be a lot easier if you have a soulmate-level love for authentic pizza.  Why Slice?  Join a community of best-in-class engineers who combine creativity, curious minds and a commitment to excellence with the desire and commitment to grow and build on the engineering skill base and community here in NI.  Benefits  Market Leading Salary Strong Pension contribution Personal Health, Dental and Eye Care Income and Death insurance Cycle Scheme of up to £2500 £750 per annum self-learning budget Health and wellbeing benefits Market leading Maternity and Paternity Schemes Flexible working / Hours and WFH Generous time off allowance and policies Free Friday Pizza and Monday Breakfast Fully stocked kitchen/snacks Annual conference attendance and training/development budget Substantial gym membership discount Discounts for local Pizzerias  How to apply?  We do not use agencies as we have a strong network of referrals, and also want you to have the best recruiting experience possible. A CV gives us a good idea of your background, we are interested in your latest work and projects. Education is great to see, but it's not overly important to us. If you have them, be sure to include links to any personal projects, blogs, contributions, or anything you want to add to your application.  My Pizza Slice Ltd is an equal opportunities employer and we value Diversity. We appreciate the differences in style and perspective as we believe it adds value to the organization, and we aim to recruit like-minded employees. We are also proud members of the Diversity Mark NI initiative as a Bronze Member.",Algo de responsabilidad,Jornada completa,Otro,"Marketing y publicidad, Software, Internet",None,None,False,,9,ACTIVELY_HIRING_COMPANY
495,2232841312,2020-11-02,UpCloud,Senior Data Engineer,Finland,"UpCloud's Data team is looking for a senior software engineer with a passion for data, to build, develop and maintain our internal data platform services. You have a strong belief in automation and approach your work with an analytical, iterative mindset. Your opinion changes with new information. Team Data provides UpCloud’s data warehousing, business intelligence and internal tools across our teams. We develop and maintain everything from data models to full suites of data-oriented tools and APIs that allows teams to collect, integrate and utilize data in a consistent and streamlined manner. We also provide an in-house developed CRM and Business Intelligence platform that allows data discovery regardless of technical expertise, two-way synchronization and integrations with third-party services, and the traditional ad-hoc financial reports requested by the teams. Why would you join UpCloud and the Data team?The team is still in its early stages, so you will have a direct impact on not only our team, but on UpCloud as a whole. We utilize a data-driven process to identify high impact opportunities that can be scalable in an automated fashion. And while we highly encourage automation, we understand the value of rolling up our sleeves and validating opportunities in a non-scalable fashion first. We have our HQ in Helsinki, but we welcome both full and partial remote work. We embrace our remote work culture and make sure everyone is in the loop through Slack, the occasional paid trip to the office, and our annual company retreat, where we bring the entire company to an exotic location. As part of our work-life balance culture and based on our belief that people should have time for themselves, we prefer candidates that are based in European time zones and hence won't need to work unsociable hours. What you will be working on:Building and maintaining containerized services of business-critical databases and APIs.Implement CDC, ETL and data integrations with various internal and external services.Centralized logging and system monitoring for our data infrastructure and services.Automated CI/CD pipelines to stand up staging environments for rapid prototyping. What you will be working with:Go/Python: we mostly use Python but are moving towards Go across the company.Timeseries data: we store most of our data in PostgreSQL using TimescaleDB.Advanced SQL: efficient indexing, common table expressions, functions, triggers, etc.Distributed data processing: CDC/ETL pipelines and workflows in Python/Go.“Infrastructure as code”: GitLab CI/CD, Terraform, and Kubernetes.Linux server environments: we primarily use open source technologies running on Linux, and no Microsoft-based applications and services. We believe that a good ballpark figure would be 5 years or more of production experience in this area. We don’t expect you to be a master in all areas, though. If you don’t tick all the boxes, don’t feel discouraged to apply. If we can’t have you in our Data team, we might be able to find another role for you here at UpCloud. We review all applications and we do get back to all our candidates. That is a promise.",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Interconexión en red, Software",14,None,False,,143,ACTIVELY_HIRING_COMPANY
496,2268032018,2020-10-08,Skiltrek,Sr. Data Scientist - Claims - REMOTE,"Louisville, KY, US","Position Title: Sr. Data Scientist Location: Jacksonville FL or ( Open to 100 % Remote ) Job Type: Contract Work Auth: GC/USC/GCEAD Salary Method: W2 Client Type: Healthcare Insuance Job Duration: Long Term Contract - 12 months + Rate: $126,000-$170,000 /year  Job Description  This a niche skillset and not just any data scientist. Candidate must have worked in Claims and used Machine Learning models to gain for efficiencies in Prepay / Post Pay reviews ** Data Scientists produce innovative solutions driven by exploratory data analysis from complex and high-dimensional datasets. Apply knowledge of statistics, data modeling, and advanced mathematics to recognize patterns, identify opportunities, pose business questions, and make valuable discoveries. Use a flexible, analytical approach to design, develop, and evaluate predictive models. Generate and test hypotheses. The Data Scientist proactively seeks to develop their skillsets and provide value-added support within the Data Science team.  Essential Functions  Communication & Project Ownership  Support large projects, and manage smaller projects in their entirety Partner with senior team members to assess customer needs and define business questions. Emerging ability to influence customers to take action on analytical insights. Communicate results and insights, both verbally and written (including visual graphics), in a clear and concise manner to a non-technical audience. Identify and communicate roadblocks. Work on multiple concurrent projects and accommodate frequent interruptions and changing priorities Effectively participate in meetings with customers and emerging ability to guide discussion and decision making. Data Analysis  Acquire and bring structure to data so that it can be used in existing and new data systems. Build tools that help you and the other Data Scientists translate insights into action at scale. Identify, define and translate business needs/problems into analytical questions. Design and execute experiments, models, algorithms, and visualizations Understand data sources and limitations, warehousing system and the impact of the data on business decisions. Identify, retrieve, and manipulate data from internal and external datasets. Apply statistical and computational methodologies to provide actionable insights and identify opportunities that optimize quality, consumer experience, and healthcare costs. Develop scalable, efficient, and automated processes for large scale data analyses and model development, validation, and implementation. Reporting & Other  Contribute to technical reports, white papers, and publications. Stay current on new processes and technology in Data Science and communicate findings to team Perform all other tasks as assigned Job Requirements  Strong programming experience in R, or Python Requires expert proficiency in SQL Strong analytical and problem-solving skills Experience in supporting large projects, and manage smaller projects in their entirety Ability to partner with senior team members to assess customer needs and define business questions. Emerging ability to influence customers to take action on analytical insights. Ability to communicate results and insights, both verbally and written (including visual graphics), in a clear and concise manner to a non-technical audience. Must have applied experience with advanced analytics e.g. predictive analytics models Must have applied experience in Machine Learning Experience in Big Data - e.g. s3/presto is a plus Business Intelligence tool development Other programming experience - Java, Perl, UNIX/Linux scripting Healthcare, medical, or pharmaceutical work experience Experience with analysis around quality, consumer experience, and healthcare costs Experience in consumer analytics Experience in business analytics Required Experience  5-8 years related work experience in advanced analytics or equivalent combination of transferable experience and education  Minimum Five Years' Experience As a Data Scientist  PhD or Masters in a quantitative discipline: Computer Science, Statistics, Applied Mathematics, Operations Research, Engineering Working knowledge of health care systems and healthcare terminology Expert in various healthcare datasets. Expert in analyzing large complex, multi-dimensional data sets with a variety of tools Ability to thrive and demonstrate constant applied learning in highly complex, interdisciplinary, and dynamic work environment Design anomaly detection models to detect and eliminate FWA in claim payments. Experience in implementing Machine Learning Models to gain efficiencies in Claims Prepay / Post Pay reviews  Required Education  Related Bachelor’s degree in Data Science, Applied Mathematics, Computer science (e.g. specialization: Machine learning/Artificial Intelligence /Visualization, databases, and Big Data), Statistics, Epidemiology, Health Services Research, or closely related field with Data Science specialization or additional related equivalent work experience  This person can work 100% remotely even after Covid-19!",Sin experiencia,Jornada completa,Tecnología de la información,"Sanidad, bienestar y ejercicio",0,None,False,,10,None
497,2276777471,2020-10-11,ekosystem group,Data Engineer H/F – Grenoble et « remote » - Grenoble,"Grenoble, FR","Grenoble… Si comme moi tu y a étudié. Si comme moi tu adores cette ville et ses montagnes environnantes et si (alors pour le coup pas du tout comme moi…) tu t’éclates à coder en .NET/Angular… j’ai l’opportunité pro qu’il te faut !  Une super boîte (très connue !!) qui monte… qui monte… mais qui a su conserver l’esprit bienveillant et humain de ses débuts !  Un projet passionnant (ou plutôt DES projets passionnants), des bureaux au top, une ambiance géniale, un turnover quasi-nul, un management participatif… La liste des avantages à intégrer cette entreprise est longue (et encore je ne parle pas de son CE super dynamique et de son ouverture au télétravail…).  Bref, tu l’auras compris, cette opportunité est d’or !  Chez Ekosystem (comme chez notre client d’ailleurs) on aime faire les choses différemment! À commencer par cette offre d’emploi  Car au-delà de tes compétences techniques et de ton expérience en développement fullstack .NET/Angular, c’est TOI qui nous intéresse!  Ce facteur humain, cette attention particulière à qui tu es, ce que tu aimes et ce que tu veux… c’est notre modus operandi. Zéro bullshit! Cette dimension humaine, c’est elle qui drive chacune de nos décisions. C’est en fonction d’elle que nous choisissons nos clients et c’est grâce à elle qu’on s’éclate quotidiennement au taf.  Résultats Nous te proposons des boîtes qui recrutent dont l’ADN « match » à 200% avec toi, tes aspirations pro et tes projets de vie.Nous sommes convaincus que nos clients te permettront de grandir aussi bien professionnellement qu’humainement. Pas d’offre d’emploi spécifique donc. Mais une multitude de combinaisons élargissant ton/notre horizon des possibles!  Car tu es plus qu’une fiche de poste, rien ne vaut un échange, qu’il soit téléphonique, VoIP ou physique!  Comment postuler?  Shoot nous ton CV (en cliquant sur le bouton « APPLIQUER » se trouvant à la droite de ton écran (notre webmaster montréalais tenait à utiliser cet anglicisme québécois :)) et nous revenons vers toi ASAP!",Sin experiencia,Jornada completa,Tecnología de la información,Importación y exportación,3,None,False,,28,JOB_SEEKER_QUALIFIED
498,2249351283,2020-11-05,NAVA - Technology for Business,Cientista de dados,"São Paulo, Brasil","Ei, Cientista de dados, #vemserincrivel na NAVA, faça parte do #navadreamteam e atue em projetos que transformam o mundo dos negócios. Topa o desafio? Então dá uma olhada nos requisitos: Sólida experiência na atuação como Cientista de dados.Programação Python ou R (intermediário) voltados para métodos de Machine learning (aplicação de modelagem). Diferenciais:Conhecimento do Negócio - Setor Financeiro. Nós oferecemos:Contratação CLT com excelentes benefícios, como: Assistência Médica,Assistência Odontológica, Seguro de Vida, Vale-refeição, Vale-alimentação,Gympass, auxílio-estudo e muito mais. Sobre a NAVA:Somos uma empresa de tecnologia e Cultura Lean voltada a negócios, formada por profissionais apaixonados por desafios e comprometidos com resultados.Há quase 25 anos no mercado, conectamos talentos, habilidades e oportunidades para entregar soluções tecnológicas alinhadas aos propósitos dos nossos Clientes.Se você se identificou, junte-se a nós",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Servicios y tecnologías de la información,136,None,True,,503,ACTIVELY_HIRING_COMPANY
499,2275636272,2020-11-04,Strategic Systems Inc,User Experience Researcher,"Indianapolis, Indiana, United States","Role of the UI/UX researcher is a critical leadership role in the adoption of Human Centered Design (HCD) within company’s environment. The adoption of HCD practices and artifacts is a critical component in the company’s ability to competitively respond to CMS and other agency bids. The UI/UX researcher skill set will support the company’s ability to connect to the provider and beneficiary through interview knowledge, survey building and knowledge of a variety of HCD tools and techniques. The UI/UX Researcher will demonstrate how empathy and connection will help development teams build an experience that delights the customer. Role DescriptionAt least 2 years of work experience in statistical analysis, qualitative analysis, quantitative analysis, product usability moderating, experimental design, and test method selection. In addition,Must have had proven successful experience in the integration of consumer research into a business’s product design practice.Experience in product usability testing tools, for example Keynote.Experience related requirement, a UX Researcher candidate must display a strong comprehension of the strengths and limitations of the different research methods, inclusive of when and how to apply each in product/market/consumer analyses.Candidate possess excellent communication skills to be able to relay these research methodology concepts and findings to product department personnel and to other collaborating personnel in a clear, simple, and relatable manner.Candidate must possess an effective problem solving ability even under short notice. The UX Researcher must be able to come up with creative solutions and consider a variety of alternative solutions for each problemCandidate must show proficiency in Sketch, InDesign, Illustrator, Keynote and Photoshop computer software(s).Candidate must display a genuine passion for product-centric innovation: an ability to work well independently as well as with a team: must have a keen and exceptional attention to detail: and more importantly, an ability to identify root recommendations inspired by the consumers’ needs and behaviors.",Algo de responsabilidad,Contrato por obra,Tecnología de la información,"Servicios y tecnologías de la información, Seguros",57,None,True,,218,ACTIVELY_HIRING_COMPANY
500,2233629196,2020-10-27,Discover Financial Services,Lead Software Data Engineer – Full Stack (ETL & Spark & Snowflake or Teradata & Cloud),United States,"Lead Software Data Engineer – Full Stack (ETL & Spark & Cloud Native Development & Relational Databases)  Location: Remote, USA Our Value Proposition to CandidatesDiscover exceeds the industry average in benefits by offering the following: 5 Weeks PTO401K (5% Company Match)Generous Relocation PackageTuition Assistance ($10K)Training & DevelopmentMetra/Bus Discount Option & Campus ShuttlesOn-Site HealthcareOn-Site GymFamily Care BenefitsWork/Life BalanceEmployee Stock Purchase Plan OverviewDevelops and maintains full stack solutions to fit business needs. Full stack solutions require one or more of the following: front-end (user interfaces), back-end (APIs), database and DevOps development. Works directly with business partners to understand business requirements. Works independently or with own team to innovate on and advocate for best practices within the team. Designs complex solutions and leads them from inception to production within the agile team. Responsible for working with data asset-related technology that has been approved by the architecture organization to move, transform, and validate data between systems, both internal to Discover Financial Services and with external data sources that provide value to Discover Financial Services. Responsible for writing extract, transform, and load (ETL) scripts, data maps, or integration programs to capture data from source systems and to transform it and load it into a destination system to enable data mining, business intelligence (BI) capabilities for the organization. Translates business functional detailed design requirements into technical solutions through the design, development, integration, and testing (unit and system) of ETL solutions. The Lead position also participates in data solution design, strategy, including resolving strategic data integration issues, such as data quality and stewardship, real time or event-based data integration, and crafting a vision for data integration working with the architecture organization. The Lead position leads the technical design, development, integration, and testing efforts for ETL to create quality solutions that meet the business requirements. Other responsibilities include: mentoring other Data Engineers, preparing detailed and creating technical design plans. ResponsibilitiesDevelops and maintains complex front-ends with a focus on user experienceDevelops and maintains backend systemsWorks with key stakeholders to design complex solutions and lead from inception top productionCreates and maintains DevOps processes, application infrastructure, and utilizes cloud services (including database systems and models)Innovates on and advocates for best practices and improved team processes: mentors junior team membersSupports live systems to ensure business continuityLead data technology strategy, including resolving strategic data integration issues, such as data quality and stewardship, real time, event-based data integration, and crafting a universal vision for data integration, plan and document succession planning within scope of responsibilityDesign, develop, test, and implement data-driven solutions to meet business requirementsPerform the technical design, development, integration, and testing efforts for data using various development languages and tools to create quality solutions that meet the business requirementsLead code review sessions & create technical design plans/STTsOptimize the performance of ETL processes and scripts by working with other technical staff as needed and document data solution and processes Skills RequiredBachelor’s degree in information technology6+ years of experience in Computer Science, Information Technology, or related experienceIn lieu of degree, 8+ years of experience in computer science, information technology or related field Skills Desired6 or more years of work experience in BI lifecycle, from strategy to ETL to report implementationExperience in an Agile-based environment Big Data stacks/ecosystem including Kafka, Python, Spark, NoSQLExpertise in the concepts, technology, and practices of building data solutionsExpertise with open-source, ETL scripting and processes and related toolsExpertise with the design and development of ETL data integration solutionsExpertise with relational databases and experience with Cloud-based technologiesExpertise in enabling business intelligence solutions through data integrationDemonstrated experience with integration technologies and how to leverage them into data mapping between systemsDemonstrated experience with transforming business needs into data design and solutionsExtensive experience with writing and performance-tuning complex SQL queries Experience in agile process and technologyExperience with Ab Initio or other ETL tools and componentsExperience with the following database and Cloud-based technologies: Snowflake, Teradata technologies or similar: Python, SparkKnowledge with AWS, Snowflake and other Cloud-related technologies is a plusStrong team player with willingness to collaborateStrong analytical and problem solving skillsStrong capability to execute tasks with qualityStrong communication and decision-making skills  The same way we treat our employees is how we treat all applicants – with respect. Discover Financial Services is an equal opportunity employer (EEO is the law). We thrive on diversity & inclusion. You will be treated fairly throughout our recruiting process and without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status or any other characteristic protected by federal, state, or local law in consideration for a career at Discover.",Intermedio,Jornada completa,"Ciencias, Ingeniería, Tecnología de la información","Servicios financieros, Banca, Banca de inversiones",64,None,True,,240,ACTIVELY_HIRING_COMPANY
501,2257504264,2020-10-13,Inside.com,Business Researcher (Remote OK),"Ontario, CA, US","Business Researcher at Inside ( Help make our subscribers smarter.   You will read the most important news of the day, grok it, and then create deeper dives by analyzing the data, history, products, companies, services, and executives in and around those stories. Our paid subscribers are CEOs, founders, investors, and big company executives who are looking to efficiently understand the story behind the stories in mainstream news.   Details   You will work in a fast-paced startup that embraces Kaizen ( (the process of continually getting better).  We'll pay you $60,000 to work from home.  If selected to move forward, we will pay you to co-work on the newsletter for a few days.   Skills Needed  Ability to quickly find & understand information online  Ability to efficiently source, contact and interview experts  Ability to read and understand financial documents  Ability to think critically and write simply  An understanding of mental models and the leading theories on thinking  An insatiable appetite to learn more, think from first principles and question everything   You likely consume WaitButWhy, The Knowledge Project, SlateStarCodex, Daniel Kahneman, business bios, Sam Harris, Brain Pickings, Freakonomics, Tim Ferris, Grammar Girl, and similar fare.  We are not looking for traditional journalists, but rather researchers. In this position, you will read today's news from a range of general and industry publications, summarize the information concisely, and then analyze what other questions need to be answered next.  Still reading? Please continue!",Algo de responsabilidad,Jornada completa,"Educación, Formación","Medios de comunicación en línea, Publicaciones, Internet",35,None,False,,178,JOB_SEEKER_QUALIFIED
502,2232531973,2020-10-23,Independent Software,Sr. Data Engineer,United States,"Outstanding permanent hire opportunity with a global manufacturing & distribution organization.   Senior Data Engineer Remote 100%Interview phone + videoSponsorship not available The Senior Data Engineer (Customer & Salesforce Data) will be responsible for the managing and optimizing the data flows and data mappings between the different global customer data platforms including Customer Data Platform (CDP), Marketing Systems, CRM Systems, other backend systems and various data integrations tools.Experience:        • 5+ years of software and data engineering experience with focus on designing and developing with Customer Data technologies and platforms, Databases, and large-scale data processing systems• 3-5 years of working with customer data flows and mappings across Customer Data Platform (CDP), Salesforce Marketing Cloud (SFMC), Salesforce Service Cloud (SFCC), MuleSoft APIs, ETL tools etc.• 3-5 years of technical design and development experience with data development languages like SQL, Python, R, SQL etc.• Experience with running complex queries to triage issues across different data platforms• Experience with data analytics• Experience with improving data reliability, efficiency and quality",No corresponde,Jornada completa,None,Servicios y tecnologías de la información,5,None,True,,30,None
503,None,None,None,None,None,"Cushion is looking for a stellar Machine Learning Engineer to join us during this exciting phase of the company!  We’re growing, generating revenue, and announced our $2.8M Seed round on TechCrunch in 2019. In addition, we have been recognized by SXSW, Bloomberg, American Banker, Inc magazine, and more.  This is a rare opportunity to join a startup as one of the first 20 employees and shape the product, strategy, and culture alongside the Founder and core team.  Who we're looking for  The core of what we're building at Cushion is a system that can perform intelligent financial actions on behalf of a consumer, better than they can.  We are on the hunt to find a humble hard-working ML Engineer who is an outstanding engineer first and foremost (e.g. can build and deploy a web app from scratch if need be). This person must be able to not only extract insights from data and build ML models, but is also able to deploy their models into production without the help of other engineers.  The ideal candidate is curious, driven, absolutely loves solving complex problems, is a pleasure to be around and work with, and has an intense bias towards making stuff happen.  As an engineer at Cushion, you will   ✋ have serious ownership - of the work that you do as well as your stake in the company 🏃‍♂️ work in a fast-paced environment where an idea on Monday can become a live feature in the hands of users by Friday 👩‍💻 work on high-impact initiatives that will affect tens of thousands of customers (hopefully millions as we grow!) 🚀 be a major contributor in building and scaling a company  What we're looking for  Based on our experience building teams at multiple companies, including Twitter, we're looking for candidates with the following background:   A college degree in Computer Science, Computer Engineering, Math, or Physics At least 4 years of full-time Software Engineering experience after getting your undergraduate degree At least 2 years of Machine Learning experience A track record of deploying ML models into production yourself Experience with AI, NLP, ML Experience with Python Experience with relational databases and SQL Experience deploying applications on AWS, Google Cloud, Azure, etc Bonus: Prior startup experience Bonus: Master's Degree or higher in Machine Learning  The salary range for this position is $120,000 - $180,000",Algo de responsabilidad,Jornada completa,Ingeniería,Software,98,None,False,,395,None
504,None,None,None,None,None,"Lixar I.T. is looking for a Data Engineer to join our data team. As a Data Engineer, you will be part of a team supporting and participating in the ongoing development of leading edge applications. The ideal candidate will be a senior developer who has a strong background in Big Data with a mix of general programming and some exposure to data visualization. AS AN EXPERIENCED DATA ENGINEER, YOU HAVE:Post-secondary education in engineering or computer science or equivalent work experienceA proven track record using the Apache Hadoop ecosystem (Spark, Data Lake, Hive, HDFS, Impala) to tackle “big data” problemsA master of all things SQL (and NoSQL)5+ years of programming experience in PythonProven experience using RESTful Web Services & JSONGood experience using Cloud based data solutions (AWS/Azure)Experience working with production systemsKnowledge of ELT, ELT, Lambda and Kappa data architectures PREFERABLY, YOU ALSO HAVE:Knowledge of Continuous Integration and Source Control systems (e.g. Gradle, Maven, Bamboo, TeamCity, Git)Experience with DataBricksSome Data Visualization experience in Power BI, Tableau, or similarExposure to data science, machine learning or statisticsSome experience using Docker AS THE IDEAL CANDIDATE, YOU:Have a sense of humourKnow that your routine is in fact, not routineCommunicate exceptionally well with management, peers, and clientsHave “Attention to detail” as your middle nameDon’t blame others for your mistakesGet things done!",Intermedio,Jornada completa,"Tecnología de la información, Ingeniería",Servicios y tecnologías de la información,2,None,False,,51,None
505,None,None,None,None,None,"'The best way to predict the future is to create it. - Abraham Lincoln  About Strivector  Strivector is a recruitment and staffing agency. We work with some of the leading, fastest growing companies in the United States. Our clients are growing so fast that they can't hire good people fast enough to keep up with their growth. So, we help them. We reach out to awesome talented individuals like you and connect them to their dream companies and dream jobs.  If you're the best, and you are looking for something better, let's talk. :-D  Desired Skills And Experience  This is a Senior Data Engineer position and requires someone who has worked on Data Engineering, SQL, Python, AWS, SaaS etc. The ideal Senior Data Engineer would be someone with deep experience in many (if not all) of the following:   'Strong SQL/Python experience is must '  Must-Haves  Expert level SQL Expert level Python Deep experience with AWS Experience building SaaS products through data insights Experience with large-scale data and query optimization techniques Experience with ETL to data warehouse systems Experience with AWS cloud services: EC2, RDS, Redshift, Aurora Expert in SQL, NoSQL, and RDBMS Knowledge in multiple scripting languages (e.g. Python) Knowledge of cloud, distributed systems, and stream-processing systems Passionate about learning new technologies and solving hard problems in a fast-paced environment   Nice-To-Haves 1 Big data background 2 Hands on prototyping 3 Database Architecture experience  We understand that even if you are a seasoned Senior Data Engineer you may not have all the skills listed here. If you are good at what you do and have a willingness to learn, let's talk.  Additional Information  Compensation: Based on Experience. One of the best in the industry Minimum Education: Bachelor's, Master's or Doctorate in Computer Science or Engineering Minimum Experience: 4+ Years on Data Engineering, SQL, Python, AWS, SaaS Type of position: Full Time with Benefits Telecommute: No Location: Remote Relocation accepted: Yes",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Servicios financieros",3,None,False,,18,None
506,2197061309,2020-10-20,CarMax,Senior Front-End Engineer,United States,"CarMax, the way your career should be! Your expertise shapes our digital businessAt CarMax, we want to disrupt our industry by empowering customers to buy a car on their own terms – allowing them to transact with us anytime, anywhere. As a Senior developer, you'll be at the forefront of driving technical innovation alongside several product teams who are creating a seamless online transaction experience for our customers and associates.  You are: Able to balance customer needs with business goals and know how to deliver technical solutions that enhance business value. Creative, curious and highly analytical, you never stop learning and thrive on constant change in the digital marketplace. From inception to completion, you will develop tools and technology, learning quickly from our spirit of experimentation. Overall, you will have a direct impact on improving the performance of our business and ensuring customers can buy the vehicles they want in a way that’s right for them.We are: A team of experts (such as a Product Manager, Lead Developer, Delivery Manager, Analyst/Data Scientist, and other Software Developers), working in a fast-paced, highly collaborative, and customer-focused environment to bring a seamless online shopping experience to life. Together we’ll be:  A passionate technology team, developing ground-breaking products. Working collaboratively and creatively as part of a close-knit product team, you will be part of the development process from end to end: consulting users, carrying out experiments, tackling complex business problems and implementing new products. What you will do – Essential responsibilities Hands-on development to create and support new products and services that provide teams the ability to progress a customer through an online transactionAs the online marketplace becomes the new dealership this position will be responsible for helping redesign how customer experience our products across all our propertiesCollaborate with colleagues in product design, product management and systems architecture to develop experimental solutions and bring great ideas to lifeMarket your new ideas internally and evolve them according to feedback and critique within an agile environmentStay on top of industry trends and best practice to continuously improve what we do and ensure our customer experience is the best it can beWhat technologies you'll be working withThis role requires hands-on work in technologies such as JavaScript, ReactJS, Azure PaaS (Functions, App Services, App Insights, Redis, and others), .NET Core, TeamCity or Azure DevOps for CI/CD, Akamai edge, Javascript, React, load testing / automated testing tools like Selenium / Browserstack, Splunk, and API management systems. But more importantly at CarMax we are always learning so our tool set will evolve as you do. Qualifications and requirements At least five years of application development experienceCross microsite development leveraging JavaScript or other technologiesDesign and deliver the next generation gallery for customers to experience vehiclesPartner with studio teams to develop contentExperience in some of the following preferred:  Microsoft.NET (C#),  .NET CoreWorking knowledge of cloud platforms such as Azure or AWS preferredUnderstanding of DevOps capabilities such as automated testing, continuous integration, and continuous delivery preferredA degree in Computer Science or a related discipline or equivalent experienceUpon an applicant's request, CarMax will consider reasonable accommodation to complete the CarMax Job Application.",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información, Diseño",Venta al por menor,27,None,False,,126,ACTIVELY_HIRING_COMPANY
507,2195903718,2020-10-20,Zenvia Mobile,Senior Data Engineer,Brasil,"About Zenvia:In a world where change is constant, companies need to transform quickly to engage consumers. Through our Multichannel Communication Platform, we help over 8,000 companies to engage their customers. Zenvia is the market leader in Latin America with solutions using SMS, Voice, Whatsapp, and others. It is already proven that brands that are in multiple channels improve the user experience and increase their results. Zenvia has everything to simplify and take communication to the next level. Be part of this revolution, after all, our rocket has no reverse. ﻿About our Data Team:We are looking for a Senior Data Engineer to help us build our new Big Data Platform. Are you up for the challenge? Here you will be responsible for:Design a new data platform using cutting-edge technologies:Implement streaming and batch analytics services:Specify data schemas:Design and implement data governance practices:Test and document analytics services:Maintain data frameworks on production. You’re a strong candidate if you have:Hands-on SQL:Strong experience in Python, Scala, or Java:Solid experience working with Big Data solutions:Experience as a Software Architect:Creativity, willingness to learn new technologies, and good communication :Advanced English skills. It's a differential if you:Have experience with Spark or Flink:Have a practice with column-oriented databases (Snowflake):Streaming platform (Kafka):AWS (S3, Redshift, Hive on EMR, Presto on EMR). What does make Zenvia a Great Place to Work?Flexible working hours:A relaxed and informal environment, with colleagues ready to share their knowledge:A challenging environment, in constant change, that boost us to go beyond:Zenvia offers you the ways to grow and develop, so you can act as the key player of your career:Gympass:Monthly meetings to network and share knowledge:No dress code:Discounts in educational institutions:Flat structure: we enjoy giving and receiving feedback, understanding that this is the best way to grow personally and professionally. We believe in the balance of life without chains, a healthy life without putting aside the fun and freedom of being who we are. If you are looking for a company that really cares about your ideas, recognizing your achievements and contributions, and providing a free and inclusive environment for you to lead your own development, this company is for you. Despite the unstable moment of Covid-19, Zenvia is proud of being a great facilitator of digital communication and helping more than 8 thousand companies to communicate effectively with their clients. That is the reason we keep growing in full steam, powering this digital change. Come and make part of a company that is proud of being a Great Place to Work!",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Telecomunicaciones,15,None,False,,285,ACTIVELY_HIRING_COMPANY
508,2234229959,2020-11-02,Analytic Recruiting Inc.,Chief Data Scientist - Fintech - Online Lender,New York City Metropolitan Area,"Leading Fintech in the lending space seeking Chief Data Scientist with a background in lending and credit to help drive strategies through advanced analytics and data science across the risk management lifecycle i.e., acquisition, underwriting, portfolio management and collections. This role will manage a team of 6. Keywords: Online Lending, Credit Risk, Data Science, Machine Learning ResponsibilitiesLeverage analytics and data science to drive optimal decision-making across the customer risk management lifecycle i.e., acquisition, underwriting, operations, portfolio management and collections.Manage and build a teamMonitoring performance and investment return across acquisition channels and using analytics to improve overall resultsEnhancing underwriting rules, default model and offer logicExploring new data sources to improve overall risk managementEnhancing early warning portfolio management strategies for accounts that require immediate attentionProvisioning, liquidity and stress-testingAnalytics associated with a securitizationEnhancing collections strategy and collectability modelMonitoring standard risk management KPIs and taking appropriate actions QualificationsDegree in a quantitative discipline such as Engineering, Mathematics, Physics etcTeam building and managementStrong applied statistics and machine learning skills5+ years in lending and credit (small business lending a plus)Creativity and ability to turn data into actionable strategies that will drive business resultsExcellent coding skills in at least one statistical language, preferably PythonStrong communication and influencing skills Please contact ilana@analyticrecruiting.com with questions",Director,Jornada completa,"Finanzas, Análisis",Servicios financieros,100,None,True,ilana@analyticrecruiting.com,338,ACTIVELY_HIRING_COMPANY
509,2277703536,2020-10-11,EBANX,Senior Data Engineer,"Curitiba, BR","Our HQ is in Curitiba, but in this position, you could work from wherever you want.  Who are we?  We are a leading FinTech company in LATAM who offer an end-to-end cross border payment solution that removes all barriers for our business and consumer clients to buy online from international outlets and suppliers. We believe that people should have the power to make choices, and that is why we offer local payment methods for the largest websites worldwide, such as Airbnb, Spotify, AliExpress, JD.com, and DHGate and we have already reached more than 50 million customers in Latin America.  In this role, your responsibilities will be:   Build and maintain data ingestion pipelines Develop data modeling algorithms Manipulate and analyse complex, high-volume, high-dimensionality data from varying sources Monitoring performance and advising any necessary infrastructure changes Collaborate with partners and development team to drive analytic projects end to end  What is essential for the job?   Strong knowledge in SQL At least one programming language (python or scala is preferred) AWS Data Lake related services knowledge Advanced systems architecture knowledge  What else would we like to see?   Experience with data visualization tools (Tableau, Qlik, PowerBI) Experience with stream processing techniques Experience with AWS Redshift or another Data Warehousing tool Experience with large production environments   EBANX offers:   A challenging environment, with opportunities to growth: Casual office and dress code: Spanish, English and Portuguese classes: WAVES - Program of goals and results (variable compensation): EBANX Play - Wellness (Gympass, e-Sports, SESC ): Semi flexible hours (8 hours a day - Monday to Friday): Meal Allowance: Transportation voucher (if needed): EBANX Education: scholarship: EBANX Skills: budget for workshops and courses: Hello ebanker: psychology, finance and legal orientation. Health and Dental Insurance: Blue Club: Exclusive discount for ebankers in bakeries, restaurants, courses, electronics store and more!  Follow us on Instagram and look for the hashtag #ebanxlife to learn more about EBANX's culture.",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Internet",3,None,False,,22,ACTIVELY_HIRING_COMPANY
510,2254435492,2020-10-29,RMS STAFFING,German Speaking Recruitment Researcher | Remote position,"Durban, ZA",Cape Town Based Recruitment Consultancy specialising in International Recruitment seeking a German Speaking Recruitment Researcher. Applicants must be fluent with verbal/written German communication skills. You will be required to work remotely and can be based anywhere  Excellent German communication (verbal/written) Excellent German communication (verbal/written),Algo de responsabilidad,Jornada completa,"Investigación, Análisis, Tecnología de la información","Logística y cadena de suministro, Dotación y selección de personal, Servicios financieros",10,None,False,,65,JOB_SEEKER_QUALIFIED
511,2287600673,2020-10-13,Gympass,Senior Data Engineer,"São Paulo, BR","GET TO KNOW US  We are on a mission to defeat inactivity! Gympass is a discovery platform that empowers companies to engage their workforce in physical activity by providing access to the largest global network of workout facilities. With a single monthly membership, companies can help employees find their perfect fit among 800 different activities at over 50,000 fitness facilities across the US, Europe, and Latin America. We increase the number of people exercising every day, helping them to become active and reach their goals. Let's help people get there together!  WHAT MAKES A GYMPASSER?  We are passionate about our mission! Whatever your job title is, here you can make a global impact and change people's lives. At Gympass, we collaborate, set high achievable goal expectations and focus on the end result. It's a challenging, evolving environment that allows you to learn and grow. You will face a disruptive and emerging business model that will push you in several areas, with no boundaries for creation and collaboration.  THE OPPORTUNITY  We are hiring a Senior Data Engineer in São Paulo!  YOUR IMPACT  We are looking for a team member to help us grow our Data Engineering team, improve our pipelines, adopt new technologies, find new ways to democratize data: We are responsible to empower all teams by providing a scalable and reliable infrastructure to collect, organize and process the deluge of data generated daily on Gympass (all in a manner protected by privacy): Our infrastructure is completely in the cloud, running Kubernetes, Presto, Spark, Kafka, Airflow and more cutting edge projects:  We use software engineering principles to solve large scale production challenges. We want to help all teams to be data driven.  WHO YOU ARE  You have designed and maintained large scale pipelines (really, we have a deluge of data): You understand how cloud providers works, costs involved and latency: You understand data quality issues and how to troubleshoot them: At your last companies you were responsible for introducing technologies that made people empowered with data.  COMPETENCIES REQUIRED  Design and execution of data architectures, such as lambda and streaming: Proficient in Python, Java or a similar language: Message queues, notebooks, scheduling concepts and serialisation formats: Datalakes in AWS: Data storages and databases: Hadoop ecosystem.   What We Offer You  We're a wellness company that is committed to the health and wellbeing of our employees. Our benefits include:   WELLNESS: health, dental, and life insurance health.   GYMPASS DISCOUNT: We believe in our mission and encourage our employees and their families to find their passion too.   PAID TIME OFF: We know how important it is that our employees take time away from work to recharge.  LATAM: 30 Working days as a personal day off.   PAID PARENTAL LEAVE: Welcoming a new child is one of the most special moments in your life and we want our employees to take the time to be present and enjoy their growing family.   CAREER GROWTH: Outstanding opportunities for personal and career growth. That means we maintain a growth mindset in everything we do and invest deeply in employee development.   CULTURE: An exciting and supportive atmosphere with ambitious people from around the world!   FLEXIBLE SCHEDULE: We give our employees some flexibility to adjust their working hours, letting them adjust their starting time within a range of 3 hours.   REMOTE WORK: After 6 months working with us, employees are also allowed to work remotely once per week. This does not apply to interns and Aprendice.  And to get a glimpse of Life at Gympass... Check out our new Instagram account! @gympasscareers  Gympass is an Equal Opportunity Employer. We don't discriminate on the basis of race, religion, color, sex, gender identity, sexual orientation, age, non-disqualifying physical or mental disability, national origin, veteran status or any other basis covered by appropriate law. All employment is decided on the basis of qualifications, merit, and business need.",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Recursos humanos, Servicios financieros",0,None,False,,6,ACTIVELY_HIRING_COMPANY
512,2241506773,2020-11-05,EvolveAI,Quantitative Researcher,"New York, United States","Quant Researcher - Alt DataNew York$150k - $200k EvolveAI has been retained by a leading institutional investor to help build its Quantitative Research team based in New York/Remote. Our client is looking for a talented Quant Researcher who is well versed in Alternative Data to conduct innovative quantamental research by working with the equity analyst teams. Role Responsibilities: Combine quantitative processes with fundamental insights to identify industry key performance indicators, develop sector-specific signals, build conviction on a call, predict stock returns, and track company-specific risks etc.Develop, backtest, and implement statistics/machine learning models to test the efficacy of sector data: Explore, and evaluate alternative data to gain insights into new alphaHelp build out and expand our data and quant framework. Develop tools to load, process, clean, query, analyze data, and work closely with the technology team to ensure data quality and manage data processActively source new ideas and collaborate with other research teams: Partner closely with sales/marketing, providing quant proof statements to both internal and external clients Required criteria: Advanced degree in quantitative field such as statistics, computer science, engineering, mathematics or finance, PhD preferred3-5 years’ experience in statistics/econometrics modeling, proficiency working with a large dataset, machine learning, data mining, and numerical methodsStrong programming skills including Python, C/C++, R, and scripting languagesExperience working with database, web-scraping, or dealing with alternative data a major plusStrong creative thinking and problem-solving skills: able to decompose complex problems into manageable piecesStrong verbal and written communication skills: able to present quant solutions clearly to both internal and external clients",Intermedio,Jornada completa,Tecnología de la información,Dotación y selección de personal,209,None,True,,621,ACTIVELY_HIRING_COMPANY
513,2208418745,2020-10-23,Delta Faucet Company,Associate Marketing Researcher,"Indianapolis, IN, US","Job Description  Job Description Purpose  The Associate Marketing Researcher is responsible for supporting the marketing research activities of DFC organization. This role is for person who is interested in the bringing the customer’s voice into the organization and helping Delta use customer insights to improve its position in the market.  Responsibilities  This position interacts with all levels within DFC and supports research initiatives including project scoping, vendor selection and management, data analysis, report writing, and presentations. Projects will have a heavy emphasis on primary research with some secondary analysis. The incumbent will be expected to challenge the status quo by exploring new research methodologies and evaluating them for appropriate implementation. The Associate Marketing Researcher reports to the Sr. Marketing Research Manager and some travel will be required.  Some Specific Responsibilities Include Active participant on projects including such areas as: meeting with internal stakeholders to establish clear research objectives, development of request for proposals (RFP), and vendor relationship and project managementDevelopment of questionnaire drafts, discussion guides, data collection and analysis, report developmentIdentification and presentation of key findings to stakeholdersContribute to annual research planning strategySeek out and evaluate new research methodologies appropriate for DFCEducation & Experience:  This Position Requires 4-year degree in Business, Social Science, Math, or Marketing, and 2+ years related research and analysis experience: or an equivalent combination of education and experienceProficiency in Word, Excel, and PowerPointExcellent written, verbal, and presentation skillsDemonstrated skill at data analysis, questionnaire development, and report writingAn eye for detailPersistent creativity in problem solving  It Is Preferred That The Candidate Will Have SPSS and Qualtrics experienceResearch supplier experience  Shift   Full or Part Time  Full time Delta Faucet Company  (the “Company”) is an equal opportunity employer and we want to have the best available persons in every job. The Company makes employment decisions only based on merit. It is the Company’s policy to prohibit discrimination in any employment opportunity (including but not limited to recruitment, employment, promotion, salary increases, benefits, termination and all other terms and conditions of employment) based on race, color, sex, sexual orientation, gender, gender identity, gender expression, genetic information, pregnancy, religious creed, national origin, ancestry, age, physical/mental disability, medical condition, marital/domestic partner status, military and veteran status, height, weight or any other such characteristic protected by federal, state or local law. The Company is committed to complying with all applicable laws providing equal employment opportunities. This commitment applies to all persons involved in the operations of the Company regardless of where the employee is located and prohibits unlawful discrimination by any employee of the Company.    Delta Faucet Company is an E-Verify employer. E-Verify is an Internet based system operated by the Department of Homeland Security (DHS) in partnership with the Social Security Administration (SSA) that allows participating employers to electronically verify the employment eligibility of their newly hired employees in the United States. Please click on the following links for more information.    E-Verify Participation Poster:  English & Spanish   E-verify Right to Work Poster: English , Spanish",Sin experiencia,Jornada completa,"Marketing, Ventas","Marketing y publicidad, Servicios y tecnologías de la información, Artículos de consumo",85,None,False,,602,ACTIVELY_HIRING_COMPANY
514,2289215849,2020-10-21,Búsquedas IT,MACHINE LEARNING ENGINEER (Remote working for USA) - Montevideo,"Montevideo, UY","Description  We are looking for a Machine Learning Engineer to join our awesome multi-disciplinary team. We build data analytics platforms for our clients that incorporate machine learning to solve business problems. The company works across multiple industries, this role provides an exciting set of experiences across a wide range of domains.  Your primary focus will be architecting and developing systems that include data ingestion, data processing, algorithm development, and ML model development & deployment for Recommendation Systems. Major technologies involved include AWS, Azure, Python 3, Spark, Pandas, Tensorflow. The ideal candidate for this position has a mixture of experience in Machine Learning model development, Cloud Engineering, and Data Engineering.  Core Responsibilities & Skills  At least 6 years of experience in an ML senior engineer or technical lead role.  Experience with SageMaker required and experience with other AWS tools preferred (S3, Lambda, Redshift)  Experience developing and designing scalable distributed systems with a deep understanding of object-oriented design, modern program languages, and design patterns.  Excellent communication skills and ability to work effectively with engineers, product managers, data scientists, analysts, and business stakeholders.  Experience developing and designing recommendation systems and production quality ML models for real-time decisions is a plus.  Algorithm and model development experience for large-scale applications  Experience distilling informal customer requirements into problem definitions, dealing with ambiguity and competing objectives This position is a contract to hire, fully remote position for candidates in Latin America. Resume must demonstrate English ability Must be within +/- 2 hours of Eastern Standard Timezone (NYC)  Qualifications  BA/BS degree in Computer Science or a related technical field, or equivalent practical experience.  Advanced experience in Python with an excellent understanding of computer science fundamentals, data structures, and algorithms  Experience in Amazon AWS, Azure, DevOps, and Automation (Cloudformation)  Experience with distributed machine learning using tools like Dask, Tensorflow, Kubernetes, airflow.  Enjoys collaborating with other engineers on architecture and sharing designs with the team  Interacts with others using sound judgment, good humor, and consistent fairness in a fast-paced environment We are an AWS partner and work on projects that use the latest and greatest technologies. We care about the products we build and only work with clients who understand that good applications come from happy engineers and team members. We’re headquartered in NYC and DC with additional remote engineers across the US.",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Software, Recursos humanos",2,None,False,,4,None
515,2235785764,2020-11-04,"AQUA Information Systems, Inc",GCP Data Engineer,"Hartford, Connecticut, United States",BigData/GCP Remote or Contract W2 Need Exp candidate with Bigdata and GCP Exp,Intermedio,Jornada completa,"Tecnología de la información, Otro, Ingeniería","Servicios y tecnologías de la información, Software, Seguridad del ordenador y de las redes",18,None,True,,52,JOB_SEEKER_QUALIFIED
516,2205281826,2020-10-23,AI Probably,Researcher,India,"AI Probably is seeking a talented researcher in scour public market information and glean valuable insights for the use of company What will you be doing? • Perform qualitative and quantitative research and consultation on relative markets • Understand the needs of the organization • Create clear and useful reports and recommendations for organizational use  Skills required: • knowledge on various research and testing methodologies • good experience with statistics analysis of software • Proficient using Microsoft office suite, strong math and statistical skills • Effective in communication, soft skills and presentation. • Experience : 0-2 years  Eligibility: Students who are pursuing or have completed: - BE/B.Tech - BCA - MCA -MTech Employment type: Full time  Salary to be discussed during interview process",No corresponde,Jornada completa,None,None,152,None,True,,902,JOB_SEEKER_QUALIFIED
517,2251580379,2020-11-06,Mitchell Martin Inc.,Big Data Engineer,"Franklin Lakes, New Jersey, United States","Our direct client is in need of multiple Big Data Engineers. Mid level and Sr level. Remote for the foreseeable future but will require a lot of travel once Covid has cleared. Plus expenses for travel.  Big Data Engineer Location: remote for foreseeable future. Will require heavy travel once Covid clearsDuration: 12 months (initial)Contract Skill Community: Big Data Systems & Engineering for AIMarketing Job Title: Senior Specialist – Big Data EngineerArea of Interest: Data & Analytics Big Data:1)big data methodologies (hadoop, spark, kafka, netezza, sap hana, aws)2)Comfortable in Unix, Linux or .NET environment3)Familiar with Source code systems like GIT or SVN4)Cloud/on-prem/hybrid hosting5)Fluency in multiple programming languages (python, scala, java)6)Large scale big data methods (MapReduce, Hadoop, Spark, Impala, Storm) Responsibilities:Rapidly architect, design, prototype, and implement and optimize architectures to tackle the Big Data and Data Science needs for a variety of Fortune 1000 corporations and other major organizations: develop modular code base to solve “real” world problems and conduct regular peer code reviews to ensure code quality and compliance following best practices in the industry.Work in cross-disciplinary teams with industry experts to understand client needs and ingest rich data sources (social media, news, internal/external documents, emails, financial data, and operational data).Research, experiment, and utilize leading Big Data methodologies (Hadoop, Spark, Kafka, Netezza, SAP HANA, and AWS) with cloud/on premise/hybrid hosting solutions: provide expert documentation and operating guidance for users of all levels.Translate advanced business analytics problems into technical approaches that yield actionable recommendations, across multiple, diverse domains: communicate results and educate others through design and build of insightful visualizations, reports, and presentations.Develop skills in business requirement capture and translation, hypothesis-driven consulting, work stream and project management, and client relationship development.Help drive the process for pursuing innovations, target solutions, and extendable platforms for clients: participate in developing and presenting thought leadership, and assist in ensuring that the Lighthouse technology stack incorporates and is optimized for using specific technologies: help promote client brand in the broader data analytics community.Qualifications:BS/MS in Computer Science, Computer Engineering, or related field and minimum four years of big data experience with multiple programming languages and technologies: or PhD in Computer Science, Computer Engineering, or related field: two or more years of experience related to professional services is preferred.Expert ability to rapidly ingest, transform, engineer, and visualize data for both ad hoc and product-level (e.g., automated) data & analytics solutions: expertise with programming methodologies (version control, testing, and QA) and development methodologies (Waterfall and Agile): ability to work efficiently under Unix/Linux environment or .NET, experience with source code management systems like GIT and SVN.Market-leading fluency in several programming languages (Python, Scala, or Java) with the ability to pick up new languages and technologies quickly: understanding of cloud and distributed systems principles (load balancing, networks, scaling, in-memory vs. disk, etc.): and experience with large-scale big data methods (MapReduce, Hadoop, Spark, Hive, Impala, or Storm): full-stack development capability is preferred.Have experience with object-oriented design, coding and testing patterns as well as experience in engineering (commercial or open source) software platforms and large-scale data infrastructures: familiarity with different architecture patterns of development such as Event Driven, SOA, micro services, functional programming, Lambda, etc.: capability to architect highly scalable distributed systems, using different open source tools.Ability to work with other technical and non-technical team members to assess needs, provide assistance, and resolve technical problems: understand engagement objectives which includes a clear understanding of the client’s business problem, and how the engagement helps address the client’s business problemOnce Covid clears, ability to travel up to 80% of the time. Must be legally authorized to work in the United States.",Intermedio,Contrato por obra,Tecnología de la información,Dotación y selección de personal,39,None,True,,126,ACTIVELY_HIRING_COMPANY
518,2234524479,2020-11-06,ABA Finance,Marketing Data Scientist,"Tijuana, Baja California, México","This is the next step your career needs to keep growing. We’re a leading finance company in California that specializes in providing capital to property owners for renewable energy, and more than 100 types of improvements. Be the key component in the creation of new market strategies and get the chance to enter other industries in the US by taking charge of projects, and collaborating alongside different departments. Make your way to the top and increase your value with one of the most competitive offers in the market. WHAT CAN YOU DO FOR US? We are looking for a professional with a value of personal responsibility, self-sufficiency, dedication, and a desire to succeed. Your contribution to our team will focus on market research by implementing marketing automation technology through various platforms to enable data-driven outcomes. This includes capturing, storing, managing, and analyzing said data to create effective strategies that will help in marketing and sales decisions. In this role, you will make a big impact on our company by combining the importance of marketing automation and data science in order to maximize the effectiveness of campaigns, improving customers’ digital experience, and measuring the overall business outcome. You will be helping the sales team with potential prospects and the marketing team by enhancing key areas of digital marketing such as SEO, content marketing, customer engagement, and more.Plus, this is your chance to play with intricate data and analytical experiments that will help us gather customer insights such as preferences, demographics, buying habits, competitors offers, and details that could influence product demand. Take charge of projects from start to finish, and give your career the push it needs to grow internationally in this industry. Skills required for this position include:- Knowledge in Python, HTML, APIs- Knowledge of Granular Targeting processes – to manage large amounts of customer data through the integration of CRM and other transactional systems.- Knowledge of omnichannel Touchpoints – To gauge the value of the leads generated through different digital channels (Website, Social Media, Email Campaigns, Mobile, Search, and so on.).- Experience in analyzing leads generated in the past to predict future behaviors/purchases.- Running different experiments (A/B multivariate testing)- Understanding audience real-time behavior. WHAT CAN WE DO FOR YOU? Our reach is growing faster this year and we’re expanding into new markets with the creation of multiple financing programs. This is where you step in and why the Marketing Data Scientist position is of high importance to our company. This role will be in charge of decision-making along with Sales and Marketing department leaders. The knowledge and the skills this experience will provide for you will increase your areas of expertise. Apply now to one of the best offers in the industry that combines Data Science and Marketing. Complete your application with us here!",Intermedio,Jornada completa,"Análisis, Investigación, Marketing",Banca de inversiones,19,None,True,,135,JOB_SEEKER_QUALIFIED
519,2227373587,2020-10-30,Talent,Senior Data Scientist - Finance,"Seattle, Washington, United States","A rapidly growing IT Solutions Firm has hired Talent International to assist them in their search for a Senior/Principal Data Scientist with a background in FP&A.  Salary Range - 170-205K Depending on Experience Candidate must have a high business IQ and have the ability to easily speak to CFOs all day. They prefer someone with experience in IT consulting, but it's not required. They also need great communication skills as this role is a problem fixer. They have to be a great DS and also understand business and what make the most monetary sense. The ideal candidate would have deep experience in designing high-value advanced analytics solutions utilizing popular analytical frameworks running on Azure, GCP, and AWS. This position will be responsible for leading customer engagements, creating and presenting project architecture, and leading delivery.  Candidate will also be tasked with targeted collaboration with CFOs and other finance leaders to create extreme value data initiatives and solutions. Responsibilities:Data Science Practice GrowthDrive growth through business development, resourcing, & quality delivery.Monitor business impact and value generation of analytics projects.Plan strategy for growth of practice capabilitiesHelp created go-to-market strategies around advanced AI and ML services and hardware.This role will be directly involved in the business development process, delivering customer demos to show the value of how data can drive business goals.Create proposals and SOWsWork closely with sales and other practice leaders to recommend strategies to grow our data science services.Manage full sales cycles, end-to-end, for high potential clientsEvaluate business impact and priority initiatives for our portfolio of managed analytics customers. Talent Leadership and Product OwnershipHelp with planning and staffing for data science projects.Provide support for project managers through developing tasks, estimates, and dependencies to meet expectations.Train the data science team on best practices and new technology initiatives.Anticipate the impact of new technologies and frameworks and help create compelling data science offerings to our clients. RequirementsBackground in finance and accounting and knowledge of how to use data science techniques in operations to impact corporate financials8+ years of experience with advanced data science techniques, frameworks, libraries, and technologies including but not limited to Tensorflow, KubeFlow, Python, R, Keras, NumPY, SciKit, PyTorch, Databricks, SQL.Experience with all aspects of Artificial Intelligence, Machine Learning, and Deep Learning.Working knowledge of DevOps processes (CI/CD) applied to data science and ML opsAdvanced Math or Data Science Degree.Ability to articulate concepts to people with a varying technical background",No corresponde,Jornada completa,"Ingeniería, Tecnología de la información",Servicios y tecnologías de la información,90,None,True,,329,ACTIVELY_HIRING_COMPANY
520,2181307911,2020-10-13,LaBine & Associates,Backend / Data Engineer,San Francisco Bay Area,"Our startup client is hiring senior engineers to help build cloud service, data pipelines, and Machine Learning platform. While the founders are located here in Silicon Valley, this is a remote culture with employees around the United States. We're hiring engineers that get excited about building and owning the process from inception to deployment.   What they're looking for:Python (extra credit for PySpark)experience working with the suite of AWS technologiesExperience building and scaling distributed architectures, and perhaps data pipelines tooStrong communication skills, and history of working remotely successfully If you're interested in learning more, apply today!!!",Intermedio,Jornada completa,Ingeniería,Servicios y tecnologías de la información,67,None,False,,304,JOB_SEEKER_QUALIFIED
521,2203301273,2020-10-22,Pondurance,Data Engineer,United States,"Our mission at Pondurance is to ensure that every organization is able to detect and respond to cyber threats – regardless of size, industry or current in-house capabilities. We believe AI and automation alone aren’t enough, you also need experienced human intervention because behind every nefarious cyber-attack is a person with their own mission. We combine our advanced threat intelligence platform with decades of human intelligence to speed detection and response and contain cybersecurity threats quickly to ultimately decrease risk to our customers mission - and we need you to help us.  We believe our people are what makes us different. As team members in Pondurance, we offer flexible work arrangements to help our people manage their personal and professional lives in the complex remote world we live in. We believe in transparency and fairness in all relationships and that trust and empathy towards our clients and partners, towards each other and within our communities is the best foundation for success.  Are you ready to join a team of passionate, dedicated professionals who wake up every day to make the digital world a better place?  About The RoleAs a Data Engineer on the Pondurance Data Pipeline Team, you will build, manage, and maintain the Managed Detection and Response Data Pipeline. The pipeline is responsible for collecting, processing, and enhancing security-related data used to monitor and protect our customer’s environments.  The purpose of the role is for the chosen candidate to understand the existing set of technologies and assist in the conception, architecture, design, and quality of data processing tools and algorithms. This position will work closely with software engineers to provide the data back to customers, and also with the Security Analysts to ensure applicability of enhancements to detect and address challenging problems in cybersecurity. Skills And ExperienceSystems programming experience and concurrent programming, Rust preferredExperience with API design and maintenance, REST or similar.Strong data modeling skillsScripting languages and data science experience, python, ruby, etc.Familiarity with message queues, KafkaComfortable with Git/version control workflows.Familiarity with Continuous Integration (CI), Github Actions, etc.Highly organized, able to multitask, the ability to work individually, within a team, and with other groups. What You'll NeedDegree or pursuing Degree in Computer Science, Engineering, or a related technical discipline and/or equivalent experiencePrior development experience requiredStrong technical and analytical skills Nice To Have, but always a plusData science and machine learning experienceDatabase programming, SQL, etc.Domain-Specific Language designAgile DevelopmentExperience creating or contributing to open source projects.Experience with statistical programming and graphingGPU programming experience, CUDA, etc. Let’s redefine the security and cyber risk landscape together.   We are committed to building an inclusive culture of teamwork that embraces the diversity of our people and reflects the diversity of the communities in which we work, the customers, agencies and organizations we serve, and the enable us to deliver on our mission while allowing our employees to live a balanced life. We strive to provide an environment where high performing teams apply their diverse perspectives, to make informed decisions and collectively solve industry and customer problems. In so, we can attract and retain talent from all backgrounds and create an environment where everyone feels empowered to bring their full, authentic selves to work. Pondurance is an Equal Opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex including sexual orientation and gender identity, national origin, disability, protected veteran status, or any other characteristic protected by applicable federal, state, or local law.",Intermedio,Jornada completa,Tecnología de la información,Seguridad del ordenador y de las redes,25,None,False,,157,ACTIVELY_HIRING_COMPANY
522,2252380153,2020-11-08,MAX-Security Solutions Ltd.,Researcher for Travel Consultancy (remote work),India,"We are looking for freshers/early-career researchers to be part of a 6-month project team. You will be expected to perform detailed open-source research (on security and public health issues) and present your findings. You will play a vital role in sourcing and extracting valuable information to support different clients and suppliers.  ResponsibilitiesGathering relevant information using multiple sources. Conducting detailed research of intended subject matter in a specified geographical region. Providing research and analysis for in-depth reports. Formulating effective and efficient research processesIdentifying trends and patterns Technical requirements & other expertiseThe desired research analyst must be energized and motivated - able to multitask under pressure, in a fast-paced environment. Graduate and/or Masters degree in the field of political science, public health, social sciences, journalism, security studies, international relations, or similar areas of study would be advantageous. Familiarity with social media and associated tools. Native-level English proficiency is required. Knowledge of other languages is an advantage. Experience:Individuals with previous research experience would receive preference, however, we are open to candidate profiles who can demonstrate similar capabilities.  Compensation: 30-35K per month Interested candidates, please connect with me or send your profile at the earliest at connect@temp-let.com In case you are not presently looking for such opportunity, kindly share within your network.",Algo de responsabilidad,Jornada completa,"Investigación, Análisis, Tecnología de la información",Seguridad e investigaciones,50,None,True,connect@temp-let.com,285,ACTIVELY_HIRING_COMPANY
523,2279187353,2020-11-05,Workforce Logiq,Data Engineer,"Fort Lauderdale, Florida, United States","WorkforceLogiq is currently hiring for two Data Engineer's for our Ft Lauderdale location. This position can workremotely from anywhere in the US but will need to work EST hours.  The Senior Data Engineer is responsible for building and maintaining optimized and highly available data pipelines that facilitate deeper analysis and reporting. This engineer’s duty is to monitor the existing metrics, analyze data, and lead partnerships with other Data and Analytics teams in an effort to identify and implement systems and process improvements. This engineer also designs, architects, implements, and supports key datasets. ResponsibilitiesDesign and develop highly scalable and reliable data engineering pipelines to process large volumes of data across many data sources in the cloudIdentify, design and implement internal process improvements by automating manual processes and optimizing data deliveryDevelop and promote best practices in data engineeringDevelop real-time data processing applications using Google CloudBe part of the on-call rotation supporting our SLA’sParticipate in design and code reviews  QualificationsBachelor's degree in Computer Science or equivalent experience in a related field or hands-on experience working in data warehousing or data engineering environmentAdvanced SQL programming skillsExperience developing data solutions on GCP or AWSExperience in ingestion of data from external APIs and data storesExperience in design, build and operationalization of big data pipelines on Cloud Technologies.Problem-solving, quality and ability to executeStrong experience in authoring, scheduling, and monitoring of workflows (Apache Airflow related technologies)Strong communication & interpersonal skills  Preferred Qualifications:Google Cloud Certified - Professional Data Engineer certification would be a plusKnowledge of Git, Jinja2, Docker, Bitbucket, and Bambooamiliar with a NoSQL database such as MongoDBFamiliar with version control systems (Git and Bitbucket)Familiar with Atlassian products Jira and ConfluenceHands-on experience with Apache Airflow or Google Composer",Algo de responsabilidad,Contrato por obra,Tecnología de la información,"Servicios y tecnologías de la información, Entretenimiento",110,None,True,,281,ACTIVELY_HIRING_COMPANY
524,2288430974,2020-11-07,Wiley Job Network,Data Scientist II (Remote Work Location Available),"Leming, TX, US","Purpose of Job We are currently seeking a talented Data Scientist II for San Antonio Home Office II/III or Remote Work Location Available.  This role is designated for a Data Scientist who has proficient knowledge with applying modern advanced analytics methods (predictive modeling, Machine Learning, and optimization), as well as a solid grasp of the mathematics used for each method and strong Python coding skills to develop numerical models. The Data Scientist is expected to demonstrate the ability to effectively communicate (written and oral) complex analytical and technical concepts to both technical and non-technical employees. The Data Scientist for this role is expected to have experience working with time series/forecasting models.  Within defined guidelines and framework, uses techniques that integrate traditional and non-traditional datasets and method to enable analytical solutions. Applies predictive analytics, machine learning, simulation, and optimization techniques to generate management insights and enable customer-facing applications: participates in building analytical solutions leveraging internal and external applications to deliver value and create competitive advantage. Translates complex analytical and technical concepts to non-technical employees.  Job Requirements Identifies and manages existing and emerging risks that stem from business activities and the job role. Ensures risks associated with business activities are effectively identified, measured, monitored, and controlled. Follows written risk and compliance policies and procedures for business activities. In partnership with SMEs, learns to define the business problem and works with experienced data scientists to select the appropriate model.Extracts features from structured and unstructured data (internal and external).With guidance, conducts advanced analytics: predictive modeling, Machine Learning, and optimization. Works with Data Engineering/IT partners to develop architectures for new products, services and features.Explains complex models and outcomes to colleagues who are not data scientists.  Minimum Education Bachelor's degree in Computer Science, Applied Mathematics, Quantitative Economics, Statistics, or related field or 4 additional years of related experience beyond the minimum required may be substituted in lieu of a degree.  Minimum Experience 2 years of related experience and accountability for complex tasks and/or projects.Proficient knowledge of the function/discipline and demonstrated application of knowledge, skills and abilities towards work products.Proficient level of business acumen in the areas of the business operations, industry practices and emerging trends.Strong coding skills in the dominant scripting language (such as Python).Deep academic understanding of model assumptions. Solid grasp of statistics and mathematics.Proficient knowledge of Data Science principals and experience with data science methodologies.  *Qualifications may warrant placement in a different job level*  When you apply for this position, you will be required to answer some initial questions. This will take approximately 5 minutes. Once you begin the questions you will not be able to finish them at a later time and you will not able to change your responses.  Preferred Experience Proficient knowledge with applying modern advanced analytics methods (predictive modeling, Machine Learning, and optimization).Experience with Time Series/Forecasting Modeling.Solid grasp of mathematics, with a strong foundation in calculus, linear algebra, probability, and statistics.Strong Python coding skills to develop numerical models.Demonstrated ability to effectively communicate (written and oral) complex analytical and technical concepts to both technical and non-technical employees.  The above description reflects the details considered necessary to describe the principal functions of the job and should not be construed as a detailed description of all the work requirements that may be performed in the job.  At USAA our employees enjoy one of the best benefits package in the business, including a flexible business casual or casual dress environment, comprehensive medical, dental and vision plans, along with wellness and wealth building programs. Additionally, our career path planning and continuing education will assist you with your professional goals.  USAA also offers a variety of on-site services and conveniences to help you manage your work and personal life, including seven cafeterias, two company stores and three fitness centers .  Relocation assistance is not available for this position.  For Internal Candidates  Must complete 12 months in current position (from date of hire or date of placement), or must have manager's approval prior to posting.  Last day for internal candidates to apply to the opening is 11/03/20 by 11:59 pm CST time.",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Dotación y selección de personal, Consultoría de estrategia y operaciones",0,None,False,,6,None
525,2183084946,2020-10-14,Schneider Electric,Full Stack Azure Cloud Data Scientist,United Kingdom,"Full Stack Azure Cloud Data Scientist About us:  Schneider’s purpose is to empower all to make the most of our energy and resources, bridging progress and sustainability for all. We call this Life Is On.Our mission is to be your digital partner for Sustainability and Efficiency.We drive digital transformation by integrating world-leading process and energy technologies, end-point to cloud connecting products, controls, software and services, across the entire lifecycle, enabling integrated company management, for homes, buildings, data centers, infrastructure and industries.We are the most local of global companies. We are advocates of open standards and partnership ecosystems that are passionate about our shared Meaningful Purpose, Inclusive and Empowered values.https://www.youtube.com/watch?v=YtExntUe89c www.se.com The Residential Controls business within the Schneider Electric group is a global provider of devices used to control heating, hot water, humidity and cooling in domestic and small commercial installations and is expanding into the world of Smart Products. The business is investing heavily in new product design, market expansion and further development of existing markets. In particular, it is creating an exciting new range of Internet and cloud-connected smart products to exploit the opportunities provided by the rapid growth of the Internet of Things (IoT). https://www.youtube.com/watch?v=4LXBa3UcrGI Location: – You will be working from home with occasional travels to Plymouth and London when requested, less than 20% of your time travelling. You will be working closely with Schneider R&D teams in the UK and across the world. Your mission: We are looking for an experienced full-stack cloud developer with experience of data science and AI/ML techniques to help drive Drayton’s Smart Controls business to the next level. This is an exciting opportunity to work on the creation of data-driven products in the Internet of Things space. Working closely with members of the product development team (product management, firmware, cloud services, electronics, mechanical and systems design), you will play a leading role in developing cloud-based applications that scale across multiple use cases, customers, and devices. This is largely a hands-on green-field development role that offers great opportunity for shaping the total design of our IoT cloud services.Within the Schneider cloud ecosystem, this role will focus primarily on the movement, analysis and presentation of big-data in order to provide value-add features to end-users and partners, and business insight to internal stakeholders and partners alike. Data analysis is expected to utilise a combination of bespoke development, off-the-shelf components and integration with third-party services, whilst presentation will span APIs and Business Intelligence dashboards and charting.The role will also be responsible for defining and/or validating requirements to be implemented by our cloud service providers(s) and verifying their correct implementation. Cloud based services are only useful if they are available and responsive, so a key element of this role is to proactively engage with the service operations manager, 1st line support and cloud service providers to ensure appropriate service monitoring is in place and incidents are managed to conclusion in a timely manner. Your main responsibilities:Generic Development ResponsibilitiesDesign and develop data-driven applications on the Azure cloud platform which work on a wide range of data types and integrate with data analytics solutionsApply AI/ML techniques in pursuit of the above, modelling complex scenarios to inform, predict and feed into control algorithms.Apply a mixture of BDD and edge-case exploration to author effective automated unit testsDesign and implement continuous integration (specifically build, deployment and test) in order to maintain consistent delivery to specification and quality.Where appropriate produce concise, high quality documentation to provide overall context and explanations for complex areas of codeQA·        Work with the test manager, other internal stakeholders and cloud service providers to define and/or validate cloud service requirements, and verify their correct implementationCollaborationHelp identify and work with third-party solution providers, infrastructure providers, cloud application services that can help enrich the Smart Home propositionParticipate in the agile process, including backlog refinement, driving completion of sprint goals, and continuous improvement of the processWork with Systems Engineering, UX, and Firmware Development teams to create scalable end-to-end solutions that drives the company’s business forwardService OperationsAssist the service operations manager in the timely, customer-focused resolution of service incidentsProactively engage with internal stakeholders and cloud service providers to ensure appropriate monitoring, alerting, SLAs and incident management processes are in place About you: EssentialExperience working with, designing and defining cloud services and data pipelinesMicrosoft Azure development using C# to create message-oriented and micro-services architectures. Keywords: Azure, C#, event hub, azure function, azure storage, azure web app, web API.Big Data experience using Apache Spark / Databricks (pyspark) to extract data from DataLakesStrong python programming skills, and solid knowledge of data-science libraries (Pandas, NumPy, scikit-learn), and visualisation libraries (matplotlib)Machine Learning encompassing understanding of core machine learning algorithms and feature engineeringDeveloping and deploying data pipelinesGit or other version control experienceAgile development methodologies.Skilled at building clean, maintainable code. Passion for product development and innovation Takes responsibility for and proactively drives work packages to completionPassionate about technology and its application to smart home automationLikes to learn about new technologyCustomer focusedGood team player and communicator PreferredBasic web front-end development experienceUse of dashboarding tools, particularly PowerBICreating data-driven applicationsAdvanced AI and Machine LearningDeployment and operations supportDeveloping systems for support of mobile applications – including authentication, subscription management, backend-as-a-service, analytics, commerce What we offer: You can look forward to growing your career in a dynamic workplace with significant personal responsibility and flexible working models to ensure the right work/life balance. A dynamic and personal atmosphere, working across teamsA company culture that encourages performance and cooperationAn attractive compensation package including the comprehensive fringe benefits expected of an international companyWe are an employer that is characterized by both the appreciation and equal opportunities of our employees, a recipe for generating success. Every day, we empower employees to achieve more and experience exciting careers. Find out how our values and unique position make Schneider Electric the employer of choice – apply now online. Diversity is our heritage and our future. Be a part of it. At Schneider Electric, Diversity & Inclusion is at the heart of our organisation, it's an integral part of our history, culture and identity. We recognise that embracing diversity unlocks innovation and creativity and fosters collaboration. We want our employees to reflect the diversity of our communities and the customers we serve. As a result, our teams are stronger to drive the company's future.  We are open to a conversation about flexible working.",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información","Manufactura eléctrica/electrónica, Electrónica de consumo",3,None,False,,139,COMPANY_RECRUIT
526,2243122947,2020-10-26,ConcertAI,Senior Data Scientist,United States,"About ConcertAIConcertAI is the leading provider of precision oncology solutions for biopharma and healthcare, leveraging the largest collection of research-grade Real-world Data and the only broadly deployed oncology-specific AI solutions. Our mission is to improve translational sciences: accelerate therapeutic clinical development: and provide new capabilities for post-approval studies to accelerate needed new medical innovations to patients and to improve patient outcomes. ConcertAI has emerged as one of the highest growth technology companies in Real-world Data and AI, backed by industry leading private equity companies: SymphonyAI, Declaration Partners, Maverick Ventures, and Alliance|Bernstein.  Role SummaryConcertAI is looking for a talented Senior Data Scientist to build advanced AI and Machine Learning solutions as part of our client-facing data science team engaging in projects and programs of high priority. You will be responsible for data exploration, analysis, development of machine learning methods for predictive/descriptive modeling of patient data in the oncology domain using ConcertAI’s RWD data. You should have a good mix of programming/CS, stats/math, and ML skills, and ideally, you have a background in life science, biology or medicine. You will work closely with a cross-functional team of subject matter experts, data scientists, and data and software engineers to assist with client technology delivery. This role reports to the Vice President of Data Science.  The person must be located in the United States with possible travel to a corporate office periodically.  ﻿ResponsibilitiesWorking with the client and internal teams, internal RWD teams, eurekaHealth solutions team to advance approaches that best utilize ConcertAI’s RWD and technologies, while providing leading and high value solutions for ConcertAI’s clients.Understand, define and solve healthcare specific problems and be able to analyze, visualize, interpret, and contextualize results for and with clients.Design, develop and implement mathematical models, methodologies and data science solutions using ConcertAI’s RWD data to address client’s needs.Understand client goals and translate them into practical initatives with actionable outcomes.Provide scientific and methological direction for a client workstream and manage client expectations.Design and develop cutting edge methodologies intended for publication and the advancement of healthcare.Collaborate on software projects with engineers, providing analytical guidance and contributing to codebase.Access and communicate with internal stakeholders as needed to support client aims and data questions, including Data Science, Data Products, Data Curation and other relevant areas. RequirementsPhD in a STEM field, with formal training in CS, stats, bioinformatics, computational biology, data science, physics or math.2+ years experience in life sciences and working with biological or healthcare data, e.g. mathematical modeling, advanced data science and computational concepts and techniques.2+ years experience in client-facing role and comfortable to run and own a client workstream is preferred,.Strong programming skills in one high level language (Python, R).Good understanding of biostatistical and statistical concepts and probability theory.Proven experience with complex individual-level data sets leveraging biological data and/or healthcare data (Electronic Health Records, claims data).Strong communication, project management and technical leadership skills with an enthusiasm for working in an interdisciplinary and client-facing environment.Comfortable in working in a fast-paced and changing high growth environment.",Intermedio,Jornada completa,"Investigación, Ciencias, Tecnología de la información","Industria farmacéutica, Biotecnología, Investigación",42,None,False,,423,ACTIVELY_HIRING_COMPANY
527,2291318203,2020-11-08,None,Junior Data Scientist - Remote / London,"London, GB","Avanti Recruitment have partnered with a Global Data Analytics and Information provider to support them in growing their Data Science team in London. A high number of candidates may make applications for this position, so make sure to send your CV and application through as soon as possible. Our client has a huge global presence with locations all over the world in over 50 locations and an annual revenue of c.&163:4bn per year. A lot of their business is done with companies within the Transport, Finance and Energy sectors and they are always looking to expand their offering, which is why they are building out their Data Science team in London to help support this. They are looking for bright, hungry and dedicated junior Data Scientists to come in and work closely with the existing team. There is loads of training on offer that ranges from online courses, mentoring from senior members of the team, 'future leaders’ training as you develop your career and industry specific expert training from thought leaders within the sector. This is a great opportunity for someone to further develop their career, with clearly defined career progression available that will see you develop from junior level right through to senior, principal, Team Lead and management and Senior Leadership positions within the business.  Experience That Interests Them Includes  Python PySpark Machine Learning experience Experience with Data Visualisation Management of Big Data Exposure to AWS or other Cloud based technologies Experience in the areas above would be hugely beneficial, but they will consider candidates with similar experience in other areas providing they have an interest in learning and developing their knowledge in the areas mentioned. Our client is offering a salary of &163:30k  &163:35k as well as a host of brilliant additional benefits that I am happy to share if you are interested in learning more. If you are interested in the role or want further information, please get in touch or apply now for immediate consideration.",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Software, Dotación y selección de personal",None,None,False,,7,JOB_SEEKER_QUALIFIED
528,2281966734,2020-10-12,Whip Media Group,Senior Data Scientist,"Los Angeles, CA, US","Whip Media Group powers a market leading enterprise platform that provides a broad range of integrated services, enhanced by unique analytics, that enables the world's leading entertainment organizations to more efficiently manage, distribute and monetize TV & Movie content. Whip Media Group has offices in Los Angeles, New York City and London.  Whip Media Group is adding a Senior Data Scientist to our consumer platforms team, which encompasses our TV Time consumer product as well as our premier entertainment metadata platform, theTVDB. This team is based primarily in Santa Monica, but we're open to data science candidates working remotely.  In this role, you will be the primary driver of all data science services and initiatives for our those products and possibly others down the line. These initiatives will include translating our business goals and ideas into data-driven features for our :15 million users as well as helping determine how best to keep growing our global user base. We are looking for a talented problem-solver who thinks outside the box, is versatile but also delivers reliable and efficient systems.  What Will You Do?    Translate our business strategy into a data science and machine learning vision: then digest that vision into short/long term plans on how we get there Create, maintain, and iterate on algorithms and machine learning systems with which millions of users will engage every month, including a content recommendation engine and user experience optimizations Collaborate with product management, engineering (platform, mobile, and data), UX research & design, and data insights teams to ensure we're driving the right metrics for our larger business. This may include work on user personas, predictive models around lifetime value and churn, A/B testing, sample balancing, and designing an achievement system  Participate in the larger data science initiatives throughout the company   What Do You Need?    3+ years working as a Senior/Lead Data Scientist 2+ years building churn models, LTV models, user segmentations, and/or other product and marketing focused predictive analytics History of leading projects alongside other functions that produced game-changing work Extensive experience architecting complex algorithms/data products, extensive knowledge on recommendation systems preferred Background in designing and instituting 'production quality' machine learning algorithms Deep understanding of python, docker, a variety of ML toolkits Ability to write complex SQL queries and a strong understanding of relational databases A passion for technology and the newest services!  PhD degree in Computer Science, Math, Statistics, or a related technical field preferred, MS required",Algo de responsabilidad,Jornada completa,Otro,"Medios de comunicación en línea, Software, Internet",None,None,False,,8,ACTIVELY_HIRING_COMPANY
529,2291198462,2020-10-14,Woebot Health,Lead Data Scientist,"San Francisco, CA, US","Our mission is to make the best mental health tools radically accessible for everyone.  We are pioneers in building personalized digital mental health tools to help millions of people with mental health difficulties. We are building a suite of regulated, prescription-only digital therapeutics as well as a sophisticated delivery platform capable of responding to the lived experience of our users.  Our tools are powered by the latest research in NLP and ML, use scientifically proven techniques from Cognitive Behavior Therapy, and are based on 10 years of intervention science at Stanford University. Our founder has an international reputation in Digital Mental Health intervention development. Our Chairman is Andrew Ng: and Dan Jurafsky is a member of our advisory board, both globally recognized leaders in AI/NLP.  There has never been a better time to use your data science skills for good. Given the recent acceleration in infrastructure to allow for the meaningful adoption of digital therapeutics, our strong product reputation, and existing relationships within health systems, Woebot is in a period of explosive growth. We are looking for a product-minded data scientist to continue to create value for our users, customers, and execute on our IP strategy.  What you will do:  As a leader in the Product team, you will work cross-departmentally with clinical and engineering team members to build machine learning and AI algorithms that are the core of Woebot's intelligence. There are four areas we want you to own and drive:  Drive An Insights & Analytics Culture  You will help create data analysis and analytics pipelines that improve not only the underlying ML algorithms but also the product and the user's experience.  You will lead a team of Analysts and be responsible for good data driven hygiene, including the creation, redesign, and maintenance of analytics dashboards and BI tools such as BigQuery, Google Data Studio, or Tableau.  You will also advise on data labeling strategy so that Woebot's conversational engine is continuously improved and informs changes in features, content, and UX.  Improve User Personalization  Woebot exchanges 4.7 M messages with our users every week. You will create & lead a data-driven personalization strategy for this audience. We consider personalization to be key for developing a relationship over time while delivering precision interventions, that is: the right method to the right person at the right time.  Contribute To Evidence  In the next 6 months, you'll help Woebot develop evidence & trends to demonstrate the value of our highest priority products.  You're helping answer the most pressing questions in the mental health field around engagement, dose, and treatment outcomes.  In partnership with our Clinical team and academic partners, we expect you to contribute to our pipeline of peer-reviewed published research.  In addition to some platform-related pieces, you will lead publication in Data Science and HCI research.   What Your First 90 Days Could Look Like  By Day 30 - Assess the lay of the landscape & team - and make suggestions around in house analytic tools, dashboard and strategies. By Day 60 - understand the roadmap with our founder and reverse engineer our tailored interventions. Deliver a prioritized list of roadmap items. By Day 90 - Submit your first publication. Execute on a plan for improving user outcomes with our analytics and ML.  Role Specific Competencies:  PhD in Data Analysis or ML/AI or computational field with 8-10+ years of applied experience Knowledge of one or more modern ML/NLP frameworks, such as PyTorch, Tensorflow, or Keras Track Record of publishing in peer reviewed academic literature  You've led and managed other analysts and data scientists. Strong written and verbal communication skills  What you will bring to our culture:   Empathic: You're a compassionate person and a team player motivated to understand others and help them be successful, too. You care as deeply for your colleagues as you do for our mission and our users. Growth Mindset: You believe abilities - like intelligence & talent - can be developed through dedication and hard work. You see failure as an opportunity to grow and welcome feedback as a pathway to your continued success. Humble: You recognize that you are one among many, and you hold a genuine desire to discover what other people can offer. You are intrigued by how others think, and how others feel differently from you. You lean into these moments with patience & curiosity.  Self-aware:  You possess a high level of emotional intelligence, which allows you to understand yourself and others, and to have a healthy emotional life in the workplace. Proactive & Flexible: You are able to hit the ground running, you take responsibility for finding a way to get the job done. You learn as quickly as possible and sometimes do things outside the immediate scope of your work, giving it all you've got. What we offer:  Competitive Salary Stock Options Flexible PTO Health, Dental & Vision Healthy Snacks & Meals   Woebot is an equal opportunity employer and we deeply value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",Algo de responsabilidad,Jornada completa,Otro,"Software, Atención sanitaria y hospitalaria, Industria farmacéutica",0,None,False,,None,ACTIVELY_HIRING_COMPANY
530,2225203247,2020-10-21,"Bluegrass Tek, LLC",Senior Data Engineer,"Frankfort, Kentucky, United States","Job Description: Role: Azure Data Engineer  Type: Contract Location : 100% REMOTE Interview: 1 WebEx  Job Description: Senior Azure Data Engineer We are looking for an Azure Data Engineer. Our ideal candidate is data focused, with a background in data engineering in Azure. This role will focus on building end-to-end solutions so having experience in modern data platform technologies such as Azure Data Lake, Azure Data Factory, Azure functions are a must.  Job Summary: Develop and maintain data pipelines including solutions for data collection, management and usage Develop and maintain ARM template along with IAAS like Data lake, blob storage, azure data factory and serverless function Write programs to cleanse and integrate data in an efficient and reusable  What you’ll be doing: Work across a cross-functional team to develop and deliver cloud, data, and analytics solution for enterprise clients Develop and deliver large-scale Azure cloud application development and transformation engagements, helping enterprise customers understand cloud considerations, develop cloud application strategies and helping refactor existing applications for Azure, as well as develop new Azure-based cloud-native applications on Azure PaaS. Implement data solutions in Azure including data factory, Cosmos DB, Azure Functions.  MUST HAVES: Experience in implementing data solutions in Azure including Azure data factory, Azure function, Cosmos DB. Hands on experience with C#, ASP.NET, MVC, .NET Core, .Net Framework (4.6) JSON, and API development  Candidate Status (acceptable status): * U.S. citizen * Green Card  Skills/ Must-Haves : * IMPLEMENTING data solutions in Azure cloud environment: Azure data factory, Azure function, and Cosmos DB - there are a lot of candidates who do the development but are not responsible for implementing the solutions, so please make sure you are qualifying this * C#, ASP.NET, MVC, .NET Core, and .NET framework 4.6 experience * API Development experience  Company / Job Insight: * This is for a Polaris project, which is an in house project * Project start date is 11/02/2020 with an initial end date of 01/08/2021 but it will most definitely will get extended beyond that - likely a 9-12+ month contract * This will be a remote role and candidates can be located anywhere in the US.",No corresponde,Contrato por obra,None,None,24,None,True,,112,None
531,2198724031,2020-10-21,GenScript,"Research Scientist, Process Optimization",United States,"Location: Piscataway, NJ Job scope:We are looking for a Research Scientist to provide technical expertise for supporting the urgent molecular biology reagent production needs. Key Responsibilities•      Optimize the workflow of automated gene synthesis process•      Participate in automated production •      Lead other laboratory procedure improvement projects•      Comply with the correct procedures, policies, and health and safety regulations•      Other assignments from supervisors Requirements•      Master degree in molecular biology related field with a minimum 2 years of independent hands on lab experience or Ph.D degree•      Solid knowledge of gene synthesis procedure•      Good understanding of laboratory automation process preferred•      Knowledge of automated units operation, work experience in automated production preferred•      Work experience in a biology or biochemistry laboratory preferred•      Working knowledge of Microsoft Office•      Patient, attend to details and is able to follow SOPs.•      Flexible to night/weekend shifts",Algo de responsabilidad,Jornada completa,Investigación,Biotecnología,73,None,True,,364,ACTIVELY_HIRING_COMPANY
532,2279234203,2020-11-05,Medix™,Lead Data Scientist,"Washington, District of Columbia, United States","Medix is currently seeking a Lead Data Scientist for an exciting DIRECT HIRE job opportunity with one of our top clients, headquartered in the Bethesda, MD area. Please note that the work location for this role is 100% remote due to COVID: however work will transition on-site in Bethesda, MD in 2021. Relocation assistance is also offered. ABOUT OUR CLIENT / ABOUT THIS ROLEOur client is a national leader within the risk management & insurance space! They are seeking to hire a Lead Data Scientist to help drive predictive analytics across several key areas within the organization - primarily on customer experience, risk & fraud, and operations. This role will be serving as a technical lead, and will be assisting in developing more junior data scientists on the team. This role will include the full lifecycle of analytics - data engineering as well as predictive modeling and presentations to the business. DAY TO DAY RESPONSIBILITIES WILL INCLUDE:Working as Lead Data Scientist in a highly collaborative environment Leveraging cloud data collaboration tools like Databricks, to explore, prototype and build models in collaboration with the team (other Data Analysts and Data Engineers)Working with big data in the cloud, using analytics engines and cluster computing frameworks like Spark, MapR, Tez and YarnProviding technical guidance and mentorship for less experienced team members Guiding, and participating in the building of data sets --working extensively with R and Python / Python libraries to extract and manipulate data from a variety of internal and external sources (Scikit-learn, Pandas, Numpy, Scipy, PySpark, NLTK)Creating and deploying various machine learning algorithms, and tuning models to achieve desired outcomes.Conducting deep analysis on business topics related to customer sentiment analysis, customer segmentation analysis, risk & fraud, etc.Running predictive analytics to gain insights into consumer behaviors Using data visualization software to effectively redact and communicate data outcomes, and recommendations to senior leadership (using Tableau, RShiny, or similar tools) Presenting outcomes and targeted recommendations to Directors and C-Suite executives  REQUIRED PROFESSIONAL EXPERIENCE & QUALIFICATIONSRequired Master of Science in a Computer Science or Engineering fieldPreferred PhD in a Computer Science or Data Science field5+ years experience as a Data ScientistExpertise with Python & Python tools (Scikit-learn, Pandas, Numpy, Scipy, PySpark, NLTK)Experience with data manipulation & analysis using R Experience working with cloud data tools - Spark/ MapRData visualization tools - Tableau or RShiny, or similarData collaboration tools such as Dataiku, Datarobot or RapidMiner ADDITIONAL INFORMATION Position Location: Bethesda, MD (Note: Currently 100% Remote due to COVID)Position Type: Direct Hire / Full TimeCompensation Range: $140,000 - $150,000 / year + profit sharing bonus Benefits: Our client offers an exceptional full-time benefits package, including a fantastic medical benefits package for employee + family members, generous paid time off, a 401K retirement savings plan with company contributions, profit sharing, continuing training and tuition reimbursement, college savings plans, Employee Assistance programs and much more! ****************Candidates must be authorized to work as a full-time employee of our client, without the need for visa sponsorship now or in the future. Sponsorship is not offered for this position. ****************",Director,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Seguros",52,None,True,,192,ACTIVELY_HIRING_COMPANY
533,2251573264,2020-11-06,Stash,Senior Data Engineer,"New York, New York, United States","Stash is pioneering the future of personal finance with the first financial subscription that helps people create better lives. From budgeting to saving for retirement, Stash unites banking, investing, and advice all in one app that has helped more than 5M people reach their financial goals and make progress towards financial freedom. We look for people who will help raise the bar for our entire engineering organization in terms of tech prowess, passion for collaboration and desire to mentor and educate fellow team members. We look for strategic thinkers and creative problem solvers with a bias for execution and we’ll expect you to contribute code as well as product/feature ideas from the get-go. Our team has built an amazing modern data platform and we would like to add many advancements such as real time streaming, many tools around data governance. As a Data Engineer, you will be responsible for enhancing our data infrastructure to take it to the next level, in collaboration with the team members. You will also be an active contributor in the ongoing maintenance of the existing pipelines. Stash is a data-driven organization and data infrastructure is a critical part of our overall infrastructure. You will have the opportunity to make an impact in the companies’ OKRs by coordinating with data science, marketing teams and backend teams by aligning with their data needs. We work with the latest technologies in the big data space and are seeking folks who would like to do the same. Tech stack (evolving):Spark, Scala, Python, Kafka, AWS EMR, Hive, Redshift, Lambda, SNS, SQS, S3, Looker, DynamoDB, CircleCI, Terraform. What you'll do:Contribute to the design/architecture new initiatives such as real time streaming pipelines, tooling around data governance, build job orchestration abstractions to manage resources on AWSCollaborate with the team to build tools for data science/marketing teamsDesign integration pipelines for new data sources and improve existing pipelines to perform efficiently at scaleProvide technical guidance to the teamLeverage best practices in continuous integration and deployment to our cloud-based infrastructureOptimize data access and consumption for our business and product colleagues Who you are:4+ years of professional experience working in data warehousing, data architecture, and/or data engineering environments, especially using spark, hadoop, hive etc with solid understanding of streaming pipelines.At least 1+ years of experience in streaming pipeline developmentProficiency in at least one high-level programming language (Scala, Java, Python or equivalent)Good understanding of databasesBS / MS in Computer Science, Engineering, Mathematics, or a related fieldYou have built large-scale data products and understand the tradeoffs made when building these featuresYou have a deep understanding of system design, data structures, and algorithmsYou have an excellent knowledge of distributed computing frameworks such as Hadoop MapReduce, Spark.You have a strong knowledge of following AWS infrastructure - EMR, S3, RedshiftYou have strong understanding of data quality, governanceYou are a team player, self-driven, highly motivated individual who loves to learn new things Gold stars:Experience in Machine Learning infrastructureExperience in Search Engines",Intermedio,Jornada completa,Tecnología de la información,"Servicios financieros, Banca, Artículos de consumo",44,None,True,,193,ACTIVELY_HIRING_COMPANY
534,2215785905,2020-10-27,Hinduja Tech Limited,Data Engineer,India,"What we are lookingResponsible to Ingest data from files, streams and databases. Process the data with Python and Pyspark and its storage into time series database.Overall 5 -10 years of experience as Data Engineer.Advanced working SQL knowledge to create complex queries.Experience in working with Time-series Database, relational databases as well as working familiarity with a variety of databases (structured & Unstructured).Good experience in doing object-oriented programming in python.Proficient in REST APIs.Experience working on Azure Cloud services IaaS, PaaS.Hands-on Experience in working on Microsoft Azure Services like ADLS/Blob Storage solutions, Event Hubs, Service Bus, scale sets, Load Balancers, Azure Functions, Databricks.Hands-on Experience in working on Kafka.Knowledge of continuous integration/continuous deployment.Experience in data migration and deployment from On-Premise to Cloud environment and vice-versa.",Intermedio,Jornada completa,Tecnología de la información,Sector automovilístico,100,None,True,,379,ACTIVELY_HIRING_COMPANY
535,2289008749,2020-11-03,Futran Solutions,"Data Engineer / Location: Remote/Mclean, VA","Reston, VA, US","Location: Remote/Mclean, VA Position: Data Engineer Duration: Direct Hire Interview Process: Online Skill Test, Phone and Video Call Citizenship: US Citizen or Green Card  For this role you will be working remotely until COVID restrictions are lifted. Must be able to work in the office in Mclean, VA. Candidate must have good communication and have experience working in a Product environment.  Skills Needed  3+ years experience is ideal (or more) this individual will be building out their data pipelines Strong Data experience, Familiar with SQL and other popular programming languages (such as Ruby, Python, .NET, etc) Able to do data modeling and database prototypes  Client looking for a Data Engineer to join our Product team to design and build a robust set of tools and pipelines to support data analytics efforts. You'll manage and optimize our core infrastructure by creating and maintaining data pipelines. You will work with other engineers and analysts from the Product and Business teams to design, implement, and maintain a data ecosystem that delivers actionable insights to make key business decisions. You have technical chops but can also work independently to prioritize issues, work within ambiguity, and manage conflicting deadlines. You are creative, data-driven, results-oriented, and eager to help us solve data problems of varying complexities.  Responsibilities Develop technical solutions using proven techniques in data and analytics processesDevelop, prototype, and build frameworks based on open source and commercially available toolsOrchestrate and maintain data pipelines that meet security standards and ensure the integrity and quality of dataDemonstrate a passion for serving the needs of internal and external customers by enabling them with self-service reporting tools and analytics capabilitiesDrive the execution of data initiatives that provide key performance metricsUnderstand the data related challenges, nuances, and requirements to identify and recommend the optimal technical approachTrain and educate team members as well as stakeholders about best practices in data engineering and governanceCollaborate closely with the engineering and devops team to implement DataOps, thus reducing our analytics development cycleResearch and improve our data platform to ingest, process, transform, and distribute insightful data to our audience ranging from executives, analysts, and engineers to customers, vendors, and partnersEvangelize data driven culture by breaking down silos and encouraging data sharingQualifications3+ years of hands-on experience in data engineering for a SaaS company or a mature startupProven experience working with various tools but more importantly, familiarity with how to best assemble and deploy production ready data stack to any cloud environmentBS in a quantitative or scientific field such as computer science, computer engineering or equivalent experienceExperience in applying agile software development approach - Git, CI/CD, Jira, etc - to data engineeringFamiliar with SQL and other popular programming languages (such as Ruby, Python, .NET, etc)Exceptional fluency with SQL: you conquered the join venn diagram long ago and have moved on to explaining cost based optimization to your peers on the engineering teamSome level of experience working in the cloud - AWS, Azure, or GCPExperience with ingesting, processing, and visualizing data sources of varying types - structured/relational and unstructuredExperience in developing, managing, and manipulating large, complex datasetsData-driven, detail-oriented individual with excellent storytelling and problem-solving abilitiesAbility to work independently and autonomously, as well as part of a teamSuperb time management, prioritization of tasks and ability to meet deadlines with little supervision  Full-time",Sin experiencia,Jornada completa,Tecnología de la información,Software,2,None,False,,7,ACTIVELY_HIRING_COMPANY
536,2285419217,2020-10-13,EKOSYSTEM,Data Engineer H/F – Grenoble et « remote » - ekosystem,"Grenoble, FR","Grenoble… Si comme moi tu y a étudié. Si comme moi tu adores cette ville et ses montagnes environnantes et si (alors pour le coup pas du tout comme moi…) tu t’éclates à coder en .NET/Angular… j’ai l’opportunité pro qu’il te faut !  Une super boîte (très connue !!) qui monte… qui monte… mais qui a su conserver l’esprit bienveillant et humain de ses débuts !  Un projet passionnant (ou plutôt DES projets passionnants), des bureaux au top, une ambiance géniale, un turnover quasi-nul, un management participatif… La liste des avantages à intégrer cette entreprise est longue (et encore je ne parle pas de son CE super dynamique et de son ouverture au télétravail…).  Bref, tu l’auras compris, cette opportunité est d’or !  Chez Ekosystem (comme chez notre client d’ailleurs) on aime faire les choses différemment! À commencer par cette offre d’emploi  Car au-delà de tes compétences techniques et de ton expérience en développement fullstack .NET/Angular, c’est TOI qui nous intéresse!  Ce facteur humain, cette attention particulière à qui tu es, ce que tu aimes et ce que tu veux… c’est notre modus operandi. Zéro bullshit! Cette dimension humaine, c’est elle qui drive chacune de nos décisions. C’est en fonction d’elle que nous choisissons nos clients et c’est grâce à elle qu’on s’éclate quotidiennement au taf.  Résultats Nous te proposons des boîtes qui recrutent dont l’ADN « match » à 200% avec toi, tes aspirations pro et tes projets de vie.Nous sommes convaincus que nos clients te permettront de grandir aussi bien professionnellement qu’humainement. Pas d’offre d’emploi spécifique donc. Mais une multitude de combinaisons élargissant ton/notre horizon des possibles!  Car tu es plus qu’une fiche de poste, rien ne vaut un échange, qu’il soit téléphonique, VoIP ou physique!  Comment postuler?  Shoot nous ton CV (en cliquant sur le bouton « APPLIQUER » se trouvant à la droite de ton écran (notre webmaster montréalais tenait à utiliser cet anglicisme québécois :)) et nous revenons vers toi ASAP!",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Internet",None,None,False,,6,JOB_SEEKER_QUALIFIED
537,2197047813,2020-10-28,Fidelity Life,Data Engineer II,"Chicago, Illinois, United States","Who we are:Fidelity Life is a leading provider of financial security for middle market consumers. With a history of innovation, the company is redefining the life insurance industry with patented products and processes. Fidelity Life pioneered the use of predictive analytics to streamline the new business process and revolutionize the speed with which policies can be issued. Established in 1896, Fidelity Life enjoys a long track-record of success and continues to build its reputation of sound fiscal management and customer-focused innovation.  In concert with Fidelity Life, eFinancial is an online and call-center-based insurance agency with a proven direct-to-consumer life insurance model. Using a proprietary and patented sales technology platform, eFinancial operates call centers in Chicago, IL: Seattle, WA: and Tempe, AZ. eFinancial’s licensed agents and representatives reach thousands of consumers each day to help meet their unique life insurance needs – often with just a single phone call. To complement this channel, the company recently expanded to offer an entirely digital purchase experience. Together, Fidelity Life and eFinancial are revolutionizing the life insurance industry to make life insurance more accessible and affordable for everyday Americans. With an integrated marketing, product manufacturing, and controlled distribution system, the enterprise is uniquely positioned for growth.  What the job looks like:As a key member of the Big Data Analytics team, you will be responsible for creating and operating the Big Data environment that enables eFinancial and Fidelity Life Association to optimize business processes and grow rapidly. You will move and integrate data across multiple disparate systems, aggregate and organize large sets of data in order to enable lead operations, analytics, and predictive modeling. If you would love being an owner-operator of a fast-growing complex online business with modern technology stacks, building analytical and infrastructure solutions, and driving success via analytics, this role is for you! What you will contribute:Own the creation and maintenance of company data structures and databases in AWS to support predictive model development, analytics, and business intelligence.Implement, test, document, and deploy integrations and maintain production readiness for cloud-based technology stack including real-time streaming, batch feeds, and predictions models from multiple cloud-based and on-premise sources.Take on specific ETL projects to assimilate data from multiple new structured and unstructured data sources in batch or real-time, as appropriate.Assimilate and implement business rules to process raw data. Set up visualization tools to meet the needs of both cloud and on-premise user community.Serve as data steward for Analytics team and third-party technology partners. What you should bring to the table:Bachelor’s degree in any relevant field required.At least 4 years of data engineer experience.Hands-on experience with AWS services: Lambda, Athena, Redshift Spectrum, Glue, S3, EKS, EC2, EMR, Kinesis, and RDS.Git experience required.Knowledge and experience in Big Data and in building Data Pipelines/ETL processes.Strong verbal and written communications skills that enable you to explain data infrastructure complexity with clarity and precision to executive management.Proficiency in SQL: and working knowledge of Python and PySpark.Ability to think strategically to anticipate and plan for future business needs.Passion for taking ownership of new opportunities and projects.Team Player mentality - you thrive in a collaborative environment.Excellent multi-tasking skills, you are able to shift gears quickly and comfortably. Nice to have skills and experience: Experience with DevOps and CI/CD preferred.",Intermedio,Jornada completa,"Tecnología de la información, Ingeniería",Seguros,132,None,True,,458,ACTIVELY_HIRING_COMPANY
538,2224712252,2020-10-29,Involvio,Data Science Engineer,India,"We are looking for a Data Scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products. ResponsibilitiesSelecting features, building and optimizing classifiers using machine learning techniquesData mining using state-of-the-art methodsExtending company's data with third party sources of information when neededEnhancing data collection procedures to include information that is relevant for building analytic systemsProcessing, cleansing, and verifying the integrity of data used for analysisDoing ad-hoc analysis and presenting results in a clear mannerCreating automated anomaly detection systems and constant tracking of its performance Skills and QualificationsExcellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.Experience with common data science toolkits, such as R, Weka, NumPy, MatLab, etc. (excellence in at least one of these is highly desirable)Great communication skillsExperience with data visualisation tools, such as D3.js, GGplot, etc.Proficiency in using query languages such as SQL, Hive, PigExperience with SQL databases, such as PostgreSQLGood applied statistics skills, such as distributions, statistical testing, regression, etc.Good scripting and programming skills in Ruby and PythonData-oriented personality",Sin experiencia,Jornada completa,Tecnología de la información,Gestión educativa,290,None,False,,997,JOB_SEEKER_QUALIFIED
539,2241532604,2020-11-08,Advanced Career Networks,Remote Data Engineer,United States,"Our client a stable and growing late-stage start-up is hiring a 100% Remote Pipeline Data Engineer. The Pipeline Data Engineer will help architect and develop our evolving data platform. The Pipeline Data Engineer role will be part of our growing data team, interfacing closely with software engineering. If you are a highly independent worker and have excellent organizational and problem-solving skills, this is the job for you. Our client offers full benefits, a competitive salary, and a friendly work environment.  As a member of a small but growing data team, you will be working closely with business partners, and software engineering teams playing a vital role in the design, build, and maintenance of data pipelines: providing timely, accurate, and reliable information to all aspects of the business. As we incrementally improve and expand our company, you will be building new systems from the ground up or replacing legacy systems outright, free from supporting legacy code bases. Here’s what you bring to the team: ·        3+ years of data and/or software engineering experience·        Experienced developing testable ETL solutions in python·        Experienced pulling and manipulating data from multiple data sources using Python·        Intermediate SQL skills·        Experience deploying to a public cloud solution (i.e., AWS (preferred), Azure, GCP) ·        Experience in delivering solutions based on Agile principles·        Experience architecting cloud data solutions·        Experience with AWS Lambda and Dynamodb·        Developing streaming data flows (i.e., w/ Kafka, AWS Kinesis, AWS SQS, Spark Streaming)·        Experience with Kubernetes / containers",Intermedio,Jornada completa,Tecnología de la información,Servicios y tecnologías de la información,72,None,True,,212,JOB_SEEKER_QUALIFIED
540,2273439736,2020-10-10,"Aledade, Inc.","Senior Research Scientist, Remote","Bethesda, MD, US","We are seeking new members of our Impact Analytics team at Aledade to evaluate the impact of Aledade's population health interventions and use innovative methods to answer pressing business and policy questions. This person will design and conduct analyses that leverage national Medicare claims data in addition to other payer claims, electronic health records, event notification, and patient reported data. They will work across teams to understand key performance and policy questions facing the business and bring data to inform strategic and tactical decision making. The successful candidate will have experience with health care data sources including Medicare claims, strong quantitative analysis and programming skills, and a passion for the intricacies of value based care.  As a Senior Research Scientist, you will be responsible for: Utilizing national Medicare claims data in addition to other payer claims, electronic health records, event notification, and patient reported data to model ACO program rules and analyze ACO performance.Driving organizational learning about which population health interventions achieve cost savings and improve health outcomes in Aledade’s network of independent primary care practices. Designing and executing descriptive and predictive analyses to identify opportunities to improve care delivery, support population health product development, and inform Aledade’s growth strategy.Employing predictive analysis techniques to target population health interventions and identify strategies that are likely to succeed.Working with teams across Aledade to identify implications of analysis results and translate findings into action. Presenting analysis results to internal and external audiences, including company executives, product development and ACO operations teams, and clinical staff at Aledade and in our partner practices. Contributing to broader dissemination of learnings via external publications, conferences, and other venues as applicable.Serving as subject matter expert on study design and quantitative analysis methods. Providing consultation services to other analysts and members of other teams across Aledade. Mentoring staff in areas of expertise.   Preferred Qualifications  Excellent quantitative analysis abilities, grounded in epidemiology, biostatistics, econometrics, health informatics, health care analytics or related field.Deep experience with Medicare claims and other health care data sources such as payer claims, electronic health record, event notification, clinical, and patient reported data.Demonstrated ability to conduct nuanced analyses to produce accurate and unbiased results and tell the story of those results in data visualizations and reports.Advanced data manipulation skills, including a strong foundation in SAS and/or SQL programming. Knowledge of standard methods for measuring health care utilization, spending, quality, and outcomes: risk adjustment: provider profiling: and related analytical tasks.Experience with descriptive and causal analysis including experimental and quasi-experimental study design and analysis methods.Intense attention to detail and data quality assurance.Ability to thrive in a fast-paced environment and manage competing deadlines and priorities.If you are passionate about transforming the healthcare system into one that best serves the needs of patients, doctors, and society, we’d love for you to join us!   Who We Are   Aledade is a leader in population health that is using innovative, value based solutions to transform the way physicians interact with their patients. We are on a mission to change healthcare for the better and solve complex problems within the healthcare system.  We follow the simple but radical idea that Aledade only succeeds when our partner practices succeed. From our cutting-edge technology platform to practice transformation services, we provide physicians with everything they need to create and run an accountable care organization (ACO), revamping the way they practice and getting them back to where they should be: quarterbacking their patients’ health care!  Our customized solutions help clinicians in communities across America preserve their autonomy, deliver better care to their patients, reduce overall costs, and keep independent physician practices flourishing.  What Does This Mean for You?  At Aledade, you will be part of a creative culture that is driven by a passion for tackling complex issues with respect, open-mindedness, and a desire to learn. You will work with team members that bring a wide range of experiences, interests, backgrounds, beliefs, and achievements to their work, united by a shared passion for public health and a commitment to the Aledade mission.  We’ve recently been recognized as a Top Workplace by The Washington Post, Best Workplace in HealthCare & Biopharma, Top 100 Best Small & Medium Workplaces, Glassdoor Best Places to Work, a Best and Brightest Companies to Work for in the Nation, a Tech Tribune 10 Best Tech Startups in Maryland and Bethesda, and a 2020 Inno on Fire by DC Inno. That’s because the things that matter to you also matter to us!   Benefits   In addition to time off to support work-life balance and enjoyment, we offer the following comprehensive benefits package designed for the needs of our team-members  Flexible work schedules and ability to work remotely available for many roles  Educational Assistant Program  Robust time off plan (20 days of PTO in your first year!)  Paid Volunteer Days  11 paid holidays  12 weeks paid Parental Leave for all new parents  6 weeks paid sabbatical  Health, dental and vision insurance paid at 80% for employees, dependents, and domestic partners  401(k) with up to 4% match  Stock options  Monthly cell phone stipend  Weekly catered lunches  Jeans everyday workplace  Gender neutral bathrooms  And more!  At Aledade, we don’t just accept differences, we celebrate them! We strive to attract, develop, and retain highly qualified individuals representing the diverse communities where we live and work. Aledade is committed to creating a diverse environment and is proud to be an equal opportunity employer. Employment policies and decisions at Aledade are based on merit, qualifications, performance, and business needs. All qualified candidates will receive consideration for employment without regard to age, race, color, national origin, gender (including pregnancy, childbirth or medical conditions related to pregnancy or childbirth), gender identity or expression, religion, physical or mental disability, medical condition, legally protected genetic information, marital status, veteran status, or sexual orientation.",Algo de responsabilidad,Jornada completa,Otro,"Gestión de organizaciones sin ánimo de lucro, Sanidad, bienestar y ejercicio, Atención sanitaria y hospitalaria",3,None,False,,55,COMPANY_RECRUIT
541,2249345301,2020-10-11,"Rackspace, the Open Cloud Company",Data Engineer,"Remote, OR, US","Our Data Engineers are experienced technologists with technical depth and breadth, along with strong interpersonal skills. In this role, you will work directly with customers and our team to help enable innovation through continuous, hands-on, deployment across technology stacks. You will work to build data pipelines be involved in the complete end-to-end Data Engineering efforts, including code development, integration, troubleshooting and testing.  If you get a thrill working with cutting-edge technology and love to help solve customers’ problems, we’d love to hear from you. It’s time to rethink the possible. Are you ready?  What You’ll Be Doing Build complex ETL code Work on Data and Analytics Tools in the Cloud Develop code using Python, Scala, R languages Work with technologies such as Spark, Hadoop, Kafka, etc. Build complex Data Engineering workflows Create complex data solutions and build data pipelines Establish credibility and build impactful relationships with our customers to enable them to be cloud advocates Capture and share industry best practices amongst the community Attend and present valuable information at Industry Events Drive the engagements with customers from the architectural pillar, from design to delivery, create runbooks etc.   Qualifications & Experience 15+ Years of Data-warehouse and Analytic system development and deployment experience 10+ years of experience in database architectures and data pipeline development 8+ years of experience in modern data ware housing platform using cloud native technologies 5+ years of experience in delivering Azure/GCP/AWS Data Solutions. Demonstrated knowledge of software development tools and methodologies Presentation skills with a high degree of comfort speaking with executives, IT management, and developers Excellent communication skills with an ability to right level conversations Demonstrated ability to adapt to new technologies and learn quickly Experience with Google Cloud Services such as Streaming + Batch, BigQuery, BigTable, DataStudio, DataPrep, Pub/Sub , Cloud Storage, Cloud Dataflow, Data Proc, DataFlow, DFunc, Big Query & Big Table knowledge and proven use of contemporary data mining, cloud computing and data management tools including but not limited to Microsoft Azure, AWS Cloud, Google Cloud, hadoop, HDFS, MapR and spark. Design and configuration of data movement, streaming and transformation (ETL) technologies such as Informatica, Nifi, Kafka, Storm, Sqoop, SSIS, Alteryx, Pentaho, Alooma, Airflow. Creation of descriptive, predictive and prescriptive analytics solutions using Azure Stream Analytics, Azure Analysis Services, Data Lake Analytics, HDInsight, HDP, Spark, Databricks, MapReduce, Pig, Hive, Tez, SSAS. Design and configuration of data movement, streaming and transformation (ETL) technologies such as Azure Data Factory, HDF, Nifi, Kafka, Storm, Sqoop, SSIS, LogicApps, Signiant, Aspera, Alteryx, Pentaho, Alooma, Airflow. Large scale design, implementation and operations of OLTP, OLAP, DW and NoSQL data storage technologies such as SQL Server, Azure SQL, Azure SQL DW, PostgreSQL, CosmosDB, RedisCache, Azure Data Lake Store, Hadoop, Hive, MySQL, Neo4j, Cassandra, HBase Experience working within an agile development process (Scrum, Kanban, etc) Expertise in data estate workloads like HDInsight, Hadoop, Cloudera, Spark, Python. Familiarity with CI/CD concepts Strong verbal and written communications skills are a must, as well as the ability to work effectively across internal and external organizations and virtual teams. Knowledge or hands-on experience with data visualization and/or data sciences.   Must Have's Hands on experience with Azure/GCP projects. Cloud certifications such as GCP Professional Data Engineer or Microsoft Data / AI certifications. Technical degree required: Computer Science or Math background desired   Location: This is a virtual roleThe candidate needs to be based in US or Canada  Travel This role would require 25 - 30% travel  About Rackspace Technology  We are the multicloud solutions experts. We combine our expertise with the world’s leading technologies — across applications, data and security — to deliver end-to-end solutions. We have a proven record of advising customers based on their business challenges, designing solutions that scale, building and managing those solutions, and optimizing returns into the future. Named a best place to work, year after year according to Fortune, Forbes and Glassdoor, we attract and develop world-class talent. Join us on our mission to embrace technology, empower customers and deliver the future.  More on Rackspace Technology  Though we’re all different, Rackers thrive through our connection to a central goal: to be a valued member of a winning team on an inspiring mission. We bring our whole selves to work every day. And we embrace the notion that unique perspectives fuel innovation and enable us to best serve our customers and communities around the globe. We welcome you to apply today and want you to know that we are committed to offering equal employment opportunity without regard to age, color, disability, gender reassignment or identity or expression, genetic information, marital or civil partner status, pregnancy or maternity status, military or veteran status, nationality, ethnic or national origin, race, religion or belief, sexual orientation, or any legally protected characteristic. If you have a disability or special need that requires accommodation, please let us know.",Sin experiencia,Temporal,Tecnología de la información,"Servicios y tecnologías de la información, Software, Servicios financieros",0,None,False,,13,COMPANY_RECRUIT
542,2025109258,2020-10-15,MBN Solutions,Machine Learning Engineer,"Edinburgh, Scotland, United Kingdom","Machine Learning Engineer – Edinburgh (Fully remote initially)Up to £60,000 + Package  MBN are exclusively partnering with a leading online technology company to help them appoint a Machine Learning Engineer in Edinburgh. The business are creating a Machine Learning platform and are looking to appoint an Engineer with experience building, deploying, optimising and maintaining machine learning solutions at scale. This is a fantastic opportunity to join a modern online tech business with offices in some of the most attractive cities in the world. Their award winning platform powered by data & analytics and used both by businesses and consumers has allowed them to achieve exponential year on year growth. In this role you will create, deploy and maintain ML algorithms which allow the business to detect fraud, enhance product features and identify additional needs of the customer. Key Skills & Experience Required:Experience developing, deploying and optimising scalable machine learning algorithmsExperience working with ML frameworks such as TensorFlow, Keras & PyTorchAbility to productionise models within a modern cloud architecture (Sagemaker, Auto ML or Azure Functions)Experience creating heuristics models such as NLP, Anomaly Detection, Neural Networks, Vectorisation.Advanced programming skills across one or more of these languages (Python, Scala, C# or Java)Engineering best practices (CI/CD, configuration management, test automation) For more information or to apply, please send an updated CV to Kris@mbnsolutions.com or press apply now.",Intermedio,Jornada completa,Tecnología de la información,Servicios y tecnologías de la información,336,None,True,Kris@mbnsolutions.com,1087,ACTIVELY_HIRING_COMPANY
543,1989687597,2020-11-04,Lookout,Senior Security Researcher,United States,"We are open to candidates across North America to work remotely.  Lookout is a cybersecurity company that makes it possible for individuals and enterprises to be both mobile and secure. With 100 million mobile sensors fueling a dataset of virtually all the mobile code in the world, the Lookout Security Cloud can identify connections that would otherwise go unseen -- predicting and stopping mobile attacks before they do harm. The world’s leading mobile network operators, including AT&T, Deutsche Telekom, EE, KDDI, Orange, Sprint, T-Mobile and Telstra, have selected Lookout as its preferred mobile security solution. Lookout is also partnered with such enterprise leaders as AirWatch, Ingram Micro and MobileIron. Headquartered in San Francisco, Lookout has offices in Amsterdam, Boston, London, Sydney, Tokyo, Toronto and Washington, D.C. To learn more, visit www.lookout.com We are looking for Senior Researchers to join our Device Security Intelligence team, a group of world-class mobile researchers who work on device compromises and other mobile platform-based threats. As a member of this team you will hunt and neutralize threats to mobile devices, research system vulnerabilities, work with exploit code, and contribute to an extensive arsenal of detection tools and technologies. Responsibilities Reverse engineer system code, exploits, and applications to determine how they work. Apply the results to improve the way Lookout detects threats and gathers telemetry.Hunt down and classify new threats and vulnerabilities before they affect our users.Identify current and future attacks on user privacy and device security, using telemetry data from our Mobile Threat Network.Contribute to the long-term design of our telemetry analysis, data stores, mobile client, and tooling. Required Qualifications & Skills Experience in reverse engineering of software at the system level.Able to read assembly code as well as C and related languages.Able to code in Python or Ruby or Java.Experience using some of the following tools: IDA Pro, Hopper, gdb, Frida.A desire to help build a diverse team of researchers with different backgrounds.Build and maintain positive relationships with security and developer communities.",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Internet",24,None,False,,419,ACTIVELY_HIRING_COMPANY
544,2225503387,2020-10-21,GCS Recruitment Specialists,Senior Data Engineer,"Austin, Texas, United States","GCS is partnered with a leader in digital asset financial services, providing institutional investors with liquidity, custody, and security solutions.  The Custody Platform team is looking for a Data Engineer to work on new and existing projects. The company processes a significant amount of cryptocurrency transactions so the applications need to be fast, accurate, scalable and secure. The integrated platforms interact with a number of exchanges, agencies, and governments around the world, and use the best technology the industry offers to build them. Requirements:Minimum 5 years of related experience building and managing ETL processesExpert in scripting, regular expressions and task automationAdvanced experience with scriptwriting, database architecture and platform/system administration process knowledgeAdvanced knowledge of database solution languagesExperience in creating and maintaining optimal data pipeline architectures, emphasizing performance, resiliency, and high-volume processingBS or MS in Computer Science or equivalent experience Nice to have:Knowledge of/or experience with blockchain technologyKnowledge of data visualization tools such as Tableau or similarPast experience with accounting toolsExperience with writing analytics tools to provide actionable insights into operational efficiency, financial reports, and other key business performance metrics (KPIs) JavasScript experience",Intermedio,Jornada completa,"Tecnología de la información, Ingeniería, Finanzas","Software, Servicios financieros, Servicios y tecnologías de la información",38,None,True,,138,ACTIVELY_HIRING_COMPANY
545,2209628270,2020-10-15,Netlify,Senior Data Engineer - Software Engineering,San Francisco Bay Area,"Company Overview At Netlify, we’re building a platform to empower digital designers and developers to build better, more elaborate web projects than ever before. We’re aiming to change the landscape of modern web development. Netlify currently serves more than 1,000,000 developers worldwide.Netlify is a diverse group of incredible talent from all over the world. We’re ~44% woman or non-binary, and are composed of more than a fourth as many nationalities as we are team members.We recently raised $63M in Series C funding to bring forward the next generation of tooling for a more accessible web. Among our investors are Andreessen Horowitz, Kleiner Perkins, EQT Ventures as well as the founders of GitHub, Slack, Figma and Yelp. This latest round brings Netlify’s funding raised in total to $108M to date. About the role: As a Senior Data Engineer working on our critical data pipelines at Netlify, your contributions will have a huge impact on our burgeoning data function's efforts. You’ll design and build pipelines that will support key analytical and business intelligence functions, help enable decision making around user-facing features, and empower your fellow team members to experiment with and develop on top of our data. Some of the things you'll do: Help to evolve and scale our data platform, with an eye towards growthWork closely with the analytics and business intelligence teams, as well as other stakeholders from finance, sales, marketing, and product, to understand the data needs of the business and produce processes that enable a better product and support growth decision-makingGenerate architecture recommendations and the ability to implement themCreate smaller issues and code changes by collaborating with stakeholders to reduce scope and focus on iterationImprove, manage, and teach standards for code maintainability and performance in code submitted and reviewedShip medium to large features independentlyHelp evolve our CI/CD strategy for our ETL jobs and pipelines We're looking for someone who has experience with: Experience developing production-grade ETL pipelines in PythonExperience with Data Extraction, Cleaning, and MiningStrong comfort implementing Kimball-style architecture in analytical data warehouses, such as Snowflake, BigQuery, and RedshiftHands on experience with data orchestrators, such as Airflow, Dagster, Prefect, or Luigi (Airflow preferred)Experience planning and executing system expansion as needed to support the company's growth and analytical needsBelief in writing documentation as part of writing codeExcellent written communication that will enable async workClear communicator who can gather technical requirements and explain technical intricaciesDesire to continually keep up with advancements in data engineering practices Nice to haves:Experience implementing a DataOps frameworkExperience implementing Python best practicesFamiliarity with CI/CD in a data engineering/ops settingRESTful API development experienceSome experience with R and/or Scala in productionExperience in the Google Suite of the data ecosystem, especially Google Cloud Data proc or Apache Beam  Within 1 month, you’ll…Learn about our Dev and DataOps process and supporting tools.Have pairing sessions with some of the people you'll be working most closely with.Identify opportunities for improvements on existing pipelines and how things are organized in our data stores.Have started committing small quality of life improvements to pipelines as part of learning the shape of our data and how it flows through systems and processes.Be helping perform code reviews for new changes. Within 2 months, you’ll…Feel comfortable spelunking in our data stack to answer your own questionsBe contributing to internal conversations on data organization and structure Within 3 months, you’ll…Be in the on-call rotation for the other data engineers and feel confident in your ability to handle most common issues (assuming they can't yet be automated away!) for your critical pipelines.Have a solid understanding of our Data peers' needs and skillsets so that we support them with data sources and schemas that enable them work efficiently.Rolled out your first few new pipelines to supply your team members with a new clean data source.Identified opportunities for improvement on our DataOps strategy that helps us increase observability, reproducibility, and supports our iteration speed. About NetlifyOf everything we've ever built at Netlify, we are most proud of our team. We believe that empowered, engaged colleagues do their best work. We’ll be giving you the tools you need to succeed and looking to you for suggestions to improve not just in your daily job, but every aspect of building a company. Whether you work from our main office in San Francisco or you are a remote employee, we’ll be working together a lot—paring, collaborating, debating, and learning. We want you to succeed! About 63% of the company are remote across the globe, the rest are in our HQ in San Francisco. To learn a bit more about our team and who we are, make sure to visit our about page. ApplyingNot sure you meet 100% of our qualifications? Please apply anyway! When applying please include: A resume or short listing of your job history & skills. (A link to a LinkedIn profile would be fine). A cover letter explaining why you would enjoy working in this role and why you’d like to work at Netlify would be great, though not required & will not impact your application. When we receive your application we’ll get back to you about the next steps. Netlify is an Equal Opportunity Employer. We are devoted to building a team of people with diverse backgrounds and lifestyles. We believe that the unique contributions of all Netlifolks is the driver of our success. We are all responsible for bringing on people from all walks of life. Driving equality empowers our team, enables us to innovate, and helps us maintain a more inclusive environment. We don’t discriminate against employees or applicants based on gender identity or expression, sexual orientation, religion, age, race, military/veteran status, citizenship, pregnancy status, or any other differences. If we can do anything to provide a better interview, i.e. accommodate a disability, then please let us know.",Intermedio,Jornada completa,Ingeniería,Servicios y tecnologías de la información,22,None,False,,143,ACTIVELY_HIRING_COMPANY
546,2215530786,2020-10-27,Grofers,Software Development Engineer II (Data Engineer),"Gurugram, Haryana, India","ABOUT THE ORGANIZATIONGrofers is the 4th largest organized grocery retailer in India, clocking an annualized GMV of $800m. It is also one of the fastest-growing grocers in the country driven by its mission of making quality products affordable for its consumers. With operations in over 27 cities across India, Grofers uses its in-house technology platform to manage a network of over 12,000 partner stores that enable the company to run a fast and lean supply chain - from manufacturers straight to consumers. The company utilizes its efficient supply chain to deliver over 50 million quality products to consumers every month. A majority of these products are sourced from over 800 small and medium manufacturing enterprises across the country.During the last 6 months, Grofers has seen a tremendous increase in new user acquisition along with a sustained lift in retention and is now poised for its next stage of growth. ABOUT THE ROLEThe Grofers Data Engineering Team in Grofers is a tightly-knit team of passionate analysts and aspiring engineers asking questions and only taking data for answers. We've been chugging along nicely for the last two years and need more hands to help scale-up and scale-out. We're looking for someone with exemplary data engineering skills to join us and help us in maintaining a great data-driven culture.As a member of this team, you will contribute to the Data Platform and leverage it to build timely data-driven solutions for various Demand teams. The Data Platform team supports the consumers in a day-to-day analysis by efficiently replicating data from backend databases and events from the frontend. It also helps our data creators populate our Data Lake and Data Warehouse in a reliable and timely manner. The platform and technology used to build it are constantly evolving as we try to meet various business needs and their latency requirements. We will keep trying to push the boundaries while being a lean team building a cost-effective platform.All areas of the business at Grofers need data that they can trust in to be agile, aid in quick decision making, and drive innovation. Key skills that will help maintain this trust is to be able to work with various teams and help them build the right data models and data pipelines to achieve their objectives. From a Vendor to our Customer, the journey of each item in a grocery cart to its final destination will come within your purview. The small tweaks you make, the processes you alter, and the business decisions you help drive will have reverberating effects on our ability to add value to our customers and keep them coming back for more.We have a long journey ahead of us and if you’re up for the challenge, come join us! KEY RESPONSIBILITIES● Aid all data users and creators in adopting and using the Data platform● Develop, maintain and evolve one or more components in the Data Platform● Collaborate with various stakeholders to identify complex business problems and help build scalable data pipelines leveraging the Data Platform● Design our data pipelines, manage ingestion for batch / real-time workflows and help build our data lake● Maintain our data infrastructure● Help teams identify and record/log data that would be critical in solving business problems● Contribute and Enforce shared Data Standards and Conventions at Grofers WHAT WE REQUIRE● 3-5 years of prior industry experience as a Data Engineer● Bachelor’s and/or Master’s degree in CS, or equivalent experience.● Solid knowledge of Computer Science fundamentals (object-oriented design, data structures, and algorithm design, problem-solving, and complexity analysis).● Understanding of data engineering paradigms like kappa and lambda architectures.● A deep understanding of programming with one or more programming languages. Python and Scala preferred.● A body of work that you can take us through (GitHub, bitbucket, etc)● Demonstrated ability to build solutions for end-users with a product and customer-first mindset.● Experience with big data techs such as Hive, Yarn, Spark, Presto, Kafka, Flink, and schedulers like Airflow is good to have.● Experience with Kubernetes is good to have.● Ability to deal with ambiguity, communicate well across team boundaries● Excellent communication skills, both written and verbal. Brownie points for puns in your code. Excited? You will be, once you visit our Engineering Blog (https://lambda.grofers.com/) where you can deep dive into all the cool stuff that our engineers have been working on.",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Internet,212,None,True,,715,ACTIVELY_HIRING_COMPANY
547,2243944442,2020-11-06,IT-Alliances,Data Engineer,"California, United States","About IT-Allieances: Since our inception, employers and job seekers have turned to IT-Alliances to provide solutions to their staffing and Talent Acquisition needs as well as various outsourcing requirements and Integrated IT solutions. We are a growing company and we maintain excellent relationships with many well known and prestigious companies. Our company has dramatically expanded over the last few years, building a strong client following with both long-term users and a growing roster of new clients interested in IT-Alliances fully blended service concept. IT-Alliances has successfully merged temporary staffing, executive search, direct hire placement, and consulting and is well known as an experienced staffing and HR solutions provider. IT-Alliances hasn't limited itself to Talent Acquisition and HR but has successfully handled various IT and engineering Offshore and Onshore projects. We have a synergistic approach to staffing that allows many IT-Alliances corporate clients to take full advantage of cross-over services, particularly those organizations with high volume staffing needs in a variety of disciplines. Many of our clients utilize our services for the cyclical, project, and ongoing temporary needs, as well as for direct-hire placements. Primarily established as One Stop External Service Provider for Staffing Solutions and outsourcing needs, the IT-Alliances approach towards its services is effective and methodological. We build partnerships and form alliances with prospective clients and promote ourselves as 'Outsourcing Consulting Partner'.  Job title: Azure Developer / Programmer / Engineer Location: Remote until COVID situation (based on Pacific Standard Time) Job type: Contract (W2 / C2C) Experience Level: 10 Years Rate: Negotiable  Job Description Population Health Advanced Analytics and Data Science (ADS) is seeking a Developer/Programmer and Developer/Engineer with both on-premises and Azure cloud programming experience.  This position will work under the direction of the Population Health ADS utilizing his/her skills to assist in designing advanced data sources and data processing solutions.  The working hours for this position will require an overlap with the morning team’s work hours (based on pacific standard time) for updates and smooth hand offs and transitions.  The following technical and functional skills are required to be successful in Developer/Engineer Role: • Ability to develop ETL pipelines in and out of cloud data warehouse using combination of Python and Snowflake’s SnowSQL • Ability to develop scripts (e.g. Python) to do Extract, Load, and Transform data • Working knowledge of the Azure Databricks analytics platform is a plus. • Actively test and clearly document implementations, so others can easily understand the requirements, implementation, and test conditions • Ability to understand data pipelines and modern ways of automating data pipeline using cloud-based and on-premise technologies  The following technical and functional skills are required to be successful in Developer / Programmer Role: • Ability to write SQL queries against Snowflake • Ability to author snowflake procedures in JavaScrpit • Ability to translate requirements for BI and Reporting to Database design and reporting design • Ability to understand data transformation and translation requirements and which tools to leverage to get the job done • Actively test and clearly document implementations, so others can easily understand the requirements, implementation, and test conditions.  Please send me your resumes to mohammed.m@it-alliances.com",No corresponde,Contrato por obra,None,None,19,None,True,mohammed.m@it-alliances.com,84,ACTIVELY_HIRING_COMPANY
548,2291148827,2020-10-14,"SecureShot, LLC",Data Engineer REMOTE,"Alexandria, VA, US","Our partner is seeking an experienced Data Engineer to provide support to a Department of Defense (DoD) Office of Inspector General (OIG) customer. The Data Engineer will integrate as part of a team focused on developing data efficiencies to facilitate the OIG's ability to discharge its oversight role of identifying waste, fraud and abuse across the DoD enterprise. This individual will leverage experience and expertise in data engineering tools, with an emphasis on Hadoop and R, to lead the architecting of a new framework and solution to efficiently and effectively track large amounts of data relevant to the OIG's oversight function, with particular implications for supply chain security across DoD.  This position is eligible for remote work, with quarterly meetings anticipated at client site in Alexandria, VA.  Responsibilities Support and maintain infrastructure for a variety of big data applications including HDFS, Hadoop, and Spark.Investigate and resolve system deterioration and/or failures, develops techniques to resolve hardware, software, and networking problems in system componentsAbility to maintain elevated rights on the DoD OIG networkAnalyze system performance, benchmark data, and system configuration for maximum performanceAssist with regular training sessions and maintain open office hours for teams to directly ask for analytics software support  Qualifications Active DoD Secret ClearanceBachelor's degree in Computer Science, Engineering, or related field and 7+ years of relevant experienceExposure to data management systems and statistical packages such as Cloudera, Hortonworks, Hadoop, Spark, and/or RExposure to creating sustainable, automated processes for data analysis using tools such as Airflow and HDFSMust be able to acquire and maintain one of the following certifications: CompTIA Security +, SCNP, or a SSCP  Desired Qualifications Experience with Hive, PIG, Sqoop, and FlumeExperience with Natural Language Processing (NLP) within R, Spark, SAS programming",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Departamento de defensa y del espacio exterior, Software",0,None,False,,2,None
549,2234213794,2020-11-02,Beyond,Senior UX Researcher,"London, England, United Kingdom","Beyond is a design and technology agency made up of passionate people focused on creating and delivering beautiful experiences for clients including Google, Montblanc, Facebook and The Royal College of Art.If you're looking for an environment where you can apply your skills with intelligent and inspiring people whilst learning and growing new areas, Beyond is the perfect place for you.Everyone is focused around making the best work and the agency is built around this: from our structure to process, training, culture and the way we engage with our clients. It is all about Making It Better. Role Overview Data is central to our process, as we use insight to inform decision making, substantiate intuition and validate our assumptions. As a UX Researcher, you’ll work with product teams of strategists, UX/UI designers, product owners and developers to solve problems and design creative solutions for our clients. Your findings and recommendations will shape new product ideas, make existing products better and help us win new business opportunities. As a Beyond UX Researcher, you’ll have the chance to: Partner with product, tech, client, delivery and design teams to identify research questions and outline product goalsIdentify and recommend the best methods to answer marketing and product research questions and prioritize them according to schedule and opportunity constraintsLeverage both qualitative and quantitative data to form a deep understanding of user behaviours, needs and pain pointsPlan, design and lead generative and evaluative research activities using a variety of methodologies including in-depth interviews, contextual inquiries, field/ethnographic research, comparative/competitive analysis, heuristic analysis, card sorting activities, site analytics and content audits/analysisCreate actionable deliverables including research reports, personas and customer journeysCollaborate with the wider team to outline research sprints and define key checkpoints of where research, testing, and feedback is completed, communicated, and integrated into design sprintsBuild out foundational and reusable desk research of industry trends, and support new business generationGive input on the planning and estimation of scope/resources on projects which include a research elementBuild out a framework for research that can be utilized by other disciplines, to help scope and design projectsEnsure that research ethics are rigorously enforced and understood throughout the studio As a Senior UX Researcher, we’d like you to bring: Previous experience of working to ensure that customer’s needs and wants are understood and considered throughout the product/service development processExperience of driving, facilitating and leading research synthesis, developing key insights at appropriate depth, translating them into actionable strategies and recommendations to guide product/service design, business strategy and contentPrevious experience of shaping engagement by translating insights into creative ideation, making strategic and creative leaps from data-led insights and moving projects forward by initiating collaborationYour willingness become an expert in new technologies, trends and consumer behaviours to help make marketing and product strategy recommendationsYour ability to mentor junior colleagues and those who want to get into researchYour expertise in creating a mentoring program for research And in return, Beyond offers: A generous learning and development budget per employee per yearExcellent salary with a flexible benefits scheme including healthcare & dental,25 days holiday, plus your birthday offPaid business closure between Christmas and New Year’s Day6% matched contribution pension schemeWe offer flexible working to everyone, under our “Beyond Flexibility” programme. Ask about this at the interview!Monthly care packagesA strong company culture whilst working on a ‘remote first’ basis - this includes weekly meetings, company updates, quizzes and celebrations. Having been named among Sunday Times Best 100 Companies, we believe culture plays a large role in what we offer as an organisation. We actively promote diversity in all its forms across our Studios and we proudly, passionately and proactively strive to create a culture of inclusivity and openness for all our employees.Beyond is committed to welcoming everyone, regardless of gender identity, orientation or expression. Our mission is to remove exclusivity and barriers and encourage new thinking and perceptions, in a space of belonging. It is not about race, gender or age, it is about people. Without our people being their most creative and innovative selves, we are nothing.",Intermedio,Jornada completa,"Diseño, Investigación, Tecnología de la información","Diseño, Servicios y tecnologías de la información",9,None,True,,292,None
550,2291038790,2020-10-17,The Dyrt,Campground Data Engineer (Remote),"Portland, OR, US","Job Title: Campground Data Engineer  Reports to: CTO  Position type: Full time  About The Dyrt  The Dyrt is the #1 ranked camping app on both iOS and Android. With over 1 million user-submitted campgrounds, reviews, and tips — more than anyone else on the Internet — The Dyrt makes it easier to find campgrounds for the 80+ million Americans who camp.  Why Working At The Dyrt Is Great  We offer an amazing benefits package that includes: Remote work environment so you can work from almost anywhere within the US time zonesStock optionsHealth, dental and vision insuranceIncredible time off starting with 3 weeks of PTO your first year, 4 weeks your second yearStandard holidays offExtra bonus week off between Christmas Eve and New YearsPaid camping opportunities (during working hours)Competitive pay and signing bonus to set up your home office The Role  We're looking for a data expert to improve the depth and accuracy of our campground database and collaborate on search and recommendation tools for our community of campers. As our first dedicated data hire, you'll work directly with the CTO to drive data improvement projects, manage data pipelines, and find ways for us to best put our data to good use.  This is a full-time, remote position. We're primarily based in Portland, OR and expect working hours to overlap +/- 3 hours with US Pacific time.  We're Looking For People Who Are great communicators — Effective communication is key to how we work. We value patience and empathy in our product planning, support, and day-to-day relations.Work well both collaboratively and independently — We come together to pair on tricky problems and architecture, then dive deep on individual tasks.Are ready to learn and share knowledge — Everyone comes to our company with their own set of skills and experiences. Cross-training, code review, mentorship, and curiosity all help us build better products.  Potential Projects Evolve and maintain campground data processing pipelines, combining public, private, and user-contributed dataUse natural language processing to extract relevant highlights and amenity information from campground review textCoordinate manual data review and improvement projects using internal staff, community crowdsourcing, or mechanical turkMake use of photo geotags and computer vision (via Amazon Rekognition / GCP Vision AI) to infer information about campground amenities.Improve techniques for matching and deduplication between multiple data sourcesImport public data on national and state parks, forests, and recreation areas to provide a better search experience  You Have 4+ years of professional experience in data engineering, data science, software development, or related fieldStrong backend programming skills in one or more languagesExperience creating and maintaining data ETL pipelines or other complex data import systemsFluency with SQL and relational schema designA friendly working relationship with CSVs  Extra Credit Advanced degree in math, statistics, computer science, information science, or related field Experience working with geospatial datasets and GIS analysisExperience applying machine learning techniques to real world problemsFamiliarity with Elasticsearch",Sin experiencia,Jornada completa,Tecnología de la información,"Marketing y publicidad, Software, Internet",0,None,False,,7,None
551,2183073601,2020-10-14,TrueTandem,Senior Azure Developer / Architect,Washington DC-Baltimore Area,"Great Senior Azure Developer / Architect Job Opportunities thru TrueTandem If you're looking for a great IT job opportunity, TrueTandem is seeking accomplished hands-on Senior Azure Developers / Architects with experience in Data Platform, Advanced Analytics and Artificial Intelligence (AI). The successful candidate must formulate Azure Data Platform, Advanced Analytics and AI solutions as well as contribute to the technical implementation of those solutions.  Ideal candidates:Will serve as both trusted technical advisor to customers and implement solutions. Must have strong software development background, be well-versed in Microsoft technologies, and easily able to clearly articulate technical direction. Must be able to capture and translate requirements to Azure solutions. May be asked to contribute to TrueTandem’s proposal teams, providing technical direction and content for commercial and federal proposals.Should be motivated, self-starters with a proven history of showing initiative and starting projects independently with minimal supervision. Are flexible, enjoys balancing multiple priorities in a fast-paced environment, and can easily lead the architecture and development of Azure solutions. Must also possess excellent oral and written communication skills and be comfortable interacting with customers at all levels of leadership NOTE: Currently our positions are working remotely for the bulk of their project time.Candidates must be able to obtain a US high-level government clearance (so must be a US Citizen). ﻿Preference will be shown to candidates with an active Secret clearance or higher. TrueTandem will not accept 3rd party candidates or sponsor candidates requiring VISAs. REQUIRED QUALIFICATIONSTechnical Skills and Experience Requirements:Microsoft Certified Professional (Developer and/or Architect)At least 10 years-experience as a software developer fully versed in all phases of the SDLCExperience architecting technical solutions using Microsoft Azure cloud services: .NET core, App Service, Virtual Networks, Azure Functions, Azure SQL, and Azure Application GatewayExperience with Azure Data Platform, Analytics, and AI services, including: Azure SQL Server, Azure Synapse, Azure ML, Azure Cognitive Services, Azure Data Factory, Big Data, Data Lake, Azure Databricks, Power BI, and othersProficiency with Azure DevOps, creating CI/CD pipelinesExtensive software development experience with the Microsoft .NET platform (MVC, ASP.NET, and C#)Proficiency in building\utilizing RESTful web services and web APIsExcellent written and verbal communications and interpersonal/customer service skillsHave provided Prior Federal government IT project experience is preferred. PREFERRED SKILLS:Bachelors degree in Information Technology or Computer ScienceProficiency in one or more Microsoft Cloud platform services: O365, SharePoint Online, OneDrive, Power Platform, Dynamics 365, Power BICurrently possess or able to obtain certification in any of the following (or willingness to obtain within 6 months of hire): Azure AI Engineer Azure Data Engineer Azure Solutions Architect Azure Data Scientist Proven experience contributing solution architecture and written content to proposal teams TrueTandem is a Microsoft Certified Partner that specializes in the rapid deployment and adoption of Microsoft technologies and solutions. We serve clients in both commercial and federal markets and have built a prestigious client base through our devotion to delivering high quality solutions. For more information on TrueTandem and our great benefits and competitive employee offerings, please go to: https://careers.smartrecruiters.com/TrueTandemInc",Intermedio,Jornada completa,"Tecnología de la información, Ingeniería, Gestión de proyectos",Servicios y tecnologías de la información,28,None,True,,149,ACTIVELY_HIRING_COMPANY
552,2241562665,2020-11-05,Very Good Security,Lead Data Engineer,United States,"Who we are: Very Good Security (“VGS”) provides a modern and efficient way for businesses to both secure and utilize their sensitive data. Founded by successful serial entrepreneurs and backed by top-tier VCs, VGS is building an amazing global team. As a young and growing company, we are laser-focused on delighting our customers and hiring talented and entrepreneurial-minded individuals to help us to secure the world's data. What you get to do: Develop and automate large scale, high-performance data processing systems to drive VGS’s business growth and improve the product experienceDefine data engineering architecture, tooling, and standards across the companyUnderstand and influence logging to support our data flow, architecting logging best practices where neededEngage in all phases of the software lifecycle- design, implement, test, deploy, and support services in production.Maintain a culture of code quality through rigorous testing, automation, and code reviews.Be proactive and innovative- we rely on your feedback to build a world-class product.Be a part of a team that believes in the core values of transparency, collaboration, grit, and humility: in going above and beyond what is required in order to do the right thing for our customers and the company: and in having fun while doing all this! What you bring to the role: BS or equivalent, and a minimum of 5+ years of software development experience- ideally in a SaaS/product development companyExperience in architecting, building and supporting scalable as well as fault-tolerant batch, real-time and/or near-real-time data pipelines Strong knowledge of data modeling experience with both relational and NoSQL databases and hands-on experience with data warehouses, preferably AWS RedshiftExpert knowledge of SQL and PythonExperience working with big data ecosystem tools such as Kafka, Protobuf/Thrift and Spark/Flink/Storm and with data-flow programming tools such as Apache NiFi, Apache Beam, etc. will be a plus!We follow modern DevOps practices, and experience with Docker, Kubernetes, Ansible, Terraform will be a plus An understanding of how to build for scale, but able to make pragmatic choices to move quickly. You have a strong bias for actionComfortable working in roles that at times may be customer-facingExcellent written and verbal communication skills Experience successfully working with distributed teams across time zones will be a plus Benefits and Perks: Highly subsidized individual medical, dental, & vision insurance coverageCompany sponsored 401k planMarket competitive compensation packageMonthly wellness stipendGenerous vacation policy12 company paid holidays",Intermedio,Jornada completa,"Tecnología de la información, Ingeniería",Seguridad del ordenador y de las redes,11,None,False,,81,ACTIVELY_HIRING_COMPANY
553,2238510954,2020-11-05,"Capstone Technology Resources, Inc. (Capstone)",Data Engineer,"San Francisco, California, United States","***Sorry, no third parties please*** Job Title: Data Engineer w/MS SQL Server Automation experienceOur client, Autodesk, is the global leader in 3D AutoCAD software. Headquartered in the SF Bay Area, they're established, award-winning, and financially solid (zero layoffs due to covid). This is a 3-month engagement to start, with expected extensions. Remote role: SF Preferred area: however, open to candidate in other areas as long as he/she can work PST time zone. Responsibilities:o            Maintain/ develop a scalable database/ data warehouse through connecting. disparate data tables housed across numerous organizational systems and different business lines.o            Maintain/ develop the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL (primarily MS SQL) and AWS technologies.o            Optimize and maintain scripts on present data warehouses and present ETL.o            Create and update data models for decision support of digital help programs and initiatives.•            Drive SQL server conversion onto AWS platform.•            Code review all current SSIS jobs for effectiveness.•            Drive the re-architecting of ADSK data sources feeding our automation workflows (re-align source file acquisitions within AWS).•            Experienced data solution architecting. Minimum Qualifications:o            Bachelor's degree computer science, information systems, or a related discipline.o            5+ years of experience.o            Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.o            Experience with transforming, developing data structures, metadata, dependency and data workflows to support an Analytics function.o            Expertise in gathering data through multiple sources through API calls and scripting languages.o            Preference given to those with advanced data modeling experience.o            Self-starter and a driver, ability to communicate/own a project to completion while working with various teams (not directly managing the teams).o            Candidate will be coordinating work with other teams.o            Hands-on/Player-Coach style candidate.o            Excellent written and verbal communication skills.o            70-Technical/30-Functional. Nice to Have but not required:o            Experience with object-oriented/object function scripting languages: Python, Java,       C++ etc.",Intermedio,Contrato por obra,Tecnología de la información,Dotación y selección de personal,63,None,True,,235,ACTIVELY_HIRING_COMPANY
554,2288581642,2020-11-05,"Medable, Inc",Data Scientist - REMOTE - London,"London, GB","Job Description Explore machine learning opportunitiesInvestigate and compile new sources of medical dataProvide clinical input to refine existing machine learning architectureDevelop and integrate machine learning algorithms for data processing and analysisBuilding models to address business problemsPresenting information using data visualization techniquesUndertake preprocessing of structured and unstructured dataAnalyze large amounts of information to discover trends and patternsBuild predictive models and machine-learning algorithmsPropose solutions and strategies to business challengesCollaborate with engineering and product development teamsOther duties as assigned  Qualifications 0-3 years working in Computer Science or a combination of education and experience (3+ preferred)Bachelor’s degree in Computer Science, Artificial Intelligence, Engineering or relevant field Experiece with R programming language, C++, Python, Java, Node.JS  Additional Information Highly analytical with a knack for analysis, math and statisticsCritical thinking and problem-solving skillsPassion for machine-learning and researchExperience in data miningAnalytical mind and business acumenProblem-solving aptitudeExcellent communication and presentation skillsExperience working in machine learning (preferred) All information will be kept confidential according to EEO guidelines.",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Marketing y publicidad, Servicios y tecnologías de la información, Software",6,None,False,,39,ACTIVELY_HIRING_COMPANY
555,2289956918,2020-10-30,"Etisbew Technology Group, Inc. (A CMMI Level 3 Company)",User Researcher Remote/Outside IR35 Spanish Speaking,"London, GB","User Researcher Remote/Outside IR35 Spanish Speaking  My client is looking for an experienced, Spanish speaking User Researcher to support one of their leading public sector clients on a project with the high likelihood of extension.  This candidate will need to be happy with remote working and immediately available to join their team for an early November start.  Ideally, the candidate will be experienced in working with managers and stakeholders to devise research strategies.  Key Skills  Focussed insight researchConcept designUser centre designStakeholder managementMultidisciplinary and agile engagement teamsExperience running workshops If you fit the above criteria and are immediately available for interviews, please share your CV.  User Researcher Remote/Outside IR35 Spanish Speaking  In Technology Group Ltd is acting as an Employment Business in relation to this vacancy.",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Dotación y selección de personal",None,None,False,,5,None
556,2179922621,2020-10-12,Symphony AyasdiAI,Data Scientist,United States,"Ayasdi is breaking new ground in enterprise AI and is looking for data scientists to join our teams in London and New York. We have a unique approach combining best in class unsupervised and supervised techniques to solve hard problems in Anti Money Laundering, Fraud, Credit Risk and Liquidity. You will learn new techniques based on Ayasdi’s patented platform that combines Topology, Information Theory and Machine Learning to create the world’s most powerful global pattern discovery capability. As part of a growing team you will deploy our technology to help our customers solve their biggest and most impactful problems whether it be discovering the sinister Unknown Unknown’s evading their detection systems or re-balancing their Liquidity in the midst of a storm. We combine the rapid agility of a start up with the financial backing of the world’s largest private AI fund. At Ayasdi your contribution will make a difference to the world. Join us now!  Responsibilities:Directly interact with customers in the Financial Services industry to understand and help solve their business problems using the Ayasdi Enterprise AI platformBecome a master user and advocate of Ayasdi’s productServe as a technical and subject matter expert in Financial Services information technology, assisting sales during pre- and post- sales effortsMake research and development contributions to our core product offeringsInteract and collaborate with engineers and product managers, relaying feedback from customers to continually develop our product Minimum Requirements: MS or PhD in quantitative field5+ years hands on experience delivering machine learning applications in financial services with demonstrable results2+ years working within a financial institution or related organization 2+ years experience working with an Analytics software vendorDomain experience in Anti Money Laundering, Fraud, Credit Risk or LiquiditySolid understanding of existing statistical and machine learning techniques Ability to translate analytic ideas into code using Python and at least one other programming languageFamiliarly with one or more data science toolkits such as Spark, Hadoop, Hive, scikit-learn and pandasAbility to travel 30% in the field as necessary",Intermedio,Jornada completa,"Tecnología de la información, Análisis, Ingeniería","Software, Servicios financieros",74,None,False,,596,ACTIVELY_HIRING_COMPANY
557,2249343888,2020-11-05,Axionable,Stagiaire Consultant·e Data & IA durable,"Paris, Île-de-France, France","Rejoindre Axionable, c'est évoluer dans une entreprise tech à taille humaine en croissance durable, certifiée B-Corp, qui te permettra d’allier sens et carrière à travers : des projets concrets d'intelligence artificielle pour le compte de nos clients, un programme de formation essentiel à ton développement professionnel et un environnement de travail transparent, bienveillant, nativement international (centre de recherche à Montréal) et engagée pour la diversité. Présentation du posteEn tant que Stagiaire Consultant.e Data et IA durable, vous serez amené·e à :Contribuer au cadrage et à la gestion de projet de missions de conseil en data et intelligence artificielle portant sur des problématiques variées et à impact positif (risques climatiques, réduction d’empreinte carbone, détection de fragilités, …) auprès de nos clients dans les domaines de l’industrie, des services financiers ou encore des médias :Interagir avec nos expert.e.s business, nos expert.e.s en développement durable et nos expert.e.s techniques (data scientist, data engineer, …) :Intervenir en support dans le cadre de propositions commerciales pour nos clients/prospects :Accompagner la mise en place d’actions RSE en interne. Le stage est à pourvoir à partir de février/mars 2021. Axionable s’engage en faveur de l’égalité des chances, de la diversité et de l’équité. Nous encourageons tout.e candidat.e ayant l’expérience requise à postuler à nos offres. Profil recherchéEtudiant·e en fin d’études en école de commerce/université, avec une spécialité développement durable et/ou analyse de donnéesDoté·e d’un bon relationnel et motivé·e par le conseil, vous possédez de bonnes capacités d’analyseAutonome, curieux.se des technologies et de l’écosystème data et intelligence artificiellePositif·ve et adoptant une posture en faveur de la Responsabilité Sociétale de l'Entreprise (RSE)Français et anglais courants",Prácticas,Jornada completa,"Tecnología de la información, Consultoría, Ingeniería",Servicios y tecnologías de la información,47,None,True,,201,ACTIVELY_HIRING_COMPANY
558,2246303960,2020-11-04,Macy's,Senior Data Scientist  (100% Remote ),Atlanta Metropolitan Area,"Macy's is looking for a passionate, talented, and innovative Lead Data Scientist with a strong machine learning background to help build industry-leading AI/ML enabled applications for retail/commerce platform. As Lead Data Scientist you can be part of the team shaping the future of retail/commerce, revolutionize how millions of customer shop online, store and other channels, you'll partner with technology and business teams to build new AI/ML enabled smart services that surprise and delight our customers. You will be working with big data (text, images, audio & other) to solve real-world problems for customers & partners. You will design and run experiments, research new AI/ML algorithms & techniques, and find new ways of optimizing risk, opportunities, profitability, and customer experience. As a Lead Data Scientist your work involves performing applied ML in the areas of feature engineering, deep learning, machine learning, data insights and analytics. Our ML applications include computer vision, search and discovery systems, recommender systems, and more. Successful candidate will work on heterogeneous data sets (behavioral, transaction and click stream data) and focuses on solving applied problems using Machine Learning. The ideal candidate will have a nice blend of applied math, data science and engineering skills, proven track record of solving critical business problems through data science and strong analytical/quantitative and engineering skills. The candidate will be expected to be strong at communication and capable of cross group collaborations. As a Lead Data Scientist, you will work on smart services that improve our operations and customer experience. You will marry state-of-art AI/ML algorithms with distributed systems engineering to build systems that drive efficiencies & improve customer engagement in our retail/commerce platform. Perform other duties as assigned. Essential Functions:Thought leader in data science and analytics who can help the business define their business problem, create solutions to address it, plan and execute the implementationWork with business stakeholders to define business requirements including KPI and acceptance criteria.Lead and work with ML engineers and data scientists to develop recommendation system using advanced machine learning techniques such as deep learning and reinforcement learning.Lead research initiatives into state-of-the-art methodologies that will enhance current models and power future personalized modelsCollaborate with data engineers, ML engineers and Data Scientists in building real-time and batch machine learning pipelines that include data preprocessing, feature engineering, model training, model validation, serving, and evaluating results of A/B test.Drive work on improving the codebase and machine learning lifecycle infrastructureMentoring and growing talent, as well as hiring, will be a critical part of the job Qualifications: Education/Experience:BA/BS Degree required (MS or PhD preferred).8+ years of hands on industry experience in leveraging data science (including ML) and analytics to solve business problems(preferably ecommerce)5+ years of industry experience in Machine Learning or related field.Experience in leading teams and being a lead data scientist on large scale projects driving value for the businessExtensive experience in Python and SQL(Nice to have Scala)Strong preference for programming experience in Spark framework and PySpark.Strong preference for hands-on experience with Scikit-learn, Pandas,  and at least one of the deep learning frameworks: PyTorch, Keras, or  TensorFlowFamiliarity with modern approaches to computer vision problems is a plus (RESNet, transfer learning, Inception, etc.)Experience with different recommender systems(Sequential recommenders, Content recommenders, RL recommenders etc.) and recommender frameworks(Ex : PredictionIO)Experience with building systems from scratch, and putting them into production, and performing A|B TestingA plus to have working knowledge of Google Cloud Platform (Big Query, Big Table, Pub/Sub, DataFlow, DataProc), real-time and batch processingExperience with Machine Learning orchestration frameworks (Kubeflow, Airflow, MLflow)Familiarity with Agile, experience with Agile is a plus",Director,Jornada completa,"Ingeniería, Tecnología de la información",Venta al por menor,149,None,True,,479,ACTIVELY_HIRING_COMPANY
559,2287678517,2020-11-06,enableit,Data Engineer (Remote),"Chicago, IL, US","The Data Engineer will collaborate within a team of technologists to produce enterprise scale solutions for our clientsrsquo needs. They develop and configure data pipelines, as well as factor in synergies with data pipelines built as part of other tracks. What are we looking for in you? Hands-on Data Engineer with Cloud platform (AWS, Azure, or Google Cloud Platform), Spark, and end-end implementation experience. BS in Computer Science or equivalent educationprofessional experience is required. Must haves 10+ years in a data engineering role with demonstrable experience in data modeling Experience with Databricks and using Spark for data processing. Experience with Kafka Experience with Azure andor AWS Experience with version control and github integration Experience with different query languages (i.e. T-SQL, PostgreSQL, PL-SQL). Experience designing and building data marts, warehouses, customer profile databases, etc.",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Servicio de información",None,None,False,,10,ACTIVELY_HIRING_COMPANY
560,2241564889,2020-11-05,B12 Consulting,Cloud Data Engineer,"Austin, Texas Metropolitan Area","SPONSORSHIP NOT AVAILABLE. C2C NOT ALLOWEDThe project is to create a data analytics platform plus data governance with Informatica Axon. The IDDI platform will facilitate the sharing, reporting, and analytics of the data collected from several systems. The organization is currently implementing a Analytics Platform with Informatica PowerCenter, Snowflake and AWS technologies as well as Informatica Axon Data Governance with a goal to accomplish improved reportinog.·  Assist program area use of the IDDI Platform to its fullest potential·  Assist with analytics use with off the shelf reporting tools like SAS, SPSS, Tableau, ARCgis·  Assist with publishing as needed to Tableau and/or ARCgis servers or other web platforms·  Data modeling, data profiling, data quality, data validation, data curation and data transformation·  Resolve any data source ingestion issues·  Operationalize ingestion of new data sources as needed·  Other work includes, but is not limited to:·  Validation of performance metric requirements·  Creation of EPICS/User Stories·  Creation and validation of dashboard and report mock-ups·  Automation of data acquisition from a variety of data sources·  Dashboard and report development·  Testing – integration, load and stress, and user·  Deployment / publication internally and externally·  Operations support and enhancement of the IDDI platform",Intermedio,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Administración gubernamental, Atención sanitaria y hospitalaria",18,None,True,,63,ACTIVELY_HIRING_COMPANY
561,2285414997,2020-11-04,Cadence Counsel,Remote Data Analyst / Engineer / Scientist - Major Int'l Corp $$,"New York City, NY, US","Major Int'l Corporation seeks several data analysts/engineers/scientists to develop data analysis plans, create analytics strategies, and assess and redesign companies' models.  Experience with various tools and programs required, such as SQL, Java, Hadoop, Hive, Python and IBM SPSS. Knowledge of predictive coding and AI a plus.  Remote at first but, post-COVID, much travel to offices of clients (Fortune 500 cos and major financial institutions).  Prefer to hire on an ongoing contract basis, but open to straight lateral hires. Top compensation paid.  Please submit your resume to us at Cadence Counsel ASAP.  Leading recruiter for contract and lateral/permanent positions.",Sin experiencia,Jornada completa,Tecnología de la información,"Dotación y selección de personal, Derecho, Servicios jurídicos",9,None,False,,39,JOB_SEEKER_QUALIFIED
562,2241570600,2020-11-05,Shift,Senior Data Scientist,San Francisco Bay Area,"About ShiftWe believe car buying should be fun, fair, and accessible to everyone. We’ve set out to transform an industry, using technology to bring transparency and convenience to the car buying process. And we aren’t stopping there. We seek to bring that same openness and simplicity to car ownership too, with payments, maintenance, and insurance in one easy app. At Shift, we’re building the tools that empower people to buy, own, and sell the cars that make life go. About The Role﻿Data is core to this transformation, from building best-in-class pricing, to loan decisioning, to logistics optimization, to in-product recommendations. If you’re passionate about using data to fix an enormous, antiquated industry, you’ll fit right in. The data Millions of cars are bought and sold in the US every year, but knowing exactly how much your car is worth is a challenge. We believe that fixing the used car industry requires providing customers with fair, detailed pricing reports in beautiful, easy-to-understand interfaces. By combining as much data as we can get our hands on, from the millions of listings available online, to car auction sales, to every vehicle’s specific repair history, we’re building the most accurate, transparent pricing tool in the industry. The impact As a two-sided marketplace, serving both car buyers and sellers, our vehicle data and pricing models are core to the business. As a Senior Data Scientist, you will have direct and immediate impact on the success of the company. Initial projects will include exploring data, building models, informing product decisions, overseeing experiments, and collaborating closely with engineers on our pricing team. Over time, you’ll play a crucial role in growing and mentoring a team of data scientists that will be involved in nearly every initiative at Shift, including lead scoring, user acquisition, optimal resource allocation, vehicle routing, and more. What You'll Do:Build models from the ground up - from data exploration to feature engineering, to model development + optimization, and deployment into productionDesign rigorous experiments and interpret results to draw actionable conclusionsWork cross-functionally with team leaders (in Engineering, Product, Operations, Marketing, etc.) to explain your analysis and make recommendationsFacilitate objective decision making across the company by democratizing data through dashboards and other analytical tools What We Ask For:Bachelor’s Degree in Statistics, Computer Science, Mathematics, or other quantitative field: advanced degree a plus4+ years of industry experience in a quantitative analysis roleKnowledge of machine learning techniques, especially deep understanding for their benefits and drawbacks in real-world applicationsExcellent statistical intuition derived from practical, hands-on experienceProficiency in PythonExperience writing efficient SQLExcellent communication skills that you’ve leveraged to influence product and leadership teamsCuriosity, desire to learn, passion for providing a great product to customers On diversity Our company depends on balance and equality — between buyers and sellers, among employees, and in our relationships with customers. Our mission to evolve car ownership and transform an industry is a challenging one. It can only be achieved by a team of diverse problem-solvers — engineers, designers, business people — from the same broad demographics as our customers. Why join now? We’ve built a small but highly talented team backed by >$275 million in funding from investors like DFJ, Goldman Sachs, BMW, and Nissan. In October 2018 we announced a deep partnership and a $140m round led by the third largest auto retailer in the US, Lithia Motors. With strong product-market fit and a great business in California, the next two years will be focused on scaling the business nationally. Shift is the Bay Area’s #1 seller of used cars with $150 million in cars sold per year. We’re serving most of California and are gearing up to scale to new markets. With a solid business model and no clear winner in our space yet, this is a hugely exciting time to join the team. Shift is an Equal Employment Opportunity Employer All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability and protected veterans status or any other characteristic protected by law.",Intermedio,Jornada completa,Ingeniería,"Sector automovilístico, Internet, Servicios financieros",67,None,True,,221,COMPANY_RECRUIT
563,2243950427,2020-11-06,Modis,Data Engineer - Machine Learning,"Boston, Massachusetts, United States","Job Title: Data Engineer - Machine Learning (*****ONLY W2)Duration: 4+ months Contract.Location: Louisville, KY (OR) Boston, MA Description:Data Engineer - Machine LearningWe are looking for a Data Engineer to work with our data science teams to collect, store, process, and analyze huge sets of data. The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them. You will also be responsible for integrating them with the architecture used across teams in our group. Responsibilities:Selecting and integrating any Big Data tools and frameworks required to provide requested capabilities.Implementing ETL process and data pipelines.Monitoring performance and advising any necessary infrastructure changes.Collaborating with Data Scientists to build Machine Learning systems and run experiments. Skills and Qualifications:5+ years of experience in data engineering.Strong algorithm and data structures knowledge.Knowledge of various databases (RDBMS, noSQL, HDFS, Cassandra, Redis).Experience building cloud data lakes and data warehouses is highly desirable.Experience with security and authentication in cloud platforms (Azure preferred).Bachelor’s Degree or above in a technical field (Computer Science preferred).Proficient in one or more programming languages (Python, Java, JavaScript, C#, etc.).Experience building stream-processing systems, using solutions such as Spark-Streaming or Flink.Familiar with Spark ecosystem (e.g. Databricks).Good knowledge of Big Data querying tools.Understanding of Data Catalog, Data Governance, Data Lineage.Knowledge of various ETL techniques and data pipelines.Knowledge of messaging systems, such as Kafka or RabbitMQ.Familiarity with Machine Learning, Deep Learning and Natural Language Processing. workflows and libraries (scikit-learn, Spark MLlib, TensorFlow/Keras/PyTorch).Running Machine Learning tests and experiments.",Intermedio,Contrato por obra,Tecnología de la información,Seguros,39,None,True,,193,COMPANY_RECRUIT
564,2235798589,2020-11-04,Euclid Innovations,Azure Data Engineer,"Chicago, Illinois, United States","Hello Hope you would find this email in your interest – Please find the below requirement for your review and reply with your interest levels on the same. Appreciate if you could send me your updated copy or resume, availability to move ahead in the process. Here is the Requirement: Azure Data Engineer Location: Chicago ILDuration: 6 monthsW2 Only  Role Description: Data analysis, data modeling, and data integration using azure technologies like Azure Data Factory (ADF). Hands on experience with Azure Synapse, Databricks, ADLS Gen 2, & Logic Apps",Intermedio,Contrato por obra,"Ingeniería, Tecnología de la información",Servicios y tecnologías de la información,32,None,True,,133,ACTIVELY_HIRING_COMPANY
565,2251597288,2020-11-06,SailGP,Senior Big Data Engineer,"London, England, United Kingdom","Senior Big Data Engineer SailGP is powered by nature and driven by purpose. We exist to race for the future, showcasing the power of nature and accelerating change. Established in 2018 and headquartered in London and New York, SailGP is an annual, global sports championship featuring bold, cutting-edge technology and awe-inspiring athleticism. The fan-centric, inshore racing takes place in some of the most iconic harbors around the globe and culminates with a $1 million winner-takes-all match race. Rival national teams from Australia, Denmark, France, Great Britain, Japan, New Zealand, Spain and the United States battle it out in identical supercharged F50 catamarans, engineered for intense racing at electrifying speeds exceeding 50 knots (nearly 60 mph). When you join SailGP, you’re joining a global team dedicated to delivering quality, breaking boundaries, leaving a legacy, standing together, and striking a balance. Our Vision Our vision to is be the ultimate in our sport by:1.    Leading – synonymous with sailing and a top global league2.    Engaging – a new generation of fans and an unmissable sailing product.3.    Leaving a legacy – accelerating change with best-in-class technology and sustainability.  Role Summary We are seeking a talented and motivated full time Senior Big Data Engineer to join our growing team, working offsite between events as well as onsite during training and racing. The successful individual will be responsible for managing big data solutions at SailGP and providing an array of data-based services throughout the organisation. This is a fantastic opportunity for someone that is looking to grow and progress in an exciting international organisation, work with a wide range of technology, have exposure to cutting edge technology, have involvement in projects and be able to make an immediate impact. The role will primarily use tools and services in the Oracle Cloud where you will manage, develop and test a variety of databases and services which all parts of the organisation depend on, from race team performance through to sustainability, broadcast and business data. You will report to the Head of Systems. Essential Responsibilities: Maintain and update Oracle data systemsEnsure that the data architecture remains efficient and scalable, as the datasets and application links growWork with the data analysis team by providing them with a high fidelity low latency data feed during a high pressure broadcast environmentDesign automated data systems to replace some of the manual database entry tasksSupport the development of an internal chatter-based messaging serviceProvide data insights via Oracle machine learning processesResponsible for creating dashboards with the data analysis team for various parts of SailGP Background Expert knowledge and practical experience of Oracle Databases and cloud-based systemsA solid working knowledge of KafkaREST API developmentJava expertisePython expertiseExperience with containers and dockersGit, Bitbucket and SVNReport writingComfortable working in Google G-SuiteGood all-round technology knowledge and experience Attributes Ability to operate both independently and in a collaborative, team environmentEntrepreneurial and passionate with a desire to exceed expectationsSuperior organisation, prioritisation and project management skillsExtremely strong attention to detail with the ability to multi-task and meet deadlines with limited supervisionAbility to work effectively and thrive in a fast-paced, start-up environmentSelf-starter, action-oriented, resourceful: can take a project or program from start to completionStrong communication skills, culturally sensitive and able to effectively work globallyAbility to work under pressureA current and valid passport Location Requirement to be able to travel to event venues during the SailGP seasonThe role will be required to work from or have meetings at our London office on a frequent basis, whilst working from home is the primary work location. SailGP is proud to be an equal opportunity workplace committed to building a team culture that celebrates diversity and inclusion. Closing Date: 22nd November 2020",Intermedio,Jornada completa,Tecnología de la información,Deportes,6,None,True,,71,ACTIVELY_HIRING_COMPANY
566,2275131313,2020-11-04,Net2Source Inc.,Data Engineer,"California, United States","Net2Source is a Global Workforce Solutions Company headquartered at NJ, USA with its branch offices in Asia Pacific Region. We are one of the fastest growing IT Consulting company across the USA and we are hiring a 'Data Engineer' for one of our clients. We offer a wide gamut of consulting solutions customized to our 450+ clients ranging from Fortune 500/1000 to Start-ups across various verticals like Technology, Financial Services, Healthcare, Life Sciences, Oil & Gas, Energy, Retail, Telecom, Utilities, Technology, Manufacturing, the Internet, and Engineering. Company: One Of Our Clients Position: Data Engineer Location: California, United States (100% remote Opportunity)Duration: 3 Months + Potential extension Job Duties & Responsibilities Description: Be part of Data Engineering team responsible for Data Analytics Platform servicing the business needs of the broader organization. Qualifications: • Bachelor’s degree in Computer Engineering, or related discipline• 3+ years relevant working with Redshift, SQL, Python, Airflow and AWS data technologies• Understanding of data architecture concepts such as data modeling, metadata, workflow management, ETL/ELT, real-time streaming), data quality• 3+ years of experience working with SQL• 6+ years of hands-on experience as a developer in Data Engineering working with data warehouse systems and data pipelines. • Intermediate to Expert level / 6+ years hands-on experience like Redshift, SQL and Python. • Experience working as Data Engineer in Finance/Financial Analytics is a strong plus.• Experience with setting up and operating data pipelines using Python or SQL• 1+ years of experience working on AWS• Exposure to open source and proprietary cloud data pipeline tools such as Airflow, and Glue• Experience working with relational databases• Experience with code management tools (e.g. Git, SVN) and DevOps tools (e.g. CICD)• Great written and verbal communication skills• Self-starter with the ability to work independently or as part of a project team• Capability to conduct performance analysis, troubleshooting and remediation﻿ ﻿About Net2Source, Inc.Net2Source is an employer-of-choice for over 2200+ consultants across the globe. We recruit top-notch talent for over 40 Fortune and Government clients coast-to-coast across the U.S. We are one of the fastest-growing companies in the U.S. and this may be your opportunity to join us!Want to read more about Net2Source?, Visit us at www.net2source.com Equal Employment Opportunity CommissionThe United States Government does not discriminate in employment on the basis of race, color, religion, sex (including pregnancy and gender identity), national origin, political affiliation, sexual orientation, marital status, disability, genetic information, age, membership in an employee organization, retaliation, parental status, military service, or other non-merit factor. Net2Source Inc. is one of the fastest-growing Global Workforce Solutions company with a growth of 100% YoY for the last consecutive 3 years with over 2200+ employees globally and 30 locations in US and operations in 20 countries. With an experience of over a decade, we offer unmatched workforce solutions to our clients by developing an in-depth understanding of their business needs. We specialize in Contingent hiring, Direct Hires, Statement of Work, Payroll Management, IC Compliance, VMS, RPO and Managed IT Services. Fast Facts about Net2Source:• Inception in 2007, privately held, Debt-free• 2200+ employees globally• 375+ In- house Team of Sales, Account Management and Recruitment with coast to coast COE.• 30 offices in US and 50+ Offices globally• Operations in 20 countries (US, Canada, Mexico, APAC, UK, UAE, Europe, , Europe, Latin America, Japan, Australia) Awards and Accolades: • 2018 – Fastest-Growing IT Staffing Firm in North America by Staffing Industry Analysts• 2018 – Fastest-Growing Private Companies in America as a 5 times consecutive honoree – Inc. 5000• 2018 – Fastest 50 by NJBiz• 2018 – Techserve Excellence Award (IT and Engineering Staffing)• 2018 – Best of the Best Platinum Award by Agile1• 2018 – 40 Under 40 Award Winner by Staffing Industry Analysts• 2018 – CEO World Gold Award by SVUS• 2017 – Best of the Best Gold Award by Agile1 RegardsSakeeb KhanSr. Technical RecruiterEmail id – sakeebk@net2source.comDesk:(201) 877-9329. Ext – 906Address: 317 George St. Suite 220, New Brunswick, NJ 08901www.net2source.com",Intermedio,Contrato por obra,"Ingeniería, Tecnología de la información, Finanzas","Servicios financieros, Banca, Software",72,None,True,sakeebk@net2source.comDesk,182,ACTIVELY_HIRING_COMPANY
567,2277626802,2020-10-11,Automattic,Senior Data Engineer,"Paris, FR","We are the company behind WordPress.com, Jetpack, WooCommerce, and Tumblr! We are looking for a Senior Data Engineer with experience in Spark/Scala to join our team of data scientists and engineers to build, deploy, and iterate on large-scale data pipelines and applications.  How Do We Work  We're kind to each other and our users – we strive to build a positive, supportive, and inclusive culture of cohesive teams focused on delivering value to our customers. We work as a global and distributed workforce resulting in a unique way of working built around our creed. We offer flexible work arrangements allowing our team members to work when they feel best. We welcome collaboration, and you can be involved in any discussion across our many communication channels.  Enough about us, let's talk more about you. The Senior Data Engineer position might be a good fit if you:  Have hands-on experience with Scala, Spark, and Python to implement large-scale data flows. Have production experience with open source technologies like Hadoop, Hive, Kafka, Airflow, HBase, etc. Have experience in managing and tuning Hadoop and related services in production. Care about architecture, unit testing, and building reliable infrastructure and pipelines. Are motivated to propose technical solutions, own software architecture, evaluate technologies and infrastructure, and develop technical roadmaps for future applications. Bring programming skills in multiple programming languages and paradigms. In addition to Scala and Python, you are likely to encounter Java, PHP, and SQL in this role and the idea of using them on a regular basis should not be a blocker for you. Are familiar with professional software engineering methods and standards such as coding conventions, code reviews, continuous integration, build processes, testing, and operations. Are open and able to travel 3-4 weeks per year to meet your teammates in person. We hold an annual all-company meeting every year, and meet up with our teams for a week once or twice per year. Important note: at the moment all company travel has been suspended due to COVID-19. Automattic is monitoring government and health agency reports closely and responding however possible to prioritize safety and well-being for our team and communities.  Like all positions at Automattic, you'll work remotely, and can be based wherever you live.  Diversity & Inclusion at Automattic  We're improving diversity in the tech industry. At Automattic, we want people to love their work and show respect and empathy to all. We welcome differences and strive to increase participation from traditionally underrepresented groups. Our D&I committee involves Automatticians across the company and drives grassroots change. For example, this group has helped facilitate private online spaces for affiliated Automatticians to gather and helps run a monthly D&I People Lab series for further learning. Diversity and Inclusion is a priority at Automattic, though our dedication influences far more than just Automatticians: We make our products freely available and translate our products into and offer customer support in numerous languages. We require unconscious bias training for our hiring teams and ensure our products are accessible across different bandwidths and devices. Read more about our dedication to diversity and inclusion.  How to apply  Please answer the following questions in the application form. Applications without these questions answered will not be considered:  Tell us some details about an interesting at-scale data problem you've worked on. What made it interesting or challenging? Include a link to a recent favorite blog post or paper about working with lots of data. What questions do you have for us?",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Internet",0,None,False,,20,COMPANY_RECRUIT
568,2226354711,2020-10-06,UCSF Medical Center,Senior Healthcare Data Engineer,"San Francisco, CA, US","Job Summary  This job is remote.  Having significant experience, applies advanced data / information management concepts and campus / medical center / OP objectives to resolve highly complex issues where analyses of situations, information or data require an in-depth evaluation of variable factors. Selects methods and techniques to obtain desired results.  Department Description  The Senior Data Analyst is responsible for providing healthcare subject matter expertise and consulting practice leadership with a goal to ensure data warehouse and infrastructure development successfully meets clinical and business requirements. A strong emphasis on data science and data management, he/she will help to achieve the growth and use of UCSFs data infrastructure. Responsibilities include development of data management recommendations, standards, and best practices as well as governance technical project management.  The Senior Data Analyst has advanced technical skills, is able to manage complex and iterative projects and has the business experience to understand and communicate with non-technical users. Projects involve relationships with a variety of teams, including Physicians and front-line staff, Business Intelligence and IT, Population Health Analytics, Decision Support Services and Campus: interest and excitement in partnership across the continuum is critical.  The Senior Data Analyst Will Provide Expertise And Drive Initiatives For Data Sourcing, Data Profiling And Data Management Standardization And Process Development Including But Not Limited To The Following Areas Data profiling and data characterization using statistics and data analysis to understand data and inform development of data infrastructure to support clinical and operational requirementsData model development using data science and analytic methods along with stakeholder requirements to inform data infrastructure projects on database designs that facilitate data usage, reduce data redundancy and promote UCSF data governance standardsData sourcing using data flow diagramming and data profiling to develop approaches and specifications for sourcing data into target data marts / databases: includes ETL mapping, data modeling, data validationStandardizing data infrastructure processes and approaches including ETL technologies and mapping standards, data modeling standards, data quality approaches and validation processes, data management for reference and master data, metadata management approaches and standardsTechnical project management including project intake and estimating processes, data team resource planning and management, data infrastructure planning and goals  Required Qualifications Five years experience as a Data Scientist / Data Analyst in the healthcare or related industryBachelor's Degree in related area and / or equivalent experience / trainingExpertise in the fields of data quality, data profiling, data governance and data standardizationDemonstrated ability to understand data modeling concepts (relational, multi-dimensional, columnar, etc.), data flows, ETL processesExpertise in creating technical specificationsAbility to development data and system testing and validation specificationsBroad, working knowledge of MS SQL, Oracle, and other database systems including DDL, DML and stored proceduresAbility to assess and solve complex data management problemsAbility to define and implement technical processes and data systemsIn-depth knowledge of business intelligence functions, advanced analytics, industry standards and best practicesAdvanced critical thinking and problem-solving skills to manage highly-complex information, assess problems, and develop effective solutionsUtilize excellent customer service skills to build service-based relationships with Medical Center and Campus customersDemonstrate leadership skills and proven success in managing and motivating teams, create an atmosphere of trust, and encourage improvement and innovationAbility to work with senior staff and managers in clinical information technology, health care management, and business analytics, serving as a technical resource and providing advice and counsel on issues of functionality, efficiency, cost-effectiveness, policy, and performanceAble to prioritize effectively according to department needs, and ability to organize a large number of changing variables.Manage several priorities and tasksAbility to work independently with minimum supervisionStrong project management / consulting skills with focus on managing projects and consistently delivering to meet or exceed stakeholders' expectationsAbility to communicate with high proficiency, both verbally and in writing, with all levels of management and staff, in both technical language and layman’s termsExcellent communication skills to describe implications of data and effectively reaches mutual understandingExcellent verbal and written communication skills, strong negotiations and consensus driven outcomesStrong leadership, interpersonal, influencing, collaboration and negotiation skillsComfortable speaking to large groups including internal and external venuesThe flexibility to orient and work at all UCSF Health locations  Preferred Qualifications Eight years as a data scientist / data analystMaster’s Degree in Medical Informatics or Information SystemsExperience with Epic Clarity and Cogito Experience with clinical, financial, operational, HR, payroll and research dataExperience in IT project / Software development across full systems development life-cycleExperience in healthcare business data management/ analysis and support, EA or IT consulting Experience in healthcare planning and healthcare economics experienceExperience implementing large and / or complex projects in healthcare facilitiesExperience with healthcare delivery setting across multiple locations, enterprise level, academic institutionUnderstanding of healthcare industry including ACOs, network management, physician profiling, population health management, and care managementExperience working with agile development process Knowledge of statistical process control principlesConsulting experience a plus - a professional service industry environment within a global matrix  About UCSF  At UCSF Health, our mission of innovative patient care, advanced technology and pioneering research is redefining what’s possible for the patients we serve – a promise we share with the professionals who make up our team.  Consistently ranked among the top 10 hospitals nationwide by U.S. News & World Report – UCSF Health is committed to providing the most rewarding work experience while delivering the best care available anywhere. In an environment that allows for continuous learning and opportunities for professional growth, UCSF Health offers the ideal atmosphere in which to best use your skills and talents. as seventh in the country – UCSF Health is committed to providing the most rewarding work experience while delivering the best care available anywhere. In an environment that allows for continuous learning and opportunities for professional growth, UCSF Health offers the ideal atmosphere in which to best use your skills and talents. Pride Values UCSF is a diverse community made of people with many skills and talents. We seek candidates whose work experience or community service has prepared them to contribute to our commitment to professionalism, respect, integrity, diversity and excellence – also known as our PRIDE values.  In addition to our PRIDE values, UCSF is committed to equity – both in how we deliver care as well as our workforce. We are committed to building a broadly diverse community, nurturing a culture that is welcoming and supportive, and engaging diverse ideas for the provision of culturally competent education, discovery, and patient care. Additional information about UCSF is available at diversity.ucsf.edu  Join us to find a rewarding career contributing to improving healthcare worldwide. Equal Employment Opportunity The University of California San Francisco is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, protected veteran or disabled status, or genetic information. Organization Health Job Code and Payroll Title 000599 DATA SYS ANL 4 Employee Class Career Percentage 100% Location Remote / Telecommute Shift Days Shift Length 8 Hours",No corresponde,Jornada completa,Tecnología de la información,Atención sanitaria y hospitalaria,8,None,False,,40,ACTIVELY_HIRING_COMPANY
569,2180223068,2020-10-13,SOPHiA GENETICS,"Field Application Scientist (Subject Matter Expert), MEA","Dubai, United Arab Emirates","In our journey to impact on patients' lives, we are currently looking for a Field Application Scientist (FAS) MEA (Middle East and Africa) to join SOPHiA GENETICS Sales Team. Be part of our mission to disrupt the healthcare and democratize the data driven medicine!  The Field Application Scientist (FAS) holds a critical role within SOPHiA GENETICS sales department and forms a crucial link between the market and our R&D team to communicate all relevant inputs from the field to continuously grow our solution portfolio.  As a Field Application Scientist (FAS) MEA (Middle East and Africa) you will support the whole sales process by regularly meeting with prospects and clients with the Sales Representatives when greater technical depth is required. The role requires a combination of pre- and post-sales technical support, wet lab and dry lab training, and troubleshooting to move clients quickly and efficiently to routine usage of genomic tests. The primary goals are to ensure customer success and satisfaction to drive revenues and sustain customer retention.  The Field Application Scientist (FAS) MEA position requires to intensely travel between various SOPHiA offices and customer sites across Middle East and Africa (60% of working time).     Conduct on-site or remote customer trainings and demos on SOPHiA solutions. Act as a trusted technical expert and consult in product support to the customers, distributors and sales team. Support sales in the achievement of the regional sales target by providing pre- and post-sales related customer support activities. Ensure customer success efficiently driving Set Up Programs on genomic solutions. Troubleshoot customer issues and complaints in close collaboration with the customer services and support team. Mentor and train other members of the sales team. Deliver presentations for pre-sales or workshops. Provides strategic and competitive feedback to R&D and product development teams.  Requirements:  Master degree in Life Sciences within a well-regarded institution: PhD will be an advantage, Excellent experience in Next Generation Sequencing (NGS), Strong technical background in genetics/genomics, sequencing applications, and understanding of variant analysis and interpretation workflows, Previous experience with NGS automation equipment is an asset, 2 years experience in sales or as a product specialist preferably in the clinical diagnostics, biotechnology or medical technology market is an asset, Excellent communication skills, including experience in communicating complex scientific principles in simple terms, Clear vision of and commitment to providing outstanding customer service, Excellent level of English, Excellent level of Arab.  Benefits:  A competitive compensation package. A flexible and friendly working environment with a collaborative atmosphere Fantastic office locations in Switzerland, France, and USA. An exciting company mission that brings together science and technology to directly impact the lives of patients with life threatening illness. A fast-growing company with plenty of opportunity for personal growth and development    Location : Home Office  Start: ASAP (or as agreed)  Contract type: Permanent full-time   Application process  If you think you fit this position, please send a CV and a cover letter. Please note that incomplete applications will not be considered.  After an initial screening process, candidates will be invited for remote interviews. Selected candidates will then be invited for personal interviews.",Algo de responsabilidad,Jornada completa,Ventas,Biotecnología,560,None,True,,1951,None
570,2237129539,2020-11-03,IT-Personalberatung Dr. Dienst & Wenzel GmbH & Co. KG,(Senior-) Consultant Data Science Finanzindustrie für innovative Financial Services bei einem wegweisenden Beratungsunternehmen (m/w/d),Deutschland,"Wir suchen den Data Scientist / Data Analyst / Data Engineer (m/w/d) für den Bereich Finance (Finanzinstitute, Banken und Versicherungen) für ein innovatives, erfolgreiches und mit Leidenschaft geführtes Beratungsunternehmen.In der Position unterstützen Sie Unternehmen in der Finanzindustrie, Big-Data, Advanced Analytics und Artificial Intelligence gewinnbringend zu nutzen. Dazu gehören die Analyse des Master Data Managements, die Bereitstellung von Prognose- und Risikomodellen sowie die Entwicklung neuer datengetriebener Finance Produkte.Sie sind aktiv in der Realisierung von modernen Data Science Kundenlösungen sowie im technischen Bereich der Beratung beim Kunden aus dem Finanzbereich tätig. Sie arbeiten im kompletten Projektzyklus, vom Requirements Engineering und Analyse von Benutzerdaten, über die Strategie- und Lösungsentwicklung, bis hin zur Realisierung innovativer Lösungen.Wenn Sie Pionierarbeit und Daten lieben und selbst die Konzepte designen und die Lösungen entwickeln wollen, dann ist dies Ihre Position.Wer Unternehmen nach vorne führen will, muss eine überdurchschnittliche Kompetenz besitzen. Ihr Wissensvorsprung wird Ihnen u.a. durch die firmeneigene Management Academy, ständigen Austausch mit Kollegen und Vorgesetzen sowie Zusammenarbeit mit Universitäten, Forschungsgruppen und renommierten Coaches ermöglicht. Zu Ihren wichtigsten Aufgaben als Data Scientist / Data Analyst / Data Engineer (m/w/d) gehören:Sie analysieren die Herausforderungen und Ziele Ihrer Kunden und finden realisierbare LösungenSie begleiten Ihre Finanzkunden durch die digitale Transformation und führen sie bei der effektiven Nutzung von (Big) Data- und Advanced Analytics an und sind selbst in die Entwicklung eingebundenAbhängig von Ihrer Erfahrung übernehmen Sie immer mehr Verantwortung in KundenprojektenMit Souveränität und Feingefühl bringen Sie die IT und die Fachbereiche zusammenSie sind kompetenter Ansprechpartner für Neukunden sowie für BestandskundenTeilweise sind Sie in Vertriebs- und Pre Sales-Prozesse mit eingebunden Es erwarten Sie ein attraktiver Gehaltsrahmen und eine herausragenden Firmenkultur, die intensiv gelebt wird. Gesucht werden Mitarbeiter mit Unternehmergeist.Die idealen Standorte sind Frankfurt und Stuttgart, gefolgt von Köln/Düsseldorf. Sie arbeiten entweder von einer Niederlassung oder Ihrem Home-Office aus. Eine hohe Reisebereitschaft ist in der Beratung immer noch unerlässlich. Verlassen Sie gewohnte Routinen, hinterfragen Sie Konventionen und suchen Sie neue Wege! Unser Auftraggeber ist eine erfolgreiche Unternehmensberatung mit modernen Werten, die sich als Vor-und Querdenker aktiv am Markt positioniert hat.Nach dem Leitsatz: „Durch Wissensvorsprung zum Wettbewerbsvorsprung“ werden Kunden kompetent beraten und Mitarbeiter gefördert. Eine eigene Management Academy und aktive Zusammenarbeit mit Universitäten, Forschungsgruppen und renommierten Coaches ermöglichen diesen Mehrwert an Know How. DAX-Konzerne, die wichtigsten Bundesbehörden und namhafte Mittelständler vertrauen auf das Know How unseres Auftraggebers. Unser Auftraggeber ist eine wirtschaftlich unabhängige Unternehmensberatung, die daher bei der Auswahl ihrer Projekte autonom entscheiden kann.Niederlassungen befinden sich z.B. in Düsseldorf, Frankfurt, Stuttgart, München, Hamburg und Berlin. Ausbildung / Studium: Sie verfügen über ein abgeschlossenes Studium oder eine Promotion, idealerweise in der Informatik, Mathematik oder Physik. Kenntnisse und Erfahrungen: Kenntnisse in einem oder mehreren der folgenden Bereiche: R, Python, Julia, RegEx, Linux/Unix, Plotly, ETL, SQL/NoSQLGute Kenntnisse im Bereich der datengestützten Programmierung und des Data EngineeringAktive Kenntnisse in Data Science, Data Analytics und Künstliche IntelligenzProzess- und IT-Kenntnisse in unterschiedlichen BereichenGutes Kommunikationsvermögen und KundenorientierungProfessionalität und Fingerspitzengefühl beim Umgang mit KundenSie verfügen über sehr gute Deutschkenntnisse in Wort und SchriftSie müssen bereits in Kundenprojekten in Deutschland gearbeitet haben, eine reine Remote-Tätigkeit bei deutschen Unternehmen reicht nicht ausGute Englischkenntnisse runden Ihr Profil abErfahrungen in der FinanzindustrieMehrere Jahre Erfahrung in den Bereichen Data Analytics und/oder Data Science.Sie müssen selbst schon in Big-Data-Bestände geforscht sowie Advanced Analytics-Funktionen und datengetriebene Produkte entwickelt habenIhre Erfahrungen können aus Live-Projekten in der Industrie oder auch wissenschaftlichen Projekten während des Studiums oder der Promotion stammenVerknüpfung der Analyseergebnisse mit finanziellen und operativen ErgebnissenErfahrungen in strategischen Bereichen von VorteilErfahrungen in der Beratung sowie Aufbau und Pflege von Kundenbeziehungen wären ideal Ort: Idealerweise Frankfurt oder Stuttgart, aber auch Köln und Düsseldorf sind möglich.Es erwartet Sie eine hoch interessante und verantwortliche Position sowie gleichzeitig eine sehr gute berufliche Chance. Wenn Sie der Meinung sind, Sich dieser Herausforderung stellen zu wollen und die geforderten Skills überwiegend mitbringen, freuen wir uns auf Ihre Kontaktaufnahme.Ihre Fragen vorab beantwortet Ihnen gerne Herr Manfred Wenzel unter der Telefonnummer +49(0)711/4560584.Senden Sie bitte Ihre Bewerbung, mit Bezug auf diese Stellenausschreibung, direkt per Mail an wenzel@it-personalberatung.de mit idealerweise folgenden Inhalten:Kurzes Anschreiben mit Darstellung Ihrer Eignung für diese PositionPrägnanter Lebenslauf, gerne mit Foto, aus dem Ihre Erfahrungen, Kenntnisse und Erfolge hervorgehenZeugnisse bevorzugt als pdf-fileFrüheste VerfügbarkeitUngefähre EinkommensvorstellungIch freue mich auf Ihre Bewerbung!Diskretion und eine umfassende Wahrnehmung Ihrer Interessen sichern wir Ihnen ausdrücklich zu.Bitte beachten Sie unsere Datenschutzhinweise:it-personalberatung.de/datenschutzhinweise.html.... weitere Jobangebote finden sie unter www.it-personalberatung.de",Algo de responsabilidad,Jornada completa,"Gestión de proyectos, Tecnología de la información, Análisis","Servicios y tecnologías de la información, Banca, Consultoría de estrategia y operaciones",10,None,True,wenzel@it-personalberatung.de,46,ACTIVELY_HIRING_COMPANY
571,2290016412,2020-11-08,Group,Snr Big data Engineer Fully remote,"London, GB","Snr. Big Data Engineer (Fully remote)  My client is looking to secure the services of an experienced Snr. Big Data Engineer to provide assistance on a critical project  Role: Snr. Big Data Engineer (Fully remote) Rate: £550 - £600 per day location: Fully Remote Duration: initial 3 months with possible extensions  MUST USE A UK UMBRELLA COMPANY AS THIS ROLE IS DEEMED INSIDE IR35  Essential Skills IT and data architecture/modellingHadoop 3.0+Big data file system, file, and field formatsSparkRanger and KerberosHiveOracle, SQL Server RDBMSInformatica Big Data Management / Quality (mappings, flows, quality rules, automation, …)SQL queriesBusiness (data) logic in a financial environmentPython 3.6+Infrastructure incl. sizing and performance tuningLinux incl. Bash scriptsGitHub and version controlCI/CD (Ansible, Jenkins)Jira (or similar tool), Confluence (or similar tool)Data and software pipeline automationAzure cloudControl-MAPI'sControlled refactoringPeer reviews, unit testing, bug fixing If you are a strong match for this Snr. Big data engineer (Fully remote) role feel free to apply or send your C.V to  By applying to this advert you are giving CPS Group (UK) Ltd authority to hold and process your data for this specific role and any other roles we may deem suitable to you over time. We will not pass your data to any third party without your verbal or written permission to do so. All incoming and outgoing calls are recorded for training and compliance purposes. CPS Group (UK) Ltd is acting as an Employment Agency in relation to this vacancy. Our new privacy policy can be found here https://company-policies",Algo de responsabilidad,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Software, Dotación y selección de personal",None,None,False,,9,None
572,2253896702,2020-11-07,Andriotto Financial Services,Innovation Researcher / Grant writer,Brazil,"WHO WE AREAndriotto Financial Services (AFS) is a Swiss leading fintech investment banking boutique, specialized in digital capital markets and financial grants, serving small-medium enterprises and companies through Security Token Offering (blockchain), traditional corporate finance services and European grants preparation.www.andriotto.comwww.edsx.ch THE CANDIDATEWe are looking for a candidate that will be responsabile of the European Grant Division of AFS with a deep experience in innovation and/or scientific research and/or business plan drafting and excellent english communication skills. He/she is motivated, organized and experienced in writing top quality research and scientific report and business plan. The ideal candidate might be a PhD, post-PhD or a professor from one of the leading universities in Brazil (or North America).Knowledge of the European grant programs (SME Intrument, EIC, Horizon 2020, Horizon Europe) is not necessary at this stage.Knowledge of basic accounting and finance for business plan drafting is required.The ideal candidate should also have capabilities in leading a team (mainly other freelancers / grant writers) and managing the daily operations of the business. He/she will be responsible for maintaining the standard of work from employees as well as onboarding and hiring new team members as well managing the timing expectations and client relationship. LOCATIONThe work will be entirely organized in Smart Working with the long term objective to open a subsidiary in San Paolo. SALARY The salary is very competitive. RESPONSABILITIES Provide leadership and direction to a team of peopleManage operations and work by goals with a strict time scheduleRecruit and train new hires on business practicesManagage clients and contractsFollow CEO' directions and constantly report Ensure that quality of work or service is maintainedManage european proposals from inception to submissionAnalyze and study the structure of new European grants QUALIFICATIONSEducation: PHD preferredLanguage: italian is preferred and excellent english written and verbal communication skills is a must5+ years of relevant working experience as writer or researcherAbility to use power point and microsoft word for quality output (content and design) Customer Service experience preferredDemonstrate ability to leadComfort working with budgets, payroll, revenue and forecastingExcellent english written and verbal communication skillsKnowledge of office package",Algo de responsabilidad,Jornada completa,Otro,Servicios financieros,13,None,True,,171,ACTIVELY_HIRING_COMPANY
573,2270926658,2020-10-31,NBCR Rekrutacja IT Sp. z o.o.,Senior Data Engineer (Cloud Expert)- 100% remote,"Warsaw, PL","NBCR Sp. z o.o. is a company with an established position in the market specializing in the recruitment of specialists in the IT industry (Certificate No. 14492). For over a dozen years, we have been helping our clients in providing highly qualified specialist staff, thanks to which they can work and grow and we accompany them as a reliable partner.  Responsibilities  We are currently looking for candidates for the position:  We focus on the finance, retail, and healthcare sectors with use cases like investment optimization, semi-automated data mapping, lead scoring. We conduct internal webinars to share knowledge in the fields of Machine Learning and Data Engineering. We’re building an ML-Ops culture within our department and we want to extend that to the Data Engineering area. We use AWS and GCP as our cloud providers. We encourage our team members to share their knowledge and experience at external conferences. We cooperate closely with the Machine Learning team. Requirements  3+ years of DE experience, Strong experience with S3 + Athena/Presto and Redshift/Redshift Spectrum, Hands-on experience with at least 2 of the following: AWS Glue/EMR or Kinesis/Kafka or ELK stack or Lambdas. Experience in designing data lakes - from structuring to managing and optimization, Knowledge of data storage formats (Parquet, ORC, AVRO, etc.), Experience with Python and Linux and shell scripting, Familiarity with relational databases like Oracle, PostgreSQL, MySQL, Advanced SQL writing skills. Nice-to-haves  Experience with: Airflow / Luigi MongoDB / ElasticSearch / Cassandra Kubernetes We Offer  attractive salary Generous private health insurance package with dental care. Optional life insurance for you and your family. A growth budget for your educational plan. Masterbenefit: discounts on car leasing. Discounts on Apple products. Various internal initiatives: webinars, knowledge sharing sessions, internal conferences.",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Internet",0,None,False,,6,None
574,2205053061,2020-11-04,i.LECO NV,Senior Data Scientist,"Geel, Vlaanderen, België","Senior data scientist – full timeAbout usi.LECO is a young, international and driven team with a rich experience of completed and value-adding complex smart energy projects and products. We are looking for a senior data scientist in Belgium to take our data products to the next level. Job descriptionAs the senior data scientist in the team, you will be involved with (and will eventually take the lead on) designing our data products. You will mentor junior colleagues, and work together with both internal and external stakeholders to gather specifications, design data-products and communicate results effectively. In your daily work, you will interact closely with other research engineers, scientists, software developers and the CEO at iLECO. ProfileEducation:PhD in a STEM field (Science, technology, engineering, and mathematics) – preferably at the intersection of data science and energy (demand response, energy markets, etc.). An MS with equivalent research (or product) experience is also acceptable. Experience and technical know-howProven track record of delivering data-driven products at scaleEnd-to-end experience of the data pipeline (data acquisition and storage to model building to decision making)Extensive knowledge of cutting edge machine learning algorithms and their strengths and weaknesses, beyond the hype and buzz wordsKnowledge of decision making under uncertainty algorithmsAbility to work independently and follow the research roadmap, while still working closely with developers and other stakeholders What’s in it for you?Possibility to shape the future of the energy market and make a meaningful contribution to the sustainable energy transitionA position in a growing, international company, with a flat hierarchyA function where personal development is importantAn attractive and competitive salary package with normal operational conditions.Being a part of an international team of experienced and highly motivated colleaguesFlexible hours and the ability to work from home (most of the time), but we are looking for someone who lives in Belgium. Are you interested in being a part of our team? Do not hesitate to contact layla.daems@ileco.energy with a CV & motivation!",Intermedio,Jornada completa,Otro,"Energía renovable y medio ambiente, Petróleo y energía",145,None,True,layla.daems@ileco.energy,599,JOB_SEEKER_QUALIFIED
575,2259509850,2020-10-06,Wikimedia Foundation,Research Scientist (Disinformation),"Boston, MA, US","Summary  We're hiring a Research Scientist strongly committed to the principles of free knowledge, open source and open data, transparency, privacy, and collaboration to join the Research team to conduct applied research on the integrity of content and disinformation in Wikipedia and other Wikimedia projects.  The surge of coordinated disinformation campaigns to infiltrate, disrupt, and co-opt movements, communities, and platforms is an important challenge for the integrity of the content in Wikimedia projects. At the same time, humans and machines rely on Wikipedia as a neutral arbiter of reliable information on the Web. Preserving the reliability of Wikipedia's knowledge is therefore key in ensuring the integrity of the information propagating in the broader web.  You'll work remotely with a distributed team, with members spread between Europe and North America. Here are some things we've worked on recently that might give you a better sense of what you could be working on:  Studying how content propagates across different Wikipedia languages, by predicting, given an article created in one language, what is the next language that will have the same article created. Modeling content inconsistencies between Wikimedia projects by aligning Wikidata statements to sentences in Wikipedia articles through natural language processing techniques. Designing algorithms to identify malicious actors such as sockpuppets, by detecting clusters of users behaving similarly. Building a model to detect unsourced content in Wikipedia using machine learning, through neural network classifiers that can detect sentences needing citations based on their content. (paper) Using qualitative methods to study Wikimedia communities and their patrolling techniques, to discover inner mechanisms of editor workflows to combat disinformation.  You can learn more about what we have done in the past six month by reading our biannual report.  You will be responsible for:  Contributing to the three directions of the team: addressing knowledge gaps on the Wikimedia projects, supporting the Wikimedia volunteers in improving content integrity, and building a more global community of Wikimedia researchers with a particular focus on improving content integrity and disinformation Collaborating with other researchers, Wikimedia volunteers, and teams within the Wikimedia Foundation, including Legal, Trust and Safety, and Security teams to define disinformation and content integrity related research projects Designing and executing experiments to collect labeled data, large-scale data analysis and/or modeling and evaluation of machine learning methods Discussing, documenting and communicating the process and results of your research publicly  Actively engaging in a collaborative, consensus-oriented environment and as part of a globally-distributed team and organization Elevating the importance of critical open research questions as well as nurturing and growing the global network of Wikimedia researchers Providing research consulting to the teams in the Wikimedia Foundation, affiliates, and the Wikimedia volunteers   Skills and experience:  PhD or MSc degree plus 1-2 years of related work experience in computer science, statistics, or related technical fields: PhD degree highly preferred Strong experience in Machine Learning and at least one of the following fields: Natural Language Processing, Algorithm Design, Social Network Analysis, HCI, Behavioral/ Experimental Economics, Computational Social Science: experience with disinformation research highly preferred. Programming experience in Python, Scala, or C++ Experience with Hadoop and any of the following related technologies: HDFS, YARN, MapReduce, Hive, Spark, etc. Contributions to research communities and research initiatives including publishing in relevant conferences and journals, organizing academic workshops Strong written and oral communication skills in English, including the ability to communicate complex technical issues to a cross-team and cross-functional audience    Qualities that are important to us:  Commitment to the mission of the organization and our values Commitment to our guiding principles Ability to disagree in a respectful manner and yet work towards a solution even when you disagree Good at async communication  Solutions-focused. The Wikimedia ecosystem is complex, resources are limited, and our guiding principles are ambitious. We want you to work to find solutions embracing these factors. Self motivated with an Ability to navigate through ambiguity and bring a project to completion with limited directions Curiosity and commitment to learn   Additionally, we'd love it if you have:  Relevant work experience in the field of disinformation, in academia or industry Experience with large-scale experiments in online platforms Experience with mixed methods research A strong record of scholarly publications Experience as a program committee member, senior program committee member, track chair, or editor in related conferences and journals Experience with tools such as Spark, Flink, Hive, Kafka Deep knowledge of the Wikimedia ecosystem and the working of the projects and/or experience with volunteer or open source communities   The Wikimedia Foundation is...   the nonprofit organization that hosts and operates Wikipedia and the other Wikimedia free knowledge projects. Our vision is a world in which every single human can freely share in the sum of all knowledge. We believe that everyone has the potential to contribute something to our shared knowledge, and that everyone should be able to access that knowledge, free of interference. We host the Wikimedia projects, build software experiences for reading, contributing, and sharing Wikimedia content, support the volunteer communities and partners who make Wikimedia possible, and advocate for policies that enable Wikimedia and free knowledge to thrive. The Wikimedia Foundation is a charitable, not-for-profit organization that relies on donations. We receive financial support from millions of individuals around the world, with an average donation of about $15. We also receive donations through institutional grants and gifts. The Wikimedia Foundation is a United States 501(c)(3) tax-exempt organization with offices in San Francisco, California, USA.  As an equal opportunity employer, the Wikimedia Foundation values having a diverse workforce and continuously strives to maintain an inclusive and equitable workplace. We encourage people with a diverse range of backgrounds to apply. We do not discriminate against any person based upon their race, traits historically associated with race, religion, color, national origin, sex, pregnancy or related medical conditions, parental status, sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, genetic information, or any other legally protected characteristics.  If you are a qualified applicant requiring assistance or an accommodation to complete any step of the application process due to a disability, you may contact us at recruiting@wikimedia.org or (415) 839-6885.  U.S. Benefits & Perks*  Fully paid medical, dental and vision coverage for employees and their eligible families (yes, fully paid premiums!) The Wellness Program provides reimbursement for mind, body and soul activities such as fitness memberships, baby sitting, continuing education and much more The 401(k) retirement plan offers matched contributions at 4% of annual salary Flexible and generous time off - vacation, sick and volunteer days, plus 22 paid holidays - including the last week of the year. Family friendly! 100% paid new parent leave for seven weeks plus an additional five weeks for pregnancy, flexible options to phase back in after leave, fully equipped lactation room. For those emergency moments - long and short term disability, life insurance (2x salary) and an employee assistance program Pre-tax savings plans for health care, child care, elder care, public transportation and parking expenses Telecommuting and flexible work schedules available Appropriate fuel for thinking and coding (aka, a pantry full of treats) and monthly massages to help staff relax Great colleagues - diverse staff and contractors speaking dozens of languages from around the world, fantastic intellectual discourse, mission-driven and intensely passionate people  Please note that for remote roles located outside of the U.S., we defer to our PEO to ensure alignment with local labor laws.  More information  Wikimedia Foundation Blog Wikimedia 2030 Wikimedia Medium Term Plan Our Commitment to Equity This is Wikimedia Foundation Facts Matter Our Projects Our Tech Stack",Algo de responsabilidad,Jornada completa,Otro,"Gestión de organizaciones sin ánimo de lucro, Software, Internet",28,None,False,recruiting@wikimedia.org,273,ACTIVELY_HIRING_COMPANY
576,2242779175,2020-10-26,OutSystems,AI Research Scientist - Automated Reasoning,Portugal,"With the recently announced Project Turing, OutSystems is creating the future by leveraging cutting-edge AI to teach machines how to program, make our products smarter and enable anyone to create groundbreaking apps faster than ever, and with higher quality. We are embedding AI into the fabric of our organization and products. As a Research Scientist in our Artificial Intelligence Group, your main role will be to do applied research and development, in order to push the state-of-the-art and make our next generation products smarter and easier to use. The sky is the limit and you’ll help us get there. Key ResponsibilitiesPush the state-of-the-art forward in Artificial Intelligence and Automated Reasoning, applied to smart App development.Design and build solutions for real-world problems, from idea, through research, prototyping and into product solutions.Work together with data scientists, engineers and product people to bring new developments to our products.Communicate research progress and milestones clearly and efficiently to internal and external audiences. Share your findings with the community, and be a thought leader in smart App development.Collaborate with other research institutions to openly advance research goals. Preferred QualificationsPh.D. degree in Computer Science, Artificial Intelligence, Automated Reasoning, or related technical fields is highly valued.M.Sc. with strong focus on Computer Science and Automated Reasoning components (e.g. Computer Science, Electrical Engineering).Deep expertise in at least one of the sub-fields of Automated Reasoning, such as Propositional Satisfiability, Satisfiability Modulo Theories and/or Constraint Programming.Hands-on experience with Automated Reasoning tools (e.g. Z3, CVC4, SAT4j, pysat, MiniZinc).Proficiency in high-level problem solving and programming languages. Able to create end-to-end working prototypes - from planning, data analysis, logical formulation and algorithm implementation. Experience in Python or R are valued.Be creative, ambitious, and curious. Be resourceful and innovative. What you can expect from OutSystems: The possibility to create disruption in the software development market:A company that cares about employees wellbeing and provides a safe and comfortable work environment, even during adverse times:A world-class software engineering team with peers and leaders that are inspired to learn and share what they know:A fast-growing company that provides many opportunities for you to grow:Fun from day one: a relaxed work environment, colleagues from diverse backgrounds, and with a diverse range of interests, fun company events. Curious about OutSystems culture? Find out more in The Small Book of The Few Big Rules.",Intermedio,Jornada completa,Ingeniería,Software,6,None,False,,138,ACTIVELY_HIRING_COMPANY
577,2194385352,2020-10-20,Aliancers,Sr. Data Engineer,Argentina,"BUSCAMOS DATA ENGINEERS PARA CUBRIR 2 VACANTES PARA TRABAJAR EN IMPORTANTE PROYECTO PARA USA. LA MODALIDAD ES TRABAJO REMOTO POR LO TANTO LA LOCALIZACION PUEDE SER EN CUALQUIER PAIS CON PREFERENCIA POR ARGENTINA Y URUGUAY. Requerimientos básicos generales (excluyentes)- Inglés avanzado- Manejo de Linux- Manejo de tecnologías: AWS & Python (Intermedio).- Conocimiento y experiencia (> 5 años) en lenguajes de bajo nivel (C, C++, Rust, Go y/o Python). Requerimientos específicos Data Engineer 1 - Equipo de Targeting (excluyentes)- Experiencia en DevOps (o conocimiento de).- Manejo de tecnologías: Go y Spark.  Requerimientos específicos para Data Engineer 2 - Equipo de Optimizations (excluyentes)- Manejo de tecnologías: SQL y Javascript (no para frontend). - Experiencia en machine learning. Se valorará: (no excluyentes)- Experiencia trabajando con datasets muy grandes.- Experiencia trabajando con sistemas distribuidos (distributed paradigms and frameworks).- Experiencia en el diseño de sistemas escalables de alto rendimiento.",Intermedio,Jornada completa,Tecnología de la información,Servicios y tecnologías de la información,20,None,True,,252,ACTIVELY_HIRING_COMPANY
578,2218845537,2020-10-28,Volt - International,Data Scientist Bioinformatician,"London, England Metropolitan Area","We are currently looking for a Genomics Data Scientist/Bioinformatician with PhD experience of working within Rare Diseases or Cancer in a computational biology background.Ideally undergraduate studies in a strongly quantitative discipline such as (e.g. physics, computer science, or maths). These skills could also have been developed, for example, through a PhD in computational biology, statistical genomics, or statistical genetics.· Excellent knowledge and experience in one or more areas of human DNA analysis, such as rare disease genomics, family-based analysis, genetic association testing, risk score prediction, structural variation, pharmacogenomics, typing of complex genomic regions such as HLA/KIR· Excellent knowledge in cancer genomics, approaches to call somatic variation and interpret cancer genomes.· Strong knowledge of statistics and/or machine learning· Strong knowledge of high throughput sequencing algorithms and available resources. Experience with full cycle of analysing NGS data from sequencing QC to annotation and prioritization of variants.· Strong programming skills (Python, R)Genomics Data Scientists work as part of squads building translating state of the art analytics into clinically-fit production quality solutions.Genomics Data Scientists investigate and develop solutions to extract more information from the genome (alignment and variant calling) and to interpret the genome in the context of a persons clinical features.",Algo de responsabilidad,Jornada completa,"Ingeniería, Tecnología de la información, Análisis","Biotecnología, Industria farmacéutica, Software",119,None,True,,536,ACTIVELY_HIRING_COMPANY
579,2246371969,2020-11-05,Kaspersky,Security Researcher ICS CERT,Italy,"As a part of the Kaspersky ICS CERT Team this role is responsible for performing cyber threat intelligence research and providing expert support to Kaspersky ICS / IIoT and IoT security projects and initiatives, promoting Kaspersky ICS / IoT cyber security expertise and building relations with key industry drivers, cyber security community and enterprise customers.The position focus will be:Participate in threat hunting and threat intelligence research projects, analyze threat landscape, perform research into cyberattacks affecting and targeting ICS / IIoT / SmartCity / Transportation / Automotive infrastructures globally.Perform cyber incident investigations on request from key industrial customersWrite analytical reports – both public and commercialSpeak at conferences across the GlobeWrite articles, give interviews on ICS/IIoT/ cyber threat related topicsProvide cyber security expert support to Kaspersky ICS CERT service development projectsParticipate in cybersecurity professional / expert training projects: develop training materials and deliver trainingsContribute to Kaspersky – academia relations building Provide support to Kaspersky governmental relations activities and initiatives in the country / region of location.What we expect from you:Excellent knowledge of IT networking ( principles, technologies, architectures and solutions, protocols)OT / IoT / telecom technologies knowledge would be an advantageIT systems deep knowledge (x86/64 architecture / assembler (ARM and/or MIPS would be an advantage), Windows and Linux internals, popular filesystems and executable file formats)Knowledge of technical methods of information security, as well as technologies and software and hardware means of information security (information security threats, software vulnerabilities and attack methods, cyberattack detection tools and technologies, malware reverse engineering and analysis, cyber threat hunting, digital forensics, incident investigation)Programming skills C/C++ , one of the scripting languagesCommunication skillsExcellent teamwork / collaboration skillsGood public speaking / presenting skillsGood working connections / relations building skillsAbility to work from remote – both as a part of a global team and as a self-sufficient combat unitSystem-level problem solving thinkingBeing self-motivatedAccuracy and due diligence to detailsAbility and will to travelThe Company offers:Interesting work as part of the professional team of the world’s largest privately held IT security companyCompetitive salariesOpportunities for career and professional developmentAn extensive benefits packageRegular corporate events and team-buildingFlexible dress codePossibility of flexible working hours",Intermedio,Jornada completa,Tecnología de la información,Seguridad del ordenador y de las redes,48,None,True,,264,ACTIVELY_HIRING_COMPANY
580,2244779229,2020-10-22,Signifyd,Data Scientist,"San Jose, CA, US","This position requires you to be located in the US  Must be willing to work EST hours  The Data Science team at Signifyd builds the models that power our fraud detection engine. Our machine learning pipeline keeps us one step ahead of fraudsters and their constantly evolving tactics and our research and experiments develop into new products that improve the merchant payments experience.  We expect our data scientists to be hands-on. We carry solutions from a brainstorm to experimentation and all the way to deployment. We're a varied group with a diversity of strengths -- some team members came to us from academic backgrounds, others from engineering, some from big companies and some from small, but all of us are curious and collaborative.  We are looking for someone who embodies our company values:  Curious and Hungry: Be willing to do research and design experiments by being hands-on  Tenacious: Creating something new is hard work, and our Data Scientist team never gives up  Customer Passion: Be the backbone to our platform, and help us stay ahead of fraudsters  Design for Scale: Work with the rest of the Data Science team to make fraud protection at scale possible  Agile: Some days you may spend doing research and designing experiments while others are spent using your analytical toolbox to surface insights into real-time fraud attacks.  Roll Up Your Sleeves: Partner closely internally to learn from others, and succeed as a team  How you'll have an impact:   Building production machine learning models that identify fraud Designing new algorithms that optimize all the key components of the Signifyd Commerce Protection Platform Writing production and offline analytical code in Python and Java Researching real-time emerging fraud patterns with the Risk Analysis team Working with distributed data pipelines Communicating complex ideas effectively to a variety of audiences Collaborating with engineering teams to continuously strengthen our machine learning pipeline Mentoring other members of the team  Past experience you'll need:   Bachelor's degree in computer science, applied mathematics, or an analytical field An advanced degree (M.S. or Ph.D) in computer science, applied mathematics, or an analytical field is highly preferred At least 3+ years of experience Hands-on statistical analysis with a solid fundamental understanding Designing experiments and collecting data Writing code and reviewing others' in a shared codebase, preferably in Python and Java Practical SQL knowledge Familiarity with the Linux command line  Experience we love to see:   Data analysis in a distributed environment Passion for writing well-tested production-grade code Using visualizations to communicate analytical results to stakeholders outside your team Previous work in fraud, payments, or e-commerce",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Software, Internet, Servicios financieros",89,None,False,,376,ACTIVELY_HIRING_COMPANY
581,2258211705,2020-10-15,Noblr Car Insurance,Senior Data Engineer,"Austin, TX, US","Join the team that's bringing innovation to car insurance. Noblr empowers its members to personalize their monthly car insurance rates using their smartphones. Our members log their trips with the Noblr app, get driving insights that help them continuously improve, and earn rewards for responsible driving. Our goal is to build a safe-driving community through responsible driving.  As a Data Engineer, you will:   Develop and maintain high-performance data pipelines to drive near real-time data warehouse: Build machine learning infrastructure that host models at scale: Use metadata driven ETL Tools and Open source data processing frameworks: Develop data APIs that feeds insights from data warehouse to customer facing apps: Work with cross functional teams to drive reporting and analytics.  Apply if you:   Have 5+ years of experience in building near real-time data pipelines and machine learning infrastructure: Have extensive experience with Java, Python, SQL, and columnar databases: Have 5+ years of experience in using various data technologies within AWS ecosystem: Have 2+ years of experience in building data APIs that facilitates easy and structured data exchange with internal and external entities: Have been working very closely with Product, Marketing, Sales, and Service function leaders in defining and measuring key business metrics: Have extensive experience with scaling machine learning models in production: Have experience with data visualizations.  Location: Austin-TX or San Francisco-CA",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Software, Seguros, Servicios financieros",3,None,False,,19,ACTIVELY_HIRING_COMPANY
582,2197358251,2020-10-30,Citymapper,Realtime Transport Data Engineer (Remote),Ukraine,"DescriptionCitymapper makes cities usable, helping people move through urban spaces, getting people from A to B.We have launched in more than 60 cities so far. We've found that having a broad and deep set of data on the transportation options in that city is key to ensuring a great experience for our users.We are launching many new cities to bring Citymapper to users everywhere. We provide essential information for millions of users, letting them know when the next bus is arriving, which trains are disrupted, and what time they should leave to get home. We need engineers to help build and maintain the systems that do that.Good transport data, especially realtime information, is why our users love our app. What you’ll doAdd and maintain sources of realtime departure information in new and existing cities. Lots of feeds and cities require non-trivial and unique strategies in order to reliably show the correct departure times to the user. 'When does my bus arrive?'Find ways to turn disruption messages from agencies into useful notifications and re-routing for our users. Check out what we did in NYC. 'Is the metro blue line running?'Integrate private transport operators into our data streams. Public transport is being complemented by private transport operators in most of the cities we cover - bikes, moped, scooters, cars, etc... 'Where's the nearest electric bike to rent?'Improve the monitoring and operational systems necessary to keep these 100s of realtime data feeds working. 'Why are we not showing trains in Lyon?'Fun projects we recently took onDeployed a real time monitoring system to help commuters in Hong Kong navigate complex route diversionsBuilt a system to approximate TfL train predictions based on sparse dataAdded real time crowdedness information to help users decide which vehicle to use RequirementsUltimately we don’t have hard requirements beyond needing you to be smart, curious, and keen to get stuck in. However we are looking for candidates with at least 1 year of professional software engineering experience within a team. Attention to detail and experience wrangling data (especially transport data) is a plus. This is a remote contracting position for a 3-6 month full time contract positionOur stack for transport dataTech: main language Python 3Tooling: GitHub, AWS, SQL, LinuxBest practices: code reviews, tests, CI BenefitsContractor position in a remote-first teamWorking on something interesting and meaningful - help to make cities usableCompany provided Macbook & needed equipmentWorking with a not-too-big, diverse engineering teamArcane public transport knowledge with which to dazzle your friends",No corresponde,Contrato por obra,None,Internet,20,None,True,,334,JOB_SEEKER_QUALIFIED
583,2291012815,2020-11-07,CPS Group,Snr Big data Engineer Fully remote,"London, GB","Snr. Big Data Engineer (Fully remote)  My client is looking to secure the services of an experienced Snr. Big Data Engineer to provide assistance on a critical project  Role: Snr. Big Data Engineer (Fully remote) Rate: £550 - £600 per day location: Fully Remote Duration: initial 3 months with possible extensions  MUST USE A UK UMBRELLA COMPANY AS THIS ROLE IS DEEMED INSIDE IR35  Essential Skills IT and data architecture/modellingHadoop 3.0+Big data file system, file, and field formatsSparkRanger and KerberosHiveOracle, SQL Server RDBMSInformatica Big Data Management / Quality (mappings, flows, quality rules, automation, …)SQL queriesBusiness (data) logic in a financial environmentPython 3.6+Infrastructure incl. sizing and performance tuningLinux incl. Bash scriptsGitHub and version controlCI/CD (Ansible, Jenkins)Jira (or similar tool), Confluence (or similar tool)Data and software pipeline automationAzure cloudControl-MAPI'sControlled refactoringPeer reviews, unit testing, bug fixing If you are a strong match for this Snr. Big data engineer (Fully remote) role feel free to apply or send your C.V to  By applying to this advert you are giving CPS Group (UK) Ltd authority to hold and process your data for this specific role and any other roles we may deem suitable to you over time. We will not pass your data to any third party without your verbal or written permission to do so. All incoming and outgoing calls are recorded for training and compliance purposes. CPS Group (UK) Ltd is acting as an Employment Agency in relation to this vacancy. Our new privacy policy can be found here https://company-policies",Algo de responsabilidad,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Software, Dotación y selección de personal",0,None,False,,4,None
584,2259975628,2020-10-31,Coterie,Data Infrastructure Engineer aka DataOps (Remote),"Minneapolis, MN, US","Data Infrastructure Engineer aka DataOps  Data is the foundation of what we do. It’s what made insurance one of the first industries to make computers a standard in doing business. But it’s time to help our industry make a leap, and to do that we need data infrastructure built on the principle of flexibility. And we’re not just talking scale, we’re talking a breadth of data types, all feeding into our host of applications and risk engines. It’s why we don’t think of data infrastructure as only an ETL thing, it’s an everything thing, and it’s why we need you, a DataOps engineer.  Full Job Description  You’re the wizard who will shrink and expand our data infrastructure to the tides of our growth. As a result, this role will be a mixture of old-school DBA obsession with optimization, DevOps penchant for automation, data engineering’s need for order at scale, and a data scientist’s desire for usable data. You’ll work alongside our director of data, our data scientists, data engineers, and software engineers to build robust data infrastructure that can support our vision of making small commercial insurance easy, intuitive, and well-priced.  Requirements Must have 5+ years of experience building and optimizing big data data pipelines, architectures and data sets within a cloud computing environment (Azure, AWS).Must have advanced working SQL knowledge and experience working with both RMDBs in a query authoring capacity as well as technologies such as No SQL and unstructured data stores.Must have expertise in DataOps techniques and modern cloud computing technologies, most importantly deep familiarity with the Azure stack.Fluency with CI/CD tools (Jenkins, Ansible, etc…) Ideally infra-as-code via Terraform.Hands-on experience with git based repositories. Git Commands, git process flow, branching & merging structure.Fluent scripting in PowerShell, Shell, Bash, or pythonMust have previously built processes supporting data transformation, data structures, metadata, dependency and workload managementStrong attention to detail including precise and effective customer communications and proven ability to manage multiple, competing priorities simultaneouslySuperior verbal and written communications skills and history of excellent team collaborationExperience with Azure Data Factory Bonus Previous work experience partnering with data analytics teams to increase the effectiveness of BI systems Experience with container technologies(Docker, Kubernetes)Fluent in Python, C#, or C++Experience with transaction data (finance, insurance, payments)  Benefits  Coterie has excellent benefits for all full-time employees. Through our partner Insperity, we offer: Health insurance through United Healthcare (UHC) (we pay 90%)Dental (UHC) and vision insurance (VSP) (we pay 100% but there are limits)Unlimited PTO. We expect you to take at least 80 hours during the year not including most bank/federal holidays - Christmas Day, New Years Day, Thanksgiving, July 4, Memorial Day, Juneteenth, Labor Day. We also encourage the celebration of personal holidays and important family events.Basic Life InsuranceFlexible Spending Account (FSA)Continuing Education Stipend100% RemoteA culture with a deep belief in Intentionality, Inclusion, and treating you like the professional you are. Our HQ is in Montgomery, Ohio (7817 Cooper Rd. Suite B Cincinnati, OH 45242), but we operate as a 100% digital business which makes it easy to work remotely as your role allows.  About Coterie  Coterie is a business insurance startup that distributes flexible-term policies on our website and partner platforms. We value integrity, humility, passion, and intelligence. If you want to push yourself, promote social good, and re-shape a $200B+ market, we’re excited to talk to you.  Powered by JazzHR  PyZM68AVtT",Sin experiencia,Jornada completa,Tecnología de la información,"Software, Internet, Seguros",6,None,False,,80,None
585,2195975415,2020-10-21,Current Health,Data Engineer,United Kingdom,"Who are Current Health? Current Health is a global healthcare technology company, focused on predicting illness and delivering earlier intervention so that every human can live a healthier, longer life. In 2020, Current Health has grown 8500%, partnering with some of the world’s leading healthcare institutions and pharmaceutical organizations and improving health outcomes for patients across the world. What does a Data Engineer at Current Health do?As a specialist in data engineering, you will help us scale our data pipelines to meet new challenges as we grow as a business and gain increasing numbers of customers and use-cases. We are currently improving our event driven, message based microservice platform to embrace real-time, highly available distributed streaming technology which will enable our engineers and data scientists to meet our ambitious product goals over the coming months Sounds great, what experience do I need? Have a degree in Computer Science, related field, equivalent training or work experienceCommercial experience in areas of distributed real-time stream processing and complex event processing techYou will have experience working with large amounts of dataHave a deep knowledge of at least one modern programming language and a willingness to learn new ones as requiredHave experience writing tests and testable codeBe comfortable reviewing, releasing, deploying and troubleshooting your and other people's codeBring experience to the team in areas of distributed real-time stream processing and complex event processing techHave previous success in engineering at scale in a distributed systems environmentHave a practical understanding of cloud computing and networking - we use AWS with Nomad for micro-service managementHave experience collaborating with data scientists, product teams and other consumers of data assets Bonus points for... Familiarity with key big data technologies, such as Hadoop, MapReduce & Apache Spark.A background involving Apache Kafka or other distributed data streaming platformsExperience with API design/development Technologies we use Backend: Java (Spring), Python, .NETFrontend: JavaScript (TypeScript), Angular, Ionic, npmDatabases: PostgreSQL (RDS), Couchbase and othersInfrastructure: Linux, RabbitMQ, AWS via Terraform, Chef, Nomad, Consul and FabioData Science and ML: H2O, Jupyter, TensorFlow, Keras and SparkMonitoring: DataDog and ELK",Intermedio,Jornada completa,Tecnología de la información,Atención sanitaria y hospitalaria,46,None,True,,368,ACTIVELY_HIRING_COMPANY
586,2205158974,2020-10-14,Acute Change,Machine Learning Engineer,United Kingdom,"MACHINE LEARNING ENGINEER | ARTIFICIAL INTELLIGENCE ENGINEER | AI RESEARCH ENGINEER | MACHINE LEARNING LEAD | LEAD MACHINE LEARNING ENGINEER  My client is looking for an ML Engineer to work in a small team of engineers and researchers. They are in the software and AI space and are working with some of the most exciting technologies and forward-thinking people… They are a well-funded start-up looking to grow out their team, looking for a Machine Learning expert with the following experience: ﻿Responsibilities:Manage Machine Learning pipelines from data labelling to distributionCreate machine learning algorithms that find fake accounts and harmful content across social media platformsMachine Learning experiments and tests. Accurately increase the performance of models.Identify best practices for ML Engineering Requirements:An undergraduate degree in Computer Science, Math (or similar), a Master’s in Machine Learning (or equivalent experience).A minimum of 2 years of professional experience working in Machine Learning.Sufficient experience with deep learning and its frameworks.Experience working in machine learning teams where you were responsible for entire projects.Expertise in Python and its libraries for machine learning.",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Consultoría de estrategia y operaciones,275,None,True,,781,JOB_SEEKER_QUALIFIED
587,2220951884,2020-10-20,None,Lead Data Scientist,United Kingdom,"Principal Data Scientist    We have opportunities to join our growing team of Data Specialists across Data Scientists, Data Engineers and Solution Architects.  We have offices in Bath, London, Barrow, near Portsmouth and Plymouth and we also promote remote working in the United Kingdom. There is often travel required to customer sites or to attend meetings, with many of our customers being in the South West and London areas.  What is the role and what are we looking for?  As a Data Scientist you will be empowered to develop, implement and support internal R&D projects: as well as delivering external R&D projects and consultancy to our customers. Applying your knowledge and experience, you will build our AI/Data Science portfolio to support winning future work. As part of this varied role you will also contribute to bid and proposal writing.   The successful candidate will have a love of problem solving and be comfortable working collaboratively, but also have the drive and ability to work independently. To thrive in this role you will need:   ·      A degree in a numerical subject – such as Machine Learning, Natural Language Processing, Data Science, Computer Science, Statistics, Physics or Engineering  ·      Practitioner experience of Python and/or R – in particular packages such as Pandas, Numpy, SciPy, Matplotlib (or equivalent)  ·      Experience of and/or interest in Machine Learning, data science, statistical data analysis and data visualisation  ·      Confidence to build relationships with both internal teams and external customers, and ability to communicate effectively with both technical and non-technical audiences  You should expect to lead teams including developing new capability and skills and supporting others whilst doing so. As a technical lead you can expect to deliver the creation of new solutions whilst supporting the bidding and delivery processes. Often as the sole data specialist on a project you should be able to communicate effectively with clients and support the wider business development effort where possible.  Please note, some of the projects within our Information Systems team require UK Government security clearance. The successful candidate will need to hold, or be able to gain, UK Government security clearance.   What can we offer you?   You will be part of an established, yet growing, AI and Data Science Team.  We value building a diverse team of data professionals where, together, we can provide outstanding expertise and benefit to our customers. From an internal perspective, our team is at the forefront of the business’s digital strategy. We are responsible for finding solutions to some of the important data challenges within BMT and improving our products.    From an external perspective, we provide professional data services consultancy support to our customers, ranging from providing expertise in Data Architecture, Data Governance and Data Management to support customer internal data initiatives: R&D in the form of rapid prototype generation using data science, Machine Learning and AI techniques: to supporting our customers using knowledge transfer sessions.   Our external projects include designing, prototyping, and building next-generation data science/machine learning services that support overall solution development. We deliver innovation projects across a range of Technology Readiness Levels (TRLs). We often work with the customer to source data sets, perform exploratory data analysis and communicate what approach will be most appropriate given their problem. We interact with them to collaboratively develop solutions to meet their needs.   Some of our recent projects have included:   ·      Automating the process of transforming satellite images into maps to support disaster relief responders ·      Using the Unity game engine to train a drone to land on a ship in a virtual environment  ·      Using computer vision to detect terrorist propaganda in online content  ·      Using Natural Language Processing to develop tooling for the BMT TechDocs team to automatically convert scanned PDFs into structured information speeding up manual processes ·      Anomaly detection for detecting anomalous landings from aircraft flight data ·      Data governance for a Cyber Security customer  BMT is an equal opportunities employer and is committed to eliminating discrimination and encouraging diversity amongst its workforce. To view our full policy please click here - https://www.bmt.org/careers/our-benefits/diversity-and-equality/. The wellbeing of the team is central to our success, so workloads are managed effectively and we don’t have a work late culture. On top of this we have a host of benefits and family friendly policies designed to support our people.   What do we do?  BMT is a leading, independent consultancy serving defence and security customers. We are known for our innovation, expertise and ability to tackle the most complex design and systems issues.   We are platform agnostic - we provide unbiased advice and choose the best approaches for our clients.    Apply online  Does this sound like you? If so, please submit your application via our company Careers page. To keep up to date with the latest BMT news, follow us on LinkedIn | Twitter | Facebook | YouTube.",Intermedio,Jornada completa,"Tecnología de la información, Consultoría",Departamento de defensa y del espacio exterior,47,None,False,,379,ACTIVELY_HIRING_COMPANY
588,2249314939,2020-11-05,Gazelle Global,Data Scientist,Poland,"DevOps CI/CD Architect - 12 month contract  One of my clients is looking for an experienced DevOps CI/CD Architect to be part of a long term project based in Poland. Requirements: Design and oversee end-to-end CI-CD solution with detailed focus on Pipelines, new Integration with External tools. Design and oversee the migration to new toolset: GITLab. Drive definition of non-functional requirements (eg. monitoring, performance, security, data privacy)Hands-on using /implementing CI-CD. APPLY NOW!!",Intermedio,Contrato por obra,"Ingeniería, Tecnología de la información",Dotación y selección de personal,35,None,True,,178,ACTIVELY_HIRING_COMPANY
589,2265046293,2020-10-17,Crowdskout,Behavioral Scientist,"New York City, NY, US","Crowdskout is a platform for advocates to create, power, and cultivate communities at local and national levels. We provide mobilization and data tools to non-profits, issue advocacy groups, electoral groups, and corporate social impact teams. We are building capabilities that live beyond a 4-year election cycle, and outside of a traditional 'Red/Blue' partisan paradigm.  We are looking for a Behavioral Scientist to join our growing Research Team. You will help Crowdskout to design, implement and analyze experiments and evidence-based interventions. As part of a cross-functional team, you will be involved in research collaborations within product, across client organizations and more broadly in society.  If you are highly motivated, super passionate about democracy, and want to join a close-knit team that is looking to build great things for regular people, Crowdskout may be for you. This is a full-time position in Durham, NC: Salt Lake City, UT: Austin TX: Washington, DC: New York City, NY, or fully remote.  Responsibilities:   Be an in-house expert in the principles and mechanisms of behavior change  Design, implement and analyze quantitative behavioral experiments (A/B tests, RCT, etc.) across Crowdskout. products and for client engagements. Work closely with User Researchers to understand user needs, goals, and experiences to create product features and content and Product Analysts to design and implement quantitative validation studies for new products and features.  Elucidate data-driven insights for product and content development for Crowdskout and clients and quickly learn from experiments to put forward new hypotheses, including identifying opportunities to improve the behavior change potential of products across the platform and organization. Conduct literature reviews and maintain up-to-date knowledge of academic research and market trends related to advocacy, civic engagement, voting, policy, campaigning, etc. Contribute to the development of quantitative survey instruments and user discussion guides  Develop behavioral and societal-level metrics and conduct appropriate statistical analysis of impact   Collaborate to develop and implement hands-on workshops, seminars, and other educational activities for Crowdskout focused on applied behavior analysis and design Improve data literacy across the organization and drive a culture of data-driven decision making   Must-haves   Deep experience in applied behavioral science: ideal candidate has a Master's Degree (or higher) in behavioral economics, experimental psychology, political science, applied behavior analysis, or closely related field 4+ years experience using evidence based behavior change interventions  Extensive training in statistical analysis and data management with demonstrated ability to use syntax-based statistical packages (e.g. R, SAS, Stata, MATLAB, etc.)  A love of experimentation and expertise with experimentation tools Excellent communication, collaboration, and interpersonal skills Strong project management skills  Nice-to-haves:    Understanding of political processes and campaign culture 2+ years proven experience working on product teams Exposure to the technical aspects of analytics, data science and data visualization software tools (Google Analytics, Mixpanel, SQL, Tableau etc.) Knowledge of technology and how to use technology and online tools in innovative ways    Crowdskout is an equal opportunity employer that encourages diversity across all spectrums in its hiring, without regard to race, gender, age, color, religion, national origin, marital status, disability, sexual orientation, or any other protected factor. With that being said, we wouldn't be able to accommodate candidates in need of work sponsorship at this time since we are a small company. If you find this role interesting and you hit on the elements above, please apply!",Algo de responsabilidad,Jornada completa,"Investigación, Análisis, Tecnología de la información","Servicios y tecnologías de la información, Software, Internet",13,None,False,,109,ACTIVELY_HIRING_COMPANY
590,2268564084,2020-11-06,Intuitext,Junier User Experience Designer,"Bucharest, Romania","Linkedin: We are an educational company with experience in the Romanian market. We have multiple online products for children ranging from 6-14 years old as well as teachers. We are looking for a Junior UX designer.  You will be responsible for building a clean and effective user experience for our customers, the children, as well as teachers. By working cross-functionally, you will understand needs from the product management, engineering, and business stakeholders and will be able to build solutions that fit those needs.  You will work closely with the another senior UX designer that will mentor you. You will work on multiple projects. You will also work with a product manager, teachers, machine learning developers and mobile developers during the development of the app. Post launch you will work with data scientist to analyse user behavior and improve the solution. You will work remotely from your home, for the next 6 months. We are looking for someone to work 9 am - 18 pm.  Responsibilities: Develop wireframes for the mobile app based on user interviewsDevelop user friendly screens that address the functionality of the app so farcreate UI for products15 % of time have user interviews for: UX Testing design15% of time have user interviews for discovery of user needs , and determine the value of feature or product to the userVery important: Make sure the business needs are met though the UX. You should have a business sense. Be interested in the usage of the app after launch via analytics, and determine what user behavior is adopted5% of time: watch user behavior on recordings for users using the appimplement usability best practices in the company, so that the product tests for usability correctly. Experience with doing UX for mobile apps Qualifications: Don’t expect us to give you tasks 30% of the time, you should have a very proactive attitude, to drive team forward.You should be very protective about a product, be very detail oriented.Be heavily oriented to UX research.Be heavily oriented to user research. You will collaborate with a user researcher. Portfolio of mobile apps designed that you can present (preferably addressed to children)",Algo de responsabilidad,Jornada completa,Tecnología de la información,Publicaciones,45,None,True,,241,ACTIVELY_HIRING_COMPANY
591,2280271350,2020-10-11,CVEDIA,Senior Machine Learning Engineer - Remote - EU Time Zone,"London, GB","CVEDIA is a funded AI company that develops deep learning solutions for some of the largest organizations on the planet. We develop neural networks for computer vision systems (imagery-based AI). We are looking for a Senior ML Engineer to help us create more accurate neural networks that perform great when deployed on the edge. In this role, you will have the opportunity of working in a team of exceptionally talented and driven individuals who are all making a massive impact on our business. There is no micromanaging or babysitting at CVEDIA, everyone here drives their own ideas all the way from start to finish, everyone is given an equal opportunity to flourish and see the fruits of their labour. Responsibilities Take on the challenge to improve the performance of real world autonomous systems and be a crucial part in shaping our clients' success.Work on the entire DL pipeline, including the generation of data, training networks, and optimizing models for deploymentInvestigate and develop deep learning architectures for imagery-based perception systemsCollaborate with engineers and other data scientists to evaluate and improve our systemsAble to be the main point of contact for enterprise projects  RequirementsSolid experience as a Machine Learning Engineer or as a Data EngineerSolid Experience with Python,Pytorch, OpenCV, Matplotlib, Numpy, SciPyAble to work with multiple programming languages, including C#/C++Confident verbal and written EnglishAble to balance pragmatism with planning and long-term thinkingProactive and self-sufficientAttention to detailLeadership skillsExperience working remotely is a plusExperience with neural network optimization (pruning/quantizing) is a plusExperience using Unity (Game Engine) is a plusBSc in Computer Science, Engineering or relevant field What We Offer Fully distributed team, located in 19 countries4 weeks paid holiday per yearYearly team meetup - this year we went to Portugal!Scrum development processAnti-discriminatory company culture - we won't discount you for things like needing to pick your kids up from school, your age, your ethnicity, or your genderAn excited, communicative, and helpful team - we keep our work environment positive, but we also place importance on honesty Our ValuesPassionWe need both energy and passion to develop cutting edge AI. To succeed at CVEDIA, you'll need to have a strong investment in both your career and the role of AI in the future of the planet.CommitmentCVEDIA has the opposite of a 'quick-n-dirty' mentality. Every aspect of our technology has been meticulously built, and is always the product of very hard work.AutonomyCarrying confidence in the work we do individually is required to work at the pace that we do as a team. Academic research, tutorials, and even creating our own solutions with the tools we have are all on the board during a regular day's work.JoyIt's one of our greatest strengths to bring excitement into our workplace. We carry this energy into meetings, project planning, and our dedication to our work, and focus on work that feels meaningful.CommunicationHonest discussions are imperative to the flow of work and ideas. Team members need to be able to effectively communicate complex ideas to those who don't work in their field. It's a regular occurrence to spontaneously discuss plans and ideas with any team member on the fly, including our CEO or CTO. Each team member is respected equally and acts as a valuable contributor. How to Apply Please mention your city and country of residence in your applicationEnglish applications only - a professional speaking and writing command of English is required for this roleDue to time zone difficulties, we're currently only accepting applicants in European timezones If you live outside of the EU time zone please do not apply. During the hiring process you will be asked to answer a technical questionnaire and fill out a relevant task. These questions and task are crucial for us to evaluate your technical skills and knowledge.  For more information about us and to see our work, please check out cvedia.com",Algo de responsabilidad,Jornada completa,"Ingeniería, Tecnología de la información",Servicios y tecnologías de la información,5,None,False,,27,None
592,2222688334,2020-10-29,Pon,Senior Data Scientist,"Almere, Flevoland, Netherlands","Ben jij diegene die onze klanten verder helpt door middel van data gedreven oplossingen? Als Senior Data Scientist leid je data science projecten, reis je de hele wereld over om trainingen te geven en voer je klantgesprekken over data-analyses. Dat doe je bij bedrijven die onder Pon vallen en die onder andere luxe auto’s, elektrische fietsen en veelzijdige graafmachines produceren. Landen als Australië, Amerika en Singapore liggen aan je voeten.Ook dichter bij huis, in Europa, verspreid jij jouw kennis. Door projecten te leiden help jij klanten met uiteenlopende vragen. Een bekend Duits fietsmerk kan zomaar bij jou aankloppen met de vraag waar zij in Nederland en België winkels moeten openen om hun omzet te maximaliseren. Je stelt direct een team samen van een of twee Junior Data Scientists om deze vraag te analyseren, een algoritme te creëren en een tool op te leveren. Dankzij jouw hulp weet de klant precies waar een nieuwe winkel de meeste kans van slagen heeft. Als Senior Data Scientist houd je je verder bezig met het:vertalen van business vraagstukken naar data gedreven oplossingen:voeren van kennismakingsgesprekken en het schrijven van voorstellen.leiden, bewaken en evalueren van verschillende projecten (deze duren gemiddeld tussen de 8 en 12 weken):adviseren van (Senior) management met actiegerichte inzichten:leiden van een klein team met Junior Data Scientists en definiëren van persoonlijke ontwikkelplannen:ontwikkelen en organiseren van data analytics trainingen:zelf volgen van cursussen en trainingen:experimenteren met de nieuwste technieken en innovaties.  Het teamHet Datalab bestaat uit 18 Data Scientists, Dataops Engineers en AI specialisten. Binnen het team rapporteer je aan een Lead Data Scientist en stuur je zelf 3 of 4 Data Scientists aan. Het Datalab is een informeel en dynamisch team dat snel beweegt. We zijn een jonge groep die van een uitdaging houdt. Wat vragen wij van jouGoede communicatieve vaardigheden zijn belangrijk. Niet alleen omdat je projecten leidt en collega’s helpt, ook omdat je veel met klanten praat. En stiekem ook omdat we een gezellig team zijn dat open met elkaar communiceert. Optimistisch, klantvriendelijk en analytisch sterk ben je zeker. En daarom heb jij:Wetenschappelijk niveau door opleiding of ervaring:3 à 4 jaar werkervaring als Data Scientist of Data Analist:3 à 4 jaar ervaring in database handeling (i.e. SQL, NoSQL):3 à 4 jaar ervaring met Python/Java/R of vergelijkbare talen:Ervaring met het ontwikkelen van oplossingen die data science methodes gebruiken zoals NLP, simulation models, machine learning, forecasting, AI, etc.:Ervaring met AWS is een pré:Ervaring in de mobiliteit industrie is een pré:Ervaring met IoT/ Smart Cities/ Connected Assets is een pré. Wat bieden wijDe (digitale) wereld ligt aan je voeten als Senior Data Scientist. Ook bieden we je op fulltime basis:een bruto maandsalaris tussen €4.200 en €5.000:thuiswerkmogelijkheden in overleg:een prestatiebonus met een maximum van 15% van je jaarsalaris:20 vakantiedagen, EN:een individueel keuzebudget: 13 extra vakantiedagen, 8% vakantiegeld:een goede pensioenregeling:een leaseauto, iPhone en Macbook:alle ruimte om door te leren:de mogelijkheid om mee te doen met de Pon Fit-activiteiten, zoals bootcamps, wielerrondes, hardloopevents, golfclinics en nog veel meer.  Over DatalabDatalab en innovatie zijn onlosmakelijk met elkaar verbonden. Op het gebied van analytics zorgen wij binnen Pon voor nieuwe inzichten, innovatie en groei. En dat voor alle bedrijven die onder Pon vallen. Zo zijn Porsche, Gazelle en Caterpillar onze klanten. We zijn een jong team vol technische kennis en enthousiasme en omdat we regelmatig in duo’s naar het buitenland reizen is de band onderling hecht. Naast de gezelligheid vinden we ontwikkeling zeker ook belangrijk. We organiseren regelmatig Datalab-dagen waarbij we aanschuiven bij trainingen en cursussen, gevolgd door een borrel. Innovatie moet wel leuk blijven.  Overige informatieHet sollicitatieproces bestaat uit 3 rondes:Je stuurt ons je CV en motivatie brief:Als je hierna geselecteerd wordt dan heb je een eerste gesprek met je potentiële manager en een teamlid:Als dit een fit lijkt te zijn heb je nog een tweede gesprek met een senior data scientist en een ander teamlid. ContactinformatieWe hebben je al veel verteld over de functie van Senior Data Scientist. Wil je graag meer inhoudelijke informatie? Dat kan. Neem contact op met Koen Haenen via koen.haenen@pon.com. Wij werven en selecteren onze nieuwe Senior Data Scientist zelf, daarom reageren we niet op aanbiedingen van intermediairs.",Intermedio,Jornada completa,Tecnología de la información,Desarrollo y comercio internacional,12,None,False,koen.haenen@pon.com.,267,None
593,2288218612,2020-10-14,WalletHub,Senior Data Scientist - Remote,"Washington, D.C., DC, US","WalletHub is one of the leading personal finance destinations in the US and rapidly growing. We're looking for a highly experienced and motivated Senior Data Scientist for a full-time, permanent position.  The main objective of the Data Science/Machine Learning Team is to improve WalletHub's services and core product. This has a direct impact on the overall user experience.  Making the right personal finance decisions by sifting through vast amounts of available information can be a daunting task for almost anyone. This is because a large number of interrelated factors need to be taken into account when making such decisions.  By designing and constructing data-driven models, the Data Science/Machine Learning Team is able to provide our users with indispensable knowledge and meaningful advice on how they can achieve their personal finance goals.  Such Goals Include  Selecting the best financial products for your needs  Taking the right actions to improve your credit score  Anticipate your future financial health based on your current financial status and history With these goals in mind, our Data Scientists use the latest cloud technologies and machine learning tools in order to exploit the potential of data analytics. We always have new and interesting projects on the horizon that aim to help our users reach their personal finance aspirations!  Expected work schedule is 50 hours/week Monday to Friday. In case you will be working from outside the US, please be aware this position requires an overlap with EST business hours.  Responsibilities  Modeling complex problems, discovering insights and identifying opportunities through the use of statistical, algorithmic, mining and visualization techniques  Participating in the areas of architecture, design, implementation, and testing  Proposing innovative ways to look at problems by using data mining approaches on the set of information available  Designing experiments, testing hypotheses, and building models  Conducting advanced data analysis and designing highly complex algorithm  Applying advanced statistical and predictive modeling techniques to build, maintain, and improve on multiple real-time decision systems Qualifications  You are the ideal candidate for this job if you have:  At least 8 years experience in Python, Spring, MySQL (or any relational database) and Java  Experience with databases (including NoSQL)  Experience in machine learning frameworks and libraries  Supervised and Unsupervised learning  Machine learning concepts and techniques: Regularization, Boosting, Random Forests, Decision Trees, Bayesian models, Neural networks, Support Vector Machines (SVM)  Experience with the whole ETL data cycle (extract, validate, transform, clean, aggregate, audit, archive)  Computer Science or Mathematics or Physics degree  Excellent communication and analytical skills  Willingness to work hard (50 hrs per week)  Very good English Nice To Have But Not Required  Experience with Apache Spark  Natural Language Processing (tokenization, tagging, sentiment analysis, entity recognition, summarization)  R programming language Compensation  Very competitive salary based on prior experience and qualifications  Potential for stock options after the first year  Raise and advancement opportunities based on periodic evaluations  Visa sponsorship (after 18 months with the company, based on performance in case you will be working from outside the US).",Algo de responsabilidad,Jornada completa,Otro,"Servicios y tecnologías de la información, Software, Servicios financieros",0,None,False,,1,None
594,2268702009,2020-11-02,DW Simpson Global Actuarial & Analytics Recruitment,RETAINED - Data Science Manager / Senior Data Scientist (Minnesota #49602),"Minneapolis, Minnesota, United States","RETAINED - Data Science Manager / Senior Data ScientistMinneapolis, MN Growing Minnesota client is seeking a talented Data Science Manager who will oversee and participate in the delivery of predictive models for Underwriting and Claims. This is a great opportunity for an individual to help build out a team and grow in rank and responsibility. Remote opportunity available for the right candidate. (#49602) RequirementsP&C insurance backgroundExcellent communication skills3+ years’ experience leading analytics projectsMentor other data scientistsMust be proficient with R or PythonMasters or PhD preferred",Intermedio,Jornada completa,"Análisis, Finanzas, Gestión de proyectos",Seguros,28,None,True,,173,JOB_SEEKER_QUALIFIED
595,2276923763,2020-11-05,ReCharge Payments,Senior Data Engineer,"Remote, OR, US","Overview  The centralized Data and Analytics team at ReCharge delivers critical analytic capabilities and insights that drive definition and implementation of our business strategies. The Data Engineer opportunity is ideal for someone who is passionate about wrangling and building pipelines for multiple large sets of data from disparate sources to provide end to end data solutions, empowering the organization to meet key business objectives.  As a Senior Data Engineer, you will own and architect Recharge’s data landscape. You will combine product usage, behavioral, transactional, business systems, and third-party data into the analytics pipeline. You will work closely with our analytics and engineering teams to implement solutions to answer complex questions and drive business decisions.  What You'll Do   Live by and champion our values: #day-one, #ownership, #empathy, #humility.   Hands-on leadership, influence, and development of all things data services.   Develop modern data architectural approaches for business intelligence reporting and analytics, including that for machine learning models and data science, ensuring effectiveness, scalability, and reliability.   Design, develop, implement, and optimize existing ETL processes that merge data from disparate sources for consumption by data analysts and scientists, business owners, and decisions makers.   Complete current evaluation of new ETL software options, propose recommendations, and implement the solution.   Facilitate data transformation, normalization, cleansing, aggregation, workflow management, and business rule application.   Detect data quality issues, identify their root causes, implement fixes, and design data audits to capture issues.   Distill technical requirements into the product development and operational process via continuous collaboration with product, engineering, and analytics team members.   Influence and communicate with all levels of stakeholders including analysts, developers, business users, and executives.   Use analytics to influence product development, surfacing data around product usage and customer behavior.   ETL tool evaluation and implementation to prepare for scaling and efficiency.   What You'll Bring   Typically, 6+ years experience in a data engineering related role (Data Warehouse Developer, ETL Developer, Business Intelligence Analytics, Software Engineer) with a track record of manipulating, processing and extracting value from datasets   Experience working with a variety of ETL platforms (Matillion {preferred}, CloverETL, FiveTran, Stitch, DBT, Spark, AWS Glue, DataFlow)   3+ years of hands-on experience designing and building ETL pipelines for ingesting, transforming and delivery of large amounts of data, from multiple sources into a Data Warehouse/Data Lake.   Experience with a variety of data storage platforms (Snowflake {preferred}, Redshift, MySQL, Postgres, Oracle, RDS)   Expert proficiency in SQL   Deep understanding and application of modern data processing technology and real-time/low-latency data pipeline and ETL architectures   Strong stakeholder interaction and influence experience at executive, business stakeholder, and engineering team levels   Bachelor degree or equivalent experience    Who We Are  Since 2014, ReCharge has helped over 15,000 merchants launch and scale their subscription business. Be it a curated monthly box, recurring necessities or access to exclusive perks, ReCharge powers billions of dollars in annual processing for nearly 30 million consumers. Our remote-first team of 250+ is building the future of subscription commerce. Come join us on our mission to connect and empower the world through payments.  ReCharge | Instagram | Twitter | Facebook  ReCharge Payments is an equal opportunity employer. In addition to EEO being the law, it is a policy that is fully consistent with our principles. All qualified applicants will receive consideration for employment without regard to status as a protected veteran or a qualified individual with a disability, or other protected status such as race, religion, color, national origin, sex, sexual orientation, gender identity, genetic information, pregnancy or age. ReCharge Payments prohibits any form of workplace harassment.",Intermedio,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Internet",10,None,False,,102,ACTIVELY_HIRING_COMPANY
596,2222455886,2020-10-29,Charlton Howard,Senior Data Scientist,"London, England Metropolitan Area","Are you a PhD/Masters graduate looking to build your career as a Data Scientist? Learn new skills in Data Engineering? Work on a variety of projects using a range of cloud tech? In a few short years this business have already established themselves as a recognised Data Science consultancy, delivering huge insight in fraud detection, bitcoin transaction risk, real-time predictive analytics (to name a few) to some of the biggest FTSE businesses in London. We are beginning to grow our Data Science function, and with that are looking to bring on a Data Scientist to help deliver on projects as well as growing out our DS function As the Data Scientist, you will be working closely Lead Data Scientist and other Data Engineers, learning from both, picking up skills in building data pipelines using a variety of different using a variety of tools, such as Apache Spark and Kafka, and improving your Python expertise, whilst honing you skills as Data Scientist. So what do you need as a Data Scientist:Commercial experience of delivering Data Science projects at a commercial levelA Masters or PhD in a Mathathmatics, Statistics or Data Science related fieldStrong programming skills in Python, R or any other programming languageA good fundimental understanding of statistical models This is an amazing opportunity for a Data Scientist, not only to learn both sides of the coin in Data Science and Data Engineering (which will accelerate your career massively), but also you as a Data Scientist will be having a massive impact on some of the biggest organisations in the country!!! Apply to this Data Scientist position now and we will be in touch to tell you more. Charlton Howard is a Trading Name of Talent Point Ltd. Talent Point Ltd and Charlton Howard are equal-opportunity employers and do not discriminate against these or any other class protected by applicable law. No terminology in this advert is designed to discriminate on grounds of gender, race, colour, religion, creed, disability, age, sex or sexual orientation.",Intermedio,Jornada completa,Tecnología de la información,Servicios y tecnologías de la información,116,None,True,,376,JOB_SEEKER_QUALIFIED
597,2252758935,2020-10-04,Jefferson Frank,AWS Data Engineer / Remote,"London, GB","Data Engineer / Remote (UK Based)  Up to £65,000  London  AWS Cloud Platform | Remote Interview / Working (2 days in the office every 3 - 4 weeks) | Progression Opportunities | Relaxed Working Environment | Fin-Tech Start-Up  A new fintech start-up is on the lookout for a new data engineer to join their in-house team.  You'll be joining as a key member of the engineering team and working on a new enterprise-grade platform. You'll be working on microservices architecture with analytics, AI and ML capabilities to leading SAAS platforms.  What you'll be working on?   Developing and designing solutions for new data pipelines and features Improvement of existing features Working on data architecture alongside Data Scientists Researching new tech to be at the forefront of modern development!  The techy part…  Have knowledge of   Strong Python Knowledge Working knowledge of AWS services e.g AWS Batch, Lambda, S3 Working with relational SQL and no-SQL databases Experience building and optimizing data pipelines, data sets and architectures Exposure to ETL pipeline building and tools  If you think this is the next exciting opportunity for you - apply today!  THIS ROLE DOES NOT PROVIDE SPONSORSHIP AND YOU MUST HAVE THE RIGHT TO WORK WITHIN THE UK  Jefferson Frank is the Amazon Web Services (AWS) & DevOps recruiter of choice. We work with organisations worldwide to find and deliver the best AWS & DevOps professionals on the planet. Backed by private equity firm TPG Growth, we have a proven track record servicing the AWS permanent and contract recruitment market and, to date, have worked with over 30,000 organisations globally from our offices in North America, Europe, and Asia-Pacific.",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Dotación y selección de personal, Recursos humanos",0,None,False,,5,ACTIVELY_HIRING_COMPANY
598,2251924542,2020-10-14,Cast & Crew,Sr. Data Engineer,"Burbank, CA, US","Position Overview  The Senior Data Engineer is an expert in business intelligence strategies and technologies comprising common functions such as data integration, data storage, data modelling, data warehousing, data mining, data analysis/analytics, and data visualization. The primary responsibility of the position will be analyzing complex business requirements along with C&C's overall strategy in order to develop self-service business intelligence solutions. A background in financial systems is a plus, as is development experience in an iterative, Agile/SCRUM environment.  Essential Functions  Shapes the BI architecture based on business need and technology efficiency. Work closely with QA, business analysts and customers to design and implement new feature requests Ensures standards and directional adherence across the various technical domains. Work with internal and external technology experts to ascertain system functional capacity, constraints and support lifecycles. Evaluate and make recommendations to ensure technology investments are optimized. Proactively identify unnecessary complexity and potential failure points, assist with creating plans to reduce or eliminate where appropriate. Build and maintain strong relationships with technology teams and business partners to facilitate improved alignment of technology initiatives to business strategies Design and Build BI solutions using technologies like Snowflake, Oracle, SQL Server, RDS PostgreSQL, ETL Tools, BI servers, Report development Tools, data event streaming pipelines.   Qualifications  5+ years hands-on Business Intelligence experience working with modern BI tools like, Tableau, SSRS. 5+ years experience with data modeling, large-scale batch, and real-time data processing, ETL design, implementation and maintenance. Hands on experience is Snowflake and RDS PostgreSQL Strong experience in massively data streaming, parallel processing & columnar databases. Strong understanding of common BI data functions, including data integration, data storage, data modelling, data mining, data visualization, and data analytics. Strong understanding of Big Data technology stack and methodologies: data streaming and data lake solutions. Strong SQL skills including the ability to write complex queries for prototyping and performance Familiar with scripting languages such as Python Familiar with managed data services on cloud platforms such as AWS. Solid experience designing and building RESTful APIs Excellent communication and teamwork skills: Results oriented, self-motivated, resourceful team player BSCS or equivalent required, advanced degree a plus Applicants must be authorized to work in the U.S  Special Work Conditions   Schedule must be flexible in order to accommodate client and business needs. Sedentary - Exerts up to 30 lbs. of force occasionally and/or a negligible amount of force frequently or constantly to lift, carry, push, or pull. Involves sitting most of the time but may involve walking or standing for brief periods of time   Benefits  Cast & Crew provides a comprehensive package of employee benefits including: Medical, Dental, Life/AD&D: LTD, additional voluntary benefits such as STD, Vision, paid vacation, holidays, and sick pay: 401(k) and employer match, Additional Life Insurance, and other company perks and benefits!  Please note: Due to the high volume of applicants, it is likely that only shortlisted candidates will be contacted.  About Cast & Crew  We enable great content. Films, television, streaming, live events. We make difficult tasks easier - think payroll, human resources, accounting, financial management and workflow. Great content is difficult enough, so we've built solutions and software and, most importantly, linked everything together through a central hub. In English, that means Cast & Crew solutions talk to each other, making those difficult tasks we listed above a whole lot easier and simpler. We do. So you can. Learn more at www.castandcrew.com  CA residents: Your personal information may be collected in connection with certain services provided by Cast & Crew or its affiliated companies. A summary of your California privacy rights can be found at: https://www.castandcrew.com/privacy-policy/  Cast & Crew is an equal opportunity employer committed to hiring a diverse workforce and sustaining an inclusive culture. It is our policy to provide equal employment opportunities to all individuals based on job-related qualifications and ability to perform a job, without regard to age, gender, gender identity, sexual orientation, race, color, religion, creed, national origin, disability, genetic information, veteran status, citizenship or marital status, and to maintain a non-discriminatory environment free from intimidation, harassment or bias based upon these grounds.",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Servicios financieros",0,None,False,,38,ACTIVELY_HIRING_COMPANY
599,2184045931,2020-10-15,Digitec Galaxus AG,Senior Search Engineer,"Zürich, Schweiz","As a search engineer at Digitec Galaxus, you will be working in 1 out of 17 functional teams on improving the search experience for our customers. At Team Endeavour, we independently define our own roadmap and set ourselves ambitious goals. We research, measure, test, automate, release, innovate - and of course, celebrate our successes! We continuously learn together, and we will actively support you in your personal development. Your work helps over 1 million people in Switzerland and Germany in finding all the needed information for an ideal purchase. TasksOur mission at Team Endeavour is to make the search experience 'relevant, fast & joyful'.Relevant: Together with the data analysts and other engineers continuously improving the relevance of the search results.Fast: Making sure that our search is fast and reliable.Joyful: Together with our UX Designers you will bring ideas that will make the search experience pleasant and easy.You have your finger on the pulse and enjoy dealing with current trends in software development, are open to new ideas and proactively drive your projects forward.In the department you will have the opportunity to take on responsibility when you discover potential and help other teams to get the best out of themselves. Requirements At least 2 years of experience in developing search engines.Basic knowledge of Information Retrieval (BM25, inverted index, evaluation metrics).Experience in software development (preferably C# or Python).As a cooperative team player, you communicate transparently and coherently and you accept constructive feedback openly.You are motivated to constantly learn and share your knowledge with the team.You have a goal-oriented mindset and a high standard for clean code and testing. Our OfferA laid back cross-functional team, comprising of engineers, a UX designer, a product owner, and a data scientist.A lot of influence and responsibility in an innovative and dynamic working environment with flat hierarchiesFinancial support or free time for your personal developmentPossibility to participate in various fun events like hiking, skiing, lan parties, hackathons or Friday night drinks.Flexible working hours and 25 days of vacation per yearFully-Remote work or work in our offices in Zurich or also relocate to SwitzerlandA German language course, so that you understand our jokes (Lächeln)Hackathon: https://www.youtube.com/watch?v=niGPWXfInasHow we develop software: https://www.digitec.ch/en/page/how-our-software-development-is-developing-4475Our tech-stack: https://digit.ec/techradarBehind the scenes: https://www.galaxus.ch/en/magazine?category=27Our values: https://www.galaxus.ch/en/Wiki/5033",Algo de responsabilidad,Jornada completa,Tecnología de la información,Venta al por menor,53,None,True,,463,ACTIVELY_HIRING_COMPANY
600,2291239148,2020-10-14,MURAL,Sr Data Scientist,"San Francisco, CA, US","MURAL is on a mission to inspire and connect imagination workers globally.  MURAL is a digital workspace for visual collaboration that connects over 50 percent of Fortune 100 enterprises. Our platform and services enable innovative teams to think and collaborate visually to solve important problems. People benefit from MURAL's speed and ease of use in creating diagrams, which are popular in design thinking and agile methodologies, as well as tools to facilitate more impactful meetings and workshops.  Global enterprises including IBM, USAA, E-Trade, Intuit, SAP, Atlassian, Autodesk and GitHub have embraced visual collaboration to align their teams, plan in real-time, speed up decision making, reduce travel costs and accelerate a culture of innovation.  MURAL is headquartered in San Francisco and employs over 200 people working across six time zones around the world like Buenos Aires, Atlanta, and across Europe. We recently raised $118m in a series B round of financing, so we are ready to take MURAL to the next level.  YOUR MISSION  As a Senior Data Scientist you will:  Work with Product, Design and Engineering teams to solve problems, identify trends and untap growth opportunities across the user journey. Deeply understand how individuals and teams interact within MURAL. Identify levers to move key product metrics that lead to product growth. Apply statistical models and build machine-learning algorithms to predict people's behaviour in MURAL. Explore and analyze people behavior, product engagement and performance data to suggest fast experiments, features and enhancements. Build and maintain key metric dashboards that are used by product teams. Present complex Product data using easy to understand data visualization techniques. Keep up with the latest trends and methods to unveil insights from the product data  YOUR PROFILE  The top candidate will have the following skills:  You have a Bachelor's degree in Computer Science, Engineering or relevant field: graduate degree in Data Science or another quantitative field is preferred. You have 4+ years' experience doing quantitative analysis in a fast-growing Saas or video games company. You consider yourself an expert at measuring activation, retention, virality, and engagement in a Saas product. You have a proven track record of success as a Data Scientist with hands-on working experience on R, SQL, or Python. You prefer to run an A/B test rather than having long discussions on what changes need to be made in the product. You have experience using business intelligence tools (e.g. Tableau) and data frameworks (e.g. Hadoop).  You enjoy finding insights in a sea of information. You are experienced in BI and machine learning projects You have strong math skills (e.g. statistics, algebra) and problem solving attitude. You have excellent communication and presentation skills. You love working in a fast-paced, growth-oriented environment. Excellent English written and verbal skills.   What We Offer  In addition to being part of our quest to help people empower their imagination, we offer:  Competitive salary and benefits Flexible working hours Ability to work remotely Flexible time off A phenomenal learning environment for you to develop  OUR VALUES  We bring people to our team that care about our mission to inspire and connect creative people globally, and who feel aligned with our values:  Make Others Successful Adapt to Thrive Show Up With a Smile Generate Wows Think Global Play to Win and Have Fun  Practicing equality through imagination work.  MURAL is committed to creating diverse and inclusive workspaces where people can make a positive impact on the world and share their vision of how they achieve it. We are dedicated to working alongside multiple communities to help build this dream and bring it to life.",Algo de responsabilidad,Jornada completa,Otro,"Servicios y tecnologías de la información, Software, Internet",0,None,False,,1,ACTIVELY_HIRING_COMPANY
601,2213041039,2020-10-26,eviCore healthcare,Senior Machine Learning Engineer,"Boston, Massachusetts, United States","eviCore Healthcare is part of Cigna Health, a global healthcare organization that makes an impact on the lives of millions of people. As a Senior Machine Learning Engineer, you will play a critical role in developing and driving products that place eviCore at the center of healthcare innovation! Our Boston inQbator is a hub of innovation, where we have set aside our brightest minds and dedicated our resources for solving tough healthcare problems and providing value to our customers.  We are seeking highly creative and motivated experienced engineers with exceptional skills across multiple disciplines who will complement our growing team and help lead us to innovative solutions. The inQbator team is known for taking on complex problems and combining elements of Natural Language Processing (NLP), Machine Learning, Data Science and traditional software engineering to bring tangible improvements to healthcare processes. Our problem space is open-ended and requires a balance of practical solutions of value in the near term combined with a roadmap of applied research for the more complete solutions demanded by the future.  This includes the latest in deep learning and other state of the art technologies. We work closely and interactively with our product team to deliver on the right mix of these efforts. We translate data into intelligence, help transform the work of clinical decision making and help solve a variety of strategic business problems in healthcare. We also feedback important business insights from our large proprietary healthcare datasets to help shape the our strategic vision. What you'll need to know: Bachelor’s degree in Computer Science, Mathematics, Statistics, Engineering, or a related field. Master’s degree a plus.Strong mathematical and statistical backgroundExperience in applying NLP/ML/Data analysis to solve real-world problemsExperience with a variety of machine learning algorithms and toolsExperience with a diverse set of computing technologies including Python, Linux, Bash, SQL, and more. Experience with healthcare data a plus. Good communication skills and leadership potential",Intermedio,Jornada completa,Tecnología de la información,Atención sanitaria y hospitalaria,116,None,True,,227,ACTIVELY_HIRING_COMPANY
602,2284918687,2020-10-13,X-Mode Social,Data Engineer,"Arlington, VA, US","X-Mode's mission is empowering innovation with quality location with a vision to set the standard for location. This will enable companies to create a more connected tomorrow by making their products and services a reality.  With 60M+ global panel, a first-party, privacy compliant SDK-driven publisher network of 400+ mobile apps, X-Mode supplies its products & services to hundreds of clients in various sectors: digital advertising, market research, location services, financial services, real estate, and smart cities. As an industry leader in providing high-quality dense location data, X-Mode takes the appropriate measures to put the right data privacy and protection policies in place as well as ensure we are transparent with our publishers and enterprise clients.  X-Mode is looking for a full-time Data Engineer who will support the development and maintenance of sustainable data integration pipelines that enable our team to perform timely analyses. The Data Engineer will also build scalable tools and work with data warehousing systems needed to support X-Mode's data customers. This position will report to our Data Team Engineering Manager.  This position can be remote or on-site at our Reston, Virginia HQ. Please note that at this time, X-Mode is not sponsoring visas for any positions.  WHAT YOU'LL DO:   Write Spark, Python/Scala, and SQL to perform ETL on billions of location records per day Implement ETL pipelines in AWS (EMR/Glue) to support feature stores for analysis and machine learning use cases. Write complex SQL, including geospatial, to fulfill customer requests for analysis Build dashboards to surface data-driven insights  WHO YOU ARE:   3-5 years of data engineering or relevant industry experience 1+ years experience and working proficiency with Spark Bachelor's Degree in Computer Science or related technical areas like Math, Statistics, and/or other Engineering degrees Strong proficiency with Python  Advanced proficiency with SQL, comfortable with complex joins Familiarity with Scala preferred Knowledge of AWS data engineering products (S3, RDS, EMR, Glue, Athena...) is a plus Experience with spatial data, joins and operations is a plus Self-initiative and an entrepreneurial mindset Strong communication skills Passion for data  WHAT WE OFFER:   Cool people, solving cool problems. Competitive Salary and Equity Package Medical, Dental and Vision Insurance for you and your family Generous PTO policy, Mental Health Days, & paid holidays Paid Parental Leave Fun Culture Activities - virtual book club, Netflix parties, and more! Learning and development opportunities - grow as the company does!  We value your input. This is a chance to get in on the 'ground floor' of a growing company  At X-Mode, we're excited about building a diverse team and creating an inclusive environment where everyone can thrive, and we encourage all applicants of any educational background, gender identity and expression, sexual orientation, religion, ethnicity, age, citizenship, socioeconomic status, disability, and veteran status to apply.",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Internet",2,None,False,,6,ACTIVELY_HIRING_COMPANY
603,2208487388,2020-10-24,TrueAccord,User Researcher,United States,"Why TrueAccord?TrueAccord is a category-defining company. We combine machine learning with a human-based approach to transform debt resolution and to get people on the path towards financial health. Every year, more than 70 million Americans have negative experiences dealing with debt. We are changing this by providing personalized digital experiences that guide lenders and consumers through this challenging financial process.  With a world-class leadership team, passionate team members, and proprietary predictive models trained on years worth of transactional data, TrueAccord is well-positioned to deliver on a huge opportunity: helping millions of consumers to regain and keep their financial footing while lowering the cost of doing business for creditors across many industries. The RoleTrueAccord is looking for our first dedicated User Researcher to help us evolve and expand our product offerings. As the first researcher, you’ll help define our research program and processes.  Our mission is to empower consumers to regain control of their financial future by building consumer-focused products that leverage technology to serve people in a way that fits their lifestyle. You’ll act as the direct channel from consumers to the design, product, and engineering teams, enabling TrueAccord to consistently deliver experiences that truly help consumers by understanding them and their needs.  The ideal candidate will help us identify new opportunities and improve our product, digital, web, and service-based experiences through thoughtful research. We’re looking for someone that has a collaborative mindset and is passionate about solving consumer problems. ResponsibilitiesWork closely with cross-functional teams to identify and evaluate research opportunitiesDesign and deploy primarily qualitative research approaches to inform design across several products and verticalsConduct exploratory research, concept validation and usability testing on various projectsCreate user journey maps, workflows, personas, and use case models to help deepen understanding of our usersGather data, generate actionable insights and recommendations, and distribute findings to various teams through reports and presentationsFacilitate workshops with designers, product managers, engineers, and other stakeholders to increase innovation and design thinking across the organizationAct as an internal evangelist for product research and the consumer QualificationsAbility to clearly articulate your design methodology and present findings to different audiences at varying levels of the organizationAbility to perform all research tasks including planning, recruiting, evaluating, and disseminating findings with little guidanceAbility to act as a strategic partner in product design decisionsWorking knowledge of industry standard design software as it relates to creating and testing prototypes (i.e Sketch, Figma, Invision, or other UX related tools)A portfolio of work that highlights your past projects and their measurable results Bonus QualificationsUser Research experience in the Fintech or other highly regulated industryDesire to work in a fast moving startup environmentExperience working with quantitative methods and statistical analysis What TrueAccord offers you + Culture & BenefitsTrueAccord is a distributed company with a major presence in the San Francisco Bay area and Lenexa, KS. We offer a healthy work environment that continuously builds an inclusive and diverse culture where everyone is able to develop the best version of themselves. We are a dynamic group of people who are subject matter experts with a passion for change. We offer:*** Generous paid time off*** Paid training*** We promote work/life harmony*** Paid holidays*** Health, dental and vision benefits*** 401K with matching Our teams are crafting solutions to big problems every day. If you’re looking for an opportunity to do impactful work, join TrueAccord and make a difference. Our Dedication to Diversity & InclusionTrueAccord is an equal opportunity employer. We promote, value, and thrive with a diverse & inclusive team. Different perspectives contribute to better solutions and this makes us stronger every day. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",Algo de responsabilidad,Jornada completa,"Gestión de productos, Investigación",Servicios financieros,82,None,False,,371,COMPANY_RECRUIT
604,2276652897,2020-10-19,PropLogix,Property Researcher - Remote,"Sarasota, FL, US","Are you a critical thinker who thrives off multi-tasking? Are you detail oriented? Charismatic on the phone? We want YOU!  This full-time entry level position that will be performing property due diligence using Google, Municipal Websites, and other online resources. Once the research is complete, you will compile reports and send this information to our respective clients. This is a vital part of any real estate closing, and we need detail-oriented people with strong computer skills to help secure a clear closing for our clients.  Perks?  Bonus rewards for loyalty and quality work Opportunities for advancement in a growing company Contribute to an innovative company  Build positive and collaborative relationships    What it's Like to be a Property Analyst - PropLogix  Position Type and Expected Hours of Work  This is a full-time position, and hours of work and days are Monday through Friday, 8 30 a.m. to 5 p.m. Occasional evening and weekend work may be required as job duties demand.  Starting Pay Rate $13.75 / hour, after 90 days will increase to $14.25 - Full benefits  Full Benefits  Insurance  Multiple health, dental & vision insurance plans to choose from FREE Employer-Paid Life Insurance, optional voluntary life for spouse, children, family Other voluntary options include LTD, STD, AD&D, Critical Illness, Whole Life, Identity Theft Protection, Legal Services, and Pet Insurance!  Financial  401k match program Employee equity program  Vacation  Year One 15 days of Paid Time Off (PTO) Year Two 20 days of Paid Time Off (PTO) 8 paid holidays  Personal Development  Job shadowing program PropYOU - Professional Reading program that increases your paycheck by 2% each year you participate 50% LinkedIn Learning Reimbursement Employee Assistance Program   Essential Functions  Requirements  Summarize and compile reports using our proprietary software Communicate with our clients, confirm deadlines, and update our clients with the progress of their orders  Search legal records Examine documents for completeness, accuracy, or conformance to standards Use computers to enter, access or retrieve data  Maintain records, reports, or files  Use library or online Internet research techniques Data entry Write business correspondence   Department Specific Functions  Conduct online research through a variety of different platforms and websites Understand property documents  Fill out business or government forms   Qualifications And Education Requirements  High school Graduate or GED, Required  2+ years of office administrative work or 2 years of customer service, Strongly Preferred  Associate or Bachelor Degree, Plus  Experience working with Adobe Acrobat, Plus    Preferred Skills  Customer service and relationship building skills Technical Understanding of real-estate industry Time management skills  Ability to work under pressure  Ability to take initiative, follow up with customers and attain self-set deadlines and company-set goals.  Ability to work with a team and independently Self-confident Ability to listen and apply feedback from critiques and reviews Adobe Acrobat DC  Understanding of Online Research    Supervisory Responsibility  There are no supervisory responsibilities currently. But you are responsible for any management tasks delegated by your direct supervisor.  Work Environment  This role routinely uses standard office equipment such as computers, phones, photocopiers, and filing cabinets. You may also be required to travel to current and potential client offices.  Physical Demands  The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. This is largely a sedentary role: however, some filing is required. This would require the ability to lift files, open filing cabinets and bending or standing on a stool as necessary.  Other Duties  Job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee for this job. Duties, responsibilities and activities may change at any time with or without notice.  Benefits  Who are we?  PropLogix is a Real Estate Tech company providing property due diligence for the title industry. In just the last two years we’ve gone from a small operation to a team of over 200. We provide Municipal Lien Searches, Association Estoppels, Surveys, Payoff Tracking, and a variety of other services. With our unmatched customer service and cutting-edge software, we’re bringing technology and innovation to the world of real estate due diligence. In 2017, 2018 AND 2019, PropLogix was recognized by Inc.com as one of the fastest-growing companies in the entire country! At PropLogix, your talent, expertise, and imagination fuel our Mission and allow you to be a part of something greater than yourself.  Equal Employment  It is the established policy of the Company, to provide equal employment opportunities to all qualified persons and to administer all aspects and conditions of employment without regard to race, religion, color, sex, gender, sexual orientation, pregnancy, age, national origin, ancestry, physical or mental disability, medical condition, marital status, ethnicity, genetics, alienage or any other protected classification, in accordance with applicable federal, state, and local laws. E-Verify Employer PropLogix participates in E-Verify and will provide the federal government with your Form I-9 information to confirm that you are authorized to work in the U.S.  Notice to external Recruiters and Recruitment Agencies  PropLogix does not accept unsolicited headhunter and agency resumes. Headhunters and recruitment agencies may not submit resumes/CVs through this website or directly to any employee. PropLogix and any of our subsidiaries will not pay fees to any third-party agency or company.",Sin experiencia,Jornada completa,"Investigación, Análisis, Tecnología de la información","Servicios y tecnologías de la información, Software, Servicios financieros",8,None,False,,85,None
605,1922567350,2020-10-30,SDL plc,"Research Scientist, Machine Translation",United States,"Research Scientist, Machine TranslationLos, Angeles, CA. ﻿Who are we?At SDL Research, we have over a decade of experience in designing, building and deploying large-scale cutting-edge software applications. We develop and deploy a state-of-the-art Machine Translation service, both on-premise and in a multi-tenant cloud product (at translate.sdl.com). We offer the opportunity of research and software development in a dynamic setting where you can have an enormous impact. As a Research Scientist at SDL, you will discover, design and implement solutions to interesting problems at the intersection of Artificial Intelligence and Software Engineering. You will use your strong knowledge of machine learning, and natural language processing to build SDL Research next-generation products and platforms. What is this role?The role will entail working alongside a friendly team of experienced researchers to develop Machine Translation and Artificial Intelligence products and services. We have our own mature state-of-the-art R&D environment and are looking for able researchers to extend it. Basic Qualifications: ·       PhD or equivalent experience in computer science, engineering, statistics, machine learning, mathematics, or in another highly quantitative field ·       Depth and breadth in state-of-the-art approaches in Machine Translation and Natural Language Processing ·       2+ years of relevant academic research or industry experience ·       Scientific mindset and the ability to invent ·       Excellent creative problem solving skills ·       Ability to design and develop system prototypes in simulation ·       Superior communication and data presentation skills ·       Effective working in a team environment  Preferred Qualifications: ·       Superior communication and data presentation skills ·       Demonstrated ability to lead research projects and identify fruitful research directions ·       Demonstrated ability to work on cross-functional teams ·       Experience with applying scientific principles Benefits:Amazing benefits. (Seriously!)Infinite training, professional development and personal growth opportunities.The rare opportunity to impact how organizations communicate globally. There’s a reason we work with 90 of the top 100 brands.Smart, engaged co-workers, a culture of diversity, innovation and opportunity.Relaxed, fun environment with a game room, in house happy hours and many great office events throughout the year.Great work life balance! SDL is an Equal Opportunity / Affirmative Action Employer. Qualified applicants will be evaluated for employment without regard to race, color, religion, sex, national origin, veteran, and disability status. For more information about EEO/AAP legislation please visit http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf.",Algo de responsabilidad,Jornada completa,"Ingeniería, Investigación, Ciencias",Software,180,None,True,,1259,COMPANY_RECRUIT
606,2243966687,2020-11-06,Tredence Inc.,Cloud Data Engineer,"San Jose, California, United States","About Tredence: Tredence is a global analytics services and solutions company. We are one of the fastest growing private companies in the country for five straight years according to the Inc. 5000 and we continue to set ourselves apart from our competitors by attracting the greatest talent in the data analytics and data science space. Our capabilities range from Data Visualization, Data Management to Advanced analytics, Big Data and Machine Learning. Our uniqueness is in bringing the right mix of technology and business analytics to create sustainable white-box solutions that are transitioned to our clients at the end of the engagement. We do this cost effectively using a global execution model leveraging our clients' existing technology and data assets. We also come in with some strong IP and pre-built analytics solutions in data mining, BI and Big Data.   THE IDEAL CANDIDATE WILL:Responsibilities:﻿Responsibilities:Delivers software solutions byUnderstanding requirementsUnderstanding deadlinesUnderstanding systems flow, data usage, and work processesManage end to end delivery by Investigating problem areas, working cross-functionally with product manager & other stakeholdersFollow the Agile development methodology: think strategically and execute methodicallyProvides information to client and leadership by collecting, analyzing, and summarizing development and service issuesAccomplishes engineering and organization mission by completing related results as needed and on time with high qualityDevelop and manage capacity and growth projection forecasts of the environment within budgetsWrite technical responses to RFP’s & RFI’sDocuments and demonstrates solutions by developing documentation in the forms of BRDs, TDDs, User Manuals, Support manuals etc. ELIGIBILITY CRITERIA:Desired Experience/Skills:2-8 years of overall experience, should have deep knowledge on the cloud ecosystem especially on GCPShould have designed end-to-end solutions on GCP starting from ingestion patterns to transformation patterns moving on-to consumption patternsShould be conversant with GCP services, like GCS, dataflow, data-proc, cloud-pub-sub, big-query etcMust have hands on experience to manage and optimize cloud-workloads on Spark especially on SCALAShould be conversant with building out-rest API’s and microservices based architecturesShould know, how to build, host and deploy API’s on GCP using App engine/docker/Kubernetes containersArchitecture Design Experience for Cloud and Non-cloud platformsExpertise with various ETL technologies and familiar with ETL toolsKnowledge on legacy database migration to cloud picking the right technologies big data, data warehousing, no sql, distributed cachingExperience to implement large scale hybrid cloud platform & applicationsKnowledge of one or more scripting languageGood understanding and implementation experience in Data Governance, Data Quality, Data Modelling etc.Ability to set and lead the technical vision while balancing business drivers  Required Skills/Qualifications:Bachelor's and/or master’s degree in computer science or equivalent experience.Strong communication, analytical and problem-solving skills with a high attention to detail. About you:You are self-motivated, collaborative, eager to learn, and hands onYou love trying out new apps, and find yourself coming up with ideas to improve themYou stay ahead with all the latest trends and technologiesYou are about following industry best practices and have high standards regarding quality Why join Tredence?               There is a reason we are one of the fastest growing private companies in the country! You will have the opportunity to work with some of the smartest, friendliest, hardest working people in the data analytics space. You will work with the latest technologies and interface directly with the key decision stakeholders at our clients, some of the largest and most innovative businesses in the world. We offer a 401k match: full medical, dental and vision benefits, a fun team atmosphere and a work life balance. Our people are our greatest asset and we value every one of them. Come see why we’re so successful in one of the most competitive and fastest growing industries in the world.",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Consultoría de estrategia y operaciones,15,None,True,,95,ACTIVELY_HIRING_COMPANY
607,2227387953,2020-11-06,Harnham,Research Data Scientist,San Francisco Bay Area,"Research Data ScientistSan Francisco Bay Area, CA $190,000 - $230,000 + Competitive Benefits THE COMPANYCOMPANY: A large and growing start up in the online internet space that is using machine learning to cater to users using personlization and recommendations.TEAM: Machine learning and data science is the core part of the company. Join a strong team of 10 data scientists and 5 machine learning engineers.CULTURE: Casual work environment along with a diverse and inclusive culture: flexible working hours and a work from home policy. Flexibility to work from the office in the SouthBay or San Francisco. THE ROLEAs a Research Data Scientist you will…Build predictive and machine learning models for understanding users through user acuisition and growth, videos, advertisement, content optimization, personalization, and more! Work closely with product teams to build out end to end solutionsLead projects and mentor more junior membersBuild end to end deep learning algorithms for recommendation, personalization, pricing, and more. YOUR SKILLS AND EXPERIENCEPhD in relevant field4+ years of full time experience in data science and analyticsExperience with recommendations, mobile advertising, content optimization, user acquisition and growthExperience working on a mobile App productExperience with predictive modeling and machine learning Grea communication skillsExperience leading teams is a huge plus.Tools: Python, Tensorflow, SQL, Spark THE BENEFITSAs a Research Data Scientist, you can expect a base salary between $180,000 to $220,000 (based on experience) plus competitive benefits. HOW TO APPLYPlease register your interest by sending your CV to Kristianna Chung via the Apply link on this page",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información, Ciencias","Dotación y selección de personal, Internet",260,None,True,,952,ACTIVELY_HIRING_COMPANY
608,2162359793,2020-11-05,ASAPP,Postdoctoral Research Scientist,United States,"At ASAPP, our mission is to solve complex and challenging problems by building transformative machine learning-powered products. We leverage artificial intelligence to address significant challenges that share three common characteristics: huge economic scale, systemic inefficiencies, and tremendous amounts of data. Our talented teams that drive our product innovation and development are located in New York City, Ithaca, San Francisco, Mountain View, and Buenos Aires. We are seeking a Postdoctoral Researcher in our Ithaca research lab. Successful applicants will work side-by-side with our talented team under the supervision of Professor Kilian Weinberger. They leverage the massive amounts of data generated by our products, and our ability to deploy AI features into real-world use to ask and address fundamental research questions in novel ways. If you thrive in an environment of deep thinking, impactful research, start up-paced execution, and strong collaboration with all parts of an organization, ASAPP is an ideal environment for you. What you'll doConduct novel and impactful research to advance the field of Machine LearningBe actively involved in the research community by publishing in top-tier conferencesLeverage the massive amounts of data generated by our products, and identify research problems that are directly related to our business and productsPrototype and productionize your research outcome by collaborating with other functions at ASAPP What you'll needPhD in any area of Machine Learning, or equivalent experienceAbility to independently develop and drive original research initiativesSolid record of peer reviewed publicationsExcellent teamwork spiritStrong communication skills What we'd like to seeFamiliarity with at least one of the deep learning toolkits, such as Pytorch, Tensorflow and MxNetSolid coding skillsAbility to thrive in an atmosphere of constant change PerksCompetitive compensationFitness and wellness perksLearning and development opportunities ASAPP is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, disability, age, or veteran status. If you have a disability and need assistance with our employment application process, please email us at careers@asapp.com to obtain assistance.",Sin experiencia,Jornada completa,Investigación,"Servicios y tecnologías de la información, Software, Internet",95,None,True,careers@asapp.com,756,ACTIVELY_HIRING_COMPANY
609,2249317823,2020-11-05,Cloud International,Senior Data Engineer - Python/ £78k,"London, GB","At Cloud International recruitment, we are always on the look out for Data Engineers who are at the top of their game and interested to here of excellent job opportunities. You will have a passion for finding trends in data sets and excel in designing solutions to make raw data more useful to the enterprise. As a Big Data Engineer you will be tasked with creating Big Data Infrastructures and have a sound knowledge of disruptive technologies within this space, We are currently working with a pan-European client who have an opening for a Lead Data Engineer to join the team. The head office is based next to the Shard at London Bridge station however the work will be remote for the foreseeable future. This will make it viable for the Data Engineer to be based anywhere in the UK or Europe.  This Lead Data Engineer will work in collaboration with various teams, specially DevOps, Data Scientists, other Data Engineers, Project Managers and Architects Some of the core responsibilities for this role are as follows: Expertise in designing, building, implementing, automating and supporting Big Data infrastructure, creating data pipelines in Cloud As part of the wider team, help to build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources. Provide expert data advice to help Clients and Senior stakeholders build robust and sustainable Big Data infrastructures Team leading the design and implementation phases across the areas of data engineering, data architecture, data ingestion (ETL  The core skills required for this Lead Data Engineer are as follows: *Strong commercial 'Hands-On' Data Engineering skills  *Highly confident in using SQL and Big Data technologies in the Cloud (Cloudera / Hortonworks / EMR, AWS, Ansible, Unix) *Commercial experience with Python, Java and Pyspark  *Worked on Spark Core & Spark SQL for data processing and data transformation Have the ability to handed data skews in Apache Spark *Strong commercial experience of Data Modelling *Ability to team lead and direct junior engineers *Excellent experience of designing data solutions *Strong English language is compulsory The client offers an extremely competitive comp & bens package and a flexible working policy. Private family healthcare, pension and a plethora of other benefits You will also be treated to free training courses across Data Science, Big Data and DevOps disciplines The team at Cloud International are looking forward to speaking with you in more detail about this role. Desired Skills and Experience Senior Data Team Lead - c£80k - Remote Data Engineer,  SQL, Python, Pyspark, Hadoop,  Cloud, Hortonworks, Big Data, Data Architecture, Apache Spark, Skews Pan European business Starting ASAP",Intermedio,Jornada completa,Tecnología de la información,Software,25,None,True,,88,ACTIVELY_HIRING_COMPANY
610,2289765499,2020-10-14,ClearedJobs.Net,Data Scientist - Remote Work,"Herndon, VA, US","Data Scientist  Location: Remote   Conduct research and modeling with an emphasis on exploratory analysis using data from polling, surveys, social media, digital media and associated metrics, website and other platform analytics. Help to add features to and maintain a Python/Django-based application that gathers social media content. Build out and add features to API calls, build custom web scrapers, and the necessary back-end pipelines to properly store and retrieve the data. Design and build front-end interfaces to display and analyze data collected in useful and intuitive ways. Contribute to in-depth analysis of strategic communications and recommendations on how the USG can better use it's social platforms.  PROGRAMMING LANGUAGES: Python, HTML/CSS, SQL, Spark, Databricks, R, JavaScript, Julia, Elm  Preferred Qualifications  Data Science (4-5 years)Python Scripting (4-5 years)Statistical Analysis (2-5 years)Experience with international affairsRelevant language skills include: Python, HTML/CSS, SQL, Spark, R, JavaScript, Julia, Elm, or similarRelevant experience with: NumPY/SciPY, Pandas, SciKit-Learn, MatPlotLib, Keras, Django, Flask, PYMC3, newspaper3k, tweep, or similarExperience with: PostgreSQL, MySQL, S3, BigQuery, Azure Data Lake, Google Object Store, NoSQL, MarinaDB, or similarExperience with: Bash, Git, Cloud Computing (AWS/Azure), GCP, Regex, Apache Spark, Databricks, IBM Watson, or similarSelf-drivenAble to work in a fast-paced environmentAble to prioritize work and complete projects on time  Education, Experience, & Certifications  Bachelor’s degree in Engineering, Mathematics, Computer Science, Information Systems, Economics or Business, or equivalentHold appropriate certifications  Benefits  Great Culture focused on our customers and team membersVHB offers a compensation plan consisting of a competitive base salaryEmployee Health coverage with Dental options401k plan offeringsPaid holidays and vacation Hold appropriate certifications.  Privacy Policy  VHB Global, Inc. is an industry leader, providing professional services including but not limited to: training specialists, linguists and field subject matter experts, in addition to operational and training support customers in the defense, intelligence, federal and commercial sectors.  VHB Global, Inc. is an Equal Opportunity Employer and supports diversity in the workplace. Applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability, veteran status, marital status or sexual orientation.  Due to Federal Contract Regulations, U.S. Citizenship is required for these positions.",No corresponde,Contrato por obra,"Ingeniería, Tecnología de la información","Manufactura eléctrica/electrónica, Construcción, Departamento de defensa y del espacio exterior",0,None,False,,2,None
611,2203382144,2020-10-23,Canva,Machine Learning Engineer (Python),"Perth, Western Australia, Australia","Designing with Canva involves making many choices, out of our incredibly large content pool of over 75M+ templates, photos, videos and elements. The Content Recommendations team is building machine learning-driven recommendations and a personalised content experience, helping to narrow down these choices, and make design easier, smarter, and more magical.  We're looking to grow the team to continue to scale the impact of recommendations across Canva. You'll be joining a fast moving team, rapidly building and shipping machine learning-driven recommendations to users, and making it effortless for users to discover the most relevant content for them. ResponsibilitiesHypothesis-driven development of recommendation features across Canva.Engineering implementation: developing and implementing ML models and features, as well as using third party APIs and pre-trained models when appropriate.Running offline and online recommendations experiments.Investigating and spiking applications of recommendations across the Canva product, considering tradeoffs between different approaches and rapidly shipping.Contributing to the full life cycle of ML/data models: data analysis, data preprocessing and pipeline, modelling, tuning and productization.Improving the scalability, speed and performance of existing models.Working alongside data specialists, software engineers and product owners to identify business and growth opportunities.Designing and creating new data workflows and deploying these workflows to users. Sharing and articulating statistical analysis, modelling, experiment and results to technical and non-technical audiences. RequirementsPrevious experience in the machine learning / data science domain.Experience building and deploying machine learning models, ideally recommendations models. Strong understanding of end-to-end machine learning pipelines and components.Coding proficiency in Python, interviews will be in Python. Experience in Scala is preferred. Strong understanding of Computer Science/Engineering fundamentals and first principles covering system design, data structures, architecture, and design patterns.Familiarity with big data tools: Apache Spark, Hadoop, MapReduce. SQL experience preferred.Strong research skills: the ability to dig through deep learning literature and translate this into product and value for users.Bachelor's degree in Computer Engineering / Science or Mathematics.Excellent collaboration and communication skills. Perks and BenefitsFlexible daily working hours, we value work-life balanceBreakfast and lunch prepared by our wonderful Vibe teamOnsite-Gym and Yoga MembershipEnd-of-Trip Facilities: Bicycle parking and showersGenerous parental (including secondary) leave policyPet-friendly officesSponsored social clubs, team events and celebrationsRelocation budget for interstate or overseas individuals (see below for visa information) Want to experience Canva for yourself?Check out what life is like at Canva on Instagram.Check out what our users are saying about us on Twitter.Learn how we work from Dave, our CTOGet to know our Chef, ChrisMeet our CEO, MelanieFinally, give Canva a go! If you're seeking professional growth and enjoy working on large, distributed, cloud-based applications that delight our millions of individual and business users alike - then apply now to be considered for the position! If you require visa sponsorship, you must ensure you have at least two (2) years of post-University commercial experience as a Software Engineer and meet the mandatory sponsorship requirements laid out by Department of Home Affairs. We will not accept or review any CVs from external recruitment agencies.",Intermedio,Jornada completa,"Tecnología de la información, Investigación","Servicios y tecnologías de la información, Software",56,None,False,,452,COMPANY_RECRUIT
612,2268187240,2020-10-08,TechDigital Corporation,"Data Engineer w Big Data-Hadoop, NoSQL, Hive, Apache Spark (Remote)","New York City, NY, US","Required Skills/Expertise  Analyze and understand data sources & APIs Design and Develop methods to connect & collect data from different data sources Design and Develop methods to filter/cleanse the data Design and Develop SQL , Hive queries, APIs to extract data from the store Work closely with data Scientists to ensure the source data is aggregated and cleansed Work with product managers to understand the business objectives Work with cloud and data architects to define robust architecture in cloud setup pipelines and work flows Work with DevOps to build automated data pipelines  Total Experience Required  10 of relevant experience The candidate should have performed client facing roles and possess excellent communication skills  Business Domain knowledge: Finance & banking systems, Fraud, Payments  Required Technical Skills  Big Data-Hadoop, NoSQL, Hive, Apache Spark Python Java & REST GIT and Version Control  Desirable Technical Skills Familiarity with HTTP and invoking web-APIs Exposure to machine learning engineering Exposure to NLP and text processing Experience with pipelines, job scheduling and workflow management  Personal Skills Experienced in managing work with distributed teams Experience working in SCRUM methodology Proven sense of high accountability and self-drive to take on and see through big challenges Confident, takes ownership, willingness to get the job done Excellent verbal communications and cross group collaboration skills",Sin experiencia,Contrato por obra,Tecnología de la información,Servicios y tecnologías de la información,None,None,False,,4,ACTIVELY_HIRING_COMPANY
613,2289312758,2020-10-29,Brightline,Data Science Engineer,"Palo Alto, CA, US","Are you a data engineer/ scientist who wants to work with a fantastic, inclusive team to build a product that will make the world a better place for kids living with behavioral health challenges? Brightline is a team you will be proud to be part of and you will get to make an impact at a well-funded, early-stage company doing work that is so timely and important.  Responsibilities include:   Building and owning analytics databases and dashboards using technologies including postgreSQL, Mode analytics, R, Jupyter/python. Building analytics reports for external customers. Analyzing member health metrics Analyzing the growth of the business including funnel optimization and marketing campaigns Anayzing clinical operations and efficiency Lots of new interesting things as we grow!  Skills and Behaviors:   Great communication/collaboration skills: being able to quickly agree on the most important work areas and stay in sync with engineers, PMs and others in the company. Freedom and responsibility: this role will have a lot of freedom and influence in the work that we do. You will also have the chance to own important areas of the business. Desire to learn and improve: in an early-stage company there will be lots of exciting changes that will require you to learn new things and grow. Great analytics: you have the ability to create new metrics and implement them in a variety of ways. This includes internal dashboards for making decisions and external reports for partners and customers. Experience with reporting for health-care stakeholders is a big plus. Ability to deploy work: these skills often fall into the engineering and devops areas and include git habits, code reviews, containers, database administration, shell scripting. These skills give you the ability to build and deploy simple things independently. SQL and Python/R: being able to do advanced/readable SQL queries is very important. We will also use Python and R for both ad hoc analysis and automated insights and reports. This includes writing scripts to do ETL. Statistical fundamentals: your background in stats should enable you to avoid common pitfalls and biases and be able to make inferences and decisions in the presence of noise and uncertainty. Examples of things to know: hypothesis testing and regression. Fancy deep learning and Bayesian statistics are nice to have but not required at all at this stage.   Experience:   You likely have 3+ years of professional experience building data systems and doing analytics. If you do not have 3 years of work experience but you have some unusual background that you think prepares you for this role we definitely would love to talk to you and learn more. Experience in consumer-focused health tech is very valuable.",Sin experiencia,Jornada completa,Tecnología de la información,"Software, Sanidad, bienestar y ejercicio, Atención sanitaria y hospitalaria",None,None,False,,11,ACTIVELY_HIRING_COMPANY
614,2231243343,2020-11-01,Branch International,Machine Learning Engineer,"Los Angeles, CA, US","Branch's Engineering Team builds products for customers in 4 markets and is distributed across 3 continents. Our team in the US works closely with teams in Africa and India on our existing products as well as new product initiatives. In the long term, we envision the US team as the team responsible for some of the most important foundational building blocks that enable us to rapidly build and improve products across multiple markets.  You will work closely with other Engineers, Product Managers, and Data Scientists to develop, improve, and deploy machine learning models and to solve other optimization problems. We make extensive use of machine learning in our credit product, where it is used (among other things) for underwriting and loan servicing decisions. We are also actively exploring other applications of Machine Learning in some of our newer products, with the ultimate goal of improving the user experience.  Machine Learning sits at the intersection of a number of different disciplines: Computer Science, Statistics, Operations Research, Data Science, and others. At Branch, we fundamentally believe that in order for Machine Learning to be impactful, it needs to be closely embedded into the rest of the product development and software engineering process, which is why we emphasize the importance of software engineering skills and experience for this role.  Qualifications  You excel at software engineering and programming in Python and SQL. You have 5+ years of experience working on Machine Learning systems in a production setting. You have a diverse range of data skills including experimentation, statistics, and machine learning, and have used these skills to inform business decisions. You have a keen eye for detail and a healthy skepticism for data before relying upon it. You are highly entrepreneurial. You teach yourself new skills. You take the initiative to solve problems before they arise. You know that startups are a team sport. You listen to others, speak your mind, and ask the right questions. You are a great collaborator and teacher. You are driven by making an impact on customers’ lives.  Project Examples  Credit Decisions - Core to our business is understanding and building signals from unstructured and structured data to identify good borrowers  Customer Service - Using machine learning, automate customer service interactions and provide context to our customer service team  Fraud Prevention - Identify patterns of fraudulent behavior and build models to detect and prevent these behaviors  Product Growth - Understand user experiences, test ideas, and improve conversion rates through experimentation  Paid Growth / Marketing - Use external and internal data sources to measure and optimize marketing spend  Benefits of Joining  Mission-driven and fast-paced, entrepreneurial environment  Competitive salary and equity package  99% coverage of insurance costs (health, dental, vision) Unlimited PTO Flexible working hours Discretionary trips to our offices around the globe (when it's safe to travel!) Pre-tax commuter and 401(k) programs Weekly team meals and quarterly team building events (virtual for now!) Generous child bonding leave policy  Location  We are primarily looking for candidates located (or willing to relocate to) the United States, ideally in the Pacific Time zone.  Branch International is an Equal Opportunity Employer. The company does not and will not discriminate in employment on any basis prohibited by applicable law. We’re looking for more than just qualifications -- so if you’re unsure that you meet the criteria, please do not hesitate to apply!  The salary range for this position is $190,000 - $250,000",Algo de responsabilidad,Jornada completa,Ingeniería,Software,53,None,False,,306,COMPANY_RECRUIT
615,2248273926,2020-10-16,"Synack, Inc.",Senior Data Engineer,"Cheltenham, GB","Imagine a world dedicated to Security Without Compromise. Synack, headquartered in Silicon Valley with regional offices around the world, protects leading global organizations by reducing companies' security risk and increasing their resistance to cyber attack. How do we do this? By utilizing the world's best and most trusted team of ethical hackers who test through our powerful and controlled platform to deliver real security without compromise. At Synack, we aren't afraid to think outside the box or take on big challenges. Backed by top-tier venture capital firms including Kleiner Perkins Caufield & Byers, Microsoft, and Google Ventures, Synack's mission is to leverage global security talent coupled with advanced technology to help enterprises discover security vulnerabilities before they become business problems. Discover the possibilities at Synack!  We are looking for an experienced and innovative Senior Data Engineer to build products that will revolutionize cyber security. Working in the Cloud and using DevOps, you will process data to improve visibility into our Red Team's activity, and enhance the ratings method measuring the security standing of our Clients. Join us!  Here's What You'll Do  Build data high availability processing pipelines using Cloud Functions, Cloud Composer, BigQuery, Data Studio and other Google Cloud Platform capabilities Support existing production products including Kubernetes, APIs, relational databases and NoSQL document stores Build innovative analytics and proof of concept ideas and the development of dashboards and interactive applications using Apache Superset Make use of a wide variety of tools, data storage solutions and programming languages Collaborate with engineers across the company Contribute to the development of Data Analytics, Machine Learning models and application of AI to real world problems Deliver new capabilities as part of journey teams to build new products and participate in Agile ceremonies   Here's What You'll Need  5+ years of experience designing and building dynamic production solutions 3+ years of experience in a Python or Java development environment Experience using various database systems such as PostgreSQL and NoSQL document storage Experience architecting and leading application development efforts Experience working with GCP Cloud services or other Cloud Computing platforms Experience with unit and integration tests, and Agile software development practices using Git  Bonus Points  Contribution to open source projects Experience with Apache Airflow Understanding of Machine Learning/AI techniques and experience in applying to real world problems Experience in DB management and optimization Understanding of Google Cloud Platform and Kubernetes/Docker  It's all hands on deck, it's hard work, it's winning, it's Synack. Join us!  Synack is committed to embracing diversity. Our people are our strength. Each addition to our team is an opportunity to grow and diversify our ideas, experiences, and viewpoints. We strive to be inclusive of Race, Ethnicity, Religion, Sex, LGBTQ+, Veterans, Disabilities, and Age. Synack welcomes you!",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Internet",4,None,True,,37,ACTIVELY_HIRING_COMPANY
616,2288805343,2020-11-05,Cognologix Technologies,Data Engineer (Remote) - Pune,"Pune, IN","You Will Work On  We help many of our clients make sense of their large investments in data – be it building analytics solutions or machine learning applications. You will work on cutting edge cloud native technologies to crunch terabytes of data into meaningful insights.  What You Will Do (Responsibilities)  Collaborate with Business, Marketing & CRM teams to build highly efficient data pipleines.  You Will Be Responsible For Dealing with customer data and building highly efficient pipelinesBuilding insights dashboardsTroubleshooting data loss, data inconsistency, and other data-related issuesMaintaining backend services (written in Golang) for metadata generationProviding prompt support and solutions for Product, CRM, and Marketing partners  What You Bring (Skills)  2+ year of experience in data engineering Coding experience with one of the following languages: Golang, Java, Python, C++Fluent in SQLWorking experience with at least one of the following data-processing engines: Flink,Spark, Hadoop, Hive  Great If You Know (Skills) T-shaped skills are always preferred – so if you have the passion to work across the full stack spectrum – it is more than welcome.Exposure to infrastructure-based skills like Docker, Istio, Kubernetes is a plusExperience with building and maintaining large scale and/or real-time complex data processing pipelines using Flink, Hadoop, Hive, Storm, etc.  Advantage Cognologix  Higher degree of autonomy, startup culture & small teams  Opportunities to become expert in emerging technologies  Remote working options for the right maturity level  Competitive salary & family benefits  Performance based career advancement  About Cognologix  Cognologix helps companies disrupt by reimagining their business models and innovate like a Startup. We are at the forefront of digital disruption and take a business first approach to help meet our client’s strategic goals.  We are an Data focused organization helping our clients to deliver their next generation of products in the most efficient, modern and cloud-native way.",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Internet",4,None,False,,29,None
617,2246364603,2020-11-05,Trilateral Research,Senior Data Engineer,"City of London, England, United Kingdom","We are an innovative company bringing the rigour of inter-disciplinary research to solve complex societal problems.Our culture is based on delivering high-quality outputs, through our commitment and passion for what we do. We work in an open and collaborative environment where the team culture provides support amongst peers and colleagues. We are seeking to engage a Senior Data Engineer to help us deliver on a key goal of setting up an ML-based, real time application for data-driven decision making for our clients in the public sector. The person will help design and build the datasets to underpin the ML models as well as help design and create the output pipeline. The primary responsibilities of this role include: Design, develop and maintain scalable, automated data pipelines on AWS, pertaining to our AWS productsMaintaining and monitoring our AWS data infrastructureResearching, learning and implementing relevant tools and technologies in the data engineering space to our AWS productsEngineer manual data flows/pipelines to enable scaling and repeatable useWrite necessary ETL/ELT code to make sure the required processes perform optimallyBuilding CI/CD pipelines for MLOps - implementing and automating continuous integration (CI), continuous delivery (CD), and continuous training (CT) for in-house machine learning (ML) algorithmsBuilding, designing, refactoring or optimising data lakes and data warehouses from a variety of data sources.Identify opportunities to re-use existing data flowsOptimise code to ensure processes perform optimallyApply knowledge of systems integration to their workSupport work on database managementLiaise with data scientists, junior data engineers, data analysts and decision-makers such as product owners and business analysts to gather and analyse the data requirements Basic Qualifications required for this role: Bachelor's degree in Computer Science, Engineering, Statistics, Mathematics or related field3-5 years’ experience in data engineeringExperience with different AWS services like Lambda, Glue, S3, Athena, DMS, Redshift, and ML toolsDemonstrable experience in European research projects (i.e. FP7, H2020)Good working knowledge of any of the following: SQL, Python, ScalaBackground in supporting data scientists in conducting large scale data analyses / modelling to support business decision makingKnowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operationsBe self-driven and show ability to deliver on ambiguous projects with incomplete or messy data.An ability and interest in working in a fast-paced environment ·Strong verbal/written communication and data presentation skills, including an ability to effectively communicate with both business and technical teamsProvide guidance and mentorship to other members of the team Location: This position is open to candidates based in the UKSalary: Commensurate with experienceHours: Full TimeContract Type: Fixed Term or Permanent In return, you get ... A competitive salaryFlexible working hours / remote working optionsCompetitive pension schemeA positive and supportive environment We are an Equal Opportunities employer and positively encourage applications from suitably qualified and eligible candidates, regardless of their age, sex, race, disability, sexual orientation, gender reassignment, religion or belief, marital/civil partnership status, or pregnancy and maternity. We are a Disability Confident committed and Living Wage employer. To Apply: Please submit both your CV and a cover letter to careers@trilateralresearch.com, linking your experience to our requirements in order to have your application considered. All appointments are subject to the receipt of satisfactory references. This role is subject to security vetting, therefore all candidates must be eligible to work in the UK and have been resident in the UK for a minimum of 3 years. All applications should be marked specifically as “Application for Senior Data Engineer“ in the subject email. We will process applications on a rolling basis until the position is filled.",Algo de responsabilidad,Jornada completa,Tecnología de la información,Investigación,24,None,True,careers@trilateralresearch.com,99,ACTIVELY_HIRING_COMPANY
618,2226320647,2020-10-30,Pactera EDGE,Data Scientist,"New York, New York, United States","About us:PacteraEdge Technology Ltd. is a trusted consulting and technology services partner with proven global capabilities & over 2,300+ employees worldwide committed to delivering Digital-themed consulting, Product & Digital Platform Engineering Services, Pactera creates business value for Fortune 2000 companies by accelerating business innovation, enabling new growth, improving operational efficiency and transforming the user experience.With regional headquarters in North America, Asia Pacific, India and Europe. Its international presence, experience and teams provide an optimized balance of personalized and high-value service.https://www.pacteraedge.com/ Title: Data ScientistResponsibilities:Retrieved Data from backend legacy systems.Stitch the data and place it in Azure.Build Reports and dashboards using Power BI.Support Feature Engineering for downstream AI/Ml Team.Build Data Pipelines for moving data to cloud (Azure Experience preferred).Support Solution architecture for Cloud powered Data Modernization for scaling AI and Reporting.Requirements:Strong Engineering degree.5 to 7 years of experience on Azure Cloud (preferred) or AWS/GCP.Overall skills required for the position: Azure Paas: Data Lake, Data Factory, Databricks, SQL DB, AAS, SSIS, Logic Apps, Python, Scala Power BI: PBI Desktop, Report Builder, SQL, DAX/MDX, Proficiency in tuning queries.",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información",Servicios y tecnologías de la información,221,None,True,,815,ACTIVELY_HIRING_COMPANY
619,2172510354,2020-11-07,Square,"Product Manager, Knowledge Graph","San Francisco, CA, US","Company Description  Square builds common business tools in unconventional ways so more people can start, run, and grow their businesses. When Square started, it was difficult and expensive (or just plain impossible) for some businesses to take credit cards. Square made credit card payments possible for all by turning a mobile phone into a credit card reader. Since then Square has been building an entire business toolkit of both hardware and software products including Square Capital, Square Terminal, Square Payroll, and more. We’re working to find new and better ways to help businesses succeed on their own terms—and we’re looking for people like you to help shape tomorrow at Square.  Job Description  All of Square's product services are organized into business units with their own product and engineering teams. Underneath, there's a connected platform team that supports the network. We are that platform. Through various data pipelines, we collect data from across Square's ecosystem of products. Our knowledge graph infrastructure contains 3 billion connections between 200 million entities across Square. This connected data is used across multiple teams, from getting more users onto the Square platform to feature development for statistical models. The scope of this team's work is rapidly growing and there are many opportunities for improving Square's growing global audience. We need an innovative leader, with knowledge graph experience, to guide the team's evolution in a quickly evolving business.  As a product manager, you will oversee the future of our knowledge graph infrastructure. This involves the full life-cycle from strategy to development through launching across different teams. You will collaborate with data scientists, analysts, and cross-functional teams to ensure that our solutions are scalable and reusable.  You Will Provide technical vision and strategy for building scalable knowledge graphs that are integrated throughout human and machine-driven decisionsPerform user research to understand workflows, customer needs, and existing solutions and experiencesBalance immediate stakeholder needs vs longer term visionWork with the engineering manager lead a dream team of software and data engineers to build your visionSet and analyze impact-based metrics for the platform to guide direction, prioritization, and measure success for the platformBuild software and glue between a diverse set of engineering, data science, product partners to support decisions affecting millions of dollars flowing daily through our payments and consumer systems.  Qualifications 5+ year(s) of product management experience2+ years in a technical role, such as a Software Engineer, Data Scientist, or Product Manager on a technical product.Strong customer empathy and experience shaping product direction and execution based on customer needs Experience with domains related to information retrieval, machine learning, entity resolution, natural language processing, ontology  Even Better A technical degree, such as Computer Science or Math.Professional experience with machine learning.Experience working with analytics practitioners in different contextsWorked with A collection of Big Data tech (S3, Spark, Elasticsearch, or graph databases)Experience with Cloud-based (GCP/AWS) application developmentExperience building platforms  Additional Information  At Square, we value diversity and always treat all employees and job applicants based on merit, qualifications, competence, and talent. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. We will consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the San Francisco Fair Chance Ordinance. Applicants in need of special assistance or accommodation during the interview process or in accessing our website may contact us by sending an email to assistance(at)squareup.com. We will treat your request as confidentially as possible. In your email, please include your name and preferred method of contact, and we will respond as soon as possible.  Perks  At Square, we want you to be well and thrive. Our global benefits package includes: Healthcare coverageRetirement PlansEmployee Stock Purchase ProgramWellness perksPaid parental leavePaid time offLearning and Development resources",Sin experiencia,Jornada completa,"Gestión de productos, Marketing","Software, Internet, Servicios financieros",89,None,False,,1359,COMPANY_RECRUIT
620,2243597196,2020-11-04,mLabs,Senior Data Engineer,"São José dos Campos, São Paulo, Brasil","Somos uma startup brasileira de marketing digital que desenvolve soluções para micro, pequenas, médias e grandes empresas nas redes sociais. Contribuímos para o sucesso e eficácia das mesmas por meio de uma plataforma inteligente e facilitadora de gestão das mídias sociais.  Nossos serviços são focados nas necessidades específicas, visando uma variedade de métodos para ajudá-las a reduzir custo de produto de conteúdo, otimizar investimentos em mídia e aumentar a eficiência na operação de gestão de mídias sociais. Para garantir a evolução contínua e desenvolvimento de nossas soluções, a área de Dados é a peça-chave. A grande maioria das empresas possui um verdadeiro tesouro em dados, muitas vezes escondido em servidores, aplicações, logs, redes sociais ou mesmo dados que ainda não foram digitalizados, mas que podem ajudar muito a alavancar as vendas e destacar a empresa frente à concorrência. Para coletar, organizar e implementar a infraestrutura necessária para que o time de Data possa fazer o melhor trabalho e construir uma plataforma de dados moderna, segura e escalável, entra em ação o papel da Engenharia de Dados (Data Engineering). Você terá o grande desafio de desbravar nosso grande volume de dados e transformá-los em informações úteis para as áreas da mLabs, nos ajudando a construir uma arquitetura de dados com poder de processamento e análise que agregará muito valor para nossas soluções. O principal atrativo desse desafio é a autonomia e liberdade para construir do seu jeito e aprender muito durante o caminho, tendo a oportunidade de construir um legado, permitindo a disseminação de uma cultura data-driven na mLabs. RESPONSABILIDADES E ATRIBUIÇÕESConstruir um processo de coleta, processamento, integração, armazenamento e disponibilização de dados:Construir e gerenciar pipelines confiáveis de dados:Colaborar com a equipe de Data Science, construindo as melhores soluções e estrutura para esse time:Contribuir para a evolução da performance da plataforma da mLabs:Ser referência de conhecimento sobre o processo de carregamento de dados da mLabs, a fim de dar suporte a outros times quando necessário. REQUISITOS E QUALIFICAÇÕESProfundo conhecimento em MongoDB:Profundo conhecimento em MySQL:Experiência com ferramentas de ETL, ex. Pentaho, Nifi, outros:Experiência com ferramentas de visualização de dados, ex. PowerBI:Experiência em ambiente cloud AWS.",Intermedio,Jornada completa,Tecnología de la información,Servicios y tecnologías de la información,15,None,False,,385,ACTIVELY_HIRING_COMPANY
621,2189488527,2020-10-26,Defyned Brands,Director of Data Engineering & Analytics,"Austin, Texas Metropolitan Area","Who We AreDefyned Brands is a premier developer, marketer, distributor and multi-channel retailer of best-in-class vitamins, supplements and apparel. Originally founded as a specialty retailer with one location, the company has grown to own and operate 50 5 Star Nutrition specialty supplement stores, five nationally recognized vitamin and supplement brands and over 200 employees all driven by the same mission: To deliver outstanding results for our customers. We are dedicated to the ultimate customer service experience & company culture is the centerpiece of our company which has been the fuel on the fire for our tremendous success & growth. A Day in the LifeDefyned Brands is seeking a highly motivated and experienced Director of Data Engineering & Analytics to drive data-centric organization through continued improvement and ownership of our data stack. Reporting to the CEO, this individual will be expected to take the existing platform to the next level. Whether it be ad-hoc analysis, business problem solving, or strategic development of the company’s data and analytics ecosystem, this candidate should be able to handle it all. You will be a business partner that can effectively work with all segments of the business to help those segments make the most out of their data. Beginning as an individual contributor, you will lay the foundation of what will be a first-class data and analytics team.  Responsibilities:Data EngineeringOwn data warehouse infrastructure (Snowflake, Stitch, dbt, etc.)Data modeling, master data management, enterprise data warehousing, ETL, reporting, querying, requirements, analysis, and data integration techniques.Continuous improvement of Snowflake data warehouse.Defining and developing optimal data pipeline architecture to collect, cleanse, transform and model data from disparate sources into reconcilable and usable data sets.Architect and implement database structures, tune SQL for performance, create queries and data transfer processes to ensure maximum/stable performance of ETL and data models.Establish, maintain and promote consistent methodology for analytics deployment.Design and manage a repository of documentation related to data architecture standards, protocols, frameworks, technique, and opportunities for documentation improvement.Ensure all data security and governance are in compliance with the latest industry standards.AnalyticsSupport front-end analysis in development of Looker visualization tool and data analysis practices.Continually analyze existing data stack and share new data product recommendations to improve data consolidation, management, analysis and interpretation.Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.Work with data and analytics experts to strive for greater functionality in our data systems.Provide ongoing Business Analytics to support key company initiatives.ManagementDevelop a plan to recruit and hire a team of data professionals, engineering and analytics as company growth dictates.Create an inspiring team environment with open communication.Set clear team and individual goals.Oversee performance and have appropriate one-on-one sessions with direct reports.Determine training needs and provide coaching.Encourage risk taking and ownership. Skills:Expert in SQL language, stored procedures and functions.Technically skilled in modern big data principles and technologies: existing data stack experience ideal – Snowflake, Stitch, dbt, Looker.Ability to code in Python, and/or Go. Ability to scale and document processes, systems and controls surrounding data.Experience with NoSQL databases.Experience with stream processing technologies: Apache Beam, Spark-Streaming, etc.Passionate, high energy, motivated self-starter who enjoys working in a fast-paced, high-growth and dynamic environment.Exceptional attention to detail and accuracy.Ability to manage and prioritize requests through strong project and time management skills. Qualifications and Experience:Bachelor’s degree in quantitative/technical field (i.e. computer science, information systems, engineering, math, statistics, etc.)10+ years of hands-on experience implementing and managing data teams/environments.Exceptional technology knowledge and experience in data warehouse methodologies including data management, data integration, ETL and analytics system architecture.Built data warehouses, data marts, and data lakes, including implementations in a hybrid environment.Experience managing data from numerous source systems including ERP’s (i.e. NetSuite), commerce platforms (i.e. Shopify), marketing analytics (i.e. Google Analytics), etc.Experience with Snowflake and Stitch required, dbt a plus.Experience working in fast-paced start-up environment with systems/processes/procedures requiring development. Defyned Brands offers a very competitive compensation & benefit package that includes: quarterly bonus potential, company sponsored health, dental & vision insurance: life and long-term disability insurance, unlimited snacks & drinks, generous product employee discounts, team social events, onsite gym & a casual high energy working environment. Defyned Brands is an Equal Opportunity Employer. This description represents the job in general terms and is not designed to contain or to be interpreted as a comprehensive listing of all the duties, responsibilities, and qualifications required of the employee performing this job.",No corresponde,Jornada completa,None,"Sanidad, bienestar y ejercicio",82,None,False,,664,None
622,2198223961,2020-10-10,Stone,Data Engineer,Brasil,"Já conhece a Stone Co.? A Stone nasceu com o desejo de transformar o mercado de pagamentos! Nosso propósito é fazer diferente e criar soluções tecnológicas com impacto de verdade na vida de quem empreende. Crescemos em ritmo acelerado e hoje somos uma das 6 empresas unicórnios do Brasil.A Stone se propõe a desenvolver quem cuida do negócio. Somos transparentes, trabalhamos em equipe, temos foco em nossos clientes e sempre com a tecnologia como referência! Somos mais que a maquininha verde no balcão, somos a Stone Digital!Conheça mais sobre a nossa empresa aqui!  O que é ser Data Engineer na Stone Co.? Buscamos uma pessoa que irá trabalhar junto ao nosso time de risco, que tem como missão mitigar e controlar as perdas da companhia. Dessa forma, terá a missão de desenvolver soluções que consigam unir o desenvolvimento de novos produtos, melhorar os antigos e diminuir as possibilidades de fraudes. Essas soluções podem ir de um simples alinhamento de um novo fluxo a até a construção de um sistema usando machine learning que consegue correlacionar uma série de dados para tomar decisões. Nosso grande desafio é conseguir desenvolver formas de identificarmos e tratar de forma automática possíveis fraudes antes de tomar o prejuízo. #Não pode faltar: 🧾 Ter forte conhecimento em SQL, Arquitetura de dados e modelos de dados relacionais e não relacionais🧠 Excelente conhecimento em trabalhar com sistemas distribuídos em ambientes de produção💻 Projeto e execução de arquiteturas de dados, como Cloud Functions e streaming🧾 Proficiente em Python, Java ou linguagem semelhante☁️ Conhecimento em soluções em nuvem (preferencialmente GCP e/ou AWS)📈 Conhecimento em design de processos ETL💻 Experiência com ecossistema Hadoop📚 Experiência no funcionamento e manutenção de banco de dados NoSQL (tais como: Cassandra, HBase, MongoDB, CouchDB, entre outros) #O que aumenta as suas chances:🧠 Experiência em construção e gerenciamento de Data Lakes e Data Warehouses💻 Ter experiência com Airflow, Kafka e/ou Spark☁️ Ter experiência com Cloud Functions e/ou Lambda Architectures:📈 Banco de Dados Search Engine (ElasticSearch)📚 Ter conhecimento em Terraform Infrastructure💻 Frameworks de aprendizado máquina (tais como: TensorFlow, Scikit-Learn, PyTorch, Keras) #O que oferecemos:🩺 Plano de Saúde e Odontológico Bradesco (sem coparticipação)🚌 Vale transporte🥗 Vale Refeição e/ou Vale Alimentação💚 Seguro de Vida💪 Gympass👶 Auxílio Creche🕗 Horário flexível #Etapas do nosso processo seletivo:✍️ Inscrição📞 Phone Screening | Entrevista com o time de People🤝 Entrevista com a liderança🎬 Apresentação do desafio técnico🏁 Feedbacks e/ou contratação E aí, deu match? Se candidate! Na Stone Co., nós acreditamos na pluralidade das ideias, respeitamos as individualidades, valorizamos as vivências e temos disposição para estabelecer diálogos para a construção de uma empresa mais diversa. Todas as nossas vagas são elegíveis a pessoas com deficiência e/ou reabilitados.",Intermedio,Jornada completa,Tecnología de la información,Servicios y tecnologías de la información,63,None,True,,661,ACTIVELY_HIRING_COMPANY
623,2261537711,2020-10-06,Cordant Health Solutions,Certifying Scientist II (Remote) - Huntington,"Huntington, NY, US","We are looking for talented Certifying Scientists to join our Lab Operations team in a remote capacity. The  Certifying Scientist II ensures the legal defensibility of scientific data generated in a technical, high volume, laboratory operation. Certifying Scientist III is primarily responsible for initial and second review of data from LC/MS/MS, GC/MS/MS, GC/MS, and GC/FID instrumentation, the final analytical review and release of Final Reports.  Duties include but are not limited to: Initial and final review of calibration curves and QC data, evaluating donor results against acceptance criteria, third review of analytical data on high detail final reports, confirmation data and instrument troubleshooting, feedback to the Confirmations team on instrument performance, communication with upstream departments and record keeping, and enforcement of acceptance criteria policies and procedures.   This position will be swing shift 4pm - 12:30am PT, with one or both weekend days. Hours will be adjusted for candidates not working in the pacific timezone.    Essential Functions:  Initial review of Confirmation data from LC/MS/MS, GC/MS/MS, and GC/FID instrumentation  Final Review and release of Confirmations data   Final Report review and release   Provide feedback to Confirmations maintenance team on assay integrity and performance  Comply with SOPs, regulations, best practices, guidelines, standards, policies and procedures  Responsible for meeting minimum productivity requirements  Applies knowledge and skills to produce quality work and facilitate meeting TAT goals  Directs efforts towards production areas that need assistance  Personal accountability for attendance, productivity, training, and technical incidents  Collaborate with co-workers, managers, and other supervisors to solve work-related problems, and resolving questions/issues daily  Participate in employee training for equipment, software, and other laboratory operations  Special projects as assigned  All other duties as assigned  Education and Experience:  Bachelor’s degree in hard science, required  Minimum of 2 years’ Chromatography experience, required  Agilent Masshunter experience of 2 years, preferred   Agilent LC/MS/MS operation and maintenance experience, preferred  Knowledge, Skills, and Abilities:  Knowledge of Horizon Laboratory Information Systems software preferred  Knowledge of CAP and CLIA desirable  Ability to work effectively in a remote, home-based role  Physical Requirements:  Light to moderate physical effort (lift/carry up to 25 lbs.) -Heavier weights with assistance  Sitting & standing for long periods of time  Repetitive motions and/or prolonged computer use  Working at a fast pace, subject to many interruptions and both physical and mental stress About Cordant Health Solutions  Working at Cordant Health Solutions means constantly being challenged to learn and grow in a fast-paced, dynamic, vibrant environment. Our team members are the key to our success and we are committed to providing an environment that not only offers a fun, positive work environment but also career building opportunities and a positive work/life balance. Cordant Health Solutions supports its employees by offering a benefits package to eligible employees that includes:  Medical / Dental / Vision Insurance  Flexible Spending Accounts (FSA)  Health Savings Accounts (HSA)  Paid Time Off (PTO)  Volunteer Time Off (VTO)  Paid Holidays  401(k) with Company Match  Company Paid Basic Life Insurance  Company Paid Long Term Disability  Short Term Disability Cordant Health Solutions is an Equal Opportunity Employer that believes diversity leads to a stronger organization. All qualified applicants will be afforded equal employment opportunities without discrimination because of race, creed, color, national origin, sex, age, disability, sexual orientation, military status, marital status, domestic violence victim status, arrest or conviction record, or predisposing genetic characteristics. Department: Laboratory Services (Facility) This is a non-management position This is a full time position",Algo de responsabilidad,Jornada completa,"Investigación, Análisis, Tecnología de la información","Dotación y selección de personal, Atención sanitaria y hospitalaria, Industria farmacéutica",2,None,False,,18,None
624,2204931447,2020-10-23,Infogrid,Senior Data Scientist,United Kingdom,"Senior Data Scientist About InfogridInfogrid is making scalable IoT (Internet of Things) a reality. Our goal is to be the global go-to provider for connected devices in smart buildings, creating dynamic solutions for everyday challenges. Our mantra is 'innovation through simplicity' and this ethos drives our product development. We are a small, rapidly expanding team but already have a broad portfolio of blue-chip clients – a testament to the strength of our product market fit. We are supported by top-tier venture capital funds. Infogrid is an IoT platform (physical sensors + SaaS) capable of handling millions of data events from hundreds of thousands of sensors every day. With cutting-edge, low-cost micro sensors provided by several 3rd party partners we're able to turn any building into a ‘smart’ building at a fraction of the cost of existing providers. The simplicity of our solution enables clients to self-install thousands of sensors in a matter of hours, and receive immediate real-time data. With the analytics and reporting we generate, companies can run more efficiently, pre-empt failures, save money, meet regulatory requirements, provide better environments for their employees and customers, and be more sustainable. About the roleOur solutions are deployed to 100+ clients in a range of industries - healthcare, commercial property, retail - producing access to a large (1bn+ and counting) number of data points and a unique dataset for building a differentiated AI capability - and we’re just getting started.  Through data science we are in the process of developing a platform that influences building owners, managers, and users towards a more sustainable future through transparency on otherwise hidden processes. We elucidate this through both direct sensor outputs (such as: current air temperature) and algorithmically-inferred outputs (such as: a temperature sensor placed in thermal contact with a water pipe can be used to infer water flow within the pipe).  Synthesising all these outputs to build up a holistic picture of a building, with an understanding of the interrelationships of the sensors - we access an ability to offer insights (such as on underused spaces), recommended actions (such as how to improve energy efficiency), and predictive aids to planning (such as when to increase capacity), in a real-time fashion that has never previously been possible as this data was unavailable. We innovate at the edge of what can be done in the new era of IoT, and we are at an inflection point in the centrality of data science to our growth - we are currently led by a highly-qualified team that we seek to expand by several senior hires that have room to grow in responsibility as the company continues to grow further.  What you will be doing●     Design novel sensor-based applications to solve hard and impactful problems for our broad client base●     Experiment with new technologies to harness an unparalleled dataset●     Develop machine learning models from concept to production deployment●     Whilst largely working in a team with other data scientists, you will also interface with specialists in other areas such as DevOps and the wider front- and backend-development teams to find the most optimal product solutions ●     Working directly under the Head of Data Science you will help to cultivate a team with huge growth potential and influence the trajectory of data science at InfogridWhat we are looking for●     3+ years experience in machine learning in a commercial environment●     Fluency in Python●     Experience with deployment of machine learning models (particularly AWS) is desired●     Experience with neural network architectures (particularly Tensorflow) is desired●     Experience with recommendation systems is desired●     A growth mindset, an interest in innovating new machine-learning products, and a willingness to work in a geographically-distributed team  Why we think you’ll love it here●     Fascinating challenges – no-one has a dataset quite like ours, which makes us uniquely placed to build AI products where solutions currently don’t exist. ●     Creative freedom - you’ll be joining us early on in our journey, with plenty of autonomy and room to develop your role as we grow●     We have a lot of flexibility on working times and fully embrace remote working●     Data science is at the heart of the company - your work will reach our clients all over the globe and set the trajectory for future innovation●     Competitive salary, holiday, perks and equity options package",Intermedio,Jornada completa,"Ciencias, Análisis, Ingeniería","Servicios y tecnologías de la información, Internet",94,None,True,,348,ACTIVELY_HIRING_COMPANY
625,2273320586,2020-11-04,Civis Analytics,Applied Data Engineer,"Chicago, IL, US","What We Do  At Civis, we take a science-first approach to solving problems. With a blend of proprietary technology and statistical advisory services, we help public and private sector organizations find, understand and connect with the people they care about, so they can stop guessing and start using mathematical proof to guide decisions. We know others use 'data science' and 'analytics' as buzzwords, but at Civis we don't stand for fluff, and we will always deliver scalable products and technologies — not PowerPoints — to drive your business forward. Learn more about Civis at www.civisanalytics.com.  Our mission  Our mission is to bring objective, data-driven truth to organizational decision-making – all the way from the boardroom to the world's largest social causes.  What We Are Looking For  Applied Data Engineers are experts in creating elegant, maintainable, and extensible data pipelines and database architectures. They partner with Civis's Applied Data Science consultants -- the Applied Data Engineers make the data clean and available, and the Applied Data Scientists analyze and present the data to clients.  As an Applied Data Engineer, you will structure, transform and clean complex data sets to enable our Applied Data Science Team to deliver exceptional data science solutions to our clients. You will also collaborate internally and with our clients to build elegant and sustainable data pipelines for our clients.  Responsibilities  Ingest data using connectors built by our Engineering team and build new data connectors as required. Collaborate with clients and client-facing teams to define user requirements and database design specifications for our clients' needs. Transform data based on business requirements. Apply data validation and/or software testing techniques to ensure data processes and pipelines are working properly. Create pipelines that deliver data error-free and on-time with features such as logging, fault tolerance, notifications, and scalability. Document and train others on data pipelines. Serve as a technical resource in resolving issues related to data pipelines. Work closely with client-facing teams. Develop your technical skills by working with our Engineering Team and other Applied Data Engineers   Minimum Requirements  Bachelor's degree in an analytical subject (statistics, math, economics, physics, engineering, business, political or social science, computer science, etc.) Demonstrated experience working with databases and data transformations  Proficiency in Python and SQL Ability to work as part of a cross-functional team to solve problems and build solutions Strong communication and teamwork skills US work authorization   Preferred Qualifications  Experience working on data pipelines in support of data analytics or data science applications Demonstrated track record working with data warehouse concepts Experience with software development practices including unit testing, version control, code review, and Agile development   Who We Are  At Civis, we have opportunities for applicants who are newcomers, seasoned professionals, and anywhere in between. Our teams are energized by complex challenges and value diversity of thought. Opportunities to stand out and inspire happen daily and we trust and encourage you to act on your ideas – no matter how big they are. We offer you the tools and community you need to do your best work. Each of us is committed to holding ourselves accountable for results, challenging the status quo and finding new ways to grow our company and each other.  Why join our team?  The opportunity to be part of a growing tech startup focused on solving interesting and meaningful problems, invested in internal promotion, and committed to fostering a diverse, equal and inclusive workplace.  Competitive benefits, including unlimited PTO, 401K match with immediate vesting, health, dental, and vision benefits, fully paid parental leave, breastfeeding support including breastmilk shipping services for traveling moms, commuter benefits, wellness initiatives including weekly group meditations, monthly on-site massage therapy, and pet insurance.  To support employees in our now fully remote work environment, we also have expanded our virtual journal and book clubs, Donut Pals (organized virtual coffee meet-ups), Lightning Talks (5-minute presentations on anything you'd like), Lunch-and-Learns, and HR Open Discussions (bi-weekly meet-up where we discuss ideas and topics of the day in a casual format). We are also able to support and accommodate flexible work from home schedules to help employees juggle responsibilities at home.  Civis Analytics embraces the individuality of our employees and we celebrate each other's differences. Our products, services, and culture benefit from and thrive on the unique perspectives brought by each person in our community. We're proud to be an equal opportunity workplace, and we are committed to equal employment opportunity regardless of race, age, sex, color, ancestry, religion, national origin, sexual orientation, gender identity, citizenship, marital status, disability, or Veteran status. If you have a disability or special need that requires accommodation, please contact internalrecruiting@civisanalytics.com  In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States.  EEO IS THE LAW  EEO Supplement  Pay Transparency",Sin experiencia,Jornada completa,Tecnología de la información,"Marketing y publicidad, Software, Internet",52,None,False,internalrecruiting@civisanalytics.com,219,ACTIVELY_HIRING_COMPANY
626,2281978916,2020-10-12,FlexJobs,Machine Learning Engineer,"Boulder, CO, US","Who We Are  In the past 13 years, FlexJobs has established itself as the leader in the professional flexible job market to help job seekers connect with employers that offer these highly desired arrangements, as well as to help employers reach these candidates. We do this by utilizing both technology and human intelligence to provide a friendly, effective, and valuable service.  Our mission is to help people find the best work from home and flexible jobs in an easier, safer, and faster way. We are committed to doing this internally and externally with integrity, intelligence, balance, communication, and care.  In terms of work flexibility, we also walk the talk. This is a remote job, as our entire team works remotely from locations all across the United States. Having a great company culture is really important to us and we've been named one of Outside magazine's Best Places to Work (2019) and Best Company Culture by Entrepreneur magazine (2018, 2017, and 2015). To learn more about our current team, you can explore our Team & Culture page.  Responsibilities Of The Job - The Opportunity  We're looking for an exceptional Machine Learning Engineer to join our engineering team. As an engineer at FlexJobs you'll work on challenging projects in collaboration with our Product and Quality Assurance teams to build, release, and maintain features for our user base.  Our team moves quickly and the ideal candidate will be comfortable working independently and at a fast pace, while also being adept at collaborating in a 100% remote environment.  Experience And Skills For This Role  3-5 Years Experience with NLP technologies, NLP model creation, implementations of grammar and semantic formalisms, machine learning, probabilistic reasoning, and/or information retrieval 3-5 Years Experience with NLP applications, such as named entity extraction, named entity resolution, relationship extraction, and natural language generation Knowledge of Natural Language Processing tools Understanding of Deep Neural Networks Strong technical proficiency with Python Understanding of basic computer science and statistical concepts in relation to NLP Familiar with basic NLP processing pipelines such as Text Cleaning, Tokenization, Vocabulary Building, Numericalization, etc. Familiar with common NLP tasks such as Language Modeling, Information Extraction, Sequence to Sequence Generation, etc. Experience using Python deep learning frameworks such as Pytorch (preferred), Tensorflow and Keras. Preferably having experience in training and deploying models at scale Ability to conduct detailed, annotated research 3-5 Years Experience with data science toolkits, such as Python's NLTK, REGEX, SciPy, or NumPy 3-5 Years Experience with NoSQL databases, such as MongoDB, Cassandra, or HBase Comfortable working with modern development tooling (Linux, Git, GitHub, Docker, Bash, AWS)   Traits Required Of All Team Members At FlexJobs  A sense of pride in your work A streak of perfectionism when it comes to details Being highly organized, responsible, and ethical Being proactive when it comes to asking questions, brainstorming, and working with colleagues Excellent time management and organizational skills An appreciation and enthusiasm for the ability to work remotely   Other Requirements  Interest in a long-term position with a company that you're proud to be a part of  A fully functioning home office, including high-speed internet access, a fast computer, and phone access A work environment that is quiet and one in which you can really focus without distractions   Benefits And Perks  Medical, dental, and vision benefits SIMPLE IRA with company match Flexible schedules and a generous time off policy Ability to work remotely Pay it Forward initiative (get paid to volunteer!) We offer many other supplemental benefits (critical illness, legal, etc) and stipends (office, wellness, professional development) Sustainable Office Perks   How To Apply  If this job description makes you feel as if it was written perfectly for you, then please apply! What we'll need:  An intro email/cover letter telling us why you want to work for FlexJobs (vs. another company) What makes you a great fit for this position What pay rate/salary would you be comfortable with A current resume in .doc, .docx, .pdf, .markdown, or .txt.  We respond to all applicants, so please check your spam folder or configure your gmail settings to set our email as safe to be sure you are getting our communications.  If you are selected to move forward, you may be required to do a background check.  FlexJobs is an equal opportunity employer. We celebrate and support diversity and are committed to creating an inclusive work environment for all employees. As a part of this commitment, we have pledged to be an Open to All business.  FlexJobs is also a veteran- and military spouse-friendly employer. Our positions are perfectly structured for qualified candidates who meet this criterion and we have a workplace culture that supports their work and life.",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Marketing y publicidad, Software, Internet",5,None,False,,36,None
627,1987004521,2020-10-24,Memorang,Senior Machine Learning Engineer,India,"About MemorangMemorang is building the most advanced learning software to automate studying in medicine and healthcare throughout the US and India. We’re a dedicated team founded by MIT engineers and doctors who are passionate about solving problems in education through technology and to empower the next generation of students. Currently, we’re launching a new version of our platform and expanding our core engineering team in Chennai to take Memorang to the next level. Role and ResponsibilitiesAs a Machine Learning Engineer you will be responsible for improving and implementing novel learning algorithms and recommendation engines. One such example is AIBL, our AI-Based Learning initiative that combines cutting-edge cognitive science, memory, and human behavior to build predictive memory models to automate how students manage their time and learn complex subjects. This role is perfect for a highly-skilled engineer who specializes in machine learning, wants to explore new technologies, push their skills to the limit, have creative freedom, and feel like they have significant ownership of major features. Requirements4+ years experience in AI/ML with end-to-end implementationExcellent communication and interpersonal skillsExpertise in SageMaker, TensorFlow, MXNet, or equivalentExpertise in JavaScript (Node.js), GraphQLPassionate about education Salary₹15,00,000-25,00,000 per year",Algo de responsabilidad,Jornada completa,"Ingeniería, Tecnología de la información",E-learning,452,None,True,,1360,JOB_SEEKER_QUALIFIED
628,2241576945,2020-11-05,Big Health,Senior Data Engineer - Remote,United States,"At Big Health, our purpose is to help millions back to good mental health.  Our “digital therapeutics” - Daylight™, for worry & anxiety, and Sleepio™, for poor sleep - are fully automated cognitive and behavioral programs that are as scalable and clinically validated as drugs.  Our software combines the intimacy of the human voice, engaging animation, and clinically rigorous techniques to help people overcome their mental health challenges. Big Health’s products are backed by 50 published clinical papers including 13 randomised controlled trials (RCTs), and are cited in leading clinical guidelines including the American College of Physicians and NICE.  Today, over 12 million people worldwide have reimbursed access to Big Health’s products, via leading employers in the US and the UK’s NHS.  There is a tremendous amount of value for our end-users in our ability to leverage the data we have to refine our digital therapeutics for maximum effectiveness.  The more insight we gain, the more we can help millions get back to good mental health.  You will assist in gathering the data, processing it, and enabling your stakeholders (customer success, clinicians, product managers, etc..) to access it and explore. You will organize the data so that they can best leverage it for their needs. You will collaborate with your peers and stakeholders to build a sustainable platform and find ways to increase our capabilities in the data domain. As Data Engineer at Big Health, you will:Build, test, document and maintain optimal data pipeline architectureEvolve your data pipeline and its components in pace with the needs of the businessDesign for scalability, observability and ease of maintenanceDeploy or build analytics tools that utilize data pipelines to deliver actionable insightsAssemble large, complex data sets to meet both functional and non-functional business demandsWork with the DEVOPS team to automate the management of the data infrastructureAssist engineers with dataset design and datastore selectionAssist all data consumers in leveraging our data to power their initiativesCommunicate with stakeholders across the company  In order to be successful in this role, you will need to have:4+ years of experience in writing Cloud applications that process large volumes of dataGood knowledge of AWS data processing offering (Kinesis, DynamoDB, S3, Elasticache, Aurora, ElasticSearch) or comparable ( Redis, Kafka, Cassandra, Google DataFlow, etc.)Good knowledge of RDBMS (Postgres or similar) on the topics of SQL, Indices, query tuning, debugging.Experience with Python in a production environmentKnow how to design data modelsUnderstand and applies relevant testing development practices  Life at Big HealthBe part of a team that includes clinical psychologists, software engineers, business leaders and even a former professional magician [shh… it’s a secret]. Surround yourself with the smartest, most enthusiastic and dedicated people you’ll ever meet, but who listen well, learn from their mistakes and when things go wrong, generously pull together to help each other out Check out our values - they’re a living, breathing part of our cultureEnjoy benefits including a generous vacation policy, professional development fund, flexible working locations and more.Competitive salary packages including stock options.  Because we are on a mission to bring millions back to good mental health, we believe it’s essential to reflect the diversity of those we intend to serve. We’re an equal opportunity employer dedicated to building a culturally and experientially diverse team that leads with empathy and respect.  Additionally, we will consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the San Francisco Fair Chance Ordinance.",Intermedio,Jornada completa,Ingeniería,"Software, Sanidad, bienestar y ejercicio, Atención sanitaria y hospitalaria",6,None,False,,65,COMPANY_RECRUIT
629,2269879658,2020-10-09,"Fetch Rewards, Inc.",Data Scientist - Clients,"Chicago, IL, US","Who We Are:  We reward shoppers for digitizing their shopping experience. Our mission is to delight the world's shoppers with a free smartphone app that is easy, smart and fun.  Why Join the Fetch Family?  We make it better for users even when that's difficult for us We empower people with information and trust We challenge ideas, not people We think bigger and keep building We find ways to bring the fun to Fetch!  We're committed to building an empowered and inclusive community of innovative and passionate people. As a growing organization, we need team players who can go above and beyond their individual responsibilities to help our company build towards its vision. If you are a creative, hard-working, and fun-seeking person interested in working with a close-knit group of highly talented people, this is the right place for you.  Fetch Rewards is an equal employment opportunity employer.  The Role!  The Data Science & Analytics team embodies these values and works with a laser focused objective to enable data driven decision making for both internal stakeholders and external partners. We are looking for a Data Scientist - Clients to contribute to this vision and reap the rewards of joining an exciting company in the high growth phase.  You will create analytical solutions and machine learning models that help Fetch teams leverage and monetize actionable insights from our unique data. This is a challenging and high visibility position, responsible for creating these solutions as well as guiding technical direction. Success in this role requires the ability to take on challenging problems and design & develop an amazing solution with little to no assistance.  You possess:   Hands-on experience in developing / deploying machine learning models that are tied to business value. At bare minimum, a good grasp of machine learning techniques, and their application in the real world. Ability to create SQL/Python programming modules for custom insights required by our clients. Leverage statistical analysis to understand what is 'acceptable' versus 'outliers'. Ability to successfully collaborate with both business users and engineers for effective analytical solution development and deployment Passion to drive actionable insights from data and present them to external and internal clients through Tableau / Powerpoint / Excel in a compelling manner. Knack for conducting the apt Data Exploration needed to enhance the cleanliness and effectiveness of our data sources. Discipline to create well documented coding and analytics packets to ensure reusability as the team expands. Master's or PhD in Statistics, Mathematics, Computer Science or any other Quantitative field 2+ years of experience in data science workstream  Bonus points for:   Experience in CPG/Retail domain and/or analytics at app-based B2C companies Familiarity with Big Data frameworks like Snowflake, Spark and AWS services Familiarity with Tableau or any other visualization tools Effective communication, ability to translate and explain technical issues to non-technical team members Love of Dogs! . . . Or just tolerance. We're a very canine-friendly workplace",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Software, Internet",2,None,False,,37,ACTIVELY_HIRING_COMPANY
630,2211199190,2020-10-26,Resolute Asset Management,Machine Learning Engineer,Germany,"About the Team Science and Data sits at the heart of Resolute Asset Management and plays a uniquely crucialrole in what we do. With data we build intelligent Real-Estate Asset Management capabilities thathelps our Clients and Analysts to understand and maximise the return of their granular portfolios.Fundamentally, data underpins the innovation and scaling of our current and future business atResolute Asset Management and being part of the team gives you the chance to have a majorimpact across the company – apply today to join our world class data science team. About The Role The driving force of managing Real-Estate assets is to build a complete 360 digital identity ofeach asset and provide the users with the intelligence to make decisions on the liquidity, valueand segmentation to maximise the revenue from their assets.You will be in the centre of this product – as a Machine Learning Engineer you will work in theData Science team, the Back-end and Front-End Engineers as well with client teams to create aset of Products to help lead the market in Real-Estate Asset Management using a range oftechnologies such as NLP, Data extraction and remediation, Image recognition, financialmodelling, Proprietary models for Asset value, Liquidity and target Audience, GIS and localinformation driven insights. What Skills You'll Need 1-3 years proven experience as a Machine Learning Engineer or similar roleFluent in Python for data modelling, advanced analytics, automated pipelines and software developmentAble to come up with new data ideas as well as focus on the internal business to drive efficiencies and innovationKnowledge of ML and AI algorithms and the theoretical/practical/statistical reasoning behind themFamiliarity with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn)Fluent in SQL for working with database (PostGIS knowledge is desired)Experience of cloud technologies like google cloud platform (BigQuery, Google Storage etc.) and distributed data computingWorked with data visualisation techniques from simple charts to maps within custom reports or interactive dashboards (with Javascript, Qliksense, PowerBI etc.)Used data scraping techniques to extract information from various websitesInterest in Real Estate and Property MarketCommercial and business development knowledgeFollow methodologies for existing projects and research/develop new technologies and solutionsHave communication skills, good at data storytelling and confident to present products and service offeringsDesign proof of concepts and deliver minimum viable products to internal stakeholders and external clients Fluent in EnglishExperience in geospatial domain, GIS applications and expertise in spatial data engineering is desirable A Bit About Us Resolute Data Science believes that enabling our clients and analyst with impactful data and intelligent technology will enable the growth of projects with our existing clients and to acquirenew clients.Resolute Asset Management started in 2010 and Resolute’s combination of real estate, bankingand finance capabilities allows us to deliver tangible, measurable benefits to our FinancialInstitution clients throughout the business cycle. Our ability to understand not just asset specificand real estate sector issues, but also regulatory, accounting and general banking frameworksensures we deliver practical solutions to real estate related banking challenges. What We Are Looking For You will be self-motivated and yearn for making an impact through your skills and determination.You look for solutions to overcome problems and lead by example even if in a junior position.You can work autonomously and take ownership. We thrive with the space and responsibility tosolve problems.You operate best without lots of bureaucracy. We don’t hide behind fancy job titles or clunkyprocesses ‘because that’s how things are done’.You approach work in a logical way. We are not afraid to make mistakes, but we use scienceand data and logic to backup decisions and improve understanding.  The Benefits Competative Salary €50,000 - €55,000Inclusion in company annual bonus schemeAll the latest tech you needWork Anywhere - working from home and flexible hoursPension planRest up with 25 days’ holiday per year",Algo de responsabilidad,Jornada completa,"Ingeniería, Tecnología de la información","Servicios financieros, Bienes inmobiliarios, Bienes inmobiliarios comerciales",314,None,True,,967,ACTIVELY_HIRING_COMPANY
631,2193840333,2020-10-19,Oak Ridge Institute for Science and Education,Postdoctoral Researcher in Fusion Energy Sciences,United States,"Department of Energy Fusion Energy Sciences Postdoctoral Research Program Application deadline: January 4, 2021Recommendation(s) deadline: January 4, 2021 The Fusion Energy Sciences Postdoctoral Research Program is looking for applicants that have recently received or are currently pursuing a doctoral degree (received prior to the desired start date) and interested in conducting research in an area of interest to FES, specifically in the following areas:Burning Plasma Science: Foundations advances the predictive understanding of plasma confinement, dynamics, and interactions with surrounding materials.Burning Plasma Science: Long Pulse explores new and unique scientific regimes that can be achieved with long-duration superconducting international machines and addresses the development of the materials and technologies required to withstand and sustain a burning plasma. Discovery Plasma Science supports research that explores the fundamental properties and complex behavior of matter in the plasma state to improve the understanding required to control and manipulate plasmas for a broad range of applications. The Benefits: You will receive an annual stipend of $71,000 plus a supplement to offset the cost of health insurance. The program will also provide a one-time $3,000 relocation allowance (if eligible). You will also receive a $4,000 travel allowance per year. Travel allowance can be used to support travel to FES-related conferences (domestic or foreign). Appointment periods are for up to two years. The initial appointment period is for one year. Extension of the appointment for the second year will be subject to satisfactory progress toward completion of the project assignments and availability of funds. An International Collaboration Supplement (ICS) is also available (optional). See ICS section for more information. Eligibility Requirements ﻿You must:Be a U.S. Citizen or Lawful Permanent Resident.Have received a doctoral degree in an appropriate science or engineering discipline within four years of the desired start date or expect to complete degree requirements prior to the desired start date.Be available to conduct research at the hosting facility for up to two years. Preferred academic fields include:Experimental Plasma PhysicsTheoretical Plasma PhysicsComputational Plasma PhysicsPlasma-Material Interfacial ScienceNuclear EngineeringMaterial SciencePhysicsComputer ScienceMathematics",Sin experiencia,Jornada completa,Investigación,Administración gubernamental,5,None,False,,184,None
632,2255969645,2020-10-20,Tilting Point,Growth Marketing Director,"New York City, NY, US","Our Growth Marketing Director will lead our UA team to provide our developer partners with the best growth service offering of the market. Driving by excellence, you are tech-savvy and have exceptional analytical skills and strong valuable experience in strategies that attract high value players.  Here you'll join a team that's fully committed to our developer partners in supporting their games with first-class services. In this role, you'll play a critical strategic part in shaping the future of Tilting Point and the future of our developer partners from around the world.  Your Future at Tilting Point  Own our Growth marketing service across a portfolio of awesome games and apps spanning a variety of channels worldwide. Maximize ROAS for each game, channel and user cohort, ensuring acquired customers meet objectives for overall revenue and volume. Collaborate with creative teams to construct exciting campaigns, landing pages, creative directions, and messaging. Work closely with our Data Scientist team to consistently upgrade and enhance our User Acquisition Tech. Build and groom our Growth marketing team successfully. Help Tilting Point becoming a beacon of Growth Marketing excellence on the mobile apps market.   Your XP & Skills  Positive attitude, passion for games, and a love for problem solving. 5+ years of mobile experience managing mobile performance-based user acquisition campaigns. Highly analytical, with deep understanding of cohort analysis and customer acquisition metrics including LTV, CPC, CPA, and payback period. Experience with A/B and multivariate testing and creative, copy, and landing page development. Excellent communication skills to develop strong relationships with creative partners. Has built a team of successful people. Excited to work in a lean, small team environment working with the world's leading developers.  Interested? We would love to hear from you. All submissions are confidential.  *Direct applicants only - No agencies/headhunters please.*  Tilting Point provides equal employment opportunity to all individuals regardless of their race, color, creed, religion, gender, age, sexual orientation, national origin, disability, veteran status, or any other characteristic protected by state, federal, or local law. Discrimination of any type will not be tolerated. This policy applies to all terms and conditions of employment, including recruiting, hiring, promotion, termination, time off, and compensation.",Director,Jornada completa,"Marketing, Ventas","Marketing y publicidad, Software, Internet",12,None,False,,97,COMPANY_RECRUIT
633,2251944309,2020-10-29,Quora,Senior Data Scientist,"Mountain View, CA, US","[As of June 2020, Quora has become a 'remote-first' company. This position can be performed remotely from anywhere in the world, regardless of any location that might be specified above.]  About Quora:  The vast majority of human knowledge is still not on the internet. Most of it is trapped in the form of experience in people's heads, or buried in books and papers that only experts can access. More than a billion people use the internet, yet only a tiny fraction contribute their knowledge to it. We want to democratize access to knowledge of all kinds — from politics to painting, cooking to coding, etymology to experiences — so if someone out there knows something, anyone else can learn it. Our mission is to share and grow the world's knowledge, and we're building a world-class team to help us achieve this mission.  About the Team:  The Data Team is highly empowered at Quora, helping navigate complexity and influencing product and company strategy directly. Quora's outsized commitment to data is visible in everything we do, from our rigor-driven experimentation processes to the backgrounds of our leaders. With this emphasis on data and empirics, we aim to balance rigor and pragmatism, searching for scrappy solutions in pursuit of our mission. In joining Quora's strong data team, you'll both benefit from and work to advance our culture of rational decision making.  About the Role:  As a data scientist, you'll work closely with product managers, product designers, and engineers to devise appropriate measurements and metrics, design randomized controlled experiments, build visualizations, and tackle hard, open-ended problems that uncover usage patterns and opportunities for the company. Quora has a wide range of rich data, giving you ample room for exploration and creativity. Examples of some projects our data scientists have worked on include modeling our long-term growth, improving the relevance and personalization of the homepage feed, and exploratory analysis of factors driving question-asking behavior. For more about our work, see Quora's Data blog at https://data.quora.com/.  As a senior data scientist, you will draw on your experience to excel not only in your own work but also to elevate data's impact at a company-wide level. You will provide team mentorship that propels the work of your colleagues while helping to establish best practices for data usage across Quora.  Responsibilities:   Extract actionable insights from broad, open-ended questions Design and evaluate experiments to measure the impact of product changes Analyze data from across the product to uncover the root causes of metric movements Communicate results to cross-functional stakeholders to inform product decisions Develop tools to scale and automate analyses, improving productivity across the company Improve the work of other data scientists through mentorship and by bringing industry best practices to the team  Minimum Qualifications:   Ability to be available for meetings and impromptu communication during Quora's 'coordination hours' (Mon-Fri: 9am-3pm Pacific Time).  Learn why here 3+ years work experience in an analytical or quantitative role as a Data Scientist or similar title 2+ years experience working on product analytics Extensive experience generating insights using statistical techniques (e.g. regression, hypothesis testing) Demonstrated ability to clearly explain data results to cross-functional teams Experience using a procedural programming language (e.g. Python, R) to manipulate, clean, and analyze data Ability to exercise judgment and combine quantitative skills with intuition and common sense Experience evangelizing best practices and process improvements on your team  Preferred Qualifications:   Experience working with large data sets and distributed computing tools (e.g. Redshift, Presto) Experience pushing code and navigating a complex codebase Active Quora user with curiosity about the product   We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.  California Consumer Privacy Act (CCPA) disclosure",Algo de responsabilidad,Jornada completa,Otro,"Marketing y publicidad, Software, Internet",102,None,False,,350,COMPANY_RECRUIT
634,2218880965,2020-10-28,IQVIA,Data Scientist (IA),"Warsaw, PL","Data Science & Advanced Analytics  Data Science & Advanced Analytics - with departments in Frankfurt, Philadelphia, Beijing and Warsaw as well as a network of over 150 team members worldwide - is the global competence centre for data science at IQVIA. Complex advanced analysis at the highest level are conceptualized and implemented to support international customers in the pharmaceutical industry - often within multinational projects. As a member of our team you can expect exciting international projects with interesting development perspectives.  Data Scientist, Data Science & Advanced Analytics – the role Collaboration in projects of the European Data Science & Advanced Analytics TeamSupport in concept design and development of innovative sampling approaches.Ongoing development and improvement of quality control (e.g., anomaly detection, isolation trees), ML based imputation and various projection methodologies (e.g., geo-spatial, cloning, ML based, etc), specifically for large data sets.Support in development and automation of machine learning solutions and technologies and high scale deployment for Healthcare Big Data (Pharmacy, Hospital, Physician, Patient)Selection and application of machine learning techniques, in connection with Healthcare Big Data to identify complex patternsWorking with technology teams to support machine-learning algorithms in big data platforms  Our Ideal Candidate Will Have Master degree in Mathematics/Statistics, Economics/Econometrics, Computer Science or related fieldAt least 2 years of professional experience in quantitative data analysis or PhD with at least 1 year of relevant professional experience with research in machine learning algorithmsGood knowledge and understanding of Machine Learning methodsExperience applying Machine Learning methods to business questionsGood knowledge of the higher statistical and econometric methods in theory and practiceExperience with handling Big DataSkilled in Python/R and SQLFluent in EnglishKnowledge of German and/or Polish language would be an assetStrong analytic mindset and logical thinking capability, strong QC mindsetDemonstrates consulting, creativity, critical thinking, project planning, and attention to detail capabilitiesKnowledge of pharmaceutical market and experience with pharmaceutical data (medical, hospital, pharmacy, claims data) would be a plus, but not a must  We know that meaningful results require not only the right approach but also the right people. Regardless of your role, we invite you to reimagine healthcare with us. You will have the opportunity to play an important part in helping our clients drive healthcare forward and  Whatever your career goals, we are here to ensure you get there!  We invite you to join IQVIA™.  At IQVIA, we believe in pushing the boundaries of human science and data science to make the biggest impact possible – to help our customers create a healthier world. The advanced analytics, technology solutions and contract research services we provide to the life sciences industry are made possible by our 67,000+ employees around the world who apply their insight, curiosity and intellectual courage every step of the way. Learn more at jobs.iqvia.com.",No corresponde,Jornada completa,"Ingeniería, Tecnología de la información",Industria farmacéutica,106,None,True,,442,COMPANY_RECRUIT
635,2289599778,2020-11-06,Springboard,Data Engineering Course Office Hours Host (Part-Time/Flexible/Remote),"Coronado, KS, US","Springboard runs an online Data Engineering Career Track in which participants learn with the help of a curated, project-based curriculum and 1-1 guidance from an expert mentor. As part of the program, students have access to a variety of different resources which includes weekly Office Hours with a Data Engineer. Data Engineering Career Track is a 6-month intensive bootcamp and we are looking for an Office Hours Host to help support students outside of their mentor calls.  Requirements  Host and facilitate weekly 30-minute Zoom video call sessions to students (the time commitment will be 30 minutes/week) Provide high quality responses to technical/curricular questions in each office hour Each Office Hour will be 30 minutes long, sessions will either be a QA format or alumni can present their completed projects. The OH Host will be expected to be familiar with Springboard support and the curriculum. Welcome each cohort of students and regularly share relevant events, resources, articles with the students during the session.  Requirements Are as passionate about teaching Data Engineering as about Data Engineering itselfHave at least 3 years of experience as a Data Engineer or Data Developer or related fields (Machine Learning, Data Scientist, etc)Azure cloud experience preferredProfessional experience with SQL and an OOP language like Python or JavaHave an excellent understanding of fundamental data engineering skills, tools, and concepts including working with Big Data (Hadoop, Spark), Cloud platforms (AWS, Azure), building data pipelines (batch/streaming, APIs), orchestration (Airflow), and containerization (Kubernetes, Docker).Are empathetic and have excellent communication skills, able to break down complex concepts for beginners  More details  Completely online and self-paced. Coursework is 200 hours and on average, students finish it in 6 months. Participants in this course are working professionals and college students from all over the world, interested in getting started with data science. Participants learn about Data Engineering with the help of a curated online curriculum and a personal mentor. They go through the curriculum at their own pace and have a weekly 30-minute checkin with their mentor to discuss questions, projects, and career advice!  Part-time (Contract)  The Springboard team of 180 works out of offices in the heart of San Francisco and Bengaluru. We’re backed by top investors, including Costanoa Ventures, Reach Capital, Learn Capital, Pearson Ventures, and the founders of LinkedIn and Princeton Review. Working with us, you’ll enjoy competitive compensation and an opportunity to impact thousands of lives alongside a fun, dedicated and mission-driven team. To learn more about our team and culture, follow us on Instagram @springboardlife!",Sin experiencia,Media jornada,"Atención al cliente, Tecnología de la información",Software,None,None,False,,4,JOB_SEEKER_QUALIFIED
636,2239854066,2020-09-30,B12,Data Engineer,"New York City, NY, US","Data Engineering at B12  B12's engineering team views software as a craft, but improving the world as the reason to practice it. Our engineers are responsible for prioritizing, conceptualizing, co-designing, building, testing, and engaging users for any concept we are building out. We're generalists in encouraging each other to experience the full stack, but we're also aware of each other's preferences in the stack. We mentor and teach where we can, both inside and outside of the company.  We value sharing our work with the outside world. Our team has published papers on forming expert flash teams and machine-mediated worker hierarchies. We've baked our research into Orchestra, the system that coordinates our expert and machine teams, and released Orchestra into open source to contribute our software back to the community.  We're looking for a Data Engineer to help us answer critical questions our business faces while improving our data systems and architecture to support greater variety, volume, and velocity of data and data sources. We hope our engineers have more longevity than any one tool we use, but here is a sampling of our current thoughts about technology:  We build our product on Python/Django and JavaScript/React. We store blobs in Amazon's S3, munch on them in Amazon's EC2, develop in Docker, and deploy containers to Amazon's Elastic Beanstalk. We believe Postgres should be the first system you consider when you think about persisting structured data. We religiously clean and centralize data in Amazon's Redshift, and are able to answer most any question in SQL. We recently wrote our 1000th query in Metabase! Before building complex statistical machine learning models, we build simple ones we can understand. Rarely, we build complex models. We have near-full test coverage on the backend, and are making progress on our frontend and integration tests. We set up continuous integration and deployment because, while this model comes with its own pains, we've disliked being on fixed release schedules on previous projects. We like to move fast and support point-in-time recovery :).  As a Data Engineer, you will  Collaborate with operational teams including sales, marketing, and customer success. Contribute to infrastructure that enables and informs B12's analytical efforts. Write SQL queries and reusable views that enable various analyses including funnel, retention, and performance reporting. Use Python to clean data, send it to various systems including our data warehouse and operational services, and perform feature engineering to power the creation of predictive models. Build rules-based models and statistical machine learning models in Python using packages like scikit-learn.  You'd be a good fit if  You are fluent in SQL and Python. You have experience building and using data infrastructure, including systems like Postgres and Redshift. You've used reporting tools like Metabase, Tableau, or Looker in the past. You know that no dataset is ever pristine, but love to interrogate, structure, and clean data. You've contributed to extract-transform-load pipelines to collect data from disparate sources and centralize them in a data warehouse.  You feel comfortable managing your time and deciding amongst competing priorities. You have worked with non-engineering teams and are comfortable explaining technical solutions to them. You are passionate about the future of work. You enjoy learning and teaching. You have strong written and verbal communication skills in English. You care about and want to contribute to our mission of helping people do meaningful work.  Don't fear  We don't have a minimum number of years of experience for this role. We highly favor talent and interest. Some candidates may see this list and feel discouraged because they don't match all the items. Please apply anyway: there's a good chance you're more wonderful than you think you are.  B12 is a safe place for human beings. We are dedicated to building a diverse and inclusive team with a wide range of backgrounds and experiences, each helping us understand our customers better, and strengthen our team. We particularly encourage you to apply if you identify as a woman, are a person of color or other underrepresented minority, or are a member of the LGBTQIA community.   How To Apply  Please provide:  A pointer to your CV, resume, LinkedIn profile, or any other summary of your career so far. Some informal text introducing yourself and what you are excited about. If you have a profile on websites like GitHub or other repositories of open source software, you can provide that as well. If you don't have one, it's still very possible for us to get along just fine!",Sin experiencia,Jornada completa,Tecnología de la información,"Marketing y publicidad, Software, Internet",27,None,False,,115,ACTIVELY_HIRING_COMPANY
637,2261414384,2020-10-06,eyeo,Senior Data Scientist (ML),"Berlin, DE","Get to know us  eyeo is an open-source software company that builds products like Adblock Plus, Adblock Browser and Flattr. By leveraging distribution partnerships, we bring ad-blocking technology everywhere, giving users control over their online experience while offering creators, publishers and advertisers more ways to earn money for the free content they provide.  In combining our reach based on distribution partnerships and our own products, our technology runs on over 150 million devices.  At eyeo, we're passionate about user agency, personal privacy, sustainability and keeping the web an open, fair resource for everyone.  How we work  eyeo colleagues are based all over the world. We practice agile and work in distributed, cross-functional teams that span nearly every timezone. Many of our tech teams prefer to work asynchronously.  What you'll do  Creating an MVP for a greenfield project with a vision and a timeline.  Put the privacy and control of the user at the heart of all you do Create models Categorize the web's content Translate models to app & extension developers Help shape the future of the project by providing the team with information and solution options  Balance usefulness with performance on mobile devices Work on a solution scalable to more than hundred million users Integrate data from remote devices into your model in a privacy safe way (federated learning)  What you bring to the table...  Ability to self-manage, explore and research Ability to present and pitch results to a variety of stakeholders Fast learner Several years of experience with production quality ML models  Developing, training, deploying and iterating on models Python  pandas, numpy, scikit-learn PyTorch TensorFlow     Training and deployment of ML models in the Cloud  Preferably Google Cloud Platform (GCP) Alternatively AWS, Azure, IBM   Some background in software and/or ML engineering Relevant statistics skills (specialized statistics for ML and/or generic from maths, physics and other natural sciences, economics)   It's Awesome, But Not Required, If You Know About...  Experience in AdTech Hands-on experience with recommender systems (movies, songs, shop items, friends, jobs, hotels) or search engines Experience collaborating with software developers bringing ML models into client applications  Javascript development Android development   Natural language processing (NLP) or understanding (NLU)  Text Classification Transformers / BERT   Distributed learning, federated learning Git Linux, bash Containerization R: tidyverse Experience working remotely Participation/winning in coding/ML competitions  What we offer  Work from home, one of our offices, or a co-working space—we trust you to find what works best for you Stipend for one of the following: home office, co-working space, or relocation Flexible working hours 26 days paid vacation days Your choice of hardware and setup Personal and professional development budget Monthly childcare stipend for children under 6 Offsite team days and annual summer company retreat in Cologne Company-sponsored hackathons  Privacy Notice  When you apply, you'll be automatically forwarded to our recruitment platform operated by an external service provider called Greenhouse (seated in the US). Greenhouse collects some information on its website, such as anonymous usage statistics, by using cookies, server logs, and other similar technology. For more information, please refer to Greenhouse's Privacy Policy. All documents and information provided by you are stored with Greenhouse. In order to ensure an adequate level of data protection, eyeo and Greenhouse have entered into the EU Standard Contractual Clauses ('processors') - Commission Decision C(2010)593. You can request a copy of this by contacting us at privacy[at]eyeo.com. If you don't want your data forwarded to Greenhouse, please do not apply. For detailed and further information, please refer to our Privacy Policy at https://eyeo.com/en/privacy.",Algo de responsabilidad,Jornada completa,Otro,"Servicios y tecnologías de la información, Software, Internet",8,None,False,,78,COMPANY_RECRUIT
638,2290343414,2020-11-07,Rishabh Software,Director of Data Science Remote - Myrtle Point,"Myrtle Point, OR, US","Title Director of Data Science Location Remote Notes  Need strong PythonR and Spark experience with backgrounds in MLAI (SciKitLearn, XGBoost, PyTorchTensorFlow) in addition to team management skills.  If and as we see strong Data people with backgrounds in SaaS specific products alongside the other needed skills pass along for your review as well.  Director level Data Scientist about half managerhalf technical do-er.  The CEO is a programmer and a highly technical person, that paints the picture.  Summary  We are seeking an ambitious, well-rounded Director of Data Science to run a Data Science department for an award-winning, venture-backed, fast-growing company. This role will play a key role in our growing Data Science team and provide strategic insights on how best to operate this side of the business.  This role offers a unique opportunity to work on very large data sets and solve challenging business problems focused on recommendation systems, machine learning, deep learning, and NLP. If this sounds intriguing, then we would like to talk to you about this key role leading our technical team.  This position is half manager and half technical individual contributor. It is a roll-up the sleeves management role, responsible for a team of 7 technical personal and engineers.  Responsibilities  You'll join a team of ML Engineers and Applied Research Scientists to make recommender systems as simple as possible.  You are able to lead in a collaborative fashion as well as advise and interact with the Product team and C-Level stakeholders.  You possess strong communication skills and can clearly communicate a vision, and drive innovation.  You will have a demonstrated history of implementing ML solutions into a production environment.  you will possess exceptional knowledge of Python or R (using libraries and writing custom code), and Artificial Intelligence.  Experience with Natural Language Processing (NLP) is also considered an asset  Required Skills And Experience  10+ years of experience leading a multi-faceted technical data science team  As the ideal candidate, you will have multiple degrees in Computer Science, Statistics, Mathematics, Engineering, or Computational Science as well as a history of solving difficult problems using a scientific approach.  Strong experience and knowledge in Machine Learning (ML), or Artificial Intelligence (AI)  Experience with feature engineering and storing (Spark, dataflow, etc.)  A deep understanding of algorithms and evaluation methods used in production-grade content recommender systems.  Experience deploying recommender systems into production across a range of models and platforms.  Hands-on practice of ML using machine learning libraries and frameworks such as SciKitLearn, XGBoost, PyTorchTensorFlow.  Excellent interpersonal skills are required, along with the ability to work in a dynamic, product-oriented, global team.  You understand the entire lifecycle of machine learning product development, from inception to production.",Director,Jornada completa,"Ingeniería, Tecnología de la información","Sanidad, bienestar y ejercicio, Profesiones médicas, Atención sanitaria y hospitalaria",4,None,False,,10,None
639,2281883519,2020-10-13,Coinbase,Senior Data Scientist,"Atlanta, GA, US","Coinbase has built the world's leading compliant cryptocurrency platform serving over 30 million accounts in more than 100 countries. With multiple successful products, and our vocal advocacy for blockchain technology, we have played a major part in mainstream awareness and adoption of cryptocurrency. We are proud to offer an entire suite of products that are helping build the cryptoeconomy, and increase economic freedom around the world.  There are a few things we look for across all hires we make at Coinbase, regardless of role or team. First, we assess whether a candidate demonstrates our values: Clear Communication, Positive Energy, Efficient Execution, and Continuous Learning. Second, we look for signals that a candidate will thrive in a culture like ours, where we default to trust, embrace feedback, disrupt ourselves, and expect sustained high performance because we play as a championship team. Finally, we seek people with the desire and capacity to build and share expertise in the frontier technologies of crypto and blockchain, in whatever way is most relevant to their role.  Read more about our values and culture here.  At Coinbase, our vision is to build an open financial system for the world, and to get there we'll need to continually learn from our data. Data scientists are focused on this critical step of converting data into learning.  You'll spend part of your time collaborating closely with business partners in product, engineering, finance and marketing teams — to ensure we're focused on the biggest opportunities and interpreting our data correctly. And you'll spend the other part of your time with the Data team building analytics models and systems that help scale our insights more broadly, both throughout the company and directly in the product. We expect you to demonstrate clear communication, strong desire to execute and best-in-class craftsmanship.  What you'll be doing (ie. job duties):   Measure business performance, develop core metrics and create dashboards to track and understand them. Identify data, metrics and analyses needs for business partners: Initiate, develop and maintain data pipelines and data models that powers dashboards and data products with outstanding craftsmanship.  Perform deep analyses and build models to understand customer behavior, and extract key insights that impact product decisions. Synthesize data learnings into compelling stories and communicate them throughout Coinbase. Act as a strategic partner to functional teams and Coinbase executives: initiate and execute on data-driven analyses to help prioritize opportunities and provide actionable recommendations  Prototype new analytics & machine learning models that improve both our insights and the product directly. Work across multiple subject matter experts to drive new data initiatives, automation of reports, establish best practices and mentor junior members in the team. Lead analytics projects to completion. Work with the broader Data team to find ways to scale our insights through better systems and automation.  What we look for in you (ie. job requirements):   5+ years relevant experience Demonstrate our core cultural values: clear communication, positive energy, continuous learning, and efficient execution. Understanding of statistical concepts and experience in applying them. Experience in data analyses using SQL. Experience in at least one programming language (e.g. R, Python, Java, Ruby, Scala/Spark, or Perl). Be able to independently create plans for analytics projects and build collaboration within the team. BA / BS degree or equivalent practical experience  Nice to haves:   Be able to proactively manage prioritization of work and deliver work with great quality and influence the broader team in creating leverage. Previous experience working with financial services data is a plus. Experience with Looker, Tableau or other business intelligence platforms. Domain experience in product, marketing, growth, or other business analytics areas. Experience manipulating large amounts of structured and unstructured data.",Algo de responsabilidad,Jornada completa,Otro,"Servicios y tecnologías de la información, Software, Servicios financieros",None,None,False,,26,COMPANY_RECRUIT
640,2289020384,2020-10-14,Koyo,Senior Data Scientist (UK Remote),"London, GB","Senior Data Scientist   This is a UK remote position  Who We Are  The current system of credit, based on bureau data, is deeply unfair, penalising people who live in lower income areas, people who are new to the country or customers who have used high risk products in the past (such as payday loans). Koyo was founded in 2018, on the principle that everyone should have access to affordable credit regardless of where they are from, where they live, or types of credit that have used.  Many seeking credit are charged excessive fees and interest rates for borrowing that cause financial problems, rather than solve them. We’re changing all that.  Koyo uses innovative technology to offer fairly priced credit to millions of UK customers. We’re based in London, with global ambitions. Koyo is backed by leading venture capital funds (the same funds that backed the likes of Revolut, Transferwise and others) and some of the most reputable angel investors in the UK. Join us, and help put an end to predatory financial firms and be part of an exciting and rewarding journey.  Our story so far  In 2016, Thomas, the founder of Koyo moved to the UK and found accessing credit to be difficult if not impossible. This is because his credit history did not follow him from his home country. He realised that having an imperfect credit history affects millions of people who are new to the country, but also people who have failed to build a credit history in the UK more generally. In September 2018 we raised our first round of venture funding and have since raised further debt and equity funding from venture capital funds and private investors.  What You'll Be Doing  You will be our first dedicated data scientist hire.  Improve the accuracy of our in-house banking transaction classification engine - researching, evaluating and recommending the best machine learning algorithms. Analyse the banking transaction data providing insights and recommendations for summary statistics and quality measures. Analyse and make recommendations for policies that maximise loan approval rates whilst keeping loan defaults within target using and cross-referencing across all data-sets that are available to us (including but not limited to self-stated application data, credit reference agency block-summary and detailed data and bank transaction data). Working across the wider team, providing proactive and reactive reporting and analysis. Longer term, you will help build out the data scientist function at Koyo.   Requirements  Remote but must be based in the UK Strong commercial experience, likely to have a computer science or related degree Entrepreneurial and excited about working at an early stage startup Knowledge of multiple machine learning algorithms - when to use them, when not to and how to optimise Basic programming knowledge - Python/Java/R Ability to extract, cleanse and load data in various formats and across multiple data sources. Expert knowledge in SQL Happy to work in an early stage startup You have a growth mindset You’re excited to learn new things every day and have a passion to inspire and grow. Experience in lending ideal, but not a requirement.   Benefits  Competitive salary. Equity in the business - you will own a part of the company that you are helping to build. Work with a rapidly growing Fintech with an innovative business model Opportunity to shape the strategy and direction in a company with an important mission. Working with bright ambitious people who take pride in what they do",Intermedio,Jornada completa,Tecnología de la información,"Internet, Banca, Servicios financieros",None,None,False,,13,JOB_SEEKER_QUALIFIED
641,2181303212,2020-10-13,Focus GTS,Machine Learning Engineer,United States,"ML Engineers shall provide the following functions and deliverables: Develop custom data models and algorithms to apply to data sets.ML Ops experience. Experience with doc classification and extractionUse predictive modeling to increase and optimize customer experiences Coordinate with different functional teams to implement models and monitor outcomes.Develop processes and tools to monitor and analyze model performance and data accuracy.Work with data sets and build models for document classification and OCR.Present insight into the working of relevant algorithms and models. The key difference between our ML Engineers and Data Scientists is that the former has more experience putting models into production and experience/familiarity with things like AWS Lambda, AWS Step Functions, CI/CD pipelines, using Git for version control, while the latter(Data Scientists) have more focus on model tuning, hyperparameter search, Python notebooks,etc.  Again, both types need to know all the above, but the relative focus and experience is the differentiator.",Director,Jornada completa,"Ingeniería, Tecnología de la información","Servicios financieros, Banca, Consultoría de estrategia y operaciones",286,None,True,,604,JOB_SEEKER_QUALIFIED
642,2237128176,2020-11-03,European Recruitment,Computer Vision Researcher - Machine Learning/ SLAM/ 3D Reconstruction/ Deep Learning/ Signal Processing,"Zurich, Switzerland","Computer Vision Researcher/Machine Learning - SLAM/ 3D Reconstruction/ Deep Learning/ Signal Processing  We are currently looking to speak with experienced Computer Vision/ Machine Learning Researchers to work with a global technology company based in Zurich, Switzerland.  In this role you will identify trends for next generation computer vision and machine learning architectures and develop innovative technologies and system concepts. You will be designing and developing cutting-edge CV/ML and CG technologies and related signal processing algorithms for imaging restoring, 3D vision and for utilizing novel hardware and system architectures such as camera and sensor. Requirements: In-depth understanding of multimedia signal processing, pattern recognition, scene understanding, deep learning and other fieldsGood understanding of the multimedia/camera hardware and system and have experience in developing the corresponding hardware and softwareGood understanding of large-scale 3D reconstruction and positioning technologyGood understanding of computer vision related algorithms, familiar with the mathematical foundation of CV, deep understanding of related theories such as linear algebra and multi-view geometryExperience with CG/CV and new computing architectures. Master computer vision basics, deep learning, and classic machine learningAbility to abstract the mathematical model of the real problem, and to solve mathematical problemsThe ability to innovate in the algorithm and system concepts is preferredPh.D. degree in Computer Science or similar If this position could be of interest apply today or email me at cm@eu-reruit.com to discuss this role further.  By applying to this role you understand that we may collect your personal data and store and process it on our systems. For more information please see our Privacy Notice https://eu-recruit.com/about-us/privacy-notice/",Intermedio,Jornada completa,"Ingeniería, Diseño, Tecnología de la información","Interconexión en red, Software, Investigación",54,None,True,cm@eu-reruit.com,267,COMPANY_RECRUIT
643,2249061801,2020-10-03,"3 Key Consulting, Inc.",Process Development Scientist- REMOTE (JP7716),"Boston, MA, US","Job Title: Process Development Scientist- REMOTE (JP7716) Location: Virtual Site in, Boston, Massachusetts 02110 Employment Type: Contract Duration: 12 months with likely extensions Job posting date:24 September 2020 Note: Fully Remote  3 Key Consulting is hiring a Scientist for a consulting engagement with our direct client, a leading global bio-pharmaceutical company.  Job Summary  Attribute Sciences group within Process Development is seeking a Scientist.  Candidate can sit anywhere within US & work any time zone: fully remote.  5+ years of pharma/biotech experience. Ideal candidate Master in Biochemistry, Analytical Chemistry, Physical or Life Sciences. Strong understanding of method validation/transfer for methods within the following platforms Chromatography, Bioassay, PCR, Microbiology, Immunoassay, CE, Gel, Device, Viral, and General (compendia). Biopharmaceutical leader founded on discovering, developing, manufacturing, and delivering innovative human therapeutics. The scientist will be responsible for the data verification, drafting, reviewing, and compilation for method transfer and method validation protocols and reports. The position will be a documentation centric role and the candidate will need to have experience with document management systems. The Scientist role in Commercial Process Development will be part of a team responsible for authoring method transfer and method validation protocols and reports for late stage programs for the following method platforms: Chromatography, Bioassay, Device, PCR, Microbiology, Immunoassay, CE/Gel, Viral, and General. Protocols and reports will be authored according to regulatory and industry guidelines (i.e., ICH). This individual will support clinical and commercial locations throughout the company.   Basic Qualifications  Pharma or Biotech Master’s degree and 5 years of Operations or Scientific experience OR Bachelor’s degree and 8 years of Operations or Scientific experience  Preferred Qualifications: Master in Biochemistry, Analytical Chemistry, Physical or Life Sciences. Strong understanding of method validation/transfer for methods within the following platforms Chromatography, Bioassay, PCR, Microbiology, Immunoassay, CE, Gel, Device, Viral, and General (compendia). Direct experience with method transfers and method validation processes from a Pharmaceutical or Biotechnology Company. Knowledge of analytical methods/technologies used in biologic and synthetic development and manufacturing. Excellent written and oral communication skills for the timely documentation, presentation, and discussion of scientific results in a fast-paced, multi-disciplinary, team-based environment. Demonstrated ability to critically analyze and interrogate various analytical data sets to drive and influence the process. Demonstrated ability to propose and drive new scientific initiatives.  Client is an Equal Opportunity/Affirmative Action employer and will consider all qualified applicants for employment without regard to race, color, religion, sex, national origin, protected veteran status, or disability status.  Top Must Have Skill Sets  Scientific writing skills, reviewing and writing technical documentation for analytical methods. Project management skills enabling self organization of heavy workload, communication/ electronic platform skills (verbal, written). Ability to conduct very detail oriented work - data verification, protocol writing, reporting drafting, data review.   Day-To-Day Responsibilities  Data verification of documents, drafting documents from templates (protocols/reports), organizing data for other team members to view, documentation heavy workload supporting client members.  Employee Value Proposition: dynamic global organization with fast paced cutting edge.  Red Flags  Lack of any experience in biopharma industry (i.e. research only), lack of experience with analytical methods, or document writing. Lack of detail orientation, not able to quickly verbalize tasks. Lab based experience only (must have writing, data analysis).   Interview Process  Webex or Skype with video a must for all discussions - initial 1/2 hour screening meeting, followed by 1 or 2 one hour video meetings.  We invite qualified candidates to send your resume to resumes@3keyconsulting.com. If you decide that you’re not interested in pursuing this position, please feel free to look at other positions on our website www.3keyconsulting.com. You are welcome to also share this posting with anyone you think might be interested in applying for this role.  Regards,  3KC Talent Acquisition Team",Algo de responsabilidad,Jornada completa,"Investigación, Análisis, Tecnología de la información","Biotecnología, Atención sanitaria y hospitalaria, Industria farmacéutica",5,None,False,resumes@3keyconsulting.com.,51,ACTIVELY_HIRING_COMPANY
644,2194391977,2020-10-20,Exasol,Senior Design Researcher,United States,"We are looking for our first design researcher to shape and define the research function at Exasol. This is an exciting time to join a growing product team and establish research as a core pillar of the product definition process. Key responsibilities:Plan and execute pragmatic and insightful user research: design research studies and tests, recruit participants, facilitate interviews, and analyze resultsSynthesize and package research insights into compelling narratives to present to the team in a digestible and actionable wayReview google analytics and event logs to correlate qualitative and quantitative researchOwn foundational design and research artifacts like personas and journey mapsWork closely with Marketing, Sales, Engineering and other departments to communicate and build alignment on customer needs and pain points Basic Qualifications: Proven track record of driving impact through delivering actionable insights and follow through to their implementationStrong aptitude for learning new technologiesExperience managing projects involving cross-functional teamsStrong collaboration and communication skills  Preferred Qualifications:Experience with enterprise products, especially database or data warehousesExperience recruiting enterprise prospects and customersExperience communicating and collaborating in remote and multi-time-zone settingsFacilitation experience to drive consensus and buy-in especially from various groups and stakeholders About Exasol:Exasol is one of the most exciting software companies in Europe and a global technology leader in the Big Data and Analytics market. Our high-performance, cloud-first analytics database gives companies the power to transform how their organization works with data – and turn it into value faster, easier and more cost effectively than ever before. With an ambitious international team, we help companies of all sizes achieve their goals with data support. Our team is characterized by inventiveness, enthusiasm and curiosity. In order to continue our worldwide expansion, we are looking for employees who want to make a difference and actively shape our dynamic growth.",Intermedio,Jornada completa,"Tecnología de la información, Investigación, Diseño","Software, Servicios y tecnologías de la información",23,None,False,,181,ACTIVELY_HIRING_COMPANY
645,2250021554,2020-10-28,Deloitte Belgium,(Senior) Consultant / Manager Technology Consulting in Tax,"Zaventem, BE","Are you driven to make people’s lives more fulfilling and enjoyable with the power of data, technology or processes? Would you like to explore the world of corporate finance and tax? Then this might just be for you. We are looking for somebody who loves to solve complex data, technology and process puzzles and feels comfortable interacting with clients.   Who will you be joining  You will join our team of technology consultants with an affiliation to tax matters (called Tax Management Consulting “TMC”).  Our team consists of people with very diverse backgrounds. Some of us are data scientist, others are ERP system specialists (Oracle/SAP) and others are finance/tax process generalists. What unites us is our mission to solving complex tax problems using technology and adding value to our client’s tax teams by bringing high efficiency in their day to day processes.  What your daily activities will look like  Depending on your profile and the direction you want to go, you might be involved in / leading one (or many) of the following type of projects:  Assessing the client’s current tax processes and making them more efficient by deploying best available technology solution  Designing and/or implementing tax solutions into ERP systems such as SAP or Oracle  Creating data solutions that enable clients to generate tax savings with tools such as Alteryx, Knime, Anaplan, Power BI, Python and Spark.  Develop machine learning algorithms that improve the quality of the data used by the tax department (e.g. classifying costs in the right tax deductibility category)  Helping our clients to produce electronic tax audit files in an automated way  Next to projects (the bread-and-butter), you will be also be engaged in the following activities: Internationally collaborating with other tax and consulting colleagues around specific technology initiatives  Training your more junior team mates in your area of expertise  Developing business at new and existing clients  Brainstorming with the team on new improvements, products and services  Doing research and follow training on your technology area of choice      Aptitudes y experiencia deseadas Who are you?  If you love the following, you will find yourself a good fit in our team: Solving complex problems by tackling them in a structured fact-based wayBeing hands-on with data and technology Identifying key requirements based on the client interactions/workshops and translating them in tangible technology solutions Presenting findings and conclusions to upper management (both internally and at clients e.g. partner, head of tax, CFO,…) Being agile and adaptable to learn new technologies and using them to solve complex and ever evolving finance/tax problems  If you can tick off some of the points listed below you might be able to score extra points, but they are by no means hard requirements: Background in commercial engineering, Management Information Systems or Computer Science, Finance and/or Economics qualification/degree 3 to 8 years of relevant working experience delivering projects in the area of data, technology and/or processes Experience related to one (or more) of the following technology areas:   - ERP implementations e.g. SAP (FI-CO, SD Pricing, PaPM, HANA suite), Oracle ERP, tax engines (ONESOURCE, Vertex)  - Data science in the broad sense (or some components of it) e.g.   Data engineering   Data cleaning   Data modeling in a deterministic way (i.e. no machine learning)   Machine learning   Data visualization / business intelligence  - Visual data analytics tools and/or business intelligence tools (e.g. Knime, Alteryx, Power BI, Qlik, Tableau…)  - Financial / tax planning tools (e.g. Anaplan, Thomson Reuters ONESOURCE, LongView,…)  Project management experience  Coding requirements are a plus if it is relevant for the direction you want to go. Especially if you are / want to be more of a data modeling / machine learning oriented person. The following coding languages are useful (but we don’t expect you to know them all):   - Python (numpy / pandas / scikit learn / TensorFlow / PyTorch / …)  - R  - SQL  - Spark (pyspark / SparkR / Scala)  - VBA  Prior tax experience is definitely not a must. A feel (or more than just a feel) with tax, accounting and/or corporate finance might certainly help but we are convinced you can learn this also on-the-job given the right attitude.  The goodies you can expect from us Flexible hours, remote working, on site gym Competitive salary, bonus and lots of other benefits such as a company car Endless learning and growing opportunities And did we already mention awesome colleagues?",Intermedio,Jornada completa,"Tecnología de la información, Diseño, Finanzas",Servicios y tecnologías de la información,17,None,False,,207,ACTIVELY_HIRING_COMPANY
646,2207104776,2020-10-23,ChowNow,Lead Data Engineer,"Los Angeles, California, United States","Are you looking to get in on the ground floor as a founding member of a data team? Are you looking for an opportunity to influence technology choices and direction? If having an immediate impact on ChowNow’s business sounds good, then we might have the perfect opportunity for you.  About Us  ChowNow is unique among tech startups in the restaurant space. We power branded online ordering systems for independent restaurants across North America – via websites, Google, Instagram, and through branded iOS and Android apps – and we do it all for a reasonable monthly fee regardless of order volume. We operate this way because of our belief in being fair, sustainable, and equitable with our restaurant partners. And the same goes for our workplace.  Diversity, teamwork, and mutual respect are among our core company values. And we pride ourselves on giving our teams plenty of opportunities to make their mark. To date we’ve created over 18,000 apps for our restaurant partners – something that’s never been done before in our category. And as we expand to new markets, further spreading the word about the ChowNow difference, those opportunities to create, build, and grow will only increase. If this sounds like the kind of workplace, and the kind of mission, that appeals to you, we’d love to talk.  Learn more by checking out our reviews on Glassdoor (they’re excellent). Together we can preserve neighborhood flavor, one restaurant at a time.  About The Position  As a Lead Data Engineer at ChowNow, you will be responsible for ChowNow’s central data ecosystem, built on AWS and Snowflake. You will have the opportunity to build a modern state-of-the-art data and analytics stack and be a thought leader for how data is consumed and workflows are scaled. You’ll have a direct impact on ChowNow’s business by ensuring continual data availability and quality as well as exploring new use cases (with analysts, scientists and business users as your customers). In addition, you will partner with Data and Analytics leadership to build a vision (and execute on it) for the future of data at ChowNow.  Reports to VP of Data & Analytics.  Within 30 Days You’ll Progress through our Ramp Camp (ChowNow’s New Hire Onboarding Experience)Get to know the current state of data at ChowNow, from original source to the data warehouse to visualization and reporting.Work closely with the Analytics and Business teams to understand needs and use casesLearn ChowNow’s engineering practices by contributing a change to the code base.Learn ChowNow’s analytics practices by making a table in the DWH and a dashboard  Within 60 Days You’ll Take ownership of the current data warehouse and ETL processContribute changes to the data pipeline and transformations to improve availability, quality and consumption of data.Plan for the future of the ChowNow data platform (consolidation, transformation and use cases for consumption) Understand the other data sources in use by the various customers across the business (starting with the Analytics team)  Within 90 Days You’ll Take ownership of all data ingestion codeIdentify and take ownership of core data transformationsPropose and begin working towards overall data architecture improvementsBegin building out the world class Data team  You Should Apply If You have experience building ETL pipelines into a data warehouse and event layerYou have experience with using Python in a production environment.Your SQL and relational DB experience is excellent (Snowflake is a plus)You have experience with AWS technologies You are able to gather data from a variety of sources and interfaces, including REST APIsYou have experience working in a high-volume data environment such as e-commerce and SaaS environments6+ years data management, data engineer or analytics engineer experience (practical non-data engineering experience is also valued)1+ years of experience in people management (or proven ability and passion to manage people)You enjoy iterative, agile-esc development process with frequent releasesYou like collaborating with multiple stakeholders within and outside the Data & Analytics teamYou make decisions based on data and evidenceYou take great pleasure in writing quality, highly maintainable codeYou thrive in environments supporting your growth, and where you can support othersYou are excited about new technologies and spend time staying up to date in the industryYou have experience and passion to fitting pragmatic solutions to problems (building, open source, vendor)  About Our Benefits Competitive SalaryOngoing training and growth opportunities.A 'Best Place to Work' winner multiple times where we focus on creating a great employee experienceRock solid medical, dental, and vision plans.Mental Health Coverage - we offer several programs to support your mental health and wellness goals.3 weeks paid vacation: paid holidays: we expect you to work hard, but still enjoy your personal life6 weeks of baby bonding time for all new parents (within the first year of birth or adoption), 6 Weeks of Paid Pregnancy Leave.401(k) MatchingEmployer-contributing student loan assistance program.Commuter benefits (including Uber Pool).Employee Stock Incentive Plan.Pet insurance for your fur babiesQuarterly Industry Speakers Series.Quarterly Tech Events (Women, LGBTQ, Diversity, Inclusion).Consistent & fair leadership: we’ll share info, set clear goals, show you respect, and treat everyone fairly.Enough freedom to spread your wings while still holding you accountable.Fully stocked kitchen and cold brew on tap.  As one of ChowNow’s core values, “Celebrates Diversity”, we are committed to an inclusive and diverse work environment. ChowNow is an equal opportunity employer. We do not discriminate based on race, color, ethnicity, ancestry, national origin, religion, sex, gender, gender identity, gender expression, sexual orientation, age, disability, veteran status, genetic information, marital status or any legally protected status.",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Internet, Software",17,None,False,,130,ACTIVELY_HIRING_COMPANY
647,2234214538,2020-10-08,Veeva Systems,Team Lead - Data Science (Remote),"London, GB","At Veeva, we build enterprise cloud technology that powers the biggest names in the pharmaceutical, biotech, consumer goods, chemical & cosmetics industries. Our customers make vaccines, life-saving medicines, and life-enhancing products that make a difference in everyday lives. Our technology has transformed these industries: enabling them to get critical products and services to market faster. Our core values, Do the Right Thing, Customer Success, Employee Success, and Speed, guide us as we make our customers more efficient and effective in everything they do.  The Role  As the team lead for Data Science, you will use Veeva’s industry-leading data as a foundation to build world-class machine learning models. Thereby, you’ll create a syndicated product to help the Life Sciences industry to become more efficient and effective in engaging with key people.  You drive the selection of innovative technologies to solve problems that nobody yet could solve. Your team will collaborate with internal software engineering and data quality teams.  This is a remote position.  What You’ll Do Develop machine learning models to structure and analyze scientific dataUse NLP and statistical models to classify dataCollaborate with data quality teams to define training sets and metricsVerify that your outcomes meet acceptance criteriaConsider how your models will work at terminal scaleCollaborate with engineering teams to implement models  Requirements 5+ years of experience as a data scientistProven success using machine learning frameworksFluent in Python and/or RUsed to start-up environmentsSocial competenceHigh energy and ambitionAgile mindset  Veeva’s headquarters is located in the San Francisco Bay Area with offices in more than 15 countries around the world.",No corresponde,Jornada completa,Tecnología de la información,"Software, Servicios y tecnologías de la información, Industria farmacéutica",0,None,False,,21,COMPANY_RECRUIT
648,2220581986,2020-10-28,AssemblyAI,Deep Learning Researcher - Speaker Diarization,United States,"How to Apply If you're interested in this role, please fill out the application here: https://forms.gle/2MSqQfMN14NBrRUf9 About AssemblyAI At AssemblyAI, we use State-of-the-Art Deep Learning to build the #1 most accurate Speech-to-Text API for developers. We're backed by leading investors in Silicon Valley like Y Combinator, John and Patrick Collison (Stripe), Nat Friedman (GitHub), and Daniel Gross. Customers use our API to transcribe phone calls, meetings, videos, podcasts, and other types of media. Our accurate transcripts are used to power features like visual voicemail, call analytics, closed captioning, meeting summaries, and a slew of other features. We deploy our Deep Learning models into production to process millions of API requests per day. About the Role We are growing rapidly and looking for an experienced Deep Learning Engineer to join our Speech Recognition Team, with a focus on Speaker Diarization. We're a small, creative, and democratic team interested in pushing the state of the art forward. Qualifications 3-5+ years of experience with Python3+ years of experience training Speaker Diarization models2+ years of experience with Deep Learning frameworks like PyTorch and TensorFlow2+ years of experience training distributed deep learning models on GPUs",Algo de responsabilidad,Jornada completa,None,Servicios y tecnologías de la información,65,None,True,,340,ACTIVELY_HIRING_COMPANY
649,2232894443,2020-11-03,QUOR,UX Researcher,India,"A full-time long-term project with an exciting venture-funded startup out of the US (Silicon Valley, NYC, Tel Aviv, and India) and a giant media/tech Partner building a new type of solution that has the potential of changing the way we search and consume content online. The project was initially tested successfully in Wall Street and now we are taking it mainstream. As an UX Researcher, you’ll tackle complex tasks and transform them into intuitive, accessible, and easy-to-use designs that potentially can reach millions of people around the world — from first-time users to experts. Achieving this goal requires collaboration with our teams of designers, researchers, engineers, and product managers throughout the design process — from creating user flows and wireframes to building user-interface mockups and prototypes.You’ll rely on user-centered design principles to produce high-quality visuals — from concept to execution — across many platforms. Like all of our UX jobs, you’ll collaborate with your fellow designers to constantly refine the Quor design language and create innovative, great-looking products that people love to use. ResponsibilitiesAs a UX researcher, you'll need to:meet clients to gather information about their requirements and to find out what needs researching, designing or usability testing be involved in sketching, prototyping and on occasion user testing, before passing the design onto the development team understand qualitative research methods have an awareness of costs and budgets put users at the centre of a design to make it simple, easy to use and good looking be confident in your presentation skills in order to present the stages of the design development to business users work closely within a multidisciplinary team, including web developers and programmers have technical knowledge to be able to explain what needs doing, to programmers  SkillsYou'll need to have:·        Research Skills: Interviews & surveys, Information architecture, Personas, Journey map, Affinity mapping, Usability testing, Qualitative analysis, Task flow analysisa mixture of creative and technical skills excellent teamworking skills verbal communication skills, as you present your research findings and the reasons behind your design decisions strong written communication skills, as you may be involved in writing copy for the website creativity and innovation, to come up with new ideas enthusiasm for design and technology is important some knowledge of coding, even if you're not doing it yourself, such as an understanding of HTML, Javascript and CSS experience of using prototyping software tools, for example Figma, Flowmapp and Balsamiq  Minimum qualifications:Bachelor's degree in Design (e.g. interaction, graphic, visual communications, product, industrial, etc.), Human-Computer Interaction (HCI), Computer Science (CS), a related field, or equivalent practical experience.Industry experience in a related field.MUST be able to join the company immediately (within 1-2 weeks) If you are a workaholic, can work in a fast pace environment, love the UX roll from research to the actual design and testing, can communicate clearly and effectively, responsible, can work easily and quietly from home, can attend sprint planning, and enjoy working remotely with other designers, developers and product managers (in the same and different time zones) - then this can be your new long term job. When responding please describe why you fit such a role, include your past portfolio/experiences and if we see a potential fit then we will invite you to a job interview online via video conference call.",Algo de responsabilidad,Jornada completa,Tecnología de la información,Internet,82,None,True,,333,JOB_SEEKER_QUALIFIED
650,2290908862,2020-11-07,Syfter,"Big Data Engineer opportunity with Financial Services client! Virtual Interview, Immediate Remote Start! - Alpharetta","Alpharetta, GA, US","Our Financial Services client is seeking a qualified Big Data Engineer with the followingDetailed knowledge of data warehouse technical architectures, infrastructure components, ETL ELT and reportinganalytic tools.Experience with very large data warehousing environment, data modeling concepts, and Python development experienceExperience in Big Data stack environments (EMR, Hadoop, Glue, Hive)Experience with Kafka, Flume and AWS tool stack such as Redshift and Kinesis are preferredExperience using software version control tools (Git, Jenkins, Apache Subversion)Demonstrated strength in architecting data warehouse solutions and integrating technical componentsGood analytical skills with excellent knowledge of SQL.Excellent communication skills, both written and verbal Syfter is a staffing firm headquartered in Manhattan, NY, that provides creative solutions for clients and talent nationally. Our team of experts works tirelessly to create great connections industry-wide, and after decades in the industry, we deliver best-of-breed methodology for the best hiring experience.",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Software, Servicios financieros",None,None,False,,16,JOB_SEEKER_QUALIFIED
651,2225967789,2020-10-21,Open English,Senior Data Engineer,Argentina,"We are looking for an experienced and talented data engineer to join our successful and growing BI & Analytics team. We integrate +40 data sources (mostly web services, from well known online services like Facebook to complex web services and databases) and delivery key metrics to the business every hour. What will you do?Using your technical expertise and deep understanding of modern BI and data technologies and tools, you will be working in a fast paced and highly agile environment. You should be able to work (alone or with other team members: developers, product owners and or data analysts) developing a whole end to end solution (from data gathering to ETL, DWH components, SQL Development, performance tuning and/or analysis of the data) for complex business intelligence and analytics requirements. What will help you suceed?5+ years of experience in complex SQL development and performance tuning.4+ years of experience in designing complex ETL packages and integration solutions (SSIS or other technologies).Experience in analysis, design and building of Data WareHouses componentsExperience in reporting and dashboards creation in any reporting tool.Passionate about your work and the data world Intermediate advanced written and verbal English skillsExperience integrating web services (REST/SOAP) prefered. What you will find here? You’ll be joining a team that’s empowering the organization to take their decisions based on data analyses to help us solve essential challenges in product, operational and business developmentIf you are looking for a dynamic company, working with the latest technologies, great teamwork, professional opportunities and an excellent work environment, this is for you!",Intermedio,Jornada completa,Tecnología de la información,E-learning,37,None,True,,211,ACTIVELY_HIRING_COMPANY
652,2231245153,2020-11-01,Triplebyte,Machine Learning Engineer,"San Francisco, CA, US","Triplebyte screens and evaluates thousands of engineers per month to find the best candidates for our partner companies. Human decision making doesn't work at our scale: our marketplace is powered by automated assessment and decision making. Triplebyte has three cornerstone ML products: our quiz, our interview, and our matchmaking. As a machine learning engineer, you'll be responsible for the end-to-end process of designing and running experiments to serving production models at scale. Some of our pipelines use off the shelf components, but we're also implementing custom models and techniques from the latest research papers. We're also building forecasting tools for internal teams to measure and predict outcomes. This is an ideal role for an engineer or data scientist who wants the scope and responsibility to own features/products from the inception and research phase through to measuring real-world results.  Fields your work will touch on  Psychometrics Recommender systems Time series analysis Survival analysis Bayesian inference Probabilistic programming   Requirements  Robust exploratory/experimental skills. We have a novel dataset of candidate profiles and interview outcomes from our candidate screening process and our hiring marketplace. You'll be responsible for designing and evaluating experiments to predict downstream outcomes. Ability to implement models from research. Some of our best improvements in both speed and predictiveness has come from doing literature surveys and implementing novel techniques from research papers. Engineering skills. This is a hybrid research/engineering role. You'll be responsible for productionizing your pipelines/models and integrating against our back-end services.  The salary range for this position is $150,000 - $250,000",Algo de responsabilidad,Jornada completa,Ingeniería,Software,89,None,False,,362,ACTIVELY_HIRING_COMPANY
653,2238575648,2020-11-05,StatValu,Big Data Engineer,"Bengaluru, Karnataka, India","We are an innovative product development software startup. Our customer list includes one of the top 3 reinsurance companies in the world. We are developing the next generation document analysis software platform.We are looking for a stellar Big Data Engineer who can scale software platform by hosting the software on cloud infrastructures and enable faster processing times. ﻿Hands on experience in AWS, Azure, Load balancers, Kubernetes, Docker, S3, Blobs, is a must for this role.Experience with web-scale data platforms is a plus point. If you are a Big Data Engineer looking forward to seeing your product being used by some of the multi-billion dollar companies, to work with smartest colleagues, learn applied data science scaled & applied to real-world problems, then this role is for you.You will work with PhDs, people from best colleges, people with a stellar track record.You will contribute in an agile fashion to product development. Responsibilities and DutiesWrite clean, bug-free and well-documented code to implement critical features of the product.Work with data scientists and UI developers to scale the software platformContribute in an agile fashionDevelop backend for massive computation & storageWork with UI developer for integration workEnsure that software platform can ingest big data and spit results in seconds Key SkillsAWS, EC2, S3, Apache Spark, AWS lambda, EMR, HDFS, Impala, Azure, Load balancers, Heroku",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información",Software,104,None,True,,398,JOB_SEEKER_QUALIFIED
654,2251522793,2020-10-12,Syneos Health Clinical Solutions,Clinical Research Scientist,"Toronto, CA","The Clinical Research Scientist is responsible for collecting and synthesizing scientific information in order to prepare clinical study records in accordance with regulations, customer requirements and ethical standards as well as obtaining applicable regulatory approvals. Also acts, as a resource person in his/her scientific field for clients and other divisions.   Act as a scientific consultant to clients and provide scientific and regulatory support to other company divisions. Actively participate in regulatory monitoring: prepare, revise and update the scientific database (ex.: Scientia) used by other divisions. Participate, along with members of each division implicated in the project, in reviewing Phase I protocols prepared by clients.Provide scientific support to the client regarding study design.Prepare and oversee the quality control of informed consent forms when required.Keep track of the documents until the end of the clinical portion of the study. Plan and carry out all bioequivalence and phase I study protocol writing and quality control activities as well as all related documents.Ensure that the study design is adequate and meet study objectives all the while ensuring subject safety.Suggest and justify appropriate changes to the client, when required.Keep track, within established timelines, of the protocol and related documents from their writing up until the end of the clinical portion of the study.Synthesize and integrate into the documents the comments made by the client, internal stakeholders, the ethics committee and regulatory agencies (pre and post study). Prepare, review and submit bioequivalence clinical trial applications for approval by Health Canada and perform the necessary monitoring to ensure that all regulatory requirements to begin a study are met. Communicate with regulatory agencies to ensure the feasibility and compliance of clinical trial applications at the regulatory level.  Responsible for performing activities that are in compliance with applicable Corporate and Divisional Policies, Standard Operating Procedures and Operating Guidelines and performing other duties as assigned by management.  Note: This job description describes the principal and main elements of the job. It is a guide to the nature and main duties of the job as they currently exist, but is not intended as a wholly comprehensive or permanent representation.         Master’s degree in Science  Relative alternate certification may be considered acceptable.  This determination ensures the jobholder has sufficient technical ability to perform the role.   2 years of relevant work experience would be considered an asset. Must demonstrate good computer skills especially in the utilization of Microsoft Word and Excel and Acrobat software. Excellent communication, presentation, interpersonal skills, both written and spoken, with an ability to inform, influence, convince, and persuade Experience in regulatory context will be considered an asset Experience in literature research  Primary Location  North America - CAN-Home-Based  Job  Pharmacometrics  Schedule  Full-time  Travel  No  Employee Status  Regular",Algo de responsabilidad,Jornada completa,Otro,"Biotecnología, Industria farmacéutica, Investigación",5,None,False,,59,ACTIVELY_HIRING_COMPANY
655,2025112975,2020-10-16,dunnhumby,Senior Insights Consultant,United States,"Most companies try to meet expectations, dunnhumby exists to defy them. Using big data, deep expertise and AI-driven platforms to decode the 21st century human experience – then redefine it in meaningful and surprising ways that put customers first. Across digital, mobile and retail. For brands like Tesco, Coca-Cola, Procter & Gamble and PepsiCo.  Dunnhumby is seeking a Client Lead who expects more from their career. You will be a trusted advisor for our retail and CPG clients, working side-by-side with them to ensure their success. Using customer insights derived from our data platform, you will own and develop a client plan that delivers recognizable value, client satisfaction and return on investment. You will be responsible for driving collaboration between business partners, understanding key business challenges, and embedding a Customer 1st approach into decision making.   What we expect from youBachelors degree in a relevant subjectManage assigned Retail or CPG client relationships and workplansSupport team effort to instil a Customer 1st approach and process to managing their businessBecome an expert and teacher of our Data Science, Software, and approachesSupport sales and renewal efforts with your Retail or CPG client stakeholderUndertake projects, partnering with Data Scientist colleagues, to dive deep into client data and make recommendations to clients to achieve positive business results and an improved customer experienceManage implementation of new processes, tools, and solutions with the client and as part of a large team environmentAt least 2-3 years relevant experience * This role will be remote until spring 2021. There is an expectation to work onsite in the future.   What you can expect from us We won’t just meet your expectations. We’ll defy them. So you’ll enjoy the comprehensive rewards package you’d expect from a leading technology company. But also, a degree of personal flexibility you might not.Plus, thoughtful perks, like early finish Friday and your birthday off. You’ll also benefit from an investment in cutting-edge technology that reflects our global ambition. But with a nimble, small-business feel that gives you the freedom to play, experiment and learn. And we don’t just talk about diversity and inclusion. We live it every day – with thriving networks including dh Women’s Network, dh Proud, dh Parent’s & Carer’s, dh One and dh Thrive as the living proof. Everyone’s invited. Our approach to Flexible Working  At dunnhumby, we value and respect difference and are committed to building an inclusive culture by creating an environment where you can balance a successful career with your commitments and interests outside of work. We believe that you will do your best at work if you have a work / life balance. Some roles lend themselves to flexible options more than others, so if this is important to you please raise this with your recruiter, as we are open to discussing agile working opportunities during the hiring process.",Algo de responsabilidad,Jornada completa,"Estrategia/planificación, Tecnología de la información, Desarrollo empresarial",Marketing y publicidad,225,None,True,,847,ACTIVELY_HIRING_COMPANY
656,2256782695,2020-10-30,EPAM Systems,Remote Senior Data Scientist,"Kremenchuk, UA","Striving for excellence is in our DNA. Since 1993, we have been helping the world’s leading companies imagine, design, engineer, and deliver software and digital experiences that change the world. We are more than just specialists, we are experts.  A remote Senior Data Scientist is needed. This job is about turning (big) data into actionable knowledge, which requires a blend of scientific, problem solving, analytical, technical, and communication skills.  This position is a part of our new EPAM Anywhere program for remote workers. EPAM Anywhere offers a variety of IT jobs for remote workers. Join us to work on ambitious and long-term projects, get a stable workload, and enjoy a work-life balance!  Responsibilities Identifying the business problemsFinding the right data and methods to address themBuilding and validating analytical modelsPresenting the findings in a clear and informative wayShould be able to  Requirements 3+ years of experience in data mining, statistics or machine learningRDBMS/SQL knowledgeProgramming experience (Python preferred)Data analysis tools and libraries such as Python (NumPy / SciPy / scikit-learn / pandas / matplotlib), R, SAS, SPSS, MATLAB, etc.Big Data stack: Spark / MLlibProficiency with at least one of the Cloud providersExperience with Data Science solutions productionalizationBachelor’s/Master’s Degree in Computer Science, Math, Applied Statistics or a related fieldAptitude for problem solvingDecent communication / presentation skills (including working English fluency) We offer Competitive compensation depending on experience and skillsWork in enterprise-level projects long-termFull-time remote work (you can work from anywhere you are)Unlimited access to learning courses (LinkedIn learning, EPAM training courses, English regular classes, Internal Library)Community of 30,100+ industry’s top professionals  This is a remote position and we welcome applications from anywhere in Ukraine.",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información","Software, Servicios y tecnologías de la información",None,None,False,,6,ACTIVELY_HIRING_COMPANY
657,2168407812,2020-11-05,Intelletec,Senior Data Scientist - Machine Learning,"New York, United States","Intelletec has partnered with a leading healthcare provider who is transforming health care through innovations that make quality care more accessible, easier to use, less expensive, and patient-focused. Our client’s mission is to improve health. Due to rapid growth, our client is hiring multiple ML Data Scientists.  The role:You’ll be joining a team of MDs, PhDs, MBAs, and MSc from top tier universities and industries that bring their clinical, technical, and economic experience to bear on some of the toughest targets in healthcare – chronic disease.The complex chronic care group within clinical analytics employs cutting-edge ML, signal analysis, and time-series modeling to move the needle on healthcare using claims, commercial pharmacy, and front- end store data. As a lead data scientist supporting a portfolio of chronic disease-oriented internal products, you have strong client-service oriented skills but are a research and development champion. Skills:Have 3 or more years of technical data science leadership, focusing on the application of ML to large datasets for healthcare or similar applications.Have strong (~2 years) consultatory, clinical and commercial stakeholder management, and leadership skills.Have experience (~2 years) leading a team of 2-4 data scientists and are comfortable leading a ‘squad’ of data scientists working across multiple disease areas.Are passionate about helping patients by integrating data science research into application.Are an expert in python and/or R, git, bash, and hive/SQL. Education:MSc with significant experience.MD and/or PhD in a technical field or equivalent practical experience (e.g., PhD in machine learning, computer science, or statistics and modeling heavy engineering field (chemistry and bioengineering)).",Intermedio,Jornada completa,Ingeniería,Atención sanitaria y hospitalaria,276,None,True,,650,ACTIVELY_HIRING_COMPANY
658,2203142440,2020-10-13,Frost & Sullivan,Freelance Market Researcher - Cambodia,Cambodia,"We are seeking for experience market researchers who are keen on a remote 3 months engagement opportunity. If you meet the below requirements, please share a copy of your profile along with your monthly rate. Candidate Profile:Candidate should have a least 3-5 years of experience in healthcare sector - pharma, medical devices, healthcare services and have an understanding of domestic healthcare industry.Candidates with experience in public sector in healthcare such as ministry of health, public health policy, regulatory department etc. will be preferred. The candidate should be able to identify sources of physicians, healthcare professionals, researchers to build a database and also have a network in the healthcare industry. Understanding of market research process will be an advantage.Experienced in B2B researchMust be proficient in local language, and currently based in Cambodia  If engaged, your work scope would include:- Identification and mapping of possible stakeholders / stakeholder groups for advocacy purposes- Healthcare professionals, Research/Scientific Community, Policy Makers in Cambodia- Engage the stakeholders in preliminary discussions to understand the receptiveness of the RRPs concept and potential of advocacy engagement- Further engage the potential Key Opinion Leaders (KOLs) in in depth discussions to take them forward with the advocacy program  Note: only shortlisted candidates will be called for interview.",No corresponde,Contrato por obra,"Ventas, Desarrollo empresarial","Consultoría de estrategia y operaciones, Investigación de mercado",39,None,False,,548,ACTIVELY_HIRING_COMPANY
659,2251550107,2020-11-06,Avast,Tech Lead Data Engineer (Java/Python),Czech Republic,"Avast is a global leader in digital security products. With over 400 million users online, we offer products under the Avast and AVG brands that protect people from threats on the internet and the evolving IoT threat landscape. Our threat detection network is among the most advanced in the world, using machine learning and artificial intelligence technologies to detect and stop threats in real-time. We offer digital security products for Mobile, PC, and Mac, which are top-ranked and certified by VB100, AV-Comparatives, AV-Test, SE Labs, and others.    Headquartered in Prague, Czech Republic, with offices in the U.S., Europe, and Asia, AVAST Software employs some of the brightest new talents in the IT industry, from around 30 different nations. Job Purpose: Build backend data applications that interact with/interconnect various data platforms in either batch or streaming fashion.Key AccountabilitiesImplementation and development of software – proof of concept or production-grade codeContinuous improvement of existing applications/platforms upon internal customer requests/feedbacksCooperation with Architect, Data engineers, Analysts Good knowledge of the following areas/technologies is essential: Data platforms: Relational databases (Postgres, MsSql), Hadoop stack (HDFS, Hive, Spark)Programming languages (Java, Python)OS Linux (CentOS)Continuous integration (Teamcity)Containerization (Docker, Kubernetes)Monitoring & alerting (Logstash, Kibana, Grafana, Sentry)Comprehensive knowledge of data structures and algorithmsStrong problem-solving skillsAn understanding of modern design patterns and proven experience applying them Experience in designing/development of complex systems, high-performance APIs is a big advantage. We offer: Flexible working hours, home working5 weeks of vacationAnnual BonusEmployee Stock OptionSick daysCafeteria provided by Benefit plus (Multisport card, pension insurance, travel and much more)Trainings and conferences Sounds interesting? We would like to hear back from you!  We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",Intermedio,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Servicio de información",4,None,True,,47,ACTIVELY_HIRING_COMPANY
660,2220623622,2020-10-20,Big Cloud,Data Engineer,Atlanta Metropolitan Area,"Are you an experienced data engineer? Are you available for an initial 6-month contract? One of the worlds biggest healthcare companies is seeking to recruit a Data Engineer for an initial 6-month contract. As a Data Engineer, you’ll be designing developing and maintaining scalable data models and pipelines, collaborating across all analytics teams to develop efficient end products and building data architecture. Other responsibilities: Implements processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processesWrites unit/integration tests, contributes to engineering wiki, and documents work.Works closely with other data scientists and engineers to develop a strategy for long term data platform architectureSupporting issue analysis and fix activities during test phases, as well as production issue resolution.Contribute to project planning and implementation to ensure that solutions are delivered on time and on requirementsCollaborate and actively contribute in discussions to help define technology and development approach within the team You’ll need: 2+ years data engineering experienceMinimum bachelors degreeStrong experience in PythonCloud experience – ideally Azure or Google CloudProficiency in data modelling, database technologies (both SQL and NoSQL)Data Architecture and data pipeline design experience",Intermedio,Contrato por obra,"Tecnología de la información, Ingeniería","Atención sanitaria y hospitalaria, Seguros",163,None,True,,428,ACTIVELY_HIRING_COMPANY
661,2249315868,2020-11-05,Planet Pharma,Drug Safety Scientist,"Boston, Massachusetts, United States","Description:Reporting to a Sr. PV Scientist or above, the PV Scientist will serve as a critical team member with the lead PV Scientist for products or product groups, including project management and authoring of aggregate reports (PSUR, DSUR, PADER), safety evaluations, aggregate report planning, authoring responding to ad hoc regulatory responses, conducting safety literature reviews. The PV Scientist will serve as a Subject Matter Expert for the Safety and cross-functional team on relevant global safety regulations and guidelines: data output and analyses: and, product information. Responsibilities:Project manage, and author of aggregate safety reports such as PSURs, DSURs, PADERs, local reports in collaboration with the PV scientist LeadFacilitates signal management process for assigned products (i.e., signal tracking, leading review meetings, etc.) and in collaboration with Safety MDs and Sr. PV Scientist / AD, evaluates safety data and signals as part of ongoing pharmacovigilance activities. May include authoring signal evaluation reports, or sections of signal evaluation reports. Conducts literature review for safety information and interacts with other groups to obtain necessary data (i.e., Epidemiology, SAE data).Responsible for the Aggregate reports Master calendar (production, update, stakeholders review)In collaboration with PV Scientist lead coordinates and authors responses to safety questions from regulatory authorities.Contributes to initiatives for process improvement and consistency regarding aggregate reporting, clinical trial safety oversight, signal management and responding to ad hoc safety questions.Understands, interprets, analyzes, and clearly presents scientific and medical data in verbal and written format (including intermediate understanding and application of medical concepts and terminology).Interacts collaboratively and effectively in a team environment (including Safety, Clinical Development, Medical Affairs, Clinical Operations, and Regulatory), as well as with external colleaguesLeads and conducts, independently and/or collaboratively, all aspects of substantive projects such as signaling, authoring of aggregate data reports, and responses to regulatory agency requests. Requirements:Education Bachelor’s Degree in biologic or natural science: or health care discipline. Advanced degree (PhD, MPH, NP, PharmD, etc.) preferred.Minimum 5 years industry experience, with a minimum of 3 years of PV experience.",Intermedio,Contrato por obra,"Redacción y revisión, Atención médica, Estrategia/planificación","Industria farmacéutica, Biotecnología, Servicios médicos",55,None,True,,204,ACTIVELY_HIRING_COMPANY
662,2258187576,2020-10-30,Venturi Ltd,Azure Data Engineer ( Data Factory / Databricks / DevOps ),"Bath, England, United Kingdom","Azure Engineer ( SC Cleared ) Remote Initially (Potential of travel)6 Months ASAP£400-450/day Azure Engineer is needed to join a leading Consultancy working on a project for a Gov Organisation. This is a hands-on role for an Azure Engineer to work within an agile team. The main activity is the deployment of resources on to Azure, in line with design documentation, to assist in the migration of the legacy systems into the Azure Cloud. A secondary activity is the deployment of Azure resources to support the evaluation of software for a new software platform. You will work closely with the Cloud provider, Application Services and DevOps Team in order to provide a seamless service. Responsibilities for the Azure Engineer ( DevOps / IaC / Containers) includes:Deployment of Azure resources in-line with the architectural design for the migration to AzureFacilitating migration approaches that may make use of any appropriate Azure migration services. E.g. Azure Database Migration Service.Ability to define infrastructure as code, using an infrastructure deployment tool (ideally Terraform), to allow infrastructure to be deployed in a consistent, reproducible and version-controlled manner.Feed into the Agile team any Azure technical knowledge or experience that could assist in the migration to Azure or the evaluation of the software platform. Required skills and experience for the Azure Engineer ( DevOps / IaC / Containers) includes:Experience developing, migrating, and integrating customer workloads into Azure.Hands on Azure deployment and configuration skills.Experience in developing and deploying infrastructure as code (Terraform preferable).Able to talk about previous projects where Azure deployments/migrations have been completed and any lessons learnt from that.Ability to work in an Agile way as part of an Agile team.Ability to identify key project stakeholders and contacts and work closely with them where necessary.Analytical/problem solving skills.Team working, personal networking skills. Desirable skills and experience for the Azure Engineer ( DevOps / IaC / Containers) includes:Containerisation principles and frameworks (Kubenetes) is desirable.Knowledge around deploying/using Azure Managed SQL would be beneficial.SQL Server 2008 R2 as well as more modern versions would be beneficial.Administration of Windows Server 2008 R2 and Server 2016 would be beneficial.Azure Certifications: Administrator Associate, Developer Associate, Solutions Architect Expert, Cloud Platform and Infrastructure",Intermedio,Contrato por obra,Tecnología de la información,Dotación y selección de personal,21,None,True,,95,ACTIVELY_HIRING_COMPANY
663,2259516305,2020-10-31,SR2 - Socially Responsible Recruitment,User Researcher Public Sector ASAP Start Remote,"London, GB","User Researcher | Public Sector | ASAP Start | Fully Remote  User Researcher required by a leading consultancy for a public sector project.  The project will work across Discovery, Alpha & Beta phases.  Experience Required   Multiple contracts as a User researcher within Public Sector  Strong understand of Agile working and processes  Excellent understanding of GDS (Government Digital Service) standards  Understanding of UX design  Understanding business user perspectives  Analysis of research data   If you have these skills, please do apply. Interviews are being conducted ASAP with a view to start ASAP.",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Dotación y selección de personal",19,None,False,,121,JOB_SEEKER_QUALIFIED
664,2276004975,2020-11-04,eTeam,Data Engineer (.NET),"Peoria, Illinois, United States","Job Title: Data Engineer 3 (.NET)Duration: 12 monthsLocation: Peoria IL Candidate ResponsibilitiesJob responsibilities include the development of .NET data intake application for corporate capacity planning Oracle databases, development of SQL programs ensuring data integrity and interaction with other corporate databases (Db2, Snowflake). The position will require close collaboration with the capacity planning team as well as active collaboration with data owners and IT staff company-wide. Typical DayCore hours 9 am-3 pm Central time, otherwise flexible work hours. ﻿Remote work location possible but eventual co-location to Peoria, IL desired. Education Requirements:Minimum four-year College or University degree in Software or Data Engineering, or Computer Science or equivalent. Master's degree preferred with exposure to Statistics. Technical SkillsProven 3 years industry (internship experience will not be accepted) experience with Oracle database systems, SQL proficiency, and working experience with .NET program development. Ability to manipulate, process, and interact with larger data repositories. Soft Skills:Candidate must be comfortable reaching out and collaborate with process partners from around the world. Candidates must have excellent English communication skills and be able to effectively solve complex problems. Attention to detail is critical.",Sin experiencia,Jornada completa,"Contabilidad/Auditorías, Administración, Finanzas",Servicios y tecnologías de la información,26,None,True,,77,ACTIVELY_HIRING_COMPANY
665,2282475227,2020-10-12,Livongo,Senior User Researcher,"Mountain View, CA, US","The Opportunity It’s important to be first, and even more important to be the best. At Teladoc Health we’re both. Our success is due in large part to our box-busting product design. As a Senior User Researcher, your leadership, user empathy and research skills will drive real social impact.  Ideally, you’re a strategic systems thinker with experience solving complex problems in the health space. You’ll champion empathy for member needs as a key component in the product development conversation and play a key role in maintaining maximum impact in the lives of our rapidly-expanding member base.  Responsibilities  Lead all aspects of the user research cycle, from scoping and recruiting to method selection, analysis and presentation Lead and execute qualitative and quantitative research programs that align business goals and member needs Identify and prioritize opportunities where research can help improve a product decision or member experience Uncover the latent and unmet needs of our members to support successful design outcomes Lead creation of reports, usability studies, stakeholder maps, journey maps, personas, and other research outputs that foster user empathy across the Product organization Collaborate with Clinical, Consumer Insights, and Data Science teams to ensure our product decisions reflect a complete picture across all research domains Partner with Design Leads and Product Managers to plan and facilitate stakeholder workshops Provide actionable feedback gracefully and without ego, and openly solicit critique for your own work Providing mentorship to other team members  Candidate Profile  8+ years user research experience with mobile apps, web applications and consumer products within the health or medical fields Experience with a variety of target users: clinicians as well as patients Proven track record in partnering with Design, Product Management, Engineering, and Clinical teams The ability to derive meaningful stories from research data that resonate across the Product teams Expertise in scoping, planning and executing each step of the research process both in-person and remotely Extensive experience with tools for recording, analyzing, storing, and sharing research, including data analytics and visualization tools Experience with contextual-inquiry, user interviews, and other methods of ethnographic and generative research Experience with usability testing, accessibility reviews and other methods of evaluative research Educated recommendations for specific research protocol best practices Graduate-level degree in related field preferred  Why Join Teladoc Health? A New Category in Healthcare:  Teladoc Health is transforming the healthcare experience and empowering people everywhere to live healthier lives.    Our Work Truly Matters: Recognized as the world leader in whole-person virtual care, Teladoc Health uses proprietary health signals and personalized interactions to drive better health outcomes across the full continuum of care, at every stage in a person’s health journey.    Make an Impact: In more than 175 countries and ranked Best in KLAS for Virtual Care Platforms in 2020, Teladoc Health leverages more than a decade of expertise and data-driven insights to meet the growing virtual care needs of consumers and healthcare professionals.    Focus on PEOPLE:  Teladoc Health has been recognized as a top employer by numerous media and professional organizations. Talented, passionate individuals make the difference, in this fast-moving, collaborative, and inspiring environment.   Diversity and Inclusion:  At Teladoc Health we believe that personal and professional diversity is the key to innovation. We hire based solely on your strengths and qualifications, and the way in which those strengths can directly contribute to your success in your new position.    Growth and Innovation:  We’ve already made healthcare history, yet we remain on the threshold of very big things. Come grow with us and support our mission to make a tangible difference in the lives of our Members.   As an Equal Opportunity Employer, we never have and never will discriminate against any job candidate or employee due to age, race, religion, color, ethnicity, national origin, gender, gender identity/expression, sexual orientation, membership in an employee organization, medical condition, family history, genetic information, veteran status, marital status, parental status or pregnancy (including breastfeeding – we have a mother’s room in both our offices). In our innovative and inclusive workplace, we prohibit discrimination and harassment of any kind.",Intermedio,Jornada completa,Tecnología de la información,"Sanidad, bienestar y ejercicio, Servicios médicos, Servicios y tecnologías de la información",0,None,False,,11,ACTIVELY_HIRING_COMPANY
666,2252319547,2020-11-07,CyberCoders,Machine Learning Engineer (Deepstream/GST/Vargus),"Seattle, WA, US","If you are a Machine Learning Engineer (Deepstream/GST/Vargus) with experience, please read on!  What You Will Be Doing  Study and transform data science prototypes Design machine learning systems Research and implement appropriate ML algorithms and tools Develop machine learning applications according to requirements Select appropriate datasets and data representation methods Run machine learning tests and experiments Perform statistical analysis and fine-tuning using test results Train and retrain systems when necessary Extend existing ML libraries and frameworks What You Need for this Position  Experience in the below areas  Container orchestration Nano Automotive industry Nvidia Deepstream GST Vargus Proven experience as a Machine Learning Engineer or similar role Understanding of data structures, data modeling and software architecture Deep knowledge of math, probability, statistics and algorithms Ability to write robust code in Python, Java and R Familiarity with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn) So, if you are a Machine Learning Engineer (Deepstream/GST/Vargus) with experience, please apply today!  Email Your Resume In Word To  Looking forward to receiving your resume through our website and going over the position with you. Clicking apply is the best way to apply, but you may also:  Justin.Ciambelli@CyberCoders.com Please do NOT change the email subject line in any way. You must keep the JobID: linkedin : JC15-1609420 -- in the email subject line for your application to be considered.*** Justin Ciambelli - Executive Recruiter - CyberCoders  Applicants must be authorized to work in the U.S.  CyberCoders, Inc is proud to be an Equal Opportunity Employer  All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.  Your Right to Work - In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.",Sin experiencia,Jornada completa,Tecnología de la información,Sector automovilístico,19,None,True,Justin.Ciambelli@CyberCoders.com,72,ACTIVELY_HIRING_COMPANY
667,2239873809,2020-09-30,Peloton Advantage,"Director, Health Economics and Outcomes Research (HEOR) - REMOTE OPPORTUNITY!","Parsippany, NJ, US","Currently holding exploratory calls!   Company Overview  Peloton Advantage, an OPEN Health company, is an industry-leading medical communications company located in Parsippany, NJ. Our medical and account teams provide strategic support to pharmaceutical company clients and produce high-quality journal articles, abstracts, posters, supplements, slide presentations, monographs, and other educational materials.  Department Overview  The HEOR – Value Evidence Generation department is charged with designing, developing and/or conducting HEOR and real-world data (RWD) studies, models and analyses, strategic insights, abstracts/posters/publications and value communications tools throughout the product lifecycle with the goal of providing clients and their stakeholders with high-quality HEOR data to support decision-making.  Position Overview  The Director, HEOR, provides leadership and works as part of a multidisciplinary team (including medical, editorial, and account personnel) to produce real-world evidence (RWE) and HEOR-focused writing projects (e.g., abstracts, posters, manuscripts, etc.) for assigned accounts. The Director, HEOR will have experience/competencies in a number of areas, including health economic modeling (decision analysis, markov models, discrete event simulation models), retrospective database analyses (claims, electronic medical records, integrated datasets), and/or primary data collection studies (cross-sectional surveys, prospective cohort studies, patient/disease registries, pragmatic trials).  Research topics may include, but not be limited to, practice patterns, treatment inertia, unmet needs/treatment gaps, comparative effectiveness, adherence/persistence, cost-effectiveness, cost/burden-of illness, budget impact, quality of life/utility assessment, preference/discrete choice experimentation, treatment satisfaction, meta-analysis, predictive modeling and multiple criteria decision analysis (MCDA).  The department will create value dossiers and other field-based tools and disseminate research findings at scientific congresses and in the peer-reviewed literature within these areas of expertise. The Director, HEOR assumes responsibility for all HEOR deliverables for assigned accounts and new business efforts, must be able to work both independently and in a team structure, and must be particularly suited to high-profile client and faculty contact. As the HEOR lead on any project, the Director, HEOR is responsible for working closely with HEOR Team members including, but not limited to, the Health Economics Modeling Scientist and the Real-world Data Analysis Scientist. The Director, HEOR must also be able to clearly communicate content needs to Medical Directors, Medical Writers and HEOR Writers and concept needs to Graphic Designers.  The Director, HEOR will also provide high-level strategic input to clients and to internal account teams regarding RWE, value evidence generation and communication, health technology assessment and/or market access. Note: Although the Director, HEOR will not be directly responsible for developing health economic models or running statistical analyses, s/he must have knowledge and experience with both.  The Director, HEOR may be required to manage one or more direct reports including monitoring workload, conducting performance reviews, providing guidance and mentorship, and approving timesheets and PTO requests (full details are outlined in Section IV).  Whenever necessary, the Director, HEOR may be asked to serve as an external Subject Matter Expert (SME) from the department at client or industry meetings.  Specific Duties, Activities, And Responsibilities  Lead cross-functional internal/external teams and manage all aspects of HEOR studies and models from conceptualization through protocol development, study/model implementation, analysis and ultimately dissemination of study results at scientific congresses and in peer-reviewed journals Ability to collaborate and partner with external Scientific Leaders (SLs), Academic Research Organizations (AROs), Data Vendors and client HEOR Teams Support business development efforts across the organization relative to HEOR Identify opportunities to further leverage client’s existing HEOR data through post-hoc analyses and/or collect new/additional data through de novo research  Plan, manage, and review HEOR projects and publications and help develop HEOR education programs  Provide internal inter-departmental education on HEOR topics to improve proficiency in these areas across teams Work closely with medical direction and/or medical writing staff to ensure accurate, high-quality, on-target messaging Partner with Account Leads (SVP/VP, Client Services) to evaluate opportunities for HEOR support to drive organic growth within existing business Develop solutions for account team(s) based on product lifecycle The Director, HEOR may or may not manage other employees. Individuals with direct reports are expected to:  Monitor their workload and make proactive recommendations to Senior Management regarding plans for anticipated temporary/ongoing periods of underutilization or overload Approve and monitor their timesheets, expenses, and PTO requests Oversee their development Conduct regular performance evaluations Enforce compliance with all company SOPs  Serve as a role model for others with respect to professionalism and personal productivity Provide HEOR services to assigned accounts Represent the company at selected educational and client meetings and business pitches Attend status meetings as necessary Comply with company standards  Procure and maintain appropriate travel documentation Maintain consistent attendance  Maintain timely submission of time sheets   Position Requirements  Education or Equivalent (minimum required to perform job):  MD, PharmD, PhD, or other advanced degree in Health Economics, Health Services Research, Outcomes Research, Biostatistics, Epidemiology, Public Health or other comparable areas 5 years of HEOR/RWE experience in a medical education company or pharmaceutical/biotechnology company   Knowledge/Skills Requirements  Proven track record of high-impact HEOR programs (including publications), RWE, value evidence generation, health technology assessment (HTA), and/or market access  Experience with designing HEOR/RWE studies and writing research protocols Ability to generate statistical analysis plans (SAPs) and interpret SAS (or other statistical software) output Experience in the design, development and/or interpretation of health economic models Strong strategic thinking skills in the areas of value, affordability, evidence generation, access and reimbursement Ability to function as the Subject Matter Expert within the company with regard to HEOR topics Knowledge of the changing payer/HTA landscape in the U.S. (e.g., Value Frameworks like ICER and ASCO) and globally (HTA Agencies like NICE and IQWIG) Broad technical knowledge of outcomes research and health economics Strong technical writing skills Familiarity with pharmaceutical marketing and drug commercialization Excellent collaboration and communication skills with internal and external stakeholders, collaborators and partners Ability to meet deadlines while working on multiple parallel projects  Demonstrated ability to manage a high volume of assigned accounts and related revenue targets as the HEOR lead Ability to work independently as well as in a team structure   Business Environment  Office is in Parsippany, NJ: Full-time remote has been approved for this role. Hours 8:30am – 5pm Travel: Up to 20% domestic and/or international (including periodic travel to New Jersey HQ site and/or client sites)",Director,Jornada completa,Atención médica,"Marketing y publicidad, Atención sanitaria y hospitalaria, Industria farmacéutica",6,None,False,,136,None
668,2291165757,2020-10-24,InVision,Lead Data Engineer,"Austin, TX, US","InVision is the digital product design platform used to make the world's best customer experiences. We provide design tools and educational resources for teams to navigate every stage of the product design process, from ideation to development. Today, more than 5 million people use InVision to create a repeatable and streamlined design workflow: rapidly design and prototype products before writing code, and collaborate across their entire organization. That includes 100% of the Fortune 100, and organizations like Airbnb, Amazon, HBO, Netflix, Slack, Starbucks and Uber, who are now able to design better products, faster.  The Data Engineering team is in search of a Lead Data Engineer to help us build out the next generation of our data platform.  About the Team:  Our team is responsible for architecting, building, and enhancing InVision's internal data platform, with the sole purpose of accelerating the company's ability to make data-driven decisions across the company. InVision Lead Engineers demonstrate an enthusiasm for their field, a pragmatic decision-making ability, and can lead initiatives. They have a willingness to listen and partner with the business and are at ease working in a remote, collaborative agile environment. The ideal candidate has significant experience in developing scalable data platforms. They must have strong, firsthand technical expertise in a variety of big data technologies and the proven ability to deliver robust solutions within a practical timeframe.  What you'll do:   Architect and build technologies, processes, and data flows for many different sets of data at varying cadences Provide leadership to other data and infrastructure engineers on the team Collaborate cross-functionally with data scientists, business users, product managers, and engineers, to achieve effective data solutions Document, implement, and build data pipelines with measurable quality and understandable lineage Be a champion of the overall strategy for data governance, security, privacy, quality, and retention that will satisfy business policies and requirements Identify, document, and promote best practices Maintain and evolve our data platform (data lake, data warehouse, ETL, and BI tools)  What you'll bring:   10+ years of designing, building, and deploying data platforms Deep technical hands-on expertise in more than one of the following: Data Warehouse Modernization / Migrations, Data Science, Data Lakes, Data Engineering, Data Applications, Data Pipelines Broad range of experience with cloud data warehouse technology, ETL pipelines, and analytics Understanding of microservice patterns and architecture Comfortable delivering presentations of technical content and peers and executive audiences Knowledge of SQL, Python, Go, and/or other scripting languages A smart and friendly, can-do attitude, with collaboration and delivery as core values Self-direction and the ability to see and understand a large number of challenges, prioritizing them into a set of incrementally achievable goals Bias towards action, absolute willingness to own the problem and drive towards a speedy practical solution  Ability to dig into the detail but also establishing a strategic point of view  Leadership through direct engagement and influence, comfortable building consensus and establishing mutual respect  About InVision:  InVision offers an incredibly unique work environment. The company employs a diverse team all over the world. Each InVision team member is given the freedom and tools to do their best work from wherever they choose.  The benefits we offer in the United States and Canada include competitive health plans and retirement plans. Some InVision-wide benefits offered to all employees across the globe include a flexible vacation policy, monthly coffee shop stipends, annual allowances for books related to your profession, and home office setup & wellness reimbursements. InVision is an international employer so some benefit offerings will vary from country to country.  InVision is proud to be an equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. If you have a disability or special need that requires accommodation, please let us know.",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Internet",0,None,False,,None,ACTIVELY_HIRING_COMPANY
669,2222441001,2020-10-29,Blue Orange Digital,Data Scientist - Marketing/Advertising Optimization,United States,"This is a full-time USA-based remote position within +/- 3 hours of Eastern Standard Timezones(NYC). Job Description You will be joining a highly talented team of engineers and data scientists working on implementing production machine learning models in the media space. We are helping a large company optimize their production models and further improve accuracy by leveraging additional 3rd-party datasets. This role will require exploratory model testing, production system maintenance, and collaboration with technical SME to improve performance, accuracy, and methodology. ResponsibilitiesBuild machine learning models to solve forecasting, budgeting, optimization, and ranking problems.Work collaboratively with stakeholders across product and engineering teams to solve problems and deliver creative solutions.Deliver machine learning solutions all the way to production and optimize production implementations.Data cleaning and analysis, feature engineering, model training, and optimization in Python and Spark. QualificationsBA/BS/MA degree in Computer Science, Math, Statistics, or a related technical field, or equivalent practical experience.5+ years of professional experience in data science, doing exploratory data analysis, testing hypotheses, and building predictive models.A strong background in advanced mathematics, statistics, data mining, and machine learning.Advanced experience in Python, proficiency with SQL, and experience with distributed computing frameworks like Spark.Demonstrable experience in working on optimization problems.Experience in Amazon AWS tools - SageMaker, S3, EC2, EMRExperience with Snowflake preferred.Experience in the Ad & Marketing Tech fields is a huge plus.Applicants must have strong written and oral communication in English.Interacts with others using sound judgment, good humor, and consistent fairness in a fast-paced environment Company Introduction'Top 10 AI development and consulting Agencies in NYC' - Clutch As seen in:IBM thinkLeaders, Dell Innovators, YahooFinance, Global Banking & Finance Review Magazine, IoT Council of Europe, AiBusiness, Data-Driven Investor, DataFloq, Supply Chain Matters, Machine Learning Times.﻿Founded by freelance engineers, Blue Orange Digital aims to bring an engineering-first approach to the development agency model. We aim to work on projects that use the latest and greatest technologies. We care about the products we build and only work with clients who understand that good applications come from happy engineers. We are an entirely distributed team with members all across the US and Latin America.",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información",Servicios y tecnologías de la información,91,None,False,,620,None
670,2208410307,2020-10-23,Alert Logic,Senior Security / Threat Researcher,"Texas, United States","Senior Security / Threat ResearcherUnited States - Houston, Austin, Dallas, Denver, Boston or US remote consideredUnited Kingdom - Cardiff, London, or UK remote considered Summary The Research team in Alert Logic acquires vulnerability or threat information from internal telemetry and external sources. Using this information, a Senior Threat Researcher is expected to perform independent information gathering on familiar and new subjects to understand, replicate and propose detection methods for these threats. This can include proof of concept attack simulations / development and live sample reviews. The outcome of this work is channeled through a defined research process in order to produce the most accurate and effective detection coverage for the  organisation  across all target products. An internal training  programme  has been developed to supplement the skills required for this role.  Primary Responsibilities Analyze , translate, and document code behavior in a sanitized / sandboxed environment Document research on attack tools and systems Work with the SOC and Content teams to help prepare and protect Alert Logic’s customers against emerging Threats. Performs other duties as assigned  Required Skills and Experience Strong ethics and integrity Strong interest in security Knowledge of working to a defined, measurable process Dynamic, fast learner and versatile individual, willing to learn and explore the field of security research. Strong ability to independently identify and resolve critical and complex issues through effective problem-solving skills.  Ability to produce actionable research information for delivery to varied audiences in the form of technical reports, briefings, presentations and data feeds. Knowledge of a range of applications (such as LAMP), preferably in a virtualized environment Knowledge of a range of common networking technologies and protocols Knowledge of any SQL database setup and use Programming language / scripting knowledge in each of the following [Python, PHP, Bash, PCRE] Knowledge of cryptographic tools or theory Knowledge of defensive tools such as IDS / WAF / SIEM technologies and their content Knowledge of set up of a variety of systems in a securely configured manner Knowledge of attack / penetration testing tools and the cyber-offensive mindset  Knowledge of some of the categories within the OWASP Top 10 list.  Knowledge of common tools including [Wireshark, Metasploit]  Desired Skills, Experience and Education Degree / Graduate level education (2:1 minimum) in Computer Science / Electrical Engineering or a related discipline or related industry experience About Alert Logic Alert Logic has sparked change in the cyber security world. We are relieving customers from the complexity of the ever-changing threat landscape and helping them deny the bad guys. Our customers are winning, our business is growing, and our employees are innovating as they expand their careers. Our journey requires more great people, so we are hiring across the organization, what we call the “First Team”. If you are energized by a culture with a mission, come join us at Alert Logic! Working at Alert LogicAt Alert Logic, our greatness is achieved by the sum of our parts. We hire talented and ambitious people that volunteer their best every single day. We are inspired by our customers and being a leader in a booming industry that is regularly a trending topic. In addition to offering rewarding work and a career path gated only by an individual’s personal goals, we provide a work environment that is fun and cares for each employee.",Intermedio,Jornada completa,Tecnología de la información,Seguridad del ordenador y de las redes,53,None,True,,197,ACTIVELY_HIRING_COMPANY
671,2238932022,2020-11-04,Sentient Science,Senior/Lead Data Scientist,United States,"Here is an opportunity to join Sentient Science, a company whose solutions lie at the convergence of many exponentially accelerating innovative technologies: Cloud, edge computing and the Industrial Internet of Things (IoT): AI, machine learning and deep learning: Big Data and analytics: and 3D printing (additive manufacturing). Sentient Science helps customers lower the costs of designing, operating, and sustaining their high value mechanical assets by providing digital twin technology that predicts the life of mechanical systems. Sentient's DigitalClone® SaaS solutions use proprietary algorithms derived from physics-based modeling and machine learning. Help us achieve our vision of a world where rotorcraft manufacturers, wind energy operators and railroads rely on Sentient DigitalClone for a digital implementation of their O&M cost reduction strategy. And a high concentration of PhDs will keep you intellectually stimulated and challenged. The Senior/Lead Data Scientist leads efforts to expand the data science capabilities of Sentient’s cloud-based predictive analytics platform. Individual in this position will have a solid background in production-level machine learning systems with broad exposure to a wide variety of algorithmic techniques (demonstrable proof of impactful work in areas such as damage-anomaly detection, natural language processing, explainability-driven deep learning and time-series forecasting is valuable). Our team particularly values experience in building inferential algorithms for high-stake decisions while dealing with noisy, diverse, distributed datasets. Being able to communicate complex concepts in simple language to diverse stakeholders with an unwavering commitment to empathy and customer obsession is highly desired. The title and associated responsibility for the position can be modified for the right candidate – if our mission inspires you, please apply. Resonsibilities Building and Implementing the machine learning based statistical models to predict certain damage modes in major components in wind turbines such as Gearbox.Reviews large data sets (SCADA) of sensor-derived observations and alarm logs from operating wind turbines and utilizes subject matter expertise to ascertain veracity of these dataDevelops, implements and tests statistical algorithms for anomaly detection in large datasets from fleets of field-operating large machines e.g. wind turbines and rotorcraft Lead and mentor junior team members in design, optimization and production-deployment of machine learning and statistical forecasting models while adhering to timelines governed by the product development roadmapInterface with customer-facing executives to stay abreast with voice of the customer and update technical roadmap accordingly. Qualifications Masters or Ph.D. in mechanical engineering, industrial engineering, wind energy systems, aerospace engineering, statistics, data science, computer science, or related disciplineDemonstrable knowledge of theory and application of (one or more) techniques across supervised/unsupervised learning, natural language processing, computer vision and statistical inferenceDemonstrated experience working with large (TB+) repositories of structured and unstructured data spanning forms such as numeric, text, images/rastersFamiliar with some form of physics-based modeling, such as FEM, CFD, MD, MC, DFT, etc.Proficiency working with a modern programming language focused on data analysis and machine learning (e.g. Python, R, Julia, Matlab)Understanding/familiarity with deploying, monitoring and retraining machine learning models in cloud-facing production setting (AWS preferred)Proficiency with relevant tools and libraries for a collaborative machine learning workflow: scikit-learn, git etc.Knowledgeable in programmatically consuming data from APIs and other micro-servicesPossess a curious mind, insatiable drive to learn proactively and profound humility and empathy for your colleagues as well the customerUS citizenship required Benifits Unlimited paid time-offFlexible working hours and fully remote option availableEmployer-sponsored health insuranceOur commitment to inclusion across race, gender, age, religion, identity, and experience drives us forward every day",No corresponde,Jornada completa,None,Software,62,None,True,,395,ACTIVELY_HIRING_COMPANY
672,2268189337,2020-10-08,"Georgia IT, Inc.",Big Data Engineer 100% remote,"Detroit, MI, US","Big Data Engineer - 100% remote Location : Richmond, VA Duration : 06 months plus contract Rate : DOE  independent candidates only  Job Description  At least 8 years of experience with the Software Development Life Cycle (SDLC) At least 5 years of experience working on a big data platform At least 3 years of experience working with unstructured datasets At least 3 years of experience developing microservices: Python, Java, or Scala At least 1 year of experience building data pipelines, CICD pipelines, and fit for purpose data stores At least 1 year of experience in cloud technologies: AWS, Docker, Ansible, or Terraform At least 1 year of Agile experience At least 1 year of experience with a streaming data platform including Apache Kafka and Spark  Preferred Qualifications:  5+ years of data modeling and data engineering skills 3+ years of microservices architecture & RESTful web service frameworks 3+ years of experience with JSON, Parquet, or Avro formats 2+ years of creating data quality dashboards establishing data standards 2+ years experience in RDS, NOSQL or Graph Databases 2+ years of experience working with AWS platforms, services, and component technologies, including S3, RDS and Amazon EMR",Sin experiencia,Contrato por obra,Tecnología de la información,Dotación y selección de personal,5,None,False,,35,None
673,2246782961,2020-10-02,Nigel Frank International,GCP Data Engineer - Remote - UK Based,"London, GB","Data Engineer - London Based - Remote  up to £65,000  My client based in London would like to speak to Data Engineers in London and surrounding areas that are looking to join a fast-growing team that is always at the forefront of working with the new technologies. You will be surrounded and supported by a great team that always has a can-do attitude.  They are looking for people who help create cutting-edge, durable, and loved data solutions. While also having fun at the same time. This is a great environment to be around.  Skills & Qualifications Google Cloud PlatformStrong Programming & Architectural experience,Building Big Data solutionsPassionate about Data and AnalyticsExperience with ETL toolsHadoop-based technologies   Benefits 25 days holiday plus bank holidaysGreat pension schemeHardwareSocial events and team offsitesNetworking events, Mentoring events & conferencesExposure to expertsExplore the latest tools/technologies  This would be a great time to join this team as they are looking to expand even further and increase their client portfolio.  Do you not have all the skills mentioned above? I'd still like to hear from you.  If you are looking for an excellent salary, flexible working with minimal travel, private medical care, ongoing training, and career progression then this is the job for you.  Office Line: 0191 338 7667 Email: d.manzini@nigelfrank.com  LinkedIn: 'Dee Manzini'  Rest assured, anything discussed will remain completely confidential and fully compliant with GDPR.",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Dotación y selección de personal",0,None,False,d.manzini@nigelfrank.com,6,ACTIVELY_HIRING_COMPANY
674,2281848281,2020-10-21,TigerConnect,Sr. Data Engineer,"Santa Monica, CA, US","LOCATION: Santa Monica, CA or Remote TITLE: Sr. Data Analytics Engineer REPORTS TO: Director, Data Engineering  As the leader in secure, HIPAA compliant messaging and workflow optimization tools, TigerConnect helps physicians, nurses and other staff communicate and collaborate more effectively, accelerating productivity, reducing costs, and improving patient outcomes. Today, healthcare professionals and organizations alike rely on TigerConnect to send millions of messages a day and continually deliver on advanced product innovations.  TigerConnect is seeking a dynamic, highly motivated Sr. Data Analytics Engineer to drive the creation and execution of big data solutions that create data driven decision-making capabilities both for the business and our clients. This individual will significantly contribute to providing end-to-end data solutions and making both real-time and aggregate data available to both power a suite of customer facing applications and achieve company business goals.  What You'll Own:    Gathering & analyzing business requirements and driving creation/execution of optimal data solutions (data pipelines, data collection, integrations, aggregations, & reporting/analytics) Building & scaling data pipelines for constantly increasing data volumes (10x) Enabling TC teams and stakeholders (product, sales, marketing) to make data driven decisions through data reports and analytics Leveraging open source technologies in M/L for various types of data analytics such as predictive analysis and forecasting  Contributing to data architecture strategy as it relates to achieving immediate and long-term company business goals   What You bring to the table:    Solid understanding of distributed system concepts used in scaling big data technologies with exponential growth of data. Experience with all aspects of the data integration life cycle (source system analysis, ETL development and data model/structure design) Experience with AWS/MR and relational databases such as MySQL. Strong programming/scripting experience – Java, Map/Reduce, SQL, Python/Shell (AI/ML exposure is a plus) Experience with reporting frameworks (Looker) Experience with Elasticsearch & Kafka Excellent problem solving, communication, & teamwork skills A strong desire to learn and grow in a dynamic, fast-paced, collaborative, and high-growth startup environment. What You've accomplished:   Minimum of 4+ years developing production grade software with previous experience working on large-scale distributed systems. At least 2 years of experience using big data systems and/or using big data for data analysis.  Who We Are:  TigerConnect is healthcare's most widely adopted communication platform – uniquely modernizing care collaboration among doctors, nurses, care teams, and patients. TigerConnect is the only solution that combines a consumer-like user experience for both clinical and patient communication with serious security, privacy, and clinical workflow requirements that today's healthcare organizations demand. TigerConnect accelerates productivity, reduces costs, and improves patient outcomes.  Trusted by more than 6,000 healthcare organizations, TigerConnect maintains 99.99% verifiable uptime and processes more than 10 million messages each day.  It is recognized as a top Cyber Security Company to Know, one of the 5 Sizzling Silicon Beach Startups to Watch by Entrepreneur, Best Tech Startups in Santa Monica (2019 & 2020) and a Best Places to Work in Healthcare 5 years in a row (2015, 2016, 2017, 2018, and 2019). TigerConnect currently has over 150 employees with offices in Santa Monica, San Jose, and Shanghai.  Why We're Different:   Prime office space in the major tech ecosystems of California - Silicon Beach and Silicon Valley - each complete with a loaded fridge and tons of other perks (think rock climbing wall, food trucks, yoga, happy hours & more) An opportunity to work closely with a proven executive team, board, and serial entrepreneurs (www.tigerconnect.com/about) A fun environment that embraces a 'work hard-play hard' culture We have team members that love what they do and are willing to go the extra mile to help clients, support the company's rapid growth, and ultimately optimize healthcare workflows This is a full time opportunity with a competitive salary, medical benefits, and 401K matching plan   TigerConnect is an Equal Opportunity Employer.  Recruiting firms that submit resumes to TigerConnect without first entering into a written contract with TigerConnect will not be entitled to any compensation on candidates referred by that firm.",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Atención sanitaria y hospitalaria",None,None,False,,4,ACTIVELY_HIRING_COMPANY
675,2198712901,2020-10-21,Teikametrics,"Technical Lead, Data Science","Boston, Massachusetts, United States","Technical Lead, Data Science, Boston - Remote About the Role: Teikametrics is looking for a Technical Lead to build a team under the Data Science directorate tasked with building the prediction and control services that comprise our E-commerce AI. Candidates should have strong mathematical fundamentals, experience authoring statistical models for operation in a scalable, no-touch environment, good software engineering fundamentals, and management skills for operating a small team. The Data Science team's predictive services are developed in Python on top of AWS Sagemaker, orchestrated by Airflow and backed by a data warehouse in Snowflake. Our back-end code emphasizes a ‘functional-first’ Scala stack with cats and fs2. The team's mandate is to provide hardened prediction and control services to our sellers that solve the multi-agent, game-theoretic problems at the heart of decision-making in E-commerce. Additionally, this team will produce scientific materials geared toward helping sellers understand the utility and power of Teikametrics' data assets in the context of running their businesses. Qualified candidates should have: 6+ years of experience working as a professional software developer or data scientist, 2 of which may be graduate-level work in hard science.Strong Python with experience using some subset of the Python ML ecosystem (numpy/scipy/pandas, Tensorflow, etc.).Strong SQL. * Strong research skills: searching, reading, distilling literature on AI-related topics.Graduate-level mathematics, esp. probability, and linear algebra.Experience choosing and writing machine-learning models for deployment at scale.Familiarity with one or more of generative statistical models, reinforcement learning, game theory, control, or related field.Desire to lead a team and mentor its members.Desire to work in a collaborative environment focusing on continuous learning: participating in tech talks, code review, and pair programming. It's a bonus to have: Experience operating a system that takes automated actions entailing monetary risk.Experience with any of AWS, Kubeflow, Databricks, Spark, Snowflake.An interest in learning functional programming, or experience therewith.Experience training reinforcement learning agents using modern tools. About Teikametrics: There has never been a more exciting time to join Teikametrics, the leading Retail Optimization Platform (ROP). We’re building an operating system to optimize every aspect of a retailer's business -- from advertising to inventory to pricing. We optimize billions of transactions for thousands of entrepreneurs and brands around the world selling on Amazon and other marketplaces. The Teikametrics ROP uses proprietary econometrics and machine-learning data models packaged in a simple SaaS interface. We combine our best in class technology with coaching and support from our world-class teams based remotely and in Boston, MA, Seattle, WA, Tel Aviv, Israel and Bengaluru, India. We are looking for people who can excel, add value to our mission, and thrive in a demanding start-up environment.",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Internet,18,None,False,,191,ACTIVELY_HIRING_COMPANY
676,2283184396,2020-10-13,iScale Solutions,Big Data Engineer,"Manila, PH","Build, implement and optimize highly scalable batch and streaming data ingress/egress pipelines Collaborate with the company’s Analytics / Machine Learning teams to build and implement data pipelines to feed machine learning algorithms within Company’s Hadoop platform Develop tools and automate processes to aid in data collection, analysis and monitoring Collaborate with Product Engineering and Platform teams to make architecture design and implementation decisions atop the company’s Hadoop platform Provide engineering, installation, configuration, maintenance and support in a highly transactional 24x7 environment Perform a mix of incident management and project work focused on automation, increasing scale and optimization of processes/system performance Monitor platform and applications and take corrective action to prevent or minimize system downtime on Hadoop platform Recommend best practices, and implementation strategies using Hadoop, Java, ETL tools. Assist Hadoop admins with incident global management/resolution - light on-call rotation Work with the global Engineering team to assess current platform configuration and make recommendations to achieve optimal performance and horizontal scalability within Hadoop ecosystem Lead periodic provisioning of environments, code deployments and maintenance patching in Hadoop environments globally Collaborate with the Product Engineering team to develop proof-of-concept solutions as well as custom solutions for customers that leverage the company’s cloud-hosted Engagement Data platform   Requirements  Bachelor’s Degree in Computer Science or related field 2-4 Years hands-on experience working with data at scale Self-starters who collaborate well with others and take ownership of their projects. Experience and desire to work in a Global delivery environment Hands-on experience working within the Hadoop ecosystem (Spark, Hive, HBase, Storm) ideally in a cloud environment (AWS, GCP or Azure). Experience with optimizing SQL/Hive queries for maximum throughput SQL/noSQL technology. Familiar with Databases like Oracle, SQL Server, MySQL, MongoDB, Redis etc. Ideally in a cloud setting (ie. AWS RDS) Experience operating web-scale deployments of distributed systems, e.g. Kafka, Flink, Storm, Cassandra, Kubernetes or Elasticsearch Experience with data warehouses and building ETL workflows / data pipelines Data application/platform instrumentation, measurement, log data processing, and monitoring. Fluency in Python, Java, Scala, or a similar language—familiarity with more than one is a plus Mastery of Unix/Linux system and shell scripting Experience with orc, parquet, avro and other data formats Excellent communication skills, both verbal and written  Nice to have  Strong DevOps mindset and skill set Experience working with HDP Hive Interactive (LLAP) Experience in performance tuning for TEZ and Spark. Experience building data pipelines (ie. Apache Airflow, Spark Data Pipelines) Experience doing light data science in a Hadoop/Cloud setting (visualizations, clustering, classification, regression) to help predict and pro-actively optimize performance Experience creating dashboards with analytics tools like Looker, Tableau. Experience with Graph databases (ie. Neo4J, AWS Neptune, Cayley, Gremlin) Experience with Microsoft’s SQL Server Integration Services (SSIS) or similar tools. Experience working with AWS services (ie. S3, EC2, Kinesis, Lambda, etc…) Amazon Web Services, Google Cloud Platform or Microsoft Azure certifications  This is a remote position.",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Software,0,None,False,,6,None
677,2253787932,2020-10-29,Pluralsight,Data Engineer,"Draper, UT, US","This position is available for remote employment in these areas:Draper UT, Remote - California (Bay Area), Remote - Illinois (Chicago), Remote - New Jersey (NYC Metro Area), Remote - New York, Remote - New York (New York City), Remote - Washington (Seattle)Job Description: Our Data Engineering & Operations team is a force multiplier for data practitioners at Pluralsight. We provide tooling and data sets to make Pluralsight a data-driven organization. Our work includes: building pipelines which curate and land data, deploying data science models, and maintaining data infrastructure. You’ll have the opportunity to work with data tools, like Python and Spark, as well as web analytics and streaming data from our data platform.  Who You’re Committed To Being You utilize a multidisciplinary approach to providing solutions for the business, combining technical, analytical, and domain knowledge.You have strong development skills, experience transforming and profiling dataYou understand the benefits and risks of a variety of data technology solutions, which guide your implementation decisions.You love interfacing with data scientists and analysts to understand their needs.You have an eagerness to dive in to data sources to understand availability, utility, and integrity of our data   What You’ll Own Building and maintaining production data pipelines for data science and analyticsDeveloping tooling and solutions for data practitioners using a deep understanding of their objectives and pain pointsModeling and curating product data sets, such as web analytics and kafka topicsImproving observability in our data environment, including uptime, usage, data quality, and data freshnessBuilding production applications from data science research and exploratory analytical work  Experience You’ll Need 5+ years of taking a multidisciplinary approach to data development: we emphasize picking the right tool for the jobDeep experience with a number of data tools: e.g. SQL, Spark, Hadoop, PythonManaged systems with complex dependency management and orchestration requirementsStrong capability to manipulate and analyze complex, high-volume data from a variety of sourcesEffective communication skills with technical team members as well as business partners. Able to distill complex ideas into straightforward languageAbility to problem solve independently and prioritize work based on the anticipated business value",Sin experiencia,Jornada completa,Tecnología de la información,"Marketing y publicidad, Servicios y tecnologías de la información, Software",83,None,False,,517,ACTIVELY_HIRING_COMPANY
678,2226427225,2020-10-22,Vyne Group,Remote Senior Data Engineer,United States,"Vyne Group, a staffing and recruiting company, has a client with an exciting, fully remote open role. Please, only Green Card holders and US Citizens.  Senior Data Engineer – Remote About The Company:A small and growing organization dedicated to delivering high-value health care analytics. The Role:As a Senior Data Engineer, you will work with a small team to transform and deliver research-grade data in the healthcare sphere. You’ll be responsible for creating and managing data pipelines, building and administering Tableau reports, and assisting customers in development and analysis of data presented through Tableau. If you’re resourceful, and you enjoy working in a fast-paced environment where your contributions will be recognized, you’ll fit right in. Required:Familiarity with AWS, S3, EC2, RDSExperience working with Git, or other version control systemExperience with architecting reliable and scalable data structuresExperience designing Data Profiling and Data Governance measures5+ Years experience with T-SQL, DDL/DML3+ Years experience with ETL/ELT developmentIntermediate to advanced experience with Tableau Dashboard and Report DevelopmentIntermediate to advanced experience in Tableau Administration, Security, and LoggingExperience transforming JSON, XML, CSV into a relational databaseExperience accessing with APIsKnowledge of HIPAA and PHI regulations Desired, but not Required:Knowledge of HL7, FHIR standardsPython, Jupyter Notebook",Intermedio,Jornada completa,"Tecnología de la información, Ingeniería",Atención sanitaria y hospitalaria,36,None,True,,268,JOB_SEEKER_QUALIFIED
679,1930307231,2020-10-31,"Resolution Technologies, Inc.",Sr. Data Engineer,"Pittsburgh, Pennsylvania, United States","SR. DATA ENGINEER SR. DATA ENGINEER JOB SUMMARYA Data Engineer III is responsible for coding and continuous testing of complex modules and applications in support of the company’s platform. This person will also be charged with understanding and the interpretation of requirements to contribute to the technical architecture and related design documents. SR. DATA ENGINEER PRIMARY DUTIES AND RESPONSIBILITIESWriting, debugging, unit testing, and performance test code in the data access layer in accordance with company standards.As an agile team member, participate in code reviews, design reviews, etc.Utilize domain driven techniques and design patterns to build and contribute to technical design.Develop and maintain strong knowledge of implemented requirements and detailed application behaviors.Provide mentorship and support for junior level engineers SR. DATA ENGINEER EDUCATIONBachelor's computer information technology, computer science, management requiredMaster's preferred SR. DATA ENGINEER EXPERIENCE5-7+ years of experience in a cloud computing environment.Familiarity and strong understanding of working in the Linux operating environment.Familiarity and experience executing several software development methodologies and life cycles preferred. ﻿SR. DATA ENGINEER SKILLS7+ years of developing software using object-oriented or functional language experience5+ years of SQL7+ years working with open source Big Data technology stacks (Apache Nifi, Spark, Kafka, HBase, Hadoop/HDFS, Hive, Drill, Pig, etc.) or commercial open source Big Data technology stacks (Hortonworks, Cloudera, etc.)3+ years with document databases (e.g. MongoDB, Accumulo, etc.)3+ years of experience using Agile development processes (e.g. developing and estimating user stories, sprint planning, sprint retrospectives, etc.)2+ years of distributed version control system (e.g. git)3+ years of experience in cloud-based development and deliveryFamiliarity with distributed computing patterns, techniques, and technologies (e.g. ESB)Familiarity with continuous delivery technologies (e.g. Puppet, Chef, Ansible, Docker, Vagrant, etc.)Familiarity with build automation and continuous integration tools (e.g. Maven, Jenkins, Bamboo, etc.)Familiarity with Agile process management tools (e.g. Atlassian Jira)Familiarity with test automation (Selenium, SoapUI, etc.)Good software development and Object Oriented programming skills.Strong analytical skills and the ability to work with end users to transform requests into robust solutions.Excellent oral and written communication skills.Initiative and self-motivation to work independently on projects.",Intermedio,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Atención sanitaria y hospitalaria",141,None,True,,749,ACTIVELY_HIRING_COMPANY
680,2192243840,2020-10-19,Saranen,10 analytiikan ja datan visualisoinnin tulevaa osaajaa,Helsinki Metropolitan Area,"Datasta riittää paljon puhetta ja vielä enemmän tekemistä. Uudenmaan alueen yritykset etsivätkin nyt riveihinsä tulevaisuuden osaajia, jotka pystyvät antamaan datalle ymmärryksen ja visualisoimaan tietoa tehokkaalla tavalla. Uudet työt odottavat, oletko etsimämme tekijä? Jos haluat kasvaa uuteen työhön, jossa voit kehittää liiketoimintaa, toimia asiakasrajapinnassa, perehtyä koneoppimisen maailmaan tai tuottaa lisäarvoa data-analytiikan keinoin, tämä on sinun mahdollisuutesi. Uusista osaajista on alalla suurempi kysyntä kuin koskaan. Löydä uusi työ ja kasva data-analytiikan osaajaksi AnalyticsPro -rekrytoivan koulutusohjelman kautta pääset kouluttautumaan ja kehittymään kasvualan asiantuntijaksi uusien työtehtävien kautta, sekä kasvattamaan ammattiosaamista niiden taitojen parissa, joista työnantajat kilpailevat. Rekrytoivat yritykset etsivät ennen kaikkea motivoituneita ja oman ammattitaidon kehittämisestä innostuneita tulevaisuuden osaajia. Voit olla jo kokeneempi asiantuntija tai alalle vastavalmistunut tekijä – tärkeintä on into ja palo kasvaa data-analytiikan asiantuntijatehtäviin.  Ohjelman kautta uusi työtehtäväsi voi olla esimerkiksi: BI-konsulttiRaportointiasiantuntijaBig Data / Data SpecialistWeb AnalystBusiness AnalystMaster Data -asiantuntijaData Scientist / Data Analyst Olet varmasti meitä kiinnostava hakija, jos tunnistat itsesi joistakin näistä piirteistä:Sinulla on palava halu ja motivaatio kehittää omaa osaamistasi ja kasvaa data-analytiikan ja tiedolla johtamisen asiantuntijaksi – tämä on kaikista tärkein kriteeriSinulla on ymmärrystä liiketoiminnan tai talouden prosesseista ja olet kiinnostunut prosessikehityksestä ja muista kehitysprojekteistaAsiakasrajapinta ja sidosryhmät kiinnostavat sinua ja näet itsesi tulevaisuudessa konsultin roolissaSinulla on kokemusta tietovarastoista, raportoinnista, ERP-järjestelmistä, taloushallinnon prosesseista tai myynnistä, ja haluat ottaa uuden askeleen urallasiData-analytiikan ratkaisut ja teknologiat kuten R, Python, SQL, relaatiotietokannat, Tableu, Qlikview, Power BI, ETL, koneoppiminen, tekoäly, Alteryx, Azure, AWS tai Google Cloud herättävät sinussa innostusta ja saatat joitain tuntea jo tarkemminkinOlet matemaattisesti lahjakas ja logiikka sekä ongelmanratkaisu ovat vahvuuksiasiOlet tiedonjanoinen ja haluat pysyä ajan tasalla viimeisimmistä teknologioista ja ratkaisuista  Rekrytoiva koulutusohjelma antaa sinulle erinomaisen mahdollisuuden löytää tulevaisuuden työpaikkasi! Haluatko kuulla lisää Analytics Pro - rekrytoivasta koulutusohjelmasta? Ohjelman hakijainfotilaisuus järjestetään 28.10 klo 11-11:30 Sarasen Facebookissa. Lue lisää ohjelmasta nettisivuiltamme: https://www.saranen.fi/rekrytointikoulutus/analyticspro?utm_source=linkedin&utm_medium=cpc&utm_campaign=analyticspropks_s20!Voit hakea rekrytoivaan koulutusohjelmaan, mikäli olet tällä hetkellä työttömänä työnhakijana, työttömyysuhan alaisena, lomautettuna tai määräaikaisessa työsuhteessa ja työnhakusi TE-palveluissa on voimassa. Uusi työ asiantuntijakoulutuksestaAnalyticsPro -rekrytoivassa koulutusohjelmassa yhdistyvät käytännön työtehtävät sekä data-analytiikan asiantuntijakoulutus. Ohjelma antaakin sinulle aidon mahdollisuuden vaikuttaa uraasi sekä löytää tulevan työpaikkasi. Koulutuksesta eväät työllistymiseen. Koulutusohjelman tärkeimpänä tavoitteena on työllistää sinut yhteistyöyritykseen 6kk ohjelman päätteeksi.Asiantuntijuus uudelle tasolle. Saat ohjelman aikana laadukasta koulutusta alan johtavilta tekijöiltä 20-25 koulutuspäivän myötä, sekä pääset hyödyntämään oppimaasi uudessa työroolissasi. Lopputuloksena kasvatat oman asiantuntijuutesi uudelle tasolle.Ohjelma avaa useita erilaisia urapolkuja. Data-analytiikkaosaaminen on entistä kysytympi taito ja uusista osaajista on kasvava tarve. Yritykset etsivät ohjelman kautta tekijöitä erilaisiin ja eritasoisiin teknisiin, sekä liiketoimintalähtöisiin kehitystehtäviin. Hae mukaan pian! Voit hakea mukaan rekrytoivaan koulutusohjelmaan, mikäli olet tällä hetkellä työttömänä työnhakijana, työttömyysuhan alaisena, lomautettuna tai määräaikaisessa työsuhteessa ja työnhakusi TE-palveluissa on voimassa. Etenet hakuprosessissa, kun olet täyttänyt kaksi lomaketta:1) Täytä TE-toimiston hakulomake.https://koulutukset.te-palvelut.fi/kt/695213?searchPhrase=saranen&&&announced=0&sort=1Löydät AnalyticsPro –rekrytoivan koulutusohjelman koulutusnumerolla 695213.Esivalinta koulutukseen tehdään tämän TE-toimiston hakemuksen tietojen perusteella, joten perustele hakemuksesi huolellisesti. 2) Täytä Sarasen osaamisprofiili. Tämä osaamisprofiili toimii käyntikorttinasi rekrytoiviin yrityksiin. Voit muokata ja täydentää profiilia koko hakuajan.https://sc.rekrytointi.com/paikat/?o=A_A&jid=428 TE-palveluiden hakemus ja Sarasen osaamisprofiili kannattaa tehdä pikaisesti – esivalinta- ja hakuprosessi on jo käynnissä! Lisätietoja ohjelmasta:Ensisijaisesti lisätietoja ohjelmasta löydät Sarasen nettisivuilta: https://www.saranen.fi/rekrytointikoulutus/analyticspro?utm_source=linkedin&utm_medium=cpc&utm_campaign=analyticspropks_s20 Voit halutessasi kysyä lisää projektikoordinaattorilta Pinja Heimalalta: Pinja Heimala, Saranen Consulting, ti & to klo 9-11. Pinjan tavoitat p 040 849 3962 tai pinja.heimala@saranen.fi F.E.C. (Further Educated with Companies) -koulutusohjelmaTyösuhteeseen tähtäävässä ohjelmassa yhdistyy tehokas työssä oppiminen ja laadukas koulutus. Ohjelma toteutetaan tiiviissä yhteistyössä ELY-keskuksen, TE-palveluiden ja rekrytoivien yrityksien kanssa. Ohjelma on suunniteltu sinulle, joka olet työtön, työttömyysuhanalainen tai määräaikainen työsuhteesi on päättymässä. F.E.C.-ohjelman ajaksi tehdään sopimus koulutuksesta ja voit hakea ansiopäivärahaa, peruspäivärahaa tai työmarkkinatukea sekä kulukorvausta.",No corresponde,Jornada completa,"Otro, Análisis",Recursos humanos,10,None,False,pinja.heimala@saranen.fi,278,ACTIVELY_HIRING_COMPANY
681,2245863622,2020-10-27,ShareChat,Lead Data Scientist,"Bengaluru, Karnataka, India","AI @ ShareChat India’s active internet user population has crossed half a billion in 2019. If you look closely at the first 100 million Internet users and the rest of the users who came online in the last few years, you will notice stark differences in their needs and wants from the Internet. While the first generation Internet users in India weren’t too different from Internet users in the rest of the world, the next wave of users are truly unique in a number of ways. A huge chunk of audience is regional language first audience and therefore wants to consume content and services in their native language. Their taste in content also happens to be vastly different – we observe a long tail of content genres emerging that didn’t exist previously. Despite the internet growing so swiftly, many Indian Internet users are not comfortable with searching on the internet or finding whom to follow in order to satisfy their information needs. A radically simplified paradigm for content delivery is needed for this audience – one that automatically learns the user’s taste and pushes the right content at the right time to them based on their interest. ShareChat harnesses AI in its quest towards this mission possible.  The AI team at ShareChat is growing. We are hiring talented individuals with expertise in the areas of Recommender Systems, Reinforcement Learning, Bayesian Optimisation, Deep Learning on Graphs, Computer Vision, Natural Language Processing, Speech Processing and so on. Our team of world class scientists and engineers push the boundaries of state of the art in these areas and impact millions of people every single day. We have a strong focus on research and actively collaborate with academics on open-ended research problems.  Lead Data Scientist:  Apply state of the art in the relevant research domains to make significant contributions to the feature roadmap of the ShareChat app in the aforementioned areas.  Apply expert coding skills to develop scalable product features in partnership with other engineers on app and infrastructure teams  Apply best practices in big data processing to build feature stores, data pipelines and model inference services that can deal with massive scale.  Adapt deep learning algorithms to best exploit modern parallel environments (e.g. distributed clusters, GPUs). In case of on-device applications, tune network architectures to efficiently run on low to medium end smartphones.  Qualifications  BTech, MS degree or Ph.D degree in Computer Science or a related discipline  Experience in deploying ML models with frameworks like Tensorflow, PyTorch, MXNet, Caffe, Torch etc on Android and iOS devices  Excellent coding skills in C/C++ and Java  Knowledge of eveoving and recent technologies in Android, IOS app development and different mobile compute and memory resources and sensors  Ability to build basic Android/iOS apps using NDK for Audio-Video capture and processing pipeline with basic UI features is needed  Experience with multi threaded implementations utilizing computer units like multi core CPU, GPU, NPU, DSP and media encode/decide accelerators is a huge plus",Intermedio,Jornada completa,Ingeniería,Internet,229,None,True,,646,COMPANY_RECRUIT
682,2211568290,2020-11-03,WorldQuant Predictive,Senior Data Scientist – Machine learning / Artificial Intelligence (AI),Hungary,"Location: Budapest Ideal Candidate:Proven machine learning / data science skills (Python or R) and data analytics. What you will do:Data Scientist will take part in client facing projects mostly but not limited in CPG and Healthcare projects. We are delivering Prediction Products, it means your goal is building a scaleable and robust solution for various use cases. Part of your job is to work together with Product Delivery Managers to create proposals, then translate business needs to prediction challenges, build prediction models (machine learning models), and evaluate them, deliver insights to to the clients and also help us identify product feature needs to improve our prediction platform. Project Description:   You will be part of a talented team that contains data scientists, data engineers, software developers and delivery managers to solve various prediction problems. It can be either from FMCG (e.g demand prediction, price optimisation, marketing cost optimisation, price elasticity modelling, etc.) or Healthcare (e.g. identification of rare diseases). You can use any (edge case/latest) machine learning models, you can see your impact, and your contribution will be visible to the whole company. What have you done:3+ years proven machine learning / data science skills (Python or R)Proven Data analytics experience About us:WorldQuant Predictive provides data science capabilities and prediction services across multiple industries with offices in New York (USA) and Budapest (Hungary). Research and technology are at the core of our business, enabling us to identify insights and build models to help solve challenging real-world problems. We are an organization backed by Igor Tulchinsky, founder of WorldQuant Asset Management, a highly successful quantitative asset management firm built on the philosophy that talent is global. Our core philosophy is that good ideas can come from anyone and anywhere, and that the cross-fertilization of those ideas can lead to great solutions and innovative technologies. This philosophy is realized in our culture of collaboration and open exchange of ideas spanning multiple geographies and disciplines.",Intermedio,Jornada completa,"Tecnología de la información, Ingeniería, Consultoría","Software, Biotecnología, Consultoría de estrategia y operaciones",151,None,True,,448,JOB_SEEKER_QUALIFIED
683,2246373768,2020-11-05,Oliver Bernard,Data Engineer - £80K - £90K,"London, England, United Kingdom","Data Engineer - £80K - £90K  Our client is a leading tech and software company. They build cutting-edge solutions for on-demand streaming and real-time, online media.   Through innovation they deliver sports, television and media streaming to customers around the world - across a variety of apps and platforms.  You’ll be a key part of the DataOps team – covering Data Engineering, Data Science and Machine Learning.  This position is part of a brand new project team - building an AI-powered data platform and prediction engine, designing Machine Learning models, create data analysis tools and drive continual evolution of their software.  You’ll have the opportunity to work with streaming tech such as Spark and Kafka, TensorFlow, AWS and DevOps tools such as Kubernetes and Docker and a mix of BigQuery, PowerBI and Python amongst others.  This is a unique opportunity for a strong Data Engineer, with a good understanding of Data Science and ML to join a world-leading technology company and create innovative, greenfield solutions – not to be missed!  Requirements:  - Excellent experience in a similar Data / DataOps Engineering position - Coding skills with Python, Scala and / or Java - Machine Learning models development experience - Good AWS experience - Experience of configuration management (Terraform, Ansible etc) - Experience of large-scale data manipulation (SQL, Spark, BigQuery etc) - An understanding of data analysis and visualisation (Power BI, Tableau etc) - Excellent communication skills - A passion for sport!",Intermedio,Jornada completa,Tecnología de la información,Servicios y tecnologías de la información,106,None,True,,343,ACTIVELY_HIRING_COMPANY
684,2281866237,2020-10-21,LineTen,UX Researcher,"London, GB","We have an exciting opportunity for a UX Researcher at LineTen, to join our Product Team.  You will be someone who loves to work on challenging design problems and collaborate with product teams to ensure our customers have delightful experiences across all our products.  LineTen is a remote working company and everyone is eligible for share options.  Our products help businesses to capture online orders, to receive them in their POS system, and to book deliveries to their customers.  Summary Of UX Researcher Position  You will be responsible for leading and conducting user and business research activities to understand business requirements, user behaviour and optimal UI design, while also encouraging research-based product development throughout the business.  In this role you should be an analytical and creative researcher who is able to grasp user needs and solve problems. A strong portfolio of successful UX and other technical projects is essential.  Ultimately, you will make our products serve the needs of our customers better, through user-friendly and intuitive software that attracts and retains them.  Responsibilities include:  Collaborating with Product Owners, Designers and Developers to create intuitive, user-friendly software  Understanding user and business needs, competitor products and industry trends  Mentor and guide others and work to continuously improve the research process  Understand product specifications and user psychology  Conduct concept and usability testing and gather feedback  Create personas through user research and data  Define the right interaction model and evaluate its success  Develop wireframes and prototypes around customer needs  Use analytics and other data points to drive evidence-based design and development  Find creative ways to solve UX problems (e.g. usability, findability)  Work with UI designers to implement intuitive, effective designs  Communicate design ideas and prototypes to developers   Requirements  Proven experience as a UX researcher / designer or similar role  Strong portfolio of UX developments  Familiarity with interaction design and information architecture  Proficient in design and prototyping software (e.g. Figma, Balsamiq)  Problem-solving aptitude  Analytical mind with a business acumen  Excellent communication skills  UX qualifications desirable   LineTen is building a global, data-driven parcel delivery network. We connect a growing list of delivery providers to a likewise growing list of retailers to increase route density for delivery providers and shipping options for retailers and their customers. Due to continued demand, we are seeking to double in size over the next 12 months to 140 employees, creating excellent career opportunities for all who join us.",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Internet",4,None,False,,30,None
685,2273325479,2020-10-10,Webflow,Lead User Researcher,"San Francisco, CA, US","Webflow is a visual web development platform that empowers non-coders to create incredible experiences for the web.  We're adding a Lead User Researcher to our team who will help us better understand our customers and how to bring their needs to existing and new product initiatives for Webflow. This role will help us learn about our current and potential customers, and who we can serve by identifying continued and new opportunities in our product roadmap.  About The Role  Location: San Francisco HQ or US remote Full-time  As a Lead User Researcher, you'll …  Shape and define the research function at Webflow to make it a core pillar of the design department Plan and execute pragmatic and insightful user research: design research studies and tests, recruit participants, facilitate interviews, and analyze results Synthesize and package research insights into compelling narratives to present to the team in a digestible and actionable way Identify and drive new research initiatives that will influence the product roadmap Elevate Engineering, Product, and Design's (EPD) research capabilities by equipping them with toolkits, training, and processes to set them up for success in their own research  That said, these responsibilities are just the start! At Webflow, we encourage you to contribute wherever your interests take you — and shape your role accordingly. And this isn't just a philosophical bent: we actually give you 4 hours a week (10% of the work week) to pursue passion projects outside of your role responsibilities.  About You  You'll thrive as a Lead User Researcher if you have:  A track record of applied research that has significant impact on product and/or company goals Experience with a wide range of evaluative and generative research methods: field studies, ethnography, participatory design, diary studies, usability testing or A/B testing Facilitation experience to drive consensus and buy-in especially from various groups and stakeholders Mentored/coached other researchers and product designers Experience implementing or improving tools/processes Experience with lean research integrated with product teams in an agile process Have the ability to parse large amount of research data and notes to generate insightful and actionable learnings  If you don't meet 100% of the above qualifications, we encourage you to still apply. Studies show that meeting just 50% of a role's requirements puts you in consideration.  About Us  At Webflow, we believe that our success will be defined not only by what we do — but also by how and why we do it. So, here is the Webflow 'why' and our 'how':  Our dual missions — one for the world, one for us  For the world: To empower everyone to create for the web and spark an unprecedented wave of digital innovation. For ourselves: Lead fulfilling, impactful lives.  Our core behaviors (how we act)   Start with customers Practice extraordinary kindness Be radically candid Move intentionally fast Just fix it Lead by serving others Dream big  Our commitments to you  We'll pay you! This is a full-time, salaried position that includes equity We'll invest in your physical and mental well-being with health, dental, and vision benefits and a monthly stipend for health and wellness expenses  We'll pay you to take a vacation … seriously. We'll give you a $1,000 bonus for taking your first vacation with us that is more than 5 days  We offer flexible parental leave  We provide remote employees with the equipment they need to create a great remote work environment  We will offer you the support you need to help you grow as an impactful Lead User Researcher and a human being   Ready to apply?  If you share our values and enthusiasm for empowering the world, we'd love to review your application! We promise we do take the time and care to review every application we receive. However, as much as we wish we could interview everyone who submits an application, we cannot guarantee an interview or feedback due to the unprecedented volume of applications we are receiving today. We are rooting for you, and hope you do consider applying.  Note: You'll need valid U.S. work authorization to join us.",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Marketing y publicidad, Software, Internet",3,None,False,,27,ACTIVELY_HIRING_COMPANY
686,2251921352,2020-10-04,Paige,Data Engineer,"New York City, NY, US","Paige is a software company helping pathologists and clinicians make faster, more informed diagnostic and treatment decisions by mining decades of data from the world's experts in cancer care. We are leading a digital transformation in pathology by leveraging advanced Artificial Intelligence (AI) technology to create value for the oncology clinical team.  Paige is the first company to develop clinical grade AI tools for the pathologist, which resulted in our receiving FDA breakthrough designation for our first product.  We're seeking a Data Engineer who will be working the development and support of software applications, tools and data management pipelines for research and clinical purposes. Following modern product development practices, you will also assist in the design, implementation and maintenance of tools that extract and manipulate data from various sources, including in-house and external databases. This is an extraordinary opportunity to be part of a high-performing team and to pursue a life-changing mission with unique technical challenges!   This position can be fully remote for U.S. based applicants.  Responsibilities  Work on Data Warehouse, Data Lake and BI projects and architectures at Paige. Create and implement ETL pipelines that enables the extraction, transformation and transfer of large amounts of structured and unstructured data from various filesystems and databases, that are destined for the development of computation pathology algorithms. Handle the challenges that come with managing terabytes of data. Build tools to manage, automate and monitor our data and data processing infrastructure. Design and develop software tools into existing resources. Be responsible for design, coding, testing, packaging, debugging, documentation and deployment of software systems. Work independently to produce required functional, technical, and user documentation (e.g., business requirements, functional and technical specifications, system architecture, data flows, end-users training requirements) on assigned projects. Work and collaborate with data engineers, scientists, engineers, IT operations and medical doctors to build tools manipulating data in order to build a new generation of artificial intelligence applications for cancer detection and treatment.   Requirements  Experience in architecting, implementing and testing data processing pipelines (e.g. Spark, Beam, ...) and data mining / data science algorithms either on-premise or on a cloud environment. Experience in administrating and ingesting data into standard data warehouses (e.g. Amazon Redshift, Microsoft SQL Server, Google BigQuery or Snowflake). Experience architecting data warehouses and/or data lakes for large amounts of structured and unstructured data. Experience with data lakes and expertise with designing and maintaining a BI solution. Experience with workflow management tools and platforms, such as Airflow. Extensive experience in Python programming, or related language. Experience with RDBMS and NoSQL databases (e.g. MongoDB). Experience in packaging and deploying applications on-premise and in the cloud (e.g. AWS). Familiarity with modern development practices and DevOps. Interest in building non-standard medical software applications, in collaboration with medical partners. Cross-disciplinary and strong analytic skills. Bachelor's degree in computer science or a related field, or equivalent years of experience. 3+ years of industry experience as a data engineer.",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Atención sanitaria y hospitalaria",9,None,False,,136,ACTIVELY_HIRING_COMPANY
687,2222622835,2020-10-29,FS Technologies,Lead Data Scientist,"Mumbai, Maharashtra, India","About UsFS Technologies is a early stage venture, affiliated with one of Asia's leading private investment firms. FS Technologies has been established to build the next generation of data technologies that can be applied to private markets investing.  We are in the early stages of building a high performing team and are looking for key team members to help shape our vision and provide leadership as we scale over the coming years. This is a unique opportunity to join as a foundational team member and become a senior leader as we look to disrupt investing in private capital markets.  Job DescriptionWe are looking for a Data Scientist to establish and lead the data science function at FS Technologies. Data is core to everything FS Technologies does, and this role will give you the opportunity to build and mentor a team.  This role will require responsibilities such as hiring and managing a lean data science team, planning projects, and building the core models for FS Technologies. You should have a strong problem-solving ability anda passion for statistical analysis.  Lead Data Scientist Responsibilities IncludePlanning data projects.Building analytic systems and predictive models.Hiring and managing a team of data scientists, machine learning engineers and big data specialists over the next 1-2 years.Collaborating with stakeholders across teams to execute projects. ResponsibilitiesManage a team of data scientists, machine learning engineers and big data specialistsLead data mining and collection proceduresEnsure data quality and integrityInterpret and analyze data problems, turning business problems into data insightsConceive, plan and prioritize data projectsBuild analytic systems and predictive modelsTest performance of data-driven productsVisualize data and create reportsExperiment with new models and techniquesHas in-depth knowledge and expertise in the process of converting an unstructured problem to useful and actionable insights using data science/analytics.Align data projects with organizational goals RequirementsProven experience as a Data Scientist or similar role, with 3+ years experience.Experience working at financial institutions or high growth technology companies will be viewed favorably. Demonstrated ability to distil complex business problems, solutionize and turn them into measurable, actionable and optimizable outcomes.Have experience in building, maintaining and evaluating models in a production (real time and offline) environment. Design and build scalable systems by partnering with commercial members of the broader team. Experience building a team from scratch with a strategic vision on what we are building and why. Strong in the common data science tongues (R, Python, Scala, …), with deep expertise in common data science tools/package.Experience with SQL and NoSQL databases.Strong organizational and leadership skills, with a bias to actionBachelors, Masters Degree or PhD in Computer Science, Data Science, Mathematics or similar field",Algo de responsabilidad,Jornada completa,None,Gestión de inversiones,352,None,True,,963,JOB_SEEKER_QUALIFIED
688,2280430099,2020-10-11,SlashData,Data Storyteller (Remote - EMEA based),"Falkirk, GB","SlashData is the leading research company in the developer economy: We help the world understand developers and developers understand the world. We survey 40,000+ developers annually - across mobile, IoT, desktop, cloud, AR/VR, web, games, data science, and machine learning - to help clients such as Microsoft, Facebook, Google and Amazon understand who developers are, what tools they love or hate and where they are going next.  We’re now looking for a full-time, Data Storyteller to help drive insights out of a wealth of data points relating to developer activity. You’ll be working based in Europe or MEA, working from home or a co-working space to support our distributed team.  Who We’re Looking For  As a Data Storyteller, you will have 2-5 years working experience in data analysis, data visualisation, and data journalism. You will be fearless in data crunching and keen to unearth meaningful patterns, actionable insights and intriguing stories from the data.  You will have undertaken many data analysis projects where your novel insights and attention to detail would impress. You will have a proven record of communicating your findings to a non-technical audience, eloquently narrating the story behind the numbers. You might not have worked in the software industry before, but you have a passion for software, and wanting to figure out what makes the software economy tick - based on data.  If you’re that person, we’d love to talk.  Requirements  As a Data Storyteller you will be: Based in EMEA region (UK time ±4hrs) Performing data analysis using any scripting language (e.g. Python, R), and Excel. You‘ll be working on several data projects, extracting insights in the context of market trends, behavioural analysis, population forecasting, segmentation and profiling. Writing up your findings in short and long reports including visually appealing graphs and deep insights based on your analysis, answering the “why” behind the “what”. Tracking the latest trends in the software developer ecosystem. Helping shape our research agenda and asking developers and data scientists the right questions. Interacting with clients to provide insightful answers to tough data problems, and to support them in custom data insights projects. Helping clients identify key business questions and translate them into research questions and projects. Delivering briefings and webinars, and presenting our insights in conferences, meetups and events. Supporting the rest of the analyst team in their data and research quests as needed.   What Skills We Are Looking For A data scientist who is also into data journalism, with a background in statistics, applied mathematics or computer science. An ability to tell signal from noise in the data, and answer the ‘so what?’ question behind the observed numbers and patterns. An ability to author data stories, comprehensively and in an unbiased way, with proven previous experience in authoring insights reports, blog posts or other published writing. Excellent writing skills (English), with the ability to communicate complex insights to non-technical audiences. Advanced Excel skills. At least basic programming skills, preferably in Python including Pandas. At least a basic grasp of clustering and classification methodologies and models. Ability to visualise data effectively, producing eye-catching and easy-to-understand graphs. Very good presentation skills. Comfortable working as part of a distributed team across four continents.  Bonus Points for Having software development experience as a hobby or past work. Advanced Python skills. Advanced data modelling skills. Past experience of working with complex survey data. Past experience of consulting clients on data projects. A passion for technology, and thorough understanding of how it’s impacting people’s lives.  Key success metrics  You will be successful in the role if in the first 6 months you have: Actively contributed in shaping the research agenda and questionnaire of the upcoming Developer Economics survey. Authored at least two research reports, carrying out all data analysis and background research as needed. Authored at least one blog post based on our survey data, showcasing our research and/or promoting our surveys. Delivered at least one client briefing or webinar to our high standards. Actively supported the rest of the analysts team, by reviewing other authors’ reports. Supported our developer outreach and sales teams, promptly responding to any requests relevant to your work. Become a dependable team mate.   Benefits  What we offer Opportunity to make a difference as part of the leading research company in the developer economy Part of an entrepreneurial company that's raising the bar, and calling the trends of the developer economy Opportunity to work with some of the biggest tech brands in the world International team, great work atmosphere & flexible working environment Competitive salary + bonus twice yearly based on performance Come to work in a t-shirt, shorts and flip flops, or tie and a suit - we don't mind! You will never work on your birthday - we automatically give you this day off Annual training budget to develop your skills and career Monthly book allowance from Amazon, on any book you like Spotify Premium subscription or Netflix vouchers",Sin experiencia,Jornada completa,"Marketing, Relaciones públicas, Redacción y revisión","Investigación de mercado, Software, Investigación",2,None,False,,50,None
689,2284439177,2020-11-07,Hotel Engine,Senior Data Engineer,"Denver, Colorado, United States","Hotel Engine (https://www.hotelengine.com) is a high-growth, Denver-based tech company that is innovating the business travel industry with a free, private hotel booking management platform. With over 300,000 hotel properties globally, Hotel Engine offers up to 60% off publicly available hotel rates for small-to-medium businesses, large enterprises, and government travelers.  Serving industries like construction, transportation and logistics, healthcare, retail, and more, Hotel Engine has customized hotel reservation management solutions built for the control, transparency, billing, and support needs of organizations of any size and industry.   Hotel Engine has experienced tremendous growth and establishing and maintaining high-quality data assets, data infrastructure, and analytics capabilities is critical for the company’s continued success. We are seeking a Senior Data Engineer to help us define and execute an ambitious vision to provide trustworthy data across the organization. You will join as one of the team’s early members with an opportunity to design, build, and scale systems from the ground up.   Your responsibilities will include:  Partnering with stakeholders across product, engineering, data science, finance, sales, and marketing to define data needs of the business, build data acquisition strategies, data pipelines, and reporting infrastructure to empower the organization to make better-informed strategic, product and growth decisions  Designing and maintaining data models across the organization and formulating a strategy for appropriate data integration  Leading the development, orchestration, monitoring, and maintenance of ETL data pipeline infrastructure Continuing to improve the performance and reliability of our data warehouse  Partner with data scientists and data analysts to establish data assets and feature stores for process automation, advanced analytics and machine learning  Manage the company’s business intelligence infrastructure   Requirements: Bachelor’s and/or Master’s degree in Computer Science, Engineering or related field  5+ years of relevant experience, including managing data infrastructure and building ELT processes  Experience designing and deploying high-performance systems with reliable monitoring and logging practices  Hands-on experience with current engineering technologies and cloud infrastructure  Track record working with cross-functional teams to establish overarching data architecture and provide guidance on best practices Able to have both in-depth technical discussions with other engineers and explain concepts to a non-technical audience  Enjoys mentoring other engineers  ﻿Benefits list:Medical, dental, vision, and supplemental insuranceFree 'Employee Only' healthcare coverage401k planUnlimited vacationPaid holidays, sick time, and volunteer opportunitiesDiscounted hotel ratesPaid parental leaveCraft brews and ciders on tapCompany-sponsored social events and happy hoursFree organic fruit, snacks, and beveragesRelaxed office and dress codeFree on-site parking and bicycle storageUnmatched views of the Rocky Mountains",Intermedio,Jornada completa,"Tecnología de la información, Ingeniería","Interconexión en red, Software",7,None,True,,45,ACTIVELY_HIRING_COMPANY
690,2257943691,2020-11-08,Propel,Machine Learning Engineer - MedTech $70 million in funding,United Kingdom,"Do you want to work in an extremely well funded HealthTech business that is changing the way the clinicians diagnose serious illnesses using cutting edge AI and Machine Learning? Do you want to take a product from inception to release for a business with over $70 Million Dollars in funding? Do you want to work in a remote first team with other high quality entrepreneurial individuals? If so apply to this Machine Learning Engineer Role Engineering Role today. This is an extraordinary opportunity to be part of a high-performing team and to pursue a life-changing mission with unique technical challenges! As a Python Engineer you will: Drive development of machine learning tooling and infrastructure to improve the scale and efficiency of machine learning development.Identify and evaluate new patterns and technologies to improve performance, maintainability and traceability of our machine learning systems.Work closely with scientists as well as engineers to support planning, developing, training and testing machine learning models for the purposes of computational pathology while leveraging and championing software engineering best practices.Participate in driving the whole product development life cycle from high uncertainty research and experimentation to deployment in production and maintenance.Mentor engineers to foster a culture of technical excellence. About you - Extensive experience working in a team implementing and evaluating deep neural networks, especially for computer vision tasks. Extensive experience in Python development.Experience collaborating with teams or people who are implementing and evaluating deep neural networks, especially for computer vision tasksExtensive experience with machine learning development tooling.Extensive experience with modern product development practices, including software testing (e.g. unit testing, regression testing). Extensive experience with Agile development methodologies.Experience with parallelization, threading and concurrency problems.Experience with design patterns, algorithms and data structures.Experience with distributed systems. Apply today or email jake.kings@propellondon.com",Intermedio,Jornada completa,"Tecnología de la información, Ciencias",Dotación y selección de personal,7,None,True,jake.kings@propellondon.com,47,JOB_SEEKER_QUALIFIED
691,2278565794,2020-10-11,LAAgencia,Data Scientist (Remote),"Mexico City, MX","Hello!  ¡We are looking for a Data Scientist to work remotely in Mexico City!  Our Team  Our expectations are pretty high for Data Scientist positions. The Data Science team plays a leading role in solving our most challenging problems and guiding the decisions that we take around product.  Impact  Build, implement, and maintain machine learning systems in technology products. Lead engineering best practices for scaling ML and designing/building software that is reliable, scalable, and secure  Be responsible for the implementation, testing, and release of a range of models, both for existing and “to-be-invented” use cases  Work closely with Machine Learning scientists to design, code, train, test, deploy, iterate and own state-of-the-art systems for executing ML models  Building end-to-end data pipelines to train, maintain, and track performance of our Machine Learning and Operations Research products  Requerements 2+ years as Data Scientist  Advanced english  Python, R, SQL   Benefits  Negotiable salary 100% remote",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Software, Internet",2,None,False,,40,JOB_SEEKER_QUALIFIED
692,2249593717,2020-10-28,"HireStarter, Inc.",Senior Data Engineer - Healthcare,"Nashville, Tennessee, United States","Ideally based in Austin or Nashville, but open to remote. No C2C. Unable to sponsor or transfer visas. As a Data Engineer, you will be working on projects that help bridge the gap between the engineering and analytics teams. As a member of the team, you will be expected to share knowledge, relentlessly problem solve, have a superior work ethic and be an excellent communicator in an easy-going environment.  Responsibilities:• Design and implement ingestion pipelines to handle and transform large amounts of structured and semi-structured data from a multitude of sources.• Write, optimize, and automate data processing tasks.• Design monitoring around ingestion and processing tasks and develop runbooks in case of an outage.• Build systems with reusability and scalability in mind• Collaborate with the technology and analytics teams on developing new conventions and processes.• Optimize our search engine and help build relevancy models around results Requirements:• 3+ years of experience with Python• Experience with PostgreSQL, or a similar RBDMS• Experience with Elasticsearch• Familiarity with a cloud provider, e.g. AWS, GCP, Azure (We use Azure)• Knowledge of design patterns and software engineering best practices. Bonus!• Experience with Airflow or Luigi• Experience with R• Experience building RESTful APIs for serving processed data• Experience with Databricks",Intermedio,Jornada completa,Tecnología de la información,Software,30,None,True,,133,JOB_SEEKER_QUALIFIED
693,2219325038,2020-10-27,Prospect 33,Senior Data Engineer,"Philadelphia, Pennsylvania, United States","Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? Most importantly, do you love experimenting with new technologies and increasing your knowledge of the data space? We are looking for a seasoned data engineer who can work with a leading hedge fund in Philadelphia. They are looking for a Data Engineer that will build new pipelines and coordinate different tools to seamlessly integrate disparate data sources into a repository that can efficiently feed data to their analysts and drive alpha.  Remote work until the end of the virus then location in central Philidelphia. What you will do:Lead a small team responsible for providing best in class data services to multiple internal stakeholders including Investment and Quantitative Research, Investment Analysis, and TechnologyBuild large-scale batch and real-time data pipelines for alternative dataIntegration of alternative data with traditional data sourcesDefine the roadmap and drive executionDrive the data practice to continuously become more efficientShare your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community Qualifications/RequirementsExperience consuming bespoke data sets with no control over the format of the dataExcellent knowledge of tooling in the data space and the ability to hone in on the right stack for the problemDemonstrated experience in large dataset design and modelingDemonstrated expertise in data engineering, including but not limited to data platforms, ETL process engineering, data quality monitoring, and machine-assisted data discoveryFamiliarity with NoSQL technologies, such as key/value store, columnar store, document store, etc.Well-versed in the features of popular Big Data solutions, including cloud-hosted platformsExperience with data visualization tools such as TableauProficiency in a diverse set of programming languages, such as C# (.NET) and PythonExperience working with Redshift and SQL ServerWorking knowledge of Docker and KubernetesEffectively manage expectationsAbility to mentor junior data engineersMinimum Bachelor’s degree in Computer Science or Computer Engineering",Intermedio,Jornada completa,"Consultoría, Ingeniería, Tecnología de la información","Servicios financieros, Banca de inversiones",12,None,False,,116,ACTIVELY_HIRING_COMPANY
694,2280005986,2020-11-05,"Codeworks, Inc.",Senior Data Engineer,"Milwaukee, Wisconsin, United States","Sr. Data Engineer This is a 12 month W2 contract, remote to start with onsite work required later in 2021 in Milwaukee, Wisconsin(after Covid) We are working with a direct client in Milwaukee, Wisconsin looking for a Sr. Data Engineer to join a group providing BI and Analytic solutions for Senior and Executive Leadership within IT. In addition, they provide data solutions and guidance to empower self-service BI Developers and Analysts across all IT functions. This role will help shape and drive the data warehouse/lake for BI and Analytic solutions built by their team as well as the data solution behind the self-service function for their community of BI Developers and Analysts.   Responsibilities Design, build and support data pipelines to facilitate BI and Analytic solutions among the ETL teamSupport establishing a self-service BI data environment including data sourcing, modeling and distribution for consumption by BI Developers Accountable for ensuring data within the store meets quality and security requirements Build consensus and trust with partnered organizations on future state patterns Drive the sharing of standards on our team and the greater community through coaching, mentoring and articles around core methodologies and processesBuild reports/dashboards for consumption within the team using BI tooling: such as Tableau or Power BICollecting data systematically and consider a broad range of issues or factors to promote sustainability of the datasetQualifications Bachelor’s Degree in Computer Science, MIS or direct experience 5-8 years of professional experience in dataStrong SQL background including writing and solving complexity within SQL code and performance tuningWorking with a range of data sources: Traditional DBMS (MS SQL, IBM DB2, etc.) No SQL DBMS (Mongo), Flat Files (CSV, XLS, etc.), Web (XML, JSON, etc.)Knowledge of pipeline/ETL development standard methodologies for batch and near real-time integrationsExperience with pipeline/ETL tooling such as SSIS, Azure Data Factory, AWS Glue, PowerBI Dataflows, Informatica Data Integration, etc. Grasp of APIs (SOAP and REST)Solid grasp of summarizing technical solutions into concise and meaningful proposalsEmbraces continuous learning, curiosity, experimentation and ambiguityStrong customer/client orientationExecute alone but is a collaborative teammate",Intermedio,Contrato por obra,Tecnología de la información,Servicios y tecnologías de la información,18,None,True,,91,ACTIVELY_HIRING_COMPANY
695,2210713411,2020-11-06,RED SKY Consulting,Data Engineer,"Chicago, Illinois, United States","Job Title: Data EngineerLocation: RemoteJob Type: Direct Hire (Full-Time) Bottom Line / In a Nutshell: 4+ years of experience in Data Platform Administration/Engineering, Hands on experience with AWS based solutions such as EMR, S3, RDS, Lambda, Dynamodb, Redshift, EC2., Experience and tools/frameworks within the big Data ecosystem, Experienced in Agile methodologies.Proficiency in one of the scripting languages such as Shell/Python/Scala/Java.Good understanding of Big Data technology trends, with knowledge of technologies such as Kinesis, Kafka, Spark, Hive, pySpark.Experience in version control systems such as Git, GitLab, etc.Ability to work in a fast-paced, rapidly changing environment. 1+ years of experience using Cloud technologies and AWS Cloud Services certificationExperience with Analytical/Reporting Solutions like Alteryx, Tableau, PowerBIOverall:Understands best practices in software engineering, data management, data storage, data compute, and distributed systemsApply cloud-based AWS services to solve challenging problems around: big data processing, data warehouse design, and BI self-serviceFocuses on automation and optimization for all areas of DW/ETL maintenance and deploymentComfortable with a degree of ambiguity and willing to develop quick proof of concepts, iterate and improve. Comfortable presenting findings to leadershipDesign, develop, and operate highly-scalable, high-performance, low-cost, and accurate data pipelines in distributed data processing platforms with AWS/cloud technologiesAdopt next-generation data architecture strategies, proposing both data flows and storage solutionsCollaborate with Engineers and Scientists in the organization to construct complex data sources for algorithms and machine learning modelsBuild, analyze and present actionable data to drive marketing business development and product management decisionsKeep up to date with big data technologies, evaluate and make decisions around the use of new or existing software products to design the data architectureCollaborate with Business Intelligence Engineers to recognize and help adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentationQualifications:4+ years of experience with and detailed knowledge of data warehouse technical architectures, data modeling, infrastructure components, ETL/ ELT, reporting/analytic tools and extracting value from large datasetsExperience with Big Data technologies e.g. Hadoop, Hive, Oozie, Presto, Hue, Spark, Scala and solutions in AWS/AzureProficiency in Python or other similar languagesStrong understanding of scaling, performance and scheduling, batch and streaming data architectureKnowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operationsExperience on data platform re-architecture projects or handling operational excellence in DW via automationExperience communicating with management as well as with colleagues from engineering, analytics, and business backgroundsStrong technical and analytical aptitude: Excellent oral and written communication skillsEducation:Bachelor's degree in computer science, engineering, mathematics, or a related technical discipline",Intermedio,Jornada completa,"Finanzas, Ventas",Servicios y tecnologías de la información,94,None,True,,347,ACTIVELY_HIRING_COMPANY
696,2203390838,2020-10-23,Horizontal Talent,Data Engineer,"Madison, NJ, US","Experience/Qualifications  5+ years of of experience working in the BI/Data space Good understanding and experience in the core AWS Cloud services. Strong Technical hands-on experience in programming languages - Python/Scala, Spark, Lambda, JavaScript Experience planning, designing, developing and documenting migration plans from on-premise to cloud. Migrate complex data processing from SQL Server to Snowflake using Spark, Python/Scala , AWS Glue, and Snowpipe. Experience in using GIT/AWS code repository. Experience/Knowledge in Cloud data warehouse solutions like Snowflake, Redshift , etc. Ability to develop ETL pipelines in and out of data warehouse using combination of AWS tools/Python(or Scala) and Snowflakes SnowSQL/JavaScript stored procedures  ,",Sin experiencia,Jornada completa,Tecnología de la información,"Marketing y publicidad, Servicios y tecnologías de la información, Software",127,None,True,,422,ACTIVELY_HIRING_COMPANY
697,2271868055,2020-11-03,"Pinnacle Group, Inc.",Data Engineer,"Dallas, Texas, United States","The ideal candidate will be a self-motivated individual with experience in both Oracle and AWS tools for on-prem and cloud-based development. You will be an important member of the team tasked with transforming a traditional enterprise data architecture into a next-generation cloud-based streaming platform in a fun, challenging, fast paced work environment. Required:3+ years of experience working with a variety of ETL tools and monitoring of real-time ETL and batch ETL processesExperience with a scripting or programming language (R, Ruby, Python, Java, etc.)Oracle Database, AWS Redshift/Postgres experience, MySQL a plusExperience building self-service reporting solutions using business intelligence software (e.g., OBIEE, Tableau Server, MicroStrategy, etc.)Ability to maintain documentation on ETL process and proceduresDemonstrated proficiency developing and supporting extract, transform, and load (ETL) processesExperience conducting project-specific data analysis that includes analyzing and mapping required data and supporting all facets of the ETL processAbility to assist with the creation and maintenance of ETL specifications (e.g., source-to-target maps)Ability to develop, test, and maintain the code required to move dataAbility to participate in production on-call support rotation schedule for ETL processing and completionAbility to assist with estimates for the ETL process and suggest improvements Preferred:Bachelor's degree in Computer Science, Computer Information Systems, Management Information Systems, or related field preferred3+ years in an ETL development role utilizing an industry-recognized ETL tool3+ years of developing and supporting a data warehouseStrong knowledge and experience with SQL programming, including stored procedures, triggers, functions, and error trappingPrior experience extending or migrating existing data pipelines to cloud platforms such as AWSExperience with AWS services, specifically lambda functions, Data pipeline and Glue is a strong advantageExperience with Oracle Data Integrator also a strong advantage",Intermedio,Jornada completa,Tecnología de la información,Servicios y tecnologías de la información,133,None,True,,326,ACTIVELY_HIRING_COMPANY
698,2231443085,2020-10-23,Whitehat Analytics Limited,Senior Data Engineer,United Kingdom,"ABOUT WHITEHAT ANALYTICS Whitehat Analytics is a boutique data science consultancy specialising in providing expertise in technology-driven business transformation and advanced analytics R&D to solve our client’s most complex business problems, principally in the life sciences, retail/consumer, public sector and financial industries. We pride ourselves on the quality of technical and science talent we have. We value our developers as people as well as employees. We also offer a very attractive benefits package including 24 days annual leave, private health care, dental treatment, discounted gym membership & private pension. We are an equal opportunities employer and value diversity. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. POSITION OVERVIEW We are expanding our team and are looking for a highly motivated Senior Data Engineer, with multiple years’ experience in developing ETL pipelines in Python or Java/Scala. Most of our work is onsite with one of our clients in London or Southeast England, with travel to other parts of the UK as necessary. The company will cover any travel and accommodation costs. With the current situation involving Covid-19, this role may start as remote before moving on to client sites. KEY RESPONSIBILITIES · ETL Developmento   Work closely with colleagues in a cross-functional data science team to develop analytical software products, with efficient communication.o   Drive the development of software development best practice within the team and mentor more junior members of the team.o   Initiate, and contribute to, a team mentality of high professional standards and continuous process improvement.o   Continuous Professional Development with new technology. · Client Relationshipso   Troubleshooting and implementing enhancements to systems as needed.o   Presenting and depicting the rationale of findings in simple, engaging and easy to understand business terms to a diverse group of stakeholders. EXPERIENCE & TECHNICAL SKILLS﻿· Core Technicalo   In-depth knowledge of low latency, high throughput programming in Python, Java or Scala.o   In-depth knowledge of at least one SQL dialect (preferably Postgres or MySQL).o   Building parallelised algorithms for large (multi-TB) unstructured datasets in distributed architectures (e.g. text, image, video, audio, log and sensor data).o   Working with diverse data formats in differing use cases (e.g. xsv, json, Avro, rc, orc, parquet)o   Hadoop/Spark frameworks (especially Spark, Hive, Presto, Impala and Drill, preferably in EMR, CDH, MapR or HDP distributions) and other big data technologies.o   NoSQL and MPP databases (e.g. Teradata, HBase, MongoDB, Neo4j, DynamoDB and others) · Preferred Technicalo   Understanding of data science workflows and the ability to build models for supervised and unsupervised learning.o   Search tools (e.g. Lucene/Elasticsearch)o   Streaming data and related tools (e. g. Flume, Nifi, Kafka, Storm)o   Working in cloud environments (e.g. AWS, GCP, Azure). Some experience with test driven development.o   Proven track record of working in computationally intensive environments.o   Exposure to the DevOps toolchain and CD/CD best practices.o   Good working understanding of systems, SCM and virtualisation (e. g. Docker, Git, Linux/bash)o   Data visualisation – creating KPI dashboards and using BI tools (e.g., Tableau, PowerBI, Qlik, Pentaho, D3 and related libraries)o   Front end and API development (e.g. Flask, Django, Tkinter, Swing, AWT) · Project & Non-technicalo   Project ownership and team leadership – responsible for key aspects of projects, including identifying user needs, prioritising tasks and determining tools, data and techniques to address them in an Agile way.o   Developing business cases for stakeholders.o   Mentoring junior data engineers via the creation of personal development plans, encouraging team-wide diffusion of knowledge and being a source of analytical best practiceo   Knowledge of software development processes including object-oriented programming, rapid prototyping and agile development techniques.o   Presenting on technical topics to a wide variety of stakeholders and co-workers APPLICATION To apply, please submit your CV and cover letter care of Human Resources to jobs@whitehatanalytics.com with the subject line: Lastname, First name - Job ID: 000_103 by the closing date of 24 November 2020. We look forward to hearing from you.",Intermedio,Jornada completa,Tecnología de la información,Servicios y tecnologías de la información,62,None,True,jobs@whitehatanalytics.com,172,None
699,2232833885,2020-11-02,Cognizant,Data Engineer (Python/AWS),"Plano, TX, US","Cognizant is looking for Data Engineer/Developer to join our Artificial Intelligence and Analytics practice (AIA) for a remote project. As a trusted advisor, responsible for providing an approach for the overall project. As a domain specialist, you will drive technology discussions and analyze the existing gaps in addressing business needs. You are a thought leader-comfortable challenging the status quo to enhance our current services and technologies.  About AI & Analytics: Artificial Intelligence (AI) and the data it collects and analyzes will soon sit at the core of all intelligent, human-centric businesses. By decoding customer needs, preferences, and behaviors, our clients can understand exactly what services, products, and experiences their consumers need. Within AI & Analytics, we work to design the future—a future in which trial-and-error business decisions have been replaced by informed choices and data-supported strategies.  By applying AI and data science, we help leading companies to prototype, refine, validate, and scale their AI and analytics products and delivery models. Cognizant’s AIA practice takes insights that are buried in data and provides businesses a clear way to transform how they source, interpret, and consume their information. Our clients need flexible data structures and a streamlined data architecture that quickly turns data resources into informative, meaningful intelligence.  Cognizant Technology Solutions will not be able to provide sponsorship for this role now or in the future.  Responsibilities Create and maintain optimal data pipeline architecture, assemble large, sophisticated data sets that meet functional / non-functional business requirementsIdentify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘Big Data’ technologiesBuild analytics tools that utilize the data pipeline to deliver impactful insights into customer acquisition, operational efficiency, and other key business performance metricsWork with partners including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needsCreate data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader  Qualifications 5+ years of experience in a Data Engineer role, who has attained a Bachelor’s degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field3+ years of experience of Python programming experience with object-oriented/object function scripting languages (Scala is plus)3+ years of experience with Big Data tools: Hadoop, Apache Spark, Kafka, etc.1+ years of experience with AWS cloud services: S3, EC2, EMR, RDS, Redshift 1+ years of experience with relational SQL, Snowflake and NoSQL databases, including Postgres and CassandraExperience with stream-processing systems: Storm, Spark-Streaming, etc. (nice to have)   Why Choose Cognizant?   It takes a lot to succeed in today’s fast-paced market, and Cognizant Technology Solutions has become a leader in the industry. We love big ideas and even bigger dreams! We stand out because we put human experiences at the core. Our associates enjoy robust benefits and training opportunities from our industry recognized, award winning Academy team. You will have access to hundreds of technical training to keep your skill sets fresh and have opportunities to acquire certifications on the latest technologies.  Everything we do at Cognizant we do with passion—for our clients, our communities, and our organization. It’s the defining attribute that we look for in our people.  If you love ambiguity, excited by change, and excel through autonomy, we’d love to hear from you!  www.cognizant.com  IND123  Employee Status : Full Time Employee  Shift : Day Job  Travel : No  Job Posting : Nov 05 2020  About Cognizant  Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 194 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @USJobsCognizant.  Cognizant is recognized as a Military Friendly Employer and is a coalition member of the Veteran Jobs Mission. Our Cognizant Veterans Network assists Veterans in building and growing a career at Cognizant that allows them to leverage the leadership, loyalty, integrity, and commitment to excellence instilled in them through participation in military service.  Cognizant is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law.  If you have a disability that requires a reasonable accommodation to search for a job opening or submit an application, please email CareersNA2@cognizant.com with your request and contact information.",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Consultoría de estrategia y operaciones",41,None,False,CareersNA2@cognizant.com,394,COMPANY_RECRUIT
700,2275833553,2020-10-10,DataKind,Technical Lead,"Brooklyn, NY, US","DataKind is looking for a Technical Lead!  Location  This is ideally an onsite opportunity located in our Brooklyn, NY headquarters: however, we'd be open to a remote location for the right candidate as long as most of the workday overlaps with Eastern Standard Time. (Note that our Brooklyn office is currently closed through at least December 2020 due to the COVID-19 pandemic and we're offering flexible scheduling to staff as they manage life demands like childcare alongside their jobs.)  About DataKind  DataKind is a global nonprofit dedicated to harnessing the power of data science and artificial intelligence (AI) in the service of humanity. Named one of Fast Company's 2017 top 10 innovative nonprofits, DataKind teams talented pro bono experts from academia and industry with visionary changemakers to collaboratively design innovative solutions to tough social challenges. We help social organizations apply their data to predictive analytics, machine learning algorithms, and AI needs in a way that both increases impact and prioritizes ethics.  We are 20,000 strong: DataKind volunteers hail from almost every country across the world, representing a community of technologists and social change makers who believe in using data science and AI for a stronger planet and a more just and prosperous world. We have served 300+ projects around the world: From using satellite imagery to measure crop yields to automating the fight against hate speech online, our volunteer community has shown up to support a range of humanitarian needs around the world. Through this approach, illustrating what we call 'the art of the possible,' these projects have resulted in more effective NGOs, more funding for social change organizations, and more awareness of the power (and pitfalls) of data science and AI in the social sector.  People are at the center of our process: The most advanced machine learning algorithms are useless if they're not designed for real people's problems. DataKind celebrates human centered design principles that focus on the 'why,' the 'for whom,' and the 'should we' long before we ever get going on the 'what.' 'AI for Good' will only succeed if it's 'AI for All': We will continue our work until all people and all communities can use digital technology for the outcomes they want to see. We support not just the tech communities of today, but anyone in any community who wants to lead in how data technologies serve their needs fairly, with an emphasis on including individuals from groups that are historically underrepresented in technology or will be impacted by the intervention.   The Next Phase  DataKind has always known that we will not be able to combat all of the world's looming challenges on the backs of individual, short-term projects alone. Thanks to generous, long-term support from The Rockefeller Foundation and the Mastercard Center for Inclusive Growth, we are now focusing the DataKind network on issue areas, such as improving health outcomes through Frontline Health Systems as well as increasing economic resilience. Over a period of five years, DataKind has been granted $20M to make this vision a reality, and we are looking for people to join us in this journey. You can read more about the new strategy here.  About The Opportunity  DataKind's success ultimately comes down to the quality, timeliness, and effectiveness of our volunteer data science projects. Our Technical Lead will be responsible for overseeing a portfolio of volunteer-led projects using cutting-edge technology to help high-performing organizations worldwide make an even greater impact. In this highly visible and high impact role, you'll manage a set of long-term DataCorps projects from start to finish, staffing teams of talented pro bono data scientists with the right skills to get the work done, and building strong relationships with our nonprofit partners, ensuring everyone has a great experience in the process. We anticipate this person to spend roughly 60% of their time on project support (project management, scoping, and other activities that support others in performing data science work) and 40% on executing data science work oneself.  The Technical Lead will report to the Senior Data Scientist and will work closely with other staff, pro bono data scientists and our Community and Network team.  What You'll Do  The Technical Lead will be responsible for the following in addition to any other project assigned by the manager:  Manage a variety of projects in DataKind's flagship program, the DataCorps.  Scope potential projects, contributing to scope statements and developing project plans. Write and oversee project briefs for DataCorps project portfolio and managing scope creep.  Prepare projects for a seamless launch with volunteers and non-profit project partners, including but not limited to coordinating contracts with and collecting data from our partners, as well as making sure that tech and communications systems are in place for teams. Vet and select a diverse group of volunteers for project teams, with an eye towards individual qualifications and overall team composition. Plan and execute project kick-off meetings, overseeing client and volunteer check-ins and end of phase presentations. Consistently communicate and manage expectations of partner organizations and volunteers throughout the entire project lifecycle. Ensure the technical quality of volunteer-led DataCorps projects. Ensure volunteers have a great experience on our projects, celebrating their efforts and work throughout the project. Be willing to work a flexible schedule to meet on some nights or weekends with your volunteer teams or to run DataKind events.  Create data science for social good   Conceive of creative, and appropriate, applications of data science to amplify the impact of our project partners (i.e. turning a vague business challenge into a crisp data problem.) Conduct data audits where you will dive into complicated, messy datasets and verify that the data supports the technical solution being pursued. Prototype and document data science solutions for project partners in the initial scoping process. Own a small portfolio of internal data science projects from start to finish, being able and ready to step in on projects as needed to provide support. Stay up-to-date with emerging data science solutions. Monitor quality of DataCorps project output, both in terms of algorithmic and statistical output as well as code quality and best practices. Set up cloud infrastructure for volunteer teams.  Be a key cross-functional collaborator  Collaborate with the Business Development team to document project and portfolio successes, contribute to all grant reporting, and keep funding partners aware of project outcomes.  Share insights and feedback with the Director of Global Volunteers to identify top volunteers for projects and subsequently recognize their efforts. Work closely with the Communications team to amplify and celebrate the work of the DataKind community.  Contribute learnings to the Product team so we can update our process and our product and continuously improve.    How You'll Be Measured  At the end of year one, the Technical Lead will have accomplished the following:  Led scoping on 5-10 projects through to the completion of a Project Brief and successfully co-managed 3-5 DataCorps projects from recruitment to handoff. Expertly applied your data science skills to at least three data science projects - either ones you have owned completely or through technical support provided to volunteer teams.  Fostered strong relationships with external partners that have led to at least three collaborators expressing interest in continued DataKind engagement. Prepared DataKind project outputs for professional presentation and delivered technically sound, community invigorating presentations at both internal and external venues. Successfully completed and documented all phases of active project activities through the DataKind Project Playbook.   Qualifications  At least 3 years of work experience, preferably including experience in a nonprofit or start-up context. Fluency in data science technology stack including R/Python, SQL, Postgres, AWS, and their brethren.  Deep experience in machine learning/AI with confidence in applying, tuning and evaluating a wide variety of AI algorithms, from logistic regression and random forests to deep learning. Comfort and skill in communicating highly technical information to semi- and non-technical audiences. Proven track record of successfully managing full lifecycle tech/AI projects. Experience managing technical teams and deliverables in the volunteer, non-profit or tech spaces (or perhaps all three.)  Comfort and skill in translating a problem into technical requirements and ability to recognize when a solution might be an algorithm, a database, an application, a retrospective analysis, or none of the above. Ability to motivate people to collaborate towards a shared goal, to keep them engaged throughout the process, and to intervene as needed to make sure balls don't get dropped.  Demonstrated customer service orientation that will allow you to represent DataKind well to our volunteers and partners alike.   Why Work with DataKind  At DataKind, we believe that people are the most important asset to delivering on their mission to collaboratively design data-driven, innovative solutions to tough social challenges. Working with us means that you will have:  Flexibility in your working schedule. This includes things like working from home, leaving early to care for kids, coming in late to walk your dog, etc. This also means that you have unlimited PTO. Access to an outstanding health plan. We pay 100% of medical, vision, and dental benefits for employees and contribute partially for spouse and dependent coverage. Support to plan for your future. We offer a 401(k) match up to 5%. Opportunities to learn and grow. Each year, we budget for each staff person to have ongoing professional development support.  DataKind is an Equal Opportunity Employer  Naturally, DataKind is an equal opportunity employer and strongly encourages candidates from underrepresented groups in tech to apply. DataKind does not discriminate on the basis of race, color, gender, disability, religion, national origin, age, sexual orientation, genetic information, pregnancy, or any other protected category.   Applicants must be currently authorized to work in the United States.",Algo de responsabilidad,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Gestión de organizaciones sin ánimo de lucro, Software",2,None,False,,30,None
701,2275990979,2020-11-04,deepwatch,Data Scientist (remote),"Denver, CO, US","Description  Who We Are  deepwatch is redefining cybersecurity and is one of the fastest growing companies in the U.S. (Top 50 based on last year’s Inc5000). deepwatch serves an impressive list of Fortune 50 and Global 2000 companies as well as numerous mid-sized enterprises. We’ve established strategic partnerships with leading security vendors and serve as a trusted advisor to our customers. Our Core Values drive all aspects of the business and have been paramount to the company’s success and foster our dynamic, entrepreneurial workplace. At deepwatch, your colleagues are some of the most technically astute minds in cybersecurity, who are passionate, knowledgeable, and willing to provide mentorship and guidance at every opportunity.  deepwatch's innovative cloud SecOps platform and borderless SOC delivers data-driven managed security services while extending customers’ cybersecurity teams and proactively protecting their brand, reputation and digital assets. deepwatch's powerful analytics platform, led by 200+ experts, analyzes billions of events each month and is trusted by hundreds of leading global organizations to provide 24/7/365 managed security services. We have some of the coolest, most innovative IP in the industry and we’re rapidly expanding that.  If you have the passion, work ethic, winning attitude and competitive mindset to be at the forefront of the best entrepreneurial MSSP|MDR in the U.S., we want you on our team.  deepwatch Offers A highly collaborative environment with very bright minds and inquisitive thinkingAwesome benefits - we pay a significant portion of our employees’ medical and dental premiums (100% for the HDHP plan) and a very generous portion for dependentsFSA (medical and dependent) and HSA with employer contributionCompany paid Life Insurance, Short Term Disability and Long Term Disability401k retirement plan with employer matchPaid Time Off (PTO)10 Company HolidaysPaid time off for votingAs a fully remote company, we offer the responsible balancing of your time between work & lifeAll employees are paid a generous mobile phone and home internet allowanceApple productsAttractive referral bonus programCareer paths and the opportunity to do cool and different things as our growth continuesSignificant annual allowance per employee for Professional Development  Data Scientist  The mission of the deepwatch Security Research team is to tease from massive data sets security outcomes that provide actionable security details to customers. Data Scientists at deepwatch will analyze terabytes of data with the objective of squeezing out as much security value for our customers as possible. deepwatch will use the techniques developed by the Data Science team to automate delivering outcomes before our Analyst teams engage. We are seeking those who want to use their data science skills to help deepwatch identify threats in traditional digital threat vectors as well as cutting edge technology stacks such as Cloud Native (Azure, AWS, GCP), Internet of Things (IoT), and Serverless applications!  Responsibilities Solving difficult data problems while embracing cyber security challenges with open arms Gathering and processing data at scale, writing scripts and queries, and building and calling APIsVisualize threat signal data and uncover how bad actors use security vulnerabilities, malware, and patterns to spread across networks and drive analytic development to build libraries for persistent detection Drive the development of Machine Learning use cases to detect malicious activity in customer environments with regular content updatesProvide documentation to Threat Hunt, Research and Analyst teams around data analytics and mathematical decisions, with actionable workflows for threat investigation of ML alertsEnsure data quality and normalization throughout all stages of acquisition and processing Clean, analyze and select data to achieve goals that create desired security outcomes for deepwatch customers Build models that elevate the customer experience and track value of security outcomes for deepwatch customers over timeCollaborate with colleagues from Product, Delivery, Content, and Threat Hunting teams Present proposals and results in a clear manner backed by data and coupled with actionable conclusions that drive analytics, content libraries, and automation outcomes Work with engineers to develop efficient data analysis and data modeling infrastructure   Requirements  Required Experience, Skills and Knowledge Bachelor's Degree with an emphasis in Data Science or related field such as Mathematics or Computer Science2+ years-experience with various data analysis and visualization tools AWS/Azure/Google Cloud data engineering experienceProficiency in Python and other programming / scripting languagesExperience with various machine learning techniques and parameters that affect technique/model outputs and performanceDeep understanding of machine learning techniques and algorithms, such as Random Forests, Gradient Boosting, Ridge/Lasso, SVM, time series techniques et. al.Exceptional numerical and statistical ability, with excitement for applying analytics to client challenges and significant experience using analytic / database software and languages such as SAS, SQL, SPSS, R, Python, et. al.Experience with analytics programming languages (Python, Ruby, Shell) and automation tools (Ansible, Chef, Puppet etc.)Exemplified critical thinking and creative problem solving skills Competency with common data science toolkits, such as NumPy, pandas, sparkML, scikitLearn, et. al.Capable of leading and executing on data acquisition, cleansing, and storage for individual initiativesWilling to tackle big problems that have unknown solutions at the outsetStrong oral and written communication skills, including the ability to communicate effectively to non-technical audiences Team player with a passion for coaching colleagues and customers in the areas of data science   Preferred Experience, Skills And Knowledge Master's degree or PhD in relevant field(s) such as computer science, mathematics, or data scienceHistory of diving into data to discover hidden patterns and of conducting error/deviation analysisAbility to develop both experimental and analytical plans for data modeling processes, use of scaling baselines (trends)Strong ability to accurately determine cause and effect relationshipsUnderstands relevant statistical measures such as mathematical modeling, confidence intervals, significance of error measurements, development and evaluation data setsAn ability to work successfully across a globally distributed team and geographical boundaries to deliver joint initiatives   Equal Opportunity Employer  deepwatch is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability status, marital status, sexual orientation, gender identity, genetic information, protected veteran status, or any other characteristic protected by law. In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Software, Seguridad del ordenador y de las redes",77,None,False,,431,None
702,2275633821,2020-10-10,Cloudbeds,Data Engineer (Remote),"Dublin, IE","Cloudbeds is a travel SaaS technology company that works to make the world a more welcoming place. Heavily leveraging Amazon Web Services (AWS), we build advanced cloud-based hospitality software for hotels, hostels, vacation rentals, and groups that manages reservations and guests, distributes room availability, sells inventory, and collects payments. Our hundreds of team members are globally distributed across over 40 countries and, altogether, we speak 20+ languages. How do we do it? On a #remotefirst platform that allows every member of our team to work from wherever they are around the globe. We’re looking for people who want to disrupt the travel industry and love to travel as much as we do.  As a Data Engineer at Cloudbeds, you will implement our company-wide data strategy across all teams and departments to deliver a best in class data experience to our customers and partners in over 150 countries, as well as internally within Cloudbeds. You will work closely with our Business Intelligence, Reporting, and Infrastructure teams to progress and optimize our data lake architecture and drive the data transformation lifecycle to process terabytes of platform and industry data from multiple databases and origins in an automated and serverless fashion. The right candidate will be very experienced using Amazon Web Services (AWS) tools enabling data lake, warehousing, and processing capabilities. As a Data Engineer at Cloudbeds, you will have endless opportunities to innovate and drive the industry leading, comprehensive, and global data experience for travel.  Location: Europe (Remote)  What You Will Do:  Code ETL data transformations in PySpark/Spark.Design and manage processing pipelines via AWS Glue and/or EMR clusters.Manage ingestion and replication via DBMS from cloud MySQL databases.Process external sources like Salesforce via Appflow or kaggle datasets.Manage AWS Athena views and endpoints for consumption.Creation, modification, and maintenance of data infrastructure (Redshift [with Spectrum], S3 Parquet data, DBMS, Notebooks, etc.)Implement logging and debugging approaches in a standardized fashion.Collaborate with Business Intelligence, Analytics, and Infrastructure teams on a daily basis.Develop a framework for future extensions through standardized modern workflows. You’ll Succeed With:  Bachelor’s degree in computer science or related field, or equivalent experience.3+ years experience as a Data Engineer.2+ years experience working with Amazon Web Services.Expert knowledge and experience developing efficient ETL data pipelines having multiple sources using PySpark/Spark and DataFrames.Strong knowledge and experience developing workflows with AWS Glue, EMR, Redshift, Athena, and LakeFormation.Strong knowledge of modern data lake, data warehousing, and ETL/ELT concepts.Strong knowledge of how to compose and implement structural data models.Experience molding fresh environments into efficient mature data platforms.Experience with performance optimization for processing and storage via data partitioning and indexing techniques.Ability to take a consultative approach to data strategy.Ability to work in an Agile Scrum environment.Ability to thrive in a fast-paced environment.Ability to work remotely and manage your own time in an international team.Exceptional written and verbal communication in English.  Our company culture supports flexible working schedules with an open PTO policy and the opportunity to travel and work remotely with great people. To make it easy for our team to travel we offer 2 corporate apartment accommodations near our San Diego and Sao Paulo offices. At Cloudbeds we dedicated to your personal and professional development. You will have access to over 10,000 courses within LinkedIn Learning when you join our team for your unique individual growth! If you think you have the skills and passion, we’ll give you the support and opportunity to thrive in your career. If you would like to be considered for the role, we would love to hear from you!  Company Awards to Check Out!  Best Startup Employers in 2020 | ForbesBest Places to Work | HotelTechReport (2018, 2019, 2020)Deloitte’s North America Technology Fast 500 (2019)Inc. 500 Fastest Growing Companies (2018 & 2019) Inc. Best Places to Work (2017 & 2018) Best Places to Work | Inc Magazine (2017 & 2018)Start-Ups to Watch in 2018 | ForbesConnect MIP Award (Technology) Powered by JazzHR  z48q2jqj0k",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Internet",12,None,True,,87,ACTIVELY_HIRING_COMPANY
703,2184339602,2020-10-15,Dropbox,"Design Researcher, HelloSign - Location Flexible","Remote Lake, MN, US","Company Description Dropbox is now a Virtual First company, which means work outside of an office will be the primary experience for all employees. The location listed on the job description is simply so our jobs get picked up by job boards as they require a specific location. Being Virtual First means, location is flexible, so please feel free to apply to any position regardless of the location listed. Final location will be determined, by teams and individuals as the hiring process unfolds.    Dropbox is the world’s first smart workspace that helps people and teams focus on the work that matters. With more than 600 million registered users across 180 countries, we’re on a mission to design a more enlightened way of working. Dropbox is headquartered in San Francisco, CA, and has 12 offices around the world. Team Description Our Design team crafts delightful experiences that make people's lives easier. We're a close-knit, collaborative group, guided by a highly iterative user-centered design process. Combining research, data, and thoughtful critique, we're discovering needs and solving fundamental problems that impact work and life for millions of people around the world.  Role Description  The HelloSign Design team advocates for our users and our business, setting the vision for our growing family of products. We use data, research, strategy, and empathy to guide multidisciplinary teams toward a common goal, balancing diverse perspectives and empowering our teams to do great work. As we scale globally simplifying life for millions of people, there’s plenty of space for you to grow as part of a team always focused on we, not I, creating delightful products that are worthy of trust. This role will work on the HelloSign deep integration inside Dropbox , a very interesting first-of-its-kind integration. This role has potential for big impact and visibility. Responsibilities You will adapt research process and practices to the growing needs of the organizationYou will identify research needs in partnership with product teamsYou will design, plan, and resource user research projectsYou will communicate research insights in creative and effective ways among stakeholdersYou will advocate and guide strategy for design and product directionYou will facilitate and shape the design process Requirements 5+ years of UX-related work experienceBroad experience with a wide variety of research methods applied across the product development processDemonstrated skills for collaborating closely with other researchers, designers, product managers and engineersClear, compelling presentation and communication stylePrior B2B experienceExperience driving and supporting rapid research in a scrappy environment Benefits and Perks  100% company paid individual medical, dental, & vision insurance coverage401k + company matchMarket competitive total compensation packageFree Dropbox space for your friends and familyWellness ReimbursementGenerous vacation policy10 company paid holidaysVolunteer time offCompany sponsored tech talks (technology and other relevant professional topics) About HelloSign, A Dropbox Company: We believe that the way business gets done today is broken. That’s why we’re dedicated to simplifying work for everyone - from small startups to large enterprise companies. Millions of individuals and over 80,000 companies world-wide trust the HelloSign platform – which includes eSignature, digital workflow and eFax solutions – to automate and manage their most important business transactions. With a sharp focus on user experience and a lust for innovation, HelloSign is on a mission to Simplify Work. Life at HelloSign: Our HQ office is located in San Francisco Mission Bay near the UCSF Medical Center and we have a number of team members distributed across the US! Just over 150 employees, we are growing the company deliberately, with a keen eye towards maintaining a culture that values lifestyle, fun and continuous improvement. We were awarded the Hirepalooza Culture Award for Lifestyle in 2015 and the Healthy Mothers Workplace Bronze Award in 2016 and 2017. In 2018, we won SF Business Times' Best Places to Work Award for Small Employers. We continue to maintain an overwhelmingly positive presence on Glassdoor and The Muse. We have raving fans who love what we make We're user-focused and product-drivenWe're always evolving with an eye towards improvementWe're committed to building a product people wantWe thrive on collaboration and learning from each otherWe have a supportive, familial atmosphereWe work in an open, airy, creative spaceWe laugh a lotAnd we'll never forget your birthday!  Dropbox is an equal opportunity employer. We are a welcoming place for everyone, and we do our best to make sure all people feel supported and connected at work. A big part of that effort is our support for members and allies of internal groups like Asians at Dropbox, BlackDropboxers, Latinx, Pridebox (LGBTQ), Vets at Dropbox, Women at Dropbox, ATX Diversity (based in Austin, Texas) and the Dropbox Empowerment Network (based in Dublin, Ireland).",No corresponde,Jornada completa,"Ingeniería, Tecnología de la información","Software, Servicios y tecnologías de la información, Internet",53,None,False,,283,COMPANY_RECRUIT
704,2218573301,2020-10-19,Vertical Trail,Senior Big Data Engineer,"Chicago, Illinois, United States","Vertical Trail LLC is a rapidly growing, Chicago-based consultancy focused on delivering modern analytics, Big Data, and cloud solutions.  Vertical Trail is looking for a Senior Big Data Engineer to work closely with our dynamic project teams (both on-site and remotely). This Senior Big Data Engineer will be responsible for strategic planning and engineering big data and cloud environments and developing web-based applications to support business initiatives. This Consultant will evaluate functional and technical solution alternatives and recommend process improvements. Candidates need to be able to work for Vertical Trail as a W2 employee. Vertical Trail is not considering 3rd party or contract candidates for this role. Our Senior Big Data Engineer must have hands-on experience with:Big Data analytics platforms (Hadoop, Cloudera, Hortonworks, Databricks)Developing solutions within a Spark environmentCloud technologies (AWS, Azure, Google)CI/CD tools (Ansible, Kubernetes, Docker, Chef, Puppet, Git)Implementing complex solutions in large enterprise companies Our Senior Big Data Engineer will be responsible for:Ensuring integration components are cohesive and meet project requirementsSupporting capacity planning functions to ensure adequate infrastructure exists to support growthAssisting development team in coding, testing, implementation, and documentation of solutionsWork with web technologies (J2EE, Soap & REST Web Services, JSP, Servlets, EJB, JavaScript, Struts, Spring, WebWorks, Direct Web Remoting, HTML, XML,JMS, JSF, Ajax). Employment with Vertical Trail is an exciting opportunity that offers ample avenues for professional growth and development, as well as features including: Flexible Work EnvironmentInformed by client needs and optimal work / life balance, work locations for this role may include:Remote work from your home officeA dedicated Vertical Trail office in Schaumburg, ILCollaborative office space in downtown Chicago with plenty of perksClient sites (as needed) Attractive BenefitsComprehensive Health, Dental, and Vision insuranceEmployer-paid Life and Disability insurance401(k) / Retirement PlanProfessional Development Plan",Intermedio,Jornada completa,"Tecnología de la información, Consultoría, Ingeniería",Servicios y tecnologías de la información,25,None,True,,159,ACTIVELY_HIRING_COMPANY
705,2271874127,2020-11-06,Trust In SODA Ltd,Senior Data Engineer,"Boulder, Colorado, United States","Expert Data Software Engineer (Gaming) Our client is a world leading game developer, and they are currently hiring for a Big Data Engineer to join their softwanre engineering team in Boulder, Colorado. As a Big Data Software Engineer, in this role you would be building web data infrastructure and performing statistical analysis on in-game features. This role will work on a team developing the next generation of data-driven game experiences covering everything from the in-game economy to player personalization to game content recommendation systems.  Key Responsibilities: ·      Analyze massive data sets to optimize game engineering workflows ·      Collaborate with the team to deliver complex analytics to our portfolio of games with an easy-to-understand UI ·      Partner with game studios to identify and troubleshoot engineering bottlenecks ·      Develop web tools for extracting, analyzing, and presenting game data ·      Build and deploy back-end web architecture    Required Skills ·      Demonstrated proficiency with game and web scripting languages ·      Solid experience working with Big Data technologies (Spark, Presto, SQL) ·      Deep understanding of relational and non-relational databases (SQL, Postgres, Elasticsearch) ·      Experience working with virtualized/containerized environments (EC2, EKS, Docker) in a production environment ·      Experience mentoring other engineers ·      Flexibility and adaptability required ·      BA/BS degree in a technical field (computer science, math, physics)  Please apply for more details. We look forward to hearing from you",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Videojuegos,52,None,True,,183,ACTIVELY_HIRING_COMPANY
706,2246310656,2020-11-06,Catalyte,"Sr. Data Engineer (Sorry, No Visas or C2C Submissions)",United States,"Sr. Data Engineer  Position will be remote with occasional travel post-COVID Are you a Data Engineering enthusiast with a wide variety of experience across the data lifecycle and with multiple technology stacks? Do you love to organize data and figure out all of the ways it can be used? Do you enjoy mentoring junior and future engineers? We are looking for an innovative Senior Data Engineer to help us build the future. If you want to put your skills to use to help find and create future developers, come talk to us! You will be working with a variety of technologies and helping to design and build applications and tools with a data and analytics-driven focus. Responsibilities:·        Building data ingestion pipelines to ensure timely and quality data into our Data Lake·        Building and maintaining a dashboard solution and dashboards to enable self-serve business analysis·        Building tools and APIs to enhance Data Lake security with an eye to continuing our policy of keeping personal data completely secure using the most up-to-date guidelines·        Collaborating with our Data Science team on data and metrics·        Working with and evaluating existing data-centric applications and tools·        Automating data pipelines and ensuring that a robust CI/CD process is in place·        Working on Agile application teams to build high quality and modular back-end data structures ·        Mentoring more junior developers to allow them to grow their data career·        Working with stakeholders to help ensure that business needs are met Qualifications:·        At least 5 years working in a Data Developer, Engineer or Architect role with a broad focus on data movement, querying (SQL), analytics, storage and processing·        At least 3 years experience with Python·        Excellent skills in both RDBMS (SQL Server, PostgreSQL) and NoSQL technologies·        Exposure to data security regulation and enforcement - GDPR, HIPAA, etc·        Cloud experience is desired - AWS preferred·        Experience building pipelines in a modular, scalable way·        Strong analytical skills·        Curiosity about data and the ideal way to structure it to extract meaning from it·        A “can do” attitude and a passion for innovation Position will be remote with occasional travel post-COVID",Intermedio,Contrato por obra,"Ingeniería, Tecnología de la información",Servicios y tecnologías de la información,18,None,True,,115,ACTIVELY_HIRING_COMPANY
707,2291242858,2020-10-14,Signavio,Senior Data Engineer (m/f/d),"Berlin, DE","Data driven decisions. Data informed management. 'Data' and all related efforts around it has moved from being 'another buzzword' into becoming an essential part of the most successful corporations.  Signavio's data insights team aims to provide reliable quality data, tools and services to stakeholders both from inside the engineering department as well as from the outside (e.g. C Suite), enabling them to better understand our users, products & processes. This is a cornerstone to track the progress on our goals, to shed light on business relevant information, to discover areas that need improvement, and to enable data driven decision making throughout the whole organisation.  The human side  This team has interesting challenges ahead (some of them are listed in the responsibilities section below) and therefore collaboration is a key attribute for anyone wanting to join it. We're in this for the long run and we know that together we can go further. That's why empathy and good communication skills are essential. Healthy interpersonal relationships are a must. Being truly inclusive and respectful allows us to deliver on the expectations, manage them, and… most of the time to have fun while doing it.  Description Of Some Of Your Responsibilities  Shape and co-create a robust, scalable data platform, enabling deep business insights  Design and implement near-time and batch data transformation pipelines Ensure high data quality while keeping maintenance efforts low Define new and extend existing data models, matching business and the user's needs Partner with engineers, data scientists, and business analysts Be a sparring partner for other data engineers   Requirements  Deep knowledge of data modeling and data processing (ETL/ELT) and related technologies and concepts Proven experience in designing and implementing a cloud based data platform architecture In-depth knowledge of relational/SQL DBMS technology, being able to describe internal data structures and algorithms for query processing and optimizations, at best for PostgreSQL and MySQL Comfortable using NoSQL databases, e.g. for XML & JSON documents, key-values or graphs Significant hands-on experience with relevant technologies, such as AWS Analytics, Apache Spark & AirFlow Up to date - and regularly applied - software development skills, e.g. Java or Python Keen on modern DevOps and DataOps principles such as automated testing, infrastructure as code and automate everything  What we offer:   We keep things open, agile and communicative. It is all based on trust, no micromanaging.  The whole department is located together in one office in beautiful Berlin, however due to the current situation we work and onboard 100% remotely to keep our employees safe.  Our team members are self-organized within their teams, working on independent projects or closely with Product Leads, developers and UX designers. We value your thoughts and ideas and will give you the freedom to push and implement them!  We offer competitive salaries and support personal growth, including functional in-house coaching.  You will gain – and share – knowledge during recurring learning groups, jours fixes and our annual code camp.  You are free to use the OS of your choice, the tooling you are comfortable with and set up your workspace the way you like it.  We get that balancing a family and work can be a challenge, so everyone (family or no family) gets flexible working hours and 30 days of holidays per year.",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Marketing y publicidad, Servicios y tecnologías de la información, Internet",0,None,False,,None,ACTIVELY_HIRING_COMPANY
708,2243511802,2020-11-04,Full Circle Recruitment Ltd,"Data Scientist - greenfield data science work, Fintech, £40-55k",United Kingdom,"Python, SQL, ops and credit risk, Financial Services - leading Fintech firmRemote working with occasional trips to London baseThis leading fintech runs an analytics-rich platform that serves to introduce lenders to businesses that need to borrow money. As they continue to grow, so their data analysis team is experiencing increased workload, and greater opportunities to innovate and deliver the benefits of data science throughout the organisation.The firm now needs to hire an experienced data analyst/data scientist to build the models and analytics that underpin their pioneering, real-time credit risk product. As well as creating models, primarily using Python, with some SQL, and visualisations (using Power BI), you will be engaging with stakeholders at a partner bank, as you help to move this industry-leading analytics tool to the next level.ESSENTIAL SKILLS SOUGHTAt least 2 years professional experience in PythonAt least 2 years’ experience in one of the following:Modelling Credit Reference Agency dataModelling other Credit Risk dataOpen-banking dataSmall business transaction dataYou must also have experience of working on models that have been or can be scaled up for mass-market use. WHAT’s IN IT FOR YOU?The opportunity to work with cutting-edge technology, delivering industry-leading productsScope to grow and develop your skills, learning from well-respected analytics practitionersThe financial and other benefits that come with a start-up cultureAbility to work from remotely, anywhere in the UK, with c. fortnightly trips to London",Intermedio,Jornada completa,"Análisis, Finanzas",Banca,106,None,True,,315,ACTIVELY_HIRING_COMPANY
709,2249789570,2020-10-28,LegalShield,Sr Data Engineer,Dallas-Fort Worth Metroplex,"Remote - you can be located anywhere in the US.  This role sits within the Data Lab in the Engineering organization. Our Product, IT, and Engineering organizations are primarily focused on building a new platform to operate our business. Much of this involves building custom web and mobile applications, building the backend platforms and services to support those applications, and integrating with third-party tools and platforms. The Data Lab is our home for orchestrating the flow of data between all those systems: from our source systems to our data warehouse: from our source systems to third-party platform APIs: from third-party platform APIs to our internal systems. From everywhere to anywhere. It’s an exciting time to be a part of the Data Lab as we build a new platform to deliver quality solutions for our business. Our company is headquartered in Ada, OK, but our teams work distributed across several timezones. In terms of working hours and availability, we expect you to attend daily meetings and ensure your work commitments are met. Generally speaking, 9am-5pm CT is when many business functions occur, and 10am-2pm CT could be considered core availability time. There is some flexibility around your specific hours as long as core expectations are being met. Duties & Responsibilities:Develop pipelines to orchestrate the flow of data between systemsTransform data into performant modelsEngage in the code review process: review Pull Requests, present your work for review, provide and receive positive and constructive feedbackApply concepts, practices, and procedures within the software testing field to data engineeringLead and support documentation developmentIntegrate and translate business and technical needsBuild relationships with business stakeholders and engineering colleaguesParticipate in Agile developmentParticipate in daily stand-ups and other team meetingsCollaborate synchronously and asynchronously via Slack, Zoom, Jira, Confluence, and emailCommunicate about deadlines, blockers, and work estimationsWork independentlyLearn new skills and concepts in a self-directed mannerSupport the engineering organization’s mission to deliver high quality solutions that challenge conventions, set new standards, and spearhead constant improvement Education/Skills/Experiences:You do not need to have all of these skills or experiences, but the more the better.Significant experience in computer science, software engineering, application development, or related fieldsData warehouse design in a cloud database: we use Snowflake (facts & dimensions, slowly-changing dimensions, functional data warehousing, schema evolution)ETL, ELT, or data pipeline development: we use NiFi and dbt (error handling, performance tuning, monitoring/alerts, security)Applying software engineering concepts to data engineeringManaging real-time and steaming data: we use Debezium and KafkaLeveraging APIs as sources and destinationsAutomating and scaling solutionsUsing version control software (we use Git and GitHub)Designing solutions around cloud technologies: we use AWSWorking in containerized solutions: we use Docker and RancherKnowledge of one or more programming languagesWriting efficient SQLCollaborating within and across teams to understand problems, then design and implement solutionsEnhancing a culture of feedback and team support",Intermedio,Jornada completa,Tecnología de la información,Servicios jurídicos,77,None,True,,235,ACTIVELY_HIRING_COMPANY
710,2248136034,2020-11-07,Verys,"Remote Senior Data Engineer (Python, SQL)",United States,"Important notes:-We are not working with third parties at this time: any resumes from vendors will result in removal from our vendor list.-We are unable to provide sponsorship at this time. -This position is fully remote, with the option to work out of our Orange County CA office following Covid-19. Verys is a multi-disciplined technology delivery firm that offers a strategic approach to building software through user-centered design, modern development architecture, and business alignment all wrapped up in a structured agile environment. We build software to be proud of for clients like Blizzard, American Airlines, Kia, and Experian. Right now, we’re looking for a Senior Data Engineer to turn data into information, information into insight and insight into business decisions. The successful candidate will conduct full lifecycle activities that include requirements analysis, development of reporting capabilities (both ad hoc and dashboards) in collaboration with technical resources, and continuously auditing data cleanliness and seeking new insights into consumer behavior to support decision making. If you are excited by solving complex challenges and growing your career within an innovative software services company, we’d love to hear from you! What you will be doingInterpret data, analyze results using statistical techniques and provide ongoing reportsSupport the development of data collection systems and other strategies that optimize statistical efficiency and data qualityAcquire ad hoc data from primary or secondary data sources for analysis using offline reporting tools such as Excel, powerBIIdentify, analyze, and interpret trends or patterns in data setsFilter and clean data as neededWork closely with management to prioritize business and information needsOperationalize repeated similar ad hoc requests using a reporting continued use Skills and RequirementsYou’re smart, adaptable, and love picking up new skills.You are highly adept with reporting packages (Tableau Software), databases (SQL and NoSQL), and concepts of ETL design and execution.You have technical expertise regarding data models, database design development, data mining and segmentation techniques.You are knowledgeable and experienced with reporting packages (Tableau Software), databases (redshift), and concepts of ETL design and execution.You are adept at queries, report writing and presenting findings.You have strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.You are skilled with Python, Jenkins, and AWSBonus points if you are familiar with TerraformYou communicate well with teammates and clients, and your experience backs that up. We OfferCompetitive compensation based on your skillsLearning resources like Udemy, Saisoft, and internal development meetupsAn awesome culture with opportunities to meet like-minded people: whether you’re into gaming, reading, hiking, or craft food and drink, there’s a club for that.Philanthropic events to get involved in the communityCompetitive medical, dental, and vision coverageFlexible hours and paid time off401K matching ﻿We are excited to review your application!",Intermedio,Jornada completa,Tecnología de la información,Servicios y tecnologías de la información,18,None,True,,119,None
711,2186824654,2020-11-05,Dell,Data Engineer,"Hopkinton, MA, US","Data Engineer  Remote Role in Massachusetts USA  Dell provides the technology that transforms the way we all work and live. But we are more than a technology company — we are a people company. We inspire, challenge and respect every one of our over 100,000 employees. We also provide them with unparalleled growth and development opportunities. We can’t wait for you to discover this for yourself as aData Engineeron our global Decision Sciencesteam. The desired candidate will work to enable Dell's Global Business Operations organization with data-driven insights that support our quota planning and business transformation efforts. The ideal candidate will work with a variety of stakeholders including ML engineers, data scientists, software engineers, and peer data engineers to align and execute end-to-end solutions which start with data collection and management, extend through machine learning methodologies, and end with governance of machine learning model performance. As a Data Engineer on our team, it will be your responsibility to ensure your fellow team members have clean, reliable data that can be easily consumed into our data science and machine learning procedures.  Key Responsibilities Deep-dive into business problems relating to our quota planning and sales compensation effortsDesign and maintain optimal data architecture for our data science products: partner with your peer data engineers to build reliable systems that scaleBuild, clean, and maintain data sets that feed our machine learning algorithms and discovery processes (based in PostgreSQL database)Identify opportunities for process improvements (may results in automating, optimizing, or fully rebuilding workflows)Work with the greater Decision Sciences team to help with data related issues and analysis needs  Essential Requirements Self-learner who is driven to learn new methods and techniques to fulfill business needsCreative thinker who is success-driven both individually and as a team leader/mentorDetail-oriented with the ability to effectively prioritize tasksExperience working in an Agile environmentExpertise in PostgreSQL (experience with GreenPlum a plus)Expertise with Python, Java, or a similar object-oriented languageExperience building and optimizing data workflowsExperience architecting data pipelinesExperience in root cause analysisGood written and oral communications skillsStrong project management and organizational skills1+ year(s) of experience (preferred) in a data engineering capacity, preferably on a data science or advanced analytics teamBachelors or Masters (preferred) in Computer Science/Engineering or related field  Benefits  We offer highly competitive salaries, bonus programs, world-class benefits, and unparalleled growth and development opportunities — all to create a compelling and rewarding work environment. If you share our passion for data and you’re keen to play a key role in driving progress, this is your opportunity to develop with Dell. Dell is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at Dell are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV Status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. Dell will not tolerate discrimination or harassment based on any of these characteristics. Learn more about Diversity and Inclusion at Dell here.  Job Id: R073533",No corresponde,Jornada completa,Tecnología de la información,"Equipos informáticos, Software, Servicios y tecnologías de la información",333,None,False,,1383,COMPANY_RECRUIT
712,2254572562,2020-10-29,Facebook,AI UX Researcher,"Menlo Park, CA, US","Facebook's mission is to give people the power to build community and bring the world closer together. Through our family of apps and services, we're building a different kind of company that connects billions of people around the world, gives them ways to share what matters most to them, and helps bring people closer together. Whether we're creating new products or helping a small business expand its reach, people at Facebook are builders at heart. Our global teams are constantly iterating, solving problems, and working together to empower people around the world to build community and connect in meaningful ways. Together, we can help people build stronger communities - we're just getting started. For this position we are looking for experienced individual contributors who will help elevate the practice of research with creative but rigorous qualitative, quantitative, and/or design research methods. The right candidates will be excellent communicators, knowledgeable about product design, passionate about understanding people, curious about the relationship between technology and society, comfortable in a flat, fast moving organization, and a great collaborator. Specifically, you will support the AI research and development team and be at the center of influencing future AI enabled products.Orchestrate strategic visioning and analytical activity, moving between macro trends and micro trends and developing substantiated POV's for AI related topicsPartner with design, engineering and research peers to develop AI use cases that start with people's needs at the center and demonstrate Facebook AI technologyHelp AI research team develop easy to use development tools and interfacesWork with the AI design team to build awareness, familiarity and preference for AI technologyIdentify opportunities to constantly improve the quality of thinking applied to AI insightsBA/BS in a human behavior related field, such as human-computer interaction, psychology, sociology, communication, information science, media studies, computer science, or economics4+ years of experience in applied product researchExperience with data and utilizing numbers to define and support hypothesesExperience with storytelling to get traction with various audiencesMA/MS/MBA/PhDFacebook is proud to be an Equal Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law.   Facebook is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.",Algo de responsabilidad,Jornada completa,Arte/Creatividad,Internet,23,None,False,accommodations-ext@fb.com.,198,COMPANY_RECRUIT
713,2203347587,2020-10-22,Toptal,Senior Data Scientist,"Lisbon, PT","About Toptal  Toptal is a global network of top talent in business, design, and technology that enables companies to scale their teams, on-demand. With $100+ million in annual revenue and over 40% year-over-year growth, Toptal is the world’s largest fully remote company.  We take the best elements of virtual teams and combine them with a support structure that encourages innovation, social interaction, and fun. We see no borders, move at a fast pace, and are never afraid to break the mold.  Position Description  Here at Toptal, we always rely on data to guide all of our initiatives. This data helps to mold both our long-term strategy and our day-to-day operations. As a Senior Data Scientist, you will be working with our cross-functional team to model complex problems, use SotA approaches, and identify high-impact opportunities. You will be part of a high-energy, fast-paced team responsible for supporting initiatives and operations across the company.  Our full-stack Data Science Team uses Python for research and development and leverages Google Cloud Platform for production implementation. Our wide range of experience includes NLP, graph theory, recommendations systems, supervised and unsupervised problems. As part of the team, you are free to use the approach you see fit while relying on your colleague’s previous experience and expertise.  The ultimate goal is to solve real business problems. Our team works on problems that profoundly affect the operation of our business. We address these problems by using predictive models, automating decision-making, and other very open-ended questions. For example, our stake-holders may ask if it is feasible to predict the outcome of a particular process in order to improve our approach or to help them leverage the massive amount of feedback our users provide.  This is a remote position that can be done from anywhere. Due to the remote nature of this role, we are unable to provide visa sponsorship. Resumes and communication must be submitted in English.  Responsibilities  Build advanced and explainable models to classify objects, predict outcomes or make recommendations. Deploy the models that you build to production by building APIs or leveraging our ETL pipelines. Use statistical, algorithmic, data mining, and visualization techniques to model complex problems, find opportunities, discover solutions, and deliver actionable business insights. Own your projects and use this autonomy to find creative and innovative ways of solving problems and delivering solutions. Handle both parts of the Research & Development process, including clean, rigorous implementations of devised models inside our production environment. Be persistent, focused, and well-adapted when it comes to finishing your work. At Toptal, we always drive research from start to finish - we don’t get distracted: we don’t leave anything unfinished. Communicate data-driven insights and recommendations to key stakeholders. Be in constant communication with team members and other meaningful parties and convey results efficiently and clearly via Slack.   In The First Week, Expect To  Meet the entire Data Science team. Get familiar with our best practices guidelines. Get access to all our services.   In The First Month, Expect To  Set up your working environment. Learn our data sources and get familiar with our data warehouse. Meet our friends from the Data Engineering team.   In The First Three Months, Expect To  Start reviewing your colleagues’ work. Meet our stakeholders and start your first ad-hoc research. Get familiar with our Machine Learning implementations. Be included in our brainstorming sessions in different areas of Data Science.   In The First Six Months, Expect To  Deliver first ah-hoc analysis to our stakeholders. Start your first Machine Learning initiative. Start contributing to our live ML models.   In The First Year, Expect To  Meet the team in person during our onsite meeting. Deliver your first Machine Learning model to production.   Requirements  A strong background in advanced mathematics, in particular in probability theory and statistics, data mining, and machine learning. You must be able to think critically, to look at the big picture and spot what is missing, taking advantage of it to propose improvements and deliver business insights. 4+ years of professional experience in data science, doing exploratory data analysis, testing hypotheses, and building predictive models. Ability to quickly and accurately understand complex new concepts. Proficiency in Python and proven experience using popular ML packages (sklearn, keras, word2vec, etc), and previous experience efficiently conducting research and creating ad hoc reports. Deliver your work to production as a stand-alone microservice. Be enthusiastic about DS and stay up to date with SotA Machine Learning algorithms and developments. Be passionate about collaborating daily with your team and other groups while working via a distributed model. Be eager to help your teammates, share your knowledge with them, and learn from them. Be open to receiving constructive feedback. You must be a world-class individual contributor to thrive at Toptal. You will not be here just to tell other people what to do.  For Toptal Use Only: #latinamerica #europe #individualcontributor",Algo de responsabilidad,Jornada completa,"Control de calidad, Tecnología de la información, Ingeniería",Internet,18,None,False,,160,ACTIVELY_HIRING_COMPANY
714,2172066780,2020-10-29,RomAnalytics,"Senior Data Engineer, Pharma","Philadelphia, Pennsylvania, United States","Live and breath AI??? Join a team that is living and breathing AI into the Life Science Industry!   RomAnalytics is recruiting this exciting REMOTE position on behalf of an AI-driven pharmaceutical omni-channel marketing solution company. The company combines real-world claims data with advanced AI. The company is uniquely positioned to find, engage and convert a pharmaceutical brand’s Ideal Patient Population and their associated healthcare providers, offering a unique omni-channel solution to life sciences organizations.   The Position: Optimize code to run efficiently in a distributed data environment Support creation of architecture and manipulation of health data assets into distributed data environment and develop utilities to support data extraction and analysis Independently research and procure core knowledge of diagnoses and treatment in specific therapeutic areas to drive internal business decisions for design of user defined functions Analyze secondary data and research to identify key findings and trends Generate cohesive outputs in summary outputs (R, Scala, Python) tying project objectives and goals to data output Assist in drafting quantitative or qualitative analysis to support client deliverables and issues Assist in the management of projects and work streams and help with shifting priorities Assist in drafting and updating internal tools with supportive documentation for projects and process flows for evolving standard operations and procedures Develop broad knowledge of healthcare market and monitor market changes and events within the industry   Skills & Experience Candidate interested in joining IPM.AI should have Knowledge and basic understanding of the fundamental processes of pharmaceutical and medical device industries Avid interest in healthcare analytics, technology, and clinical data Strong attention to detail Strong capabilities in multi-tasking and flexibility for a dynamic working environment Business acumen and a fundamental understanding of the sales process Strong interpersonal and communication skills Ability to think creatively Prior working experience in any of the following forecasting, statistics, predictive modeling, primary/secondary market research, technology & applications, healthcare IT, managed markets, management consulting, sales force effectiveness, sales operations, business intelligence, epidemiology, HEOR, or data mining Advanced experience coding SQL or Scala in a distributed database environment required   Compensation Package: Generous Salary & Performance-based commission commensurate with experience",Intermedio,Jornada completa,"Tecnología de la información, Ingeniería, Análisis","Industria farmacéutica, Biotecnología, Consultoría de estrategia y operaciones",104,None,True,,431,ACTIVELY_HIRING_COMPANY
715,2247057766,2020-10-02,Socure,Lead Data Scientist - Computer Vision,"New York City, NY, US","Founded in 2012, Socure is the leader in high-assurance digital identity verification technology. Named to Forbes' 2019 AI 50 list as one of America's most promising AI companies, and a recent winner of API World's Best Data API, Socure's technology applies artificial intelligence and machine learning techniques with trusted online/offline data intelligence from email, address, phone, IP, social media and the broader Internet to verify identities in real-time. Customers include three of the top five U.S. banks, seven of the top 10 U.S. card issuers, as well as the majority of leading digital banks, lenders and insurers across the U.S. We are funded by some of the world's best investors and entrepreneurs including Scale Venture Partners, Commerce Ventures, Work-Bench, Santander InnoVentures and Two Sigma Ventures  The only way we can further our mission of becoming the single, trusted source of identity verification and eliminating identity fraud is by building the best team on the planet. This is where you come in!  Position Summary  The data science team is responsible for developing and improving Socure's identity verification products. Socure is a data science company at our core, so our team is central to everything the company does.  Socure is hiring a Lead Data Scientist to lead efforts to improve our current computer-vision based identity verification solution.  The Lead Data Scientist is part of a global team, and will work under the direction of the Director Data Science and in close partnership with data science teammates and colleagues in product and engineering. They will contribute in a hands-on capacity to the development and implementation of computer vision algorithms, as well as make technical recommendations to drive solutions.  This role can be based remotely in the USA or Canada  For more information, check out this brief video featuring Socure's SVP Data Science Pablo Abreu.  What You'll Do:  Lead the the machine learning aspect of projects related to the evolution of the product, working in collaboration with the Product and Engineering teams Identify opportunities to solve challenges with novel solutions Implement, optimize and deploy cutting edge computer-vision algorithms like OCR, RCNN, MTCNN, SSD ResNet, SSD MobileNet, Barcode Reader,… Feature Engineering Perform analysis to assess risk of fraud   Requirements  Masters or PhD. in deep learning and computer vision (document verification work would be highly valuable)  A minimum of 4+ years experience as a data scientist, contributing in both a hands-on and strategic capacity  Expertise and knowledge in the state of the art of computer vision and machine learning  You are experienced with GPU You have programming experience in Pytorch and/or TensorFlow Experienced with optimization of models to reduce memory and latency Experienced with embedding deep learning into mobile devices Demonstrate an understanding of the process to deploying deep-learning models to production Hands-on and motivated to build things and make them work Skillful communicator and collaborator partnering with cross-functional teams and communicating statistical fundamentals to a variety of audiences  Perks & Benefits:  Competitive base salary Equity - every employee is a stakeholder in our enormous upside A tech-first company culture driven by entrepreneurial thinking and talent A great team working in unison towards the same mission Transparency is what our product is built on—and so is our culture Generous medical, dental and vision benefits for employees and their dependents Parental leave and fertility support Flexible PTO 401K with company match Free meals, snacks, and drinks...and so much more",Algo de responsabilidad,Jornada completa,Otro,"Servicios y tecnologías de la información, Software, Internet",None,None,False,,39,ACTIVELY_HIRING_COMPANY
716,2273922202,2020-11-04,ASTEK Polska,Data Engineer (Python+Machine Learning),Polska,ASTEK Polska poszukuje Data Engineera z doświadczeniem w Pythonie i Machine Learingu. Stawka: 800-870 PLN/MD - zależnie od doświadczeniaPraca 100% zdalna przez cały okres trwania współpracy Projekt: branża bioinformatyczna - Digital Pathology  Wymagania:-Minimum 3 lata doświadczenia na stanowisku Inżyniera Danych -Wymagana wiedza / doświadczenie w technologiach:Docker / KubernetesLinuxPython (dobra znajomość)-Praktyczne zastosowanie algorytmów uczenia maszynowego i technik eksploracji danych -Język angielski na poziomie minimum B1,Intermedio,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Biotecnología",29,None,True,,179,ACTIVELY_HIRING_COMPANY
717,2224712819,2020-11-06,Compri Consulting,Senior Data Engineer,Denver Metropolitan Area,"Client located in Denver, Colorado (Glendale) is seeking a Senior Data Engineer for a direct hire position. This position will be part of a remote three person team responsible designing, implementing and supporting ETL / ELT processes. The ideal candidate will have experience building data systems from scratch, as well as maintaining those systems. Required:-4+ years data engineering experience.-Python.-SQL coding.-Cloud platform (preferably AWS & GCP).-Computer Science or related degree. Desired:-Snowflake.-Apache Airflow / Cloud Composer.-Apache Beam / Dataflow.-Docker and Kubernetes.-BigQuery.-Data / database related certifications.",Intermedio,Jornada completa,Tecnología de la información,Servicios y tecnologías de la información,38,None,True,,134,ACTIVELY_HIRING_COMPANY
718,2210707910,2020-10-24,"Okta, Inc.",Data Scientist Architect (Remote Eligible),"New York City, NY, US","This is an opportunity to join our fast-growing Security Intelligence Platform team to help develop cutting-edge machine learning models to better protect our users from malicious actors and attacks. We are looking for a hands-on engineering leader with deep data science and software engineering expertise who can help architect and own the platform for deploying and tuning the machine learning models used to protect user authentication and security. They will also own the pipeline which needs to process hundreds of millions of events per day and provide results back to the authentication system to make real-time risk evaluation during user authentication. This project has a directive from engineering leadership to make OKTA a leader in the use of data and machine learning to improve end-user security.  We hope you will share our passion and great pride in the work we do and will join an engineering team that strongly believes in automated testing and an iterative process to build high-quality next-generation cloud platforms.  Our elite team is fast, innovative, and flexible. We expect great things from our engineers and reward them with stimulating new projects and emerging technologies.  Job Duties And Responsibilities  Overall ownership of the architecture, platform, and pipeline for developing, deploying, and running new machine learning models in production. Work with Data Scientists to analyze security event data, develop ML models and evaluate model performance. Work with Data Scientists to help improve their productivity and implement their ideas. Design and maintain data processing pipelines to support new decision and scoring models. Analyze performance metrics and logs to identify inefficiencies and opportunities to improve scalability and performance.   Minimum Required Knowledge, Skills, And Abilities  C-level communication skills, 10+ combined years of Data Science and Data Engineering experience 5+ years of experience in production SaaS deployment C-level communication skills Expert-level understanding of relational databases (columnar and row-based), and NoSQL including mongo, Cassandra or similar 5+ years experience with streaming systems: MQ, Kafka, Storm, Spark, etc. 5+ year experience with the AWS data toolchain: EMR, Kinesis, Redshift, Glue Working knowledge of AWS Sagemaker, Lambda, and API Gateway including production deployment 5+ years Python development 5+ years of Java or OOP language development  Okta is an equal opportunity employer  Okta is rethinking the traditional work environment, providing our employees with the flexibility to be their most creative and successful versions of themselves, no matter where they are located. We enable a flexible approach to work, meaning for roles where it makes sense, you can work from the office, or from home, regardless of where you live. Okta invests in the best technologies and provides flexible benefits and collaborative work environments/experiences, empowering employees to work productively in a setting that best and uniquely suits their needs.",No corresponde,Jornada completa,"Ingeniería, Tecnología de la información","Seguridad del ordenador y de las redes, Software, Servicios y tecnologías de la información",6,None,False,,254,ACTIVELY_HIRING_COMPANY
719,2215565028,2020-10-27,Urbint,Senior Machine Learning Engineer,"New York City, NY, US","At Urbint, our mission is to make communities more resilient. We do this by pairing external data with artificial intelligence to identify areas of high risk and prevent catastrophic loss for utilities and infrastructure operators across the country. We are a team of close-knit engineers, entrepreneurs, and data geeks who obsess over problem-solving, new technologies, and making a positive impact in our communities.   Job Summary   Urbint is looking for a senior-level machine learning engineer to help guide our team’s effort on its next-generation machine learning platform. Urbint is a product with machine learning at its very heart: as a senior member of the ML team, job is to help refine this vision, continually making machine learning as impactful for our clients as it can be. Your will design and build machine learning tools to build models efficiently, effortlessly and predictably, models with a high degree of predictive accuracy. You will contribute to a strategy for collecting and fusing diverse sources of data to power our predictive systems, as well as building the tools needed for understanding the performance of models deployed in production settings. Finally, you will be a mentor, improving an already high-performing machine learning team through the breadth of your experience.  We encourage people from underrepresented groups to apply.   What You’ll Do   Be a Technical Leader - Provide technical guidance to the team to build an infrastructure that helps scientists to build models, test hypotheses, run experiments, and deploy at scale in production environments. Explore Data - Understand and identify preliminary signals in the data prior to deep processing. Quickly analyze the dataset to assess its usefulness for machine learning. Prototype Models ­- Develop features, uncover patterns, and build models. Explore Techniques - From simple regressions to neural networks, we use a variety of techniques. You'll have the freedom to explore multiple methods to squeeze insights out of data. Productize Models - ­A pattern is good, but a prescriptive solution is better. Build products that help our customers get the most out of their data and workflows.    Who You Are   Masters in a quantitative discipline (e.g. Stats, Math, Physics, Engineering, CS, etc.) 5+ years of experience in data science/machine learning roles Experience solving concrete machine learning problems in diverse settings Advanced knowledge of machine learning methods and statistical principles, including experience in Bayesian statistics, anomaly detection, and/or time series forecasting Well versed in Python or R (and willingness to continue to learn the Python ecosystem) Proven experience designing and delivering solutions using large, diverse, real-world datasets to support business decisions Up to date with the current best tools and practices in the ML and data science ecosystems  Nice to Have  Ph.D in a quantitative discipline Familiarity modeling with spatial data Experience doing machine learning on networks or in connected environments    Benefits   Mission Driven - Some companies use AI to serve better digital ads and trade stocks, we seek to make our communities more resilient Top Compensation - Competitive compensation package Best in Class Medical Coverage - 100% benefits and premiums paid Health Perks - Wellness reimbursement and citibike membership Weekly lunch stipend Remote work monthly stipend   We're an equal opportunity employer. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Software, Internet",28,None,False,,153,ACTIVELY_HIRING_COMPANY
720,2235756554,2020-11-04,"Ursus, Inc. - Talent, Services & Solutions",Senior Data Engineer,United States,"Job Title: Senior Data EngineerLocation: RemoteDuration: Permanent Summary: Help to build data pipelines that enable decision makers and facilitate the development of machine learning algorithms Responsibilities:Focus on implementing mission critical data applications and developing streaming data pipelines for Client modelsResearch, design, and test next generation data engine platformsDevelop data pipeline and storage strategies and database infrastructure and tools Build integrated and automated data pipelines using the Hadoop Ecosystem (Spark, Kafka, Hive, Yarn, Oozie) Develop efficient and effective T-SQL to extract, transform, and load data from source systemsQualifications: 5 years of experience in Data Engineering and/or Software Development plus 3 years of specific Hadoop expeirienceKnowledge of MS SQL server as well as data streaming tools such as Spark, Kafka, etcIn depth knowledge of the Hadoop Ecosystem as well as experience with ETL programmingExtensive knowledge of common data warehousing technologies and techniquesExcellent conceptual, analytical, and problem-solving skillsFamiliarity with Java, cloud data offerings, and Greenplum.",Intermedio,Jornada completa,"Tecnología de la información, Ingeniería","Envío de paquetes y carga, Transporte por carretera o ferrocarril, Servicios y tecnologías de la información",26,None,True,,136,ACTIVELY_HIRING_COMPANY
721,2248149819,2020-11-07,"TrueCar, Inc.",Machine Learning Engineer 4,"Santa Monica, CA, US","Job Description: TrueCar envisions a world where car shopping is an uplifting experience. Our shopping experience helps buyers consider choices from every angle, builds confidence in their decisions, and enables every step of the process with tools and information that make car buying easy. Ultimately, TrueCar is helping people in the second largest purchase they will make in their lives. We’re removing the complexity out of buying a car, using technology and personalization, to create a one-of-a-kind experience that transforms car buying and ultimately people’s lives.  Come join the team and help us accomplish our mission. TrueCar maintains a Dynamic Workplace, allowing employees to have their primary workstations at home, with office space in Santa Monica, CA and Austin, TX to be made available to individuals and teams to use as needed. Employees enjoy excellent benefits (health/vision/dental coverage, 401k with contribution matching, equity, etc.) as well as perks like monthly credits for at-home food delivery, internet/mobile phone service coverage, fitness expenses, and Caregiver support.  Overview:  TrueCar is seeking to add Machine Learning Engineers to our Data team. This position requires a Machine Learning Engineer who can bring bleeding edge machine learning models into production together with a team of product analysts, data engineers, product managers and business domain experts.  What you’ll do:   Partner with Data Engineering, Product and Design in a cross-functional agile team to deliver products that solve consumer problems in the automotive marketplace.  Write production ready high quality, maintainable and scalable code. Provide support on production issues as they arise.  Work on prediction algorithms, sorting algorithms, large-scale machine learning and recommendations and personalization.  Build simple yet functional models, deploy them early, and learn/iterate in order to continuously improve our products  Design and analyze metrics to verify model and algorithm effectiveness.  Keep up with the latest ML developments and evaluate how they can be applied to our products and business needs.   What you’ll need:   4+ years experience in Machine Learning and AI at Big Data scale  Proficiency in Machine learning techniques like classification, regression, anomaly detection and clustering.  Strong programming skills with data analysis languages such as Python or Scala.  Hadoop/Spark and AWS experience.  Strong analytical and problem-solving skills.  Adapt messaging for varying audiences in the team, choose appropriate media and provide context  Ability to successfully collaborate with engineers within the team and help them learn and grow.  BA/BS in related field   Nice to have:   Strong background in algorithms, data structures, and object-oriented programming.  Experience in A/B testing of models and continuous deployment to production.   About TrueCar:   TrueCar is a leading automotive digital marketplace that enables car buyers to connect to our nationwide network of Certified Dealers. We are building the industry's most personalized and efficient car buying experience as we seek to bring more of the purchasing process online. Consumers who visit our marketplace will find a suite of vehicle discovery tools, price ratings and market context on new and used cars -- all with a clear view of what's a great deal. When they are ready, TrueCar will enable them to connect with a local Certified Dealer who shares in our belief that truth, transparency and fairness are the foundation of a great car buying experience. As part of our marketplace, TrueCar powers car-buying programs for over 250 leading brands, including AARP, Sam’s Club, and American Express. Nearly half of all new-car buyers engage with TrueCar powered sites, where they buy smarter and drive happier.  TrueCar is headquartered in Santa Monica, California, with offices in Austin, Texas and Boston, Massachusetts.   Location(s):Santa Monica, CA",No corresponde,Jornada completa,"Ingeniería, Tecnología de la información","Marketing y publicidad, Software, Internet",13,None,False,,123,ACTIVELY_HIRING_COMPANY
722,2276327353,2020-11-03,TipTopJob,Data Engineer / Remote Working (UK Based) / Up to GBP51k,"Manchester, GB","Data Engineer / Hadoop, Scala, Spark, Python / up to GBP51k / Remote working (Uk Based)  Are you a Data Engineer who would like to be involved in a company:wide data transformation with a globally recognised brand? Would you like to have a real say in the technical direction and ultimately provide real business benefit? Corecom Consulting has partnered with a prestigious company based in the heart of Manchester who are rapidly growing their business offering from a data perspective. This is a fantastic time to join an ever:growing business that offer real career development opportunities, both from a career progression and technical perspective. Their long term vision is to move everything from their data warehouse in to their newly built data lake so they can move from pure reporting to creating more interactive visualisations, whilst looking at patterns in data which will lead to predictive analytics which will allow a complete 360 view of their customers. Their state:of:the:art offices are in the Greater Manchester Area and boast a friendly, but ambitious technology:driven environment. However, they are working from home at the moment, and have the confirmation that this can be done permanently moving forward (if required).  What can you look forward to?  Remote working Excellent internal and external training opportunities Progression opportunities A chance to work on a UK sector first data solution Generous holiday allowance Strong pension Childcare vouchers What we need from you  Hadoop SQL Talend What would be great to have  Python / R / Scala / Java Data modelling experience  You will form part of their existing Data Analytics team as you build and maintain their Hadoop solution. The aim is to provide their customers with ownership of their journey as well as employees with the MI needed to implement business decisions. The exciting part of this role is that you will be involved in a UK sector first data solution which will not only offer you the scope to develop personally but will add to your current career. I have interview slots for this role in the next couple of weeks so please apply as soon as possible to avoid disappointment  Data Engineer / Hadoop, Scala, Spark, Python / up to GBP51k / Remote working (Uk Based)",Sin experiencia,Jornada completa,Tecnología de la información,"Construcción, Dotación y selección de personal, Servicios financieros",3,None,False,,20,None
723,2288290039,2020-10-30,Amber Resourcing,Machine Learning Engineer (Remote),"London, GB","Machine Learning Engineer | £60,000 - £85,000 (Remote) Deep Learning | Machine Learning | Video | Python | Signal Processing  Want to get involved with a Deep Learning specialist? This deep learning video disrupter in central London are looking for a self-starting independent Machine Learning Engineer to improve upon the DL architecture, research and implement methods for maximum impact on the product.  You Have published papers with Deep Learning in Computer Vision or signal processing or IEEE transaction journals such as ICCV, CVPR, ECCV, NeurIPS, ICASSP or ICIPCompleted a research degree (PhD or MPhil) in video signal processing or deep learning video etcSelf-starter, able to operate independentlyPython  Desirable Filed patents or can showcase you've not used off-the-shelf components and built something using first principles of deep learning  Benefits Up to £85,000 per annumFully remote, even after restrictions are liftedBonus  This vacancy will be closing applications on 25th October 2020. If you have any questions or fancy a chat about the opportunity feel free to give George Bone a call on (see below) or apply for the advert and George will be in contact.  Deep Learning | Machine Learning | Engineer | Video | Signal Processing | Computer Vision | Data Scientist | Data Science | Researcher | PhD | Python | Tensorflow | PyTorch | AI | Artificial Intelligence | CPU | GPU | AWS | GCP | London | £60,000 - £85,000  Role: Machine Learning Engineer (Remote) Job Type: Permanent Location: London,  Apply for this job now.",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información",Ingeniería industrial o mecánica,0,None,False,,20,JOB_SEEKER_QUALIFIED
724,2242687735,2020-11-05,SearchDATA Group,Senior Data Engineer - Consultant,"London, England, United Kingdom","Senior Data Engineer - Consultant Are you a Data Engineer with consultancy experience? Do you want to work for a consultancy that pride themselves on delivering quality solutions? Would you be interested in working for an Elite Snowflake Partner? SearchDATA is working in partnership with a growing Data & Analytics consultancy full of people that are passionate about delivering quality Data Solutions. The business has been going from strength to strength, despite all that is going on in the world, with new business being won and new partnerships being formed. The most recent news they’re incredibly proud about is their selection as an Elite Snowflake Partner, an achievement that is sure to help them along their way to becoming an industry leader whilst also meaning their teams work on projects with the absolute latest and best data technologies. They’re looking to grow the team with like-minded people, so if you’re a Data Engineer with consultancy experience and a true passion for delivering quality data solutions, this may just be the role for you. Overview Delivering high quality data management solutionsConsult with clients on industry technologies, services and business benefits of data and analyticsHelping design and deliver cloud-based data and analytics solutions (AWS, Azure, Snowflake)Meet with clients to understand the customers’ needs for data, analytics, BI and technologyContribute towards project delivery and managing stakeholders’ expectations Requirements﻿As a technology agnostic company, technical requirements are always subject to change. We need an individual able to understand the core concepts and principles behind the tools in order to adapt their knowledge to the tech used at the time.Experience on client-facing projects, including working in close-knit teamsExperience delivering Cloud Based Data Solutions (AWS / Azure / GCP)Experience with Cloud Data Warehouse tools such as Snowflake or native AWS toolsExperience with various Data Integration tools Experience and interest in Big Data technologies (e.g. Apache products)Good knowledge of industry technologies, services and business benefits of data and analyticsAbility to build operational ETL data pipelines across a number of sources, and constructing relational and dimensional data modelsStrong development background with experience in scripting, object oriented or functional programming language, etc. SQL, PythonExperience with visualisation software Experience with leveraging Metadata to quicken project delivery and improve access to dataAn understanding of DevOps principles, practices and tooling, CI/CD with Jenkins etc",Intermedio,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Consultoría de estrategia y operaciones",52,None,True,,209,ACTIVELY_HIRING_COMPANY
725,2277595283,2020-10-11,Blueprint Technologies,Sr. Data Engineer,"Dallas, TX, US","Who is Blueprint?  Blueprint is a technology company that focuses on digital transformation. We specialize in cloud and infrastructure, data platform and engineering, data science and analytics, organizational modernization and customer experience optimization. We have a nationwide presence with offices across multiple regions and we serve customers in multiple industry verticals.  Why Blueprint?  We are innovators. Motivators. Thought provokers. Our collective backgrounds bring diverse perspectives that enable us to consistently think differently. We want you to bring your biggest and best ideas to help positively impact our culture, clients and the community around us. We believe in the importance of a healthy and happy team, which is why our benefits include full medical, dental and vision coverage, as well as paid time off, 401k, paid volunteer hours and tuition reimbursement.  What will I be doing?  Blueprint is looking for a Sr. Data Engineer to join us as we build cutting-edge technology solutions! This is a fast-paced role that needs a dedicated and passionate individual focused on team and client satisfaction!  Qualifications:   At least 7+ years' of experience as a data engineer At least 5+ years' of experience with SQL and/or other data collection tools & reporting Experience with Azure data engineering tools such as Azure Data Factory and Azure Functions Proven ability in building high-performance and scalable data solutions using Azure, or similar cloud platforms  Excellent collaboration skills to work on a team as well as independently (be self-reliant and resourceful) Experience with Python/Pyspark (Databricks or Spark) Excellent verbal and written communication skills  Experience building out large-scale integration landscapes for an Enterprise. Including strategy and execution on Enterprise level APIs for near real-time communication between software systems Ability to look at solutions in unconventional ways and see opportunities to innovate Ability to architect and build out integration pipelines Ability to quickly learn new technologies, application domains, implementing new knowledge and adapt to changes Excellent critical thinking and problem-solving skills. Ability to develop simple, elegant solutions to complex problems  Preferred Qualifications:   Expert with Azure cloud environment Experience with data masterization and defining conformed dimensions across various datasets Experience working with Attunity, Azure Data Factory, Databricks and Spark Experience with team building and mentoring A people person, being both highly motivated and motivating Bachelor's or Master's degree in Computer Science, Computer Engineering or related technical discipline is favored.  FLSA - Job Classification: Exempt - Salary, Full Time Position  Location: Remote",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Servicios financieros",0,None,False,,4,ACTIVELY_HIRING_COMPANY
726,2248114285,2020-11-06,Proofpoint,Senior Data Engineer,"Charleston, WV, US","It's fun to work in a company where people truly BELIEVE in what they're doing!  We're committed to bringing passion and customer focus to the business.  Company Overview  At Proofpoint, we have a passion for protecting people, data, and brands from today’s advanced threats and compliance risks. We hire the best people in the business to Build and enhance our proven security platform Blend innovation and speed in a constantly evolving cloud architecture Analyze new threats and offer deep insight through data-driven intel Collaborate with customers to help solve their toughest security challenges  We are singularly devoted to helping our customers protect what matters most. That’s why we’re a leader in next-generation cybersecurity—and why more than half of the Fortune 100 trust us as a security partner.  The Role  We are seeking a Senior Data Engineer to join our team at our Pittsburgh office located in the Strip District (and remote for the time-being). This individual should have experience with data systems for operational and analytical purposes, intermediate to advanced SQL knowledge, and skill in working with complex ETL processes that move millions of data points daily.  Our Engineers are designing and developing our market leading security training and assessment software.  Our goal is to help organizations teach their employees secure behavior through interactive web applications, received and managed by our customers on our proprietary SaaS platform. Our team specifically is responsible for ensuring that our end users and administrator can access their data to gain information and insight around their people based security risk and plan their mitigation strategy.  The ideal candidate is enthusiastic to work with cutting edge technologies in a fast-paced environment supporting a global SaaS product. As a Senior Data Engineer, you will lend your skillsets to help lead design and implementation of a key customer facing component that has high visibility and value within the organization as well as provide subject matter expertise in data modeling and processing to the rest of the organization.  Your day to day Work with other data engineers on the system design and delivery of a scalable, secure and supportable enterprise software solutions for our customer facing platforms Participate in our agile work-flow process, including concept development, architectural design, design specification, story decomposition, planning, executing, testing, acceptance, and retrospection   What You Bring To The Team 5+ years’ work experience with SQL3+ years’ work experience with either MySQL or PostgreSQL3+ years’ experience designing, developing, and supporting applications in a cloud environmentBS/BA in a software related fieldExperience with large-scale ETL processes, including technologies such as Airflow with Python.2+ years’ experience of Qlik Sense development (or a similar Business Intelligence tool such as Tableau, Power BI, or Looker). Have you ever created reports or visualizations for an end user using one of these applications (or others)?You should possess an intermediate to advanced knowledge of SQL in either PostgreSQL or MySQL environments (or both). For instance, what are the different kinds of JOINs and when would you use each? What is a window function and why would you use one? What's a CTE? What are some features that are available in MySQL that aren't available in PostgreSQL or vice versa? How would you go about optimizing a long-running query?Have exposure to either MySQL or PostgreSQL environments, preferably MySQL 5.7 and PostgreSQL 11.Experience in data modeling for both relational and analytical systems. What's the difference between 3NF and a star schema? When would it be appropriate to use one kind of model versus another? What are some of the kinds of slowly changing dimensions?Familiarity with AWS is a plus, especially including a subset of the following services RDS, EC2, S3, Data Pipeline, Glue, SNS, Kinesis, Lambda, DynamoDB, EMR, Redshift, and ElasticsearchComfort in working across multiple operating systems, including macOS and WindowsComfortable with Git for version controlCan work independently and thrives with autonomy  Preferred Skills Advanced SQL knowledgeAdvanced ETL experience moving data at scaleExperience with Front-end web frameworks like Ember/Angular/React Experience designing and deploying applications on Amazon Web Services Experience building customer facing applications at scale Ability to write complex scripts in Python Why Proofpoint   As a customer focused and driven-to-win organization with leading edge products, there are many exciting reasons to join the Proofpoint team. We believe in hiring the best the brightest and cultivating a culture of collaboration and appreciation. As we continue to grow and expand globally, we understand that hiring the right people and treating them well is key to our success! We are a multi-national company with locations in 10 countries, with each location contributing to Proofpoint’s amazing culture!  If you like wild growth and working with happy, enthusiastic over-achievers, you'll enjoy your career with us!",No corresponde,Jornada completa,Tecnología de la información,"Seguridad del ordenador y de las redes, Software",3,None,False,,16,ACTIVELY_HIRING_COMPANY
727,2237129566,2020-11-03,F1 Consulting & Services,Data Engineer Google Cloud Platform,"Milano, Lombardia, Italia","F1 Consulting & Services è un'azienda italiana presente sul mercato da oltre dieci anni, con forti competenze nella consulenza aziendale e strategica, che offre servizi e soluzioni informatiche innovative per importanti grandi e medie imprese. Per cliente multinazionale, siamo alla ricerca di un Data Engineer Google Cloud Platform, che possa implementare nuovi progetti, in collaborazione con il resto del team. Attività:La persona sarà chiamata a partecipare alla creazione delle infrastrutture per l'analisi dati e avrà il cruciale compito di progettare, costruire, installare, testare e mantenere i sistemi di gestione dei dati.I progetti sono in ambito Insurance/Finance/Retail e le architetture su cui andrà a lavorare sono innovative e automatizzate - fast data. Skills:• Python • SQL • GIT • Jenkins • Airflow & Google Composer • Docker  • GCP services (Cloud Functions, Kubernates, DataFlow&Apache Beam, BigQuery) Nice to have:• Terraform • BitBucket • Kafka • Spark • GCP services (Anthos, DataProc, KubeFlow) Disponibilità: immediataSede: inizialmente da remoto successivamente alla emergenza sanitaria on site nella sede di Milano La tipologia contrattuale verrà concordata con il candidato in base all’esperienze e allecompetenze possedute per ricoprire la posizione.",Algo de responsabilidad,Jornada completa,Tecnología de la información,Servicios y tecnologías de la información,19,None,True,,180,ACTIVELY_HIRING_COMPANY
728,2238564738,2020-11-05,LEAPROS™ Workforce Solutions,Principal Machine Learning Engineer (ML) - Financial Services,United States,"CLIENT PARTNER PROFILE AND VALUE PROPOSITION Join a growing team of passionate, self-motivated, talented, and creative people with big ideas about the future of data for the investment industry. Over the last few years, our client has grown considerably, won several awards, and built a lot of great software. This opportunity is a fixed-term consulting engagement with an estimated 12-months in duration and is benefit eligible. (Eligible for REMOTE work in select states)  POSITION TITLE:   Principal Machine Learning (ML) Engineer POSITION SUMMARY: Our client is seeking a fixed-term consultant with a possible extension to make a strong contribution in the role of Principal Machine Learning (ML) Engineer. for an experienced Machine Learning 'ML' engineer that has a passion for solving complex automation, classification, and prediction problems. The ideal candidate has previous experience working with data classification, tagging, and information extraction. This role will report to the CTO and start out as a Principal focused on blazing a trail with new technologies and approaches and can grow into a leadership role.  AREAS OF CONTRIBUTION:A successful candidate will apply applicable experience to innovate and enhance current client product offeringsApply a highly consultative approach from the perspective of thought leadership, hands-on technical development, and develop actionable technical specifications  Work with proprietary tools to enhance core platform functionality Maintain high visibility with leadership and cross-functional teamsMaintain high accountability for machine learning engineering/developemnt Have an interest in increased areas of responsibility  ROLE AND RESPONSIBILITIES:Design software-systems, applications, and data architectures that directly implement AI techniques to support achieving better accuracy and end-user automationImplement ML approaches to business problems for the Backstop platform utilizing techniques such as prediction, optimization, and classificationWork hands-on and provide overall guidance to a team of SW engineers to implement AI/ML softwareDesign, develop, document, test, and debugs applications software and systemsCollaborates with members of the Product team to understand business needs and translate those into technologies and usOther duties as required to meet the needs of the business  REQUIREMENTS:Expertise in Artificial Intelligence and Machine Learning to perform algorithm development and data analysisExperience with data preparation, OCR, data classification, and information extractionExperience with scalable architecture designsExperience with CI/CD on AWSDemonstrated experience in Machine Learning classification, automation, and extractions Demonstrated experience in Microsoft technology stack in complex engineering and solution development  Progressive professional development and increase responsibility in engineering and software development Deep commitment to solving advanced data problems using Machine Learning Willingness to collaborate with offshore development teams during off-hours At LEAPROS™, we are committed to our core values and guiding ethical principles, to conducting business in a non-discriminatory manner, and to operating in strict compliance with applicable federal and state laws pertaining to Equal Employment Opportunity. This commitment enhances our ability to conduct business with the highest level of integrity, solidifying our position as the most trusted workforce solutions partner.",Ejecutivo,Jornada completa,Tecnología de la información,"Servicios financieros, Software",30,None,True,,85,ACTIVELY_HIRING_COMPANY
729,2181696728,2020-10-27,SDG Group Iberia,IA Engineer (ML Ops),España,"Want some DataFun? SDG Group es una firma de consultoría global con un alto grado de especialización, ayudamos a nuestros clientes a rellenar el espacio que existe entre las acciones de negocio y los datos relevantes para la toma de decisión. Nos comprometemos en mejorar el rendimiento de nuestros clientes aplicando las mejores prácticas y los métodos y arquitecturas tecnológicas más innovadoras.   Qué harás:  Desarrollar soluciones basadas en datos, creando integraciones de modelos ML desarrollados por los data scientists.Despliegue simplificado de modelos ML en diferentes entornos de producción…. Gestionar todo el ciclo de vida del desarrollo, desde la implementación inicial del modelo hasta el test. Actualización y automatización de los modelos en cada fase del desarrollo, sin interrumpir el servicio a las aplicaciones de negocio. Proponer metodologías de desarrollo de software y buenas prácticas de código para los data scientist. Organizar y estructurar el código de los modelos de ML para optimizar la ingeniería de datosFacilitar el acceso a la documentación, comprensión y conocimiento haciendo uso de herramientas accesibles, impulsar el desarrollo de una cultura de código abierto.    Qué necesitas:  Formación en Informática, Telecomunicaciones, o similar Experiencia trabajando con Scala, patrones de diseño de software y TDD (Test Driven Development)Experiencia trabajando con grandes volúmenes de datos (Hadoop, Kafka…), incluyendo dominio de diferentes estructuras de bases de datos (SQL y NoSQL)Experiencia en integración y gestión de datos, idealmente en ecosistemas Cloud (AWS idealmente).Experiencia trabajando en entornos ágiles y continuos (Git, Jenkins, Sonar, Jira…)Será valorable tener conocimientos de desarrollo web con javascript e integración con APIs. Pasión por los datos y la analítica: desde las Data Architectures hasta la Visualización pasando por BI, Data Mining, Machine Learning o Predictive ModelingSerá muy valorable tu experiencia como desarrollador y tu interés en la Ciencia de los Datos. Aunque no tengas experiencia desarrollando algoritmos, puedes aportar conocimiento gracias tus habilidades de codificación y tu capacidad de enseñar mejores prácticas en desarrollo de software.Espíritu innovador con orientación equilibrada a cliente, negocio y tecnologíaInterés por los retos, compromiso, integridad, madurez, capacidad de trabajo en equipo y alto sentido de la responsabilidad  Qué ofrecemos: Formar parte de un equipo de primer nivel en el área de Data & AnalyticsLa oportunidad de integrarte en una empresa joven, dinámica, en plena expansión, con muy buen ambiente de trabajo, en la que se potencia el trabajo en equipo, la colaboración, el asumir nuevos retos y responsabilidades y se ofrecen múltiples oportunidades para crecer y desarrollarse personal y profesionalmenteUn plan de carrera profesional personalizado, trabajando en grandes proyectos, clientes y corporaciones a nivel local e internacionalUna retribución a la altura de la aportación profesional, negociable en función de la experiencia y los valores aportados Garantizamos absoluta confidencialidad en todo el proceso de selección",Intermedio,Jornada completa,"Consultoría, Tecnología de la información",Consultoría de estrategia y operaciones,37,None,False,,475,ACTIVELY_HIRING_COMPANY
730,2222439909,2020-10-30,tetrel.ai,Senior Machine Learning Engineer / Python Developer,"Berlin, Germany","tetrel is a start-up for machine-learning-based software solutions. Our customers include companies and non-profits in Germany and other European countries. The products and tailored solutions we create help organizations take better decisions, as well as improve their operations and processes.  We build complete machine learning software stacks, from data engineering, algorithm development, to deployment as APIs or apps. We are looking for a senior machine learning engineer / software developer to join our team remotely from anywhere in Germany or in our Berlin office. Your roleAs a member of our team, you build data-intensive applications, services, and data-science projects.You design, implement, and deploy the necessary algorithms, code, pipelines, and infrastructure.You take ownership of applications and service: you maintain, run and improve them over time. Your profileYou can work autonomously in a fast-changing, cooperative environment and have excellent problem solving skills.You communicate clearly and with empathy.Your software development skills (>2 years industry experience) are outstanding, and your command of Python is very good.You are passionate about building clean, maintainable, and efficient software.You have a deep understanding of and at least two years hands-on experience with machine learning algorithms and applied statistics.You have a good grasp of distributed systems, cloud computing and DevOps/MLOps workflows.You are based in Germany and have a valid work permit.Any of the following is a plus:A master’s or PhD degree in a field such as mathematics, physics or computer science.German language skills.Experience with NLP, Google Cloud, Kubernetes, Numpy, or pyTorch.Experience with Infrastructure as Code tools, e.g. Terraform or Pulumi. What we offerChoose your location. Work remotely or from our office in Berlin-Kreuzberg.Choose your schedule. No fixed schedule - everyone is responsible for getting their work done in time.Don’t waste your time on office politics and bureaucracy. We have a hands-on mentality and act fast.Escape Slack notification hell. We strive to build a work culture based on asynchronous communication. That means more time for uninterrupted, deep work. Learn with us. We welcome change and encourage constant learning in regard to technical, inter-personal and other skills.  Application processApply today with one click on LinkedIn or by email (please include your CV).A brief software development challenge. You complete a couple of Python functions, which are evaluated against the unit tests we provide (< 1 hour) and answer one question.Video call to get to know each other (30-45min).Interview with technical questions (remotely or in Berlin).Offer.",Algo de responsabilidad,Jornada completa,"Ingeniería, Tecnología de la información",Software,297,None,True,,1102,ACTIVELY_HIRING_COMPANY
731,2281960808,2020-11-06,ClassDojo,Data Engineer,"San Francisco, CA, US","ClassDojo's ultimate goal is to create an education system that gives every child on Earth an education they love. We are doing this by bringing together communities of teachers, children and families, and then helping them get learning experiences their children love. Last school year, we served over 40 million children—with a team of just 45.  Data is core to how ClassDojo makes decisions. As our third Data Scientist / Product Analyst, you'll help build a global consumer education business reaching tens of millions of parents, teachers, and children by creating, monetizing and analyzing products,. You'll grow ClassDojo to our next major milestone: reach 100 million+ active families, and 100 million+ in revenue, while deepening our brand love.  As a data science team, we work closely with partners across product, engineering, design, research and marketing to develop business insights and inform product and company strategy. We're looking for high-performing generalist data scientists, with experience in product and/or business analytics, to come work alongside us to take on some of the most interesting and impactful problems in education.  You'll shape direction as part of a high context, cross-functional team, where we value learning quickly to build a modern education system for hundreds of millions of teachers, children and families. You'll pursue a variety of problems ranging from understanding our users, to ensuring we invest in the right growth strategies in each of the 180+ countries we operate in, to growing our community, to empowering teams to find their own answers. You'll work with colleagues across the business to uncover insights, design experiments and measure the impact, and ultimately help influence decision-making across the entire company.  What you'll do:  Partner with product managers, engineers, marketers, designers, and operators to define product strategy and direction Develop analytical frameworks to monitor business and product performance, including growth and engagement Identify opportunities for growth by designing and analyzing product experiments, working with cross-functional teams to translate insights into action Empower teammates with the skills and tools to make data-driven decisions.   Relevant Skills / Experience  3+ years of industry experience in a data science or analytics role Ability to write structured and efficient SQL queries on large data sets Experience designing AB/multivariate tests and drawing actionable conclusions Ability to visualize and communicate insights to stakeholders Bonus: Experience with data pipelines: transforming raw production and external data into user-friendly tables. Americas timezones   About ClassDojo  ClassDojo's mission is to bring communities together, and help them create an education experience their children love. Founded in 2011 (ImagineK12 / Y Combinator) and based in San Francisco, California, ClassDojo started as a communication app: a simple way for teachers, families, and children to share the magic of the school day through photos, videos, and messages. It creates a close-knit classroom community, and exciting, inspiring and creative classrooms and homes for kids. We're one of the fastest growing education companies of all time, used and loved by tens of millions of teachers, families and children in 90% of K-8 schools in the US, and 180 other countries.  You can read more about our vision to change education from the ground up here: https://medium.com/@samchaudhary/https-medium-com-samchaudhary-how-to-change-education-from-the-ground-up-f82b8f3e4b95.  The Team  We believe focused, talented, non-hierarchical teams can achieve a surprising amount: https://blog.ycombinator.com/its-surprising-how-much-small-teams-can-get-done-sam-chaudhary-of-classdojo/. Our team is made up of engineers, designers, and educators from around the world, with deep backgrounds in education, as well as from leading consumer internet organizations like Instagram, Netflix, Dropbox, Uber, Y Combinator and more. We're building a company that will transform education, and one that is the kind of place we've all always wanted to work. We believe you'll do the best work of your life here.  Diversity  ClassDojo's vision is to give every child on Earth an education they love. We strongly feel the best way to do this is to work with people from diverse backgrounds that truly reflect the world. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. In accordance with the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records. We are happy to accommodate any disabilities or special needs. We hire both locally in San Francisco, and distributed teammates around the world.  If you're excited about having an impact in education at massive scale, we'd love to hear from you.",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Internet",69,None,False,,284,COMPANY_RECRUIT
732,2283725490,2020-10-14,Poloniex,Senior Data Engineer,"Boston, MA, US","We believe the future of finance will be built on open protocols, decentralized infrastructure, and rapid innovation. Poloniex enables 24/7/365 trading of digital assets. Since 2014, Poloniex has facilitated tens of billions of dollars in trades and custody for millions of customers around the world.  At Poloniex, you will work on the cutting edge of open financial protocols and build systems and tools that enable scalable, high performance trading. All our teams have high standards and a dedication to delivering high quality, high value solutions that meet the needs of millions of global customers. Come join us at Poloniex and build the future of finance!  As a Senior Data Engineer, you will work closely with data analysts, product managers, and software engineers to ensure secure, reliable delivery and accessibility of internal and external application data. You will help design a framework to enhance data visibility, efficiency, performance, and ease of use. You will build and maintain ETL pipelines, manage an enterprise data warehouse, and create a rock solid data science and machine learning platform.  What You'll Work On  Maintain a 100% cloud-based data architecture and enterprise data warehouse Build secure, reliable, and scalable ETL pipelines Develop internal tools and custom data solutions Collaborate with engineering teams and stakeholders across the organization Enable product owners to make informed strategic business decisions Create the foundation upon which advanced data science solutions will be built Be empowered to drive new initiatives and make a real impact   What You'll Bring To The Team  5+ years of data engineering experience Solid AWS chops (CloudFormation, S3, Glue, Lambda, RedShift, CodePipeline, Cloudwatch, ECS, SQS, SNS, you name it) SQL and relational database skills for days (MySQL, Postgres, Presto) Git, Linux, and Docker in your toolbox Python, Scala, and Spark in your lunchbox Electrical tape over your webcam (security conscious) Familiarity with front-end frameworks (JavaScript, Vue.js) A track record of writing good, clean code that adheres to SOLID principles Proficiency with at least one unit testing framework Plenty of experience digging through Splunk logs and tracking down bugs No ego and a strong desire to both teach and learn Ability to understand complex concepts and explain them in simple terms Comfort shifting gears and working on an evolving product without having all the answers  We are an equal opportunity employer and value diversity at Poloniex. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.  Hiring led by a service provider located in the United States.",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Internet",None,None,False,,1,ACTIVELY_HIRING_COMPANY
733,2249346989,2020-11-05,Applause,User Experience Researcher (Israel-based freelancer),Israel,"Usability studies are an Applause core service offering where we provide user feedback and UX studies to our customers. There are upcoming projects in Israel and we are currently looking for a UX Researcher who is a native or near-native Hebrew speaker and living in-country or very familiar with the country. Role: UX Researcher (freelance)Location: Remote, but local in-country Israel preferred Language: Native Hebrew: able to communicate effectively in EnglishDuration: Long term, open-ended Capacity: Variable, demand-based hours Responsibilities:Defining, planning and conducting user researchDelivering compelling insights to the Product and Design teamsProviding actionable feedback to guide Product and Design decisionsDeveloping, innovating and evangelizing user research best practices Qualifications:1+ years in a Usability Research role or relevant professional experienceFormal education in user experience or similar work experienceBroad experience in qualitative research methods, especially remote and unmoderated methodsComfortable with metrics: able to synthesize quantitative data with qualitative user researchProficiency in planning, scoping, conducting, analyzing and communicating researchEffective communicator able to work in native language and EnglishVery collaborative with a demonstrated ability to work effectively in a dynamic and creative environment",Intermedio,Media jornada,Tecnología de la información,Servicios y tecnologías de la información,17,None,True,,146,ACTIVELY_HIRING_COMPANY
734,2281984353,2020-11-06,Telnyx,"Backend Data Engineer, Java","Denver, CO, US","Working with a talented group of developers to focus on building a set of highly available, distributed services that powers our real-time telecommunication engine.  The Role  Our Java team runs a data pipeline that processes terabytes of telecom data. The majority of our services are critical for providing a great customer experience as they rely on our data platform. The languages we are using are Java and Scala, with a lightweight Jetty/Jersey/Scalatra stack.  You'll be part of a group of people working together to build solutions to mission-critical problems and a company that values the very best ideas. People rely on our products to communicate daily, which means they rely on us to build things with a high degree of resiliency and reliability.  In This Role You Will  Designing how to architect systems to allow for high performance and uptime. Writing well-structured code with special attention to optimization and scalability. Be involved in the full software development cycle which includes architecture definition, writing code, testing, participating in code review process, and automating deployment procedures. Effective code analysis and debugging. Participate in requirements analysis and transforming them into development tasks.  You May Be A Fit If You Have   Degree in Computer Science, Information Technology and/or equivalent work experience. Experience with Java and its ecosystem of tooling. Experience with Scala or other functional programming languages (Haskell, Clojure, Elixir, Erlang, etc.) is a plus. Experience with machine learning on Apache Spark or Tensor Flow.  Knowledge of various classification models, data normalization, and feature engineering. Experience with Linux, Git, Docker, in a CI environment (We can push code to production multiple times a day).   What It Is Like To Work At Telnyx  Telnyx is a complex machine with a simple purpose: connect people. We are an intelligent telephony engine, the beating heart of the Telnyx service that routes data along the pathways of our global, private network. We are drop-in APIs for hooking applications into our products, and an administrator portal that puts unprecedented control of configuring and orchestrating the Telnyx service into our customers' hands.  We're also an organization of industry experts and engineers focused on solving problems and building solutions. We're a concierge customer success team and a 24/7 support team. We're a communications partner, focused on agile and endless innovation, not a telecom slogged in antiquated processes and anti-competitive regulation. We keep the conversation going: the always-on, omnichannel, enriched conversation that the modern world demands.  Communications are coming untethered from devices, and more and more, they're migrating into our everyday platforms: our social media, our work applications, and our collaboration tools. But, that move started before there was infrastructure to support it—the modern internet will never offer the speed and consistency that real-time communications require. So, we built a network that does and a cloud platform tuned for real-time communications at every layer. Telnyx is the connective matrix, a worldwide nervous system, a high-speed rail tunnelling through the information superhighway. We're the foundation for calls, texts and messaging today, for the internet of things, augmented reality and 'communitainment' tomorrow, and for whatever enterprising imaginations can dream up after that.  We're Telnyx. We're the future of communications.  At Telnyx, we're looking for people with passion, grit, and integrity. You're encouraged to apply even if your experience doesn't precisely match the job description. Your skills and passion will stand out—and set you apart—especially if your career has taken some extraordinary twists and turns. At Telnyx, we welcome diverse perspectives and people who think rigorously and aren't afraid to challenge assumptions. Join us.",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Telecomunicaciones",5,None,False,,51,ACTIVELY_HIRING_COMPANY
735,2258324594,2020-10-05,AnswerLab,(Remote - Major Metropolitan Cities) Qualitative UX Researcher,"Austin, TX, US","In response to COVID-19, AnswerLab has transitioned all its client work to remote studies. This role is expected to be 100% home-based with no travel needs in the foreseeable future (12-18 months). Our commitment to our team's health and safety takes priority. In fact, we immediately transitioned all of our in-person studies to remote work in the beginning of this year to ensure the well-being and security of our people, clients, participants and partners. We may return to in-person research in the future at which point this role may require up to 25% of travel. Why We're Saying Bye to In-Person Research in 2020  Who We Are  We are a team of 130+ diverse insights experts who are passionate about solving UX challenges and creating experiences people love. AnswerLab is the leading UX Research firm in the US. We help powerful brands such as Amazon, Google, Facebook, FedEx, Wells Fargo, and Walmart bring a human-centered design process to every product launched. We focus on user experience research to understand what people see, do, think, and feel when using websites, mobile applications, voice interfaces, AR/VR, wearables, and other digital products. Our research studies are tailored to our clients' unique needs to provide clear, actionable recommendations that generate strategic business results. The secret to our success is no secret: It is the people who work here! We recruit only the most skilled and client-focused professionals to join our team. All are devoted to being at the forefront of the user experience industry. Our team is made up of smart, down-to-earth people who value a 'get it done' attitude as well as a good dose of humor during our work day. We empower them to do what they do best: lead impactful research studies from planning to analysis for the world's most innovative brands.  Who You Are  You are a driven, ambitious and results-oriented individual who is deeply passionate about UX Research. You have 5+ years of hands-on experience moderating 1:1 usability studies on large scale websites/mobile devices, and you want to become a part of a team whose mission is to improve the digital world by creating experiences people love. You thrive in a home-based work environment, and you are comfortable conducting research remotely. Click here to learn more about the AnswerLab culture and why people choose to join our team. The Qualitative UX Researcher Role AnswerLab is a growing user experience research firm that assists clients in measuring and improving the experience of their online customers. Example research methods include one-on-one usability studies (remote and in-person), eye-tracking, remote usability studies, online and in-person focus groups, mobile device testing, card sorting, ethnography, and quantitative benchmarking studies. Global market leaders select AnswerLab as their user experience research partner including Google, Amazon, Facebook, FedEx, Wells Fargo and Walmart.  The Qualified Candidate Will Be Responsible For  Working with clients to understand business needs and to craft UX research solutions Assisting in the development of screener surveys for identifying clients' target users Monitoring the participant recruiting process Developing moderator guides Consulting with clients on the development of prototypes for testing Managing technical setup for in-person labs Moderating remote and in-person user experience research studies or conducting interviews in field Analyzing the research findings Developing PPT presentations to communicate findings and recommendations Presenting to executives Keeping projects on schedule and within scope and budget Building a trusted advisor relationship with clients Contributing to AnswerLab's knowledge library Collaborating with colleagues to solve research challenges We understand that outstanding candidates can come from a variety of backgrounds. While specific experience is important, we are ultimately looking for candidates who have the personal characteristics to thrive in a growing client-focused business. The qualified candidate will have experience in and meet most of the criteria listed below.  Leading consulting engagements with clients -- either in research specifically or with a management consulting firm that uses analytical data to support conclusions 5+ years of hands-on experience moderating 1:1 usability studies, particularly on large scale websites, web-based applications or mobile devices Experience in financial services preferred Designing and writing discussion guides, screeners, test protocols, and final reports Using online/remote usability tools (i.e. Zoom, WebEx, GoToMeeting, etc.) Conducting presentations with senior-level business managers and executives Working with the Internet and web-based tools Demonstrated ability to 1) work independently and drive towards deadlines, 2) produce high-quality deliverables for clients, and 3) think creatively and solve problems. Ability to engage with business and research managers in Fortune 500 companies. Excellent communication skills and the ability to facilitate discussions Ability to work in a fast-paced deadline-driven environment, manage competing priorities, and be an independent problem-solver Presentation skills, including building PowerPoint presentations and presenting results and recommendations to clients Undergraduate and/or advanced degree - preferably an educational background in Experimental Psychology, Cognitive Psychology, Human Factors, Human Computer Interaction, or other related discipline with a solid foundation in research-based design using both quantitative and qualitative methods AnswerLab's Core Values  Build trust Provide amazing service Support and Encourage Inclusivity Jump in to help others Handle change with flexibility Innovate our products and processes Figure it out and get it done Make AnswerLab a great place to work Physical Requirements  Overtime may be required to meet project deadlines. Sitting for extended periods of time. Dexterity of hands and fingers to operate a computer keyboard, mouse, and other devices and objects. This is a full-time position. No staffing/recruiting agencies please. We are interested in every qualified candidate who is eligible to work in the United States, however, we are not able to sponsor visas. At AnswerLab, our mission is to create experiences people love. This means we strive to make our company a great place to work for people from all walks of life. Hiring people from a wide variety of backgrounds makes our company stronger and helps us achieve our mission. We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity and/or expression, status as a veteran, and basis of disability or any other federal, state or local protected class.",Director,Jornada completa,"Otro, Tecnología de la información, Gestión","Marketing y publicidad, Servicios y tecnologías de la información, Software",6,None,False,,61,None
736,2243514544,2020-11-05,Confidential,Researcher,Lithuania,"An exciting opportunity has opened up with a brand new fintech startup, for anyone aiming high in their career! We are seeking a young, dynamic, fast moving researcher with strong research and analytical skills, aiming to start their career in a well-reputed company and gain valuable expertise in the fintech domain! The ideal candidate should be fast learners, have an entrepreneurial mindset as well as basic web analytics and business research tools knowledge. If you are a highly motivated individual with an interest in the fintech environment, you have a passion to learn and grow with the company, share your application with us! Key Accountabilities:Coordinate with the company management to determine research objectivesWork in accordance to project brief and deliver frequent project updatesDevelop and direct given research assignmentsCreate a plan of action and set project goals and manage them to completionFormulate effective and efficient research processesIdentify market trends and patternsPerform fieldwork, interviews, experiments, concept-test, etc. to gather dataConduct detailed research of intended subject matter according to the business needsCollect data on consumers, competitors and market place and consolidate information into actionable items, reports and presentationsPerform valid and reliable market research SWOT analysisInterpret data, formulate reports and make recommendationsProvide competitive analysis on various companies’ market offerings, identify market trends, pricing/business models, sales and methods of operationProvide analysis of trends and forecasts and recommend actions for optimizationIdentify and drive process improvements, including the creation of standard and ad-hoc reportsOrganize and maintain research databasesUse Excel functions to organize and analyze dataCreate charts, graphs, and presentations for group management Requirements Required Skills / Qualifications:BS degree in Business, Statistics, Research, Economics or related fieldProven research analysis experienceKnowledgeable in various research and testing methodologiesAbility to interpret large amounts of data and to multi-taskStrong communication and presentation skillsSearch engines, web analytics and business research tools acumenStrong analytical and critical thinkingProficient using Microsoft OfficeStrong math and statistical skillsWell-versed in database managementExtra languages advantage: English, Lithuanian, Polish",Algo de responsabilidad,Jornada completa,"Investigación, Análisis, Tecnología de la información",None,90,None,True,,706,COMPANY_RECRUIT
737,2243221960,2020-10-02,Interactive Resources - iR,Sr. Data Scientist (REMOTE),"Jacksonville, FL, US","Data Scientists produce innovative solutions driven by exploratory data analysis from complex and high-dimensional datasets. Apply knowledge of statistics, data modeling, and advanced mathematics to recognize patterns, identify opportunities, pose business questions, and make valuable discoveries. Use a flexible, analytical approach to design, develop, and evaluate predictive models. Generate and test hypotheses. The Data Scientist proactively seeks to develop their skill sets and provide value-added support within the Data Science team.  Essential Functions  Communication & Project Ownership  Support large projects, and manage smaller projects in their entirety Partner with senior team members to assess customer needs and define business questions. Emerging ability to influence customers to take action on analytical insights. Communicate results and insights, both verbally and written (including visual graphics), in a clear and concise manner to a non-technical audience. Identify and communicate roadblocks. Work on multiple concurrent projects and accommodate frequent interruptions and changing priorities Effectively participate in meetings with customers and emerging ability to guide discussion and decision making. Data Analysis  Acquire and bring structure to data so that it can be used in existing and new data systems. Build tools that help you and the other Data Scientists translate insights into action at scale. Identify, define and translate business needs/problems into analytical questions. Design and execute experiments, models, algorithms, and visualizations Understand data sources and limitations, warehousing system and the impact of the data on business decisions. Identify, retrieve, and manipulate data from internal and external datasets. Apply statistical and computational methodologies to provide actionable insights and identify opportunities that optimize quality, consumer experience, and healthcare costs. Develop scalable, efficient, and automated processes for large scale data analyses and model development, validation, and implementation. Reporting & Other  Contribute to technical reports, white papers, and publications. Stay current on new processes and technology in Data Science and communicate findings to team Perform all other tasks as assigned Job Requirements  Strong programming experience in R, or Python Requires expert proficiency in SQL Strong analytical and problem-solving skills Experience in supporting large projects, and manage smaller projects in their entirety Ability to partner with senior team members to assess customer needs and define business questions. Emerging ability to influence customers to take action on analytical insights. Ability to communicate results and insights, both verbally and written (including visual graphics), in a clear and concise manner to a non-technical audience. Must have applied experience with advanced analytics e.g. predictive analytics models Must have applied experience in Machine Learning Experience in Big Data - e.g. s3/presto is a plus Business Intelligence tool development Other programming experience - Java, Perl, UNIX/Linux scripting Healthcare, medical, or pharmaceutical work experience Experience with analysis around quality, consumer experience, and healthcare costs Experience in consumer analytics Experience in business analytics Required Experience  5-8 years related work experience in advanced analytics or equivalent combination of transferable experience and education  Minimum Five Years' Experience As a Data Scientist  PhD or Masters in a quantitative discipline: Computer Science, Statistics, Applied Mathematics, Operations Research, Engineering Working knowledge of health care systems and healthcare terminology Expert in various healthcare datasets. Expert in analyzing large complex, multi-dimensional data sets with a variety of tools Ability to thrive and demonstrate constant applied learning in highly complex, interdisciplinary, and dynamic work environment Design anomaly detection models to detect and eliminate FWA in claim payments. Experience in implementing Machine Learning Models to gain efficiencies in Claims Prepay / Post Pay reviews  Required Education  Related Bachelor’s degree in Data Science, Applied Mathematics, Computer science (e.g. specialization: Machine learning/Artificial Intelligence /Visualization, databases, and Big Data), Statistics, Epidemiology, Health Services Research, or closely related field with Data Science specialization or additional related equivalent work experience",Algo de responsabilidad,Jornada completa,Otro,"Servicios y tecnologías de la información, Software, Servicios financieros",8,None,False,,53,ACTIVELY_HIRING_COMPANY
738,2244812931,2020-10-27,Adaptive Biotechnologies Corp.,AI/ML Software Architect Manager,"Seattle, WA, US","Every immune system has a story to tell— the key is knowing how to listen. Our goal is to meaningfully improve people's lives by learning from the wisdom of their adaptive immune systems. It's a bold objective that we're uniquely built to achieve.  At Adaptive, you'll be challenged, you'll be inspired, and you'll be part of an innovative organization making a real impact on improving the quality of life globally. No matter what your role is, you'll find a diverse, team-driven, fun culture where your contributions truly count.  Position Overview  The AI/ML Software Architect is responsible for leading Adaptive efforts to create a solid software foundation for implementing AI / Machine Learning (ML) algorithms and approaches into validated, maintainable code. In particular, this role will require close work with both Adaptive teams working on data science, computational biology, and ML as well as those at our outside partners such as Microsoft. These efforts support company initiatives and important projects in a range of areas, including high-profile projects in diagnostics and therapeutics development. As such, these software development projects will happen in a regulated setting, and an important part of the AI/ML Software Architect's role will be managing how the implementation of software around these novel algorithms happens in a regulatory-compliant manner. The AI/ML Software Architect develops architectures, standards, and long-term strategies and approaches for continuous improvement in process, technology, and systems in support of this work. This role also frequently interacts and coordinates with senior and executive level staff across diverse company functions.  Responsibilities  Lead the development of software architecture to support the operational implementation of machine learning and other AI algorithms and tools. Work with colleagues throughout Adaptive and partner organizations to scope, plan, and implement a shared workbench – combining of version-controlled analytics tools and data combining version-controlled analytics tools and data across the company and with partners. Leading the architecture and development of shared data and analytics resources which will be the basis for future product development research, and the core of future data products for the company.   Requirements  Master's degree or Ph.D. in computer science, data science or artificial intelligence preferred, will consider a Bachelor's degree in those fields with significant related work experience. 5+ years of full-time experience as either an AI or ML Engineer or Data Scientist 5+ years of experience with architecture, design and implementation of AI/ML technologies 5+ years of pharmaceutical / life sciences experience is desired 5+ years programming in tools such as C++, Java, or Python Knowledge and experience with full AI solutions lifecycle including model management, model deployment and more Strong influencing and collaboration skills in working across organizational boundaries Excellent written and oral communications skills – aimed at both internal and external audiences, in both technical/scientific and non-technical roles. Excellent communication and interpersonal skills, with ability to building trust, listen, and ask effective questions with the goal to create a scalable and reusable business solution  Working Conditions  The position is currently completely remote, at least until we resume normal business operations at Adaptive. There is a possibility that the role may be able to be fully remote in the future, with some onsite work required on an occasional but regular basis. Formal site of work will be Adaptive's Seattle-area location.  Adaptive Biotechnologies is proud to be an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability. Equal Opportunity Employer/Veterans/Disabled  NOTE TO EMPLOYMENT AGENCIES: Adaptive Biotechnologies values our relationships with our Recruitment Partners and will only accept resumes from those partners whom have been contracted by a member of our Human Resources team to collaborate with us. Adaptive Biotechnologies is not responsible for any fees related to resumes that are unsolicited or are received by any employee of Adaptive Biotechnologies who is not a member of the Human Resources team.",Algo de responsabilidad,Jornada completa,"Ingeniería, Tecnología de la información","Biotecnología, Atención sanitaria y hospitalaria, Industria farmacéutica",3,None,False,,77,ACTIVELY_HIRING_COMPANY
739,2283746903,2020-11-06,CitySwift,Machine Learning Engineer,"Galway, IE","This is an exciting opportunity to be part of a brilliant team in a fast-paced, collaborative environment. You will have the chance to influence and shape our Product, Technology and Data Science strategy while working with billions of data points by developing machine learning models to solve real-world, measurable problems!  About CitySwift  CitySwift is a Cloud-native, specialist data engine for modern bus networks. We optimise urban bus networks using Big Data and Analytics. Ultimately, we improve the reliability of services while simultaneously reducing Operator costs, resulting in a win-win for both passengers and operators!  Our Company Values  Be Open & Honest Take Ownership & Finish it! Think like a Customer Alright is not OK! Be up for the challenge.   What You'll Do  Liaise between R&D data scientists and software engineers to prepare and implement productionisation of predictive and statistical models. Develop scalable feature engineering pipelines and from a multitude of data sources at varying frequencies. Facilitate best implementation and usage of model outputs be it batch or real time predictions. Work closely with data scientists to develop continuous evaluation and performance degradation reporting.   What You Bring  Proven experience productionising models using cloud computing and serving predictions in a variety of manors. A solid understanding of machine learning model capabilities and requirements to implement a scalable solution.  Experience of pipe-lining technologies for data large scale data curation such as Apache beam.  Experience using TensorFlow Transform for preprocessing at scale. Experience of varying hosted and cloud compute for model training and predicting.  Experience of hosted models for on demand prediction generation.   It would be great if you have  Experience with multiple neural networks architectures and approaches. Knowledge of model explain-ability and automated evaluation.  Experience with GIS software/analysis tools as well as routing algorithms with a focus on machine learning integration.   What We Can Offer You  Opportunity to make your mark in a high growth Irish Tech Company The product is scaling, with constant engagement and feedback from users and clients to inform the development roadmap. Ideas are listened to and encouraged. Experts are allowed to make decisions Open, transparent culture where everyone is kept informed and committed to the company's future.  We hire the best so that everyone can learn from each other Office in City Centre location. Flexible hours and remote working opportunities Generous Healthcare  Bike to Work & Taxsaver commuter scheme Competitive compensation  Active social club where employees are encouraged to have fun together both inside and outside of work!",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información",Servicios y tecnologías de la información,13,None,False,,161,ACTIVELY_HIRING_COMPANY
740,2242903230,2020-10-01,Michael Page,Senior Data Engineer (Remote interview process confirmed),"Peterborough, GB","Senior Data Engineer (Remote interview process confirmed) Opportunity to join a rapidly expanding teamOpportunity to work in an advanced analytics function  About Our Client  Global Manufacturer / Distributor  Job Description  Global Manufacturer are looking for a Data Engineer to work with software developers, database architects, data analysts and data scientists on strategic data initiatives. The Data Engineer will be responsible for expanding and optimizing data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. As Data Engineer you will be responsible for: Create and maintain optimal data pipeline architecture, Assemble large, complex data sets that meet functional / non-functional business requirements.Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL/Non-SQL and Azure 'big data' technologies Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisitionoperational efficiency and other key business performance metricsWork with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs Keep our data separated and secure across national boundaries through multiple data centres and Azure regions Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader. Work with data and analytics experts to strive for greater functionality in our data systems. For developing, constructing, maintenance and testing of data architectures, such as databases and large-scale processing systemsClean, aggregate, and organize data from disparate sources and transfer it to data storage for analysis. Making sure the companies data technology is operating at its peak results in massive improvements to performance, cost, or both Owning the stability of new products designed, including the on-going robustness, resilience and stability of these products Building and maintaining custom ingestion pipelines Experienced using the following software/tools: Big data tools: Hadoop, Spark, Kafka, etc. Relational SQL and NoSQL databases, including Postgres and CassandraData pipeline and workflow management tools: Azkaban, Luigi, Airflow, etcAWS cloud services: EC2, EMR, RDS, Redshift Stream-processing systems: Storm, Spark-StreamingObject-oriented/object function scripting languages: Python, Java, C++, ScalaData Integration / Archiving / Relational Databases and Data Warehousing MS SQL, Logic Apps, Function Apps, SSIS, SSRS Microsoft Azure DevOps Data Visualisation   The Successful Applicant  Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.Experience building and optimizing 'big data' data pipelines, architectures and data sets.Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.Strong analytic skills related to working with unstructured datasets.Build processes supporting data transformation, data structures, metadata, dependency and workload management.A successful history of manipulating, processing and extracting value from large disconnected datasets.Working knowledge of message queuing, stream processing, and highly scalable 'big data' data stores.Strong project management and organizational skills.  Experienced using the following software/tools: Big data tools: Hadoop, Spark, KafkaRelational SQL and NoSQL databases, including Postgres and CassandraData pipeline and workflow management tools: Azkaban, Luigi, AirflowAWS cloud services: EC2, EMR, RDS, RedshiftStream-processing systems: Storm, Spark-StreamingObject-oriented/object function scripting languages: Python, Java, C++, ScalaData Integration / Archiving / Relational Databases and Data WarehousingMS SQL, Logic Apps, Function Apps, SSIS, SSRSMicrosoft Azure DevOpsData Visualisation  What's On Offer  Opportunity to join a rapidly expanding team Opportunity to work in an advanced analytics function  Contact: James Hobson Quote job ref: 14088200",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Ingeniería industrial o mecánica, Manufactura eléctrica/electrónica",3,None,False,,28,COMPANY_RECRUIT
741,2230267104,2020-10-31,Skyrocket Ventures,Sr. to Lead Data Engineer - leading Blockchain company,San Francisco Bay Area,"Sr. to Lead Data Engineer - leading Blockchain companyLocation: Remote (both during and after the pandemic). It has always been a remote-first company. If you prefer to work in an office, the company can pay for shared office space for you.  The company is one of the top companies in the blockchain and cryptocurrency realm. Candidates must either have a passion for the space or at least a strong interest in getting into the space. The company has about 60 employees and 20 engineers, is very strong financially, and is rapidly growing. The company will pay up to $200k in salary (depending on experience), plus about crytocurrency tokens which could be lucrative.  Job Responsibilities: - Designing and architecting the data warehouse and ETL for data ingestion and processing. - Collaborating with other software engineers on various components of the data pipeline. - Interacting with the blockchain to gather data. - Working the the tech stack which includes Golang, TypeScript, Solidity, AWS, PostgreSQL, and more.  Requirements: - Experience building data pipelines ingesting large amounts of data. - Passion for blockchain. - Strong programming ability with one of these: 1) Go, 2) TypeScript, 3) Python, 4) Ruby or Scala, 6) Java. - At least 4 years of professional experience. - Experience with distributed systems.  Nice to have: - Blockchain experience. - Experience with Go. - Experience with TypeScript. - Experience with Mapreduce. - Experience with Spark. - Experience with container orchestration.",Intermedio,Jornada completa,Ingeniería,"Software, Internet, Servicios financieros",28,None,True,,133,ACTIVELY_HIRING_COMPANY
742,2208419235,2020-10-23,Smiths Detection,Senior Research Scientist - Coelenterazine,"Baltimore, Maryland, United States","Smiths is the global leader in threat detection and security screening technologies. Every minute of every day, Smiths Detection’s threat detection and security screening technology helps to protect people and infrastructure, making the world a safer place. We deliver the solutions needed to protect society from the threat and illegal passage of explosives, prohibitive weapons, contraband, toxic chemicals and narcotics.Our goal is simple – to provide the security, peace of mind and freedom of movement upon which the world depends. Smiths Detection’s global presence, combined with strong relationships with distributors and representatives, provides customers with sales and service support around the world. We have manufacturing facilities established in France, Germany, Malaysia, the UK and USA, with some of these also serving as R&D centers of excellence. Sales and Service centers in 17 countries to provide global coverage. This is an exciting opportunity to lead the technical aspects of creating a genetic cassette for de novo biosynthesis of coelenterazine. This role will source and obtain the required reagents and cells required. Day-to-day responsibilities:Initiate, execute, and manage protocol creation, evolution, and documentation of experimental procedures and results.Analyze, summarize, and present experimental results to manager and other team members.Lead and manage project to assure major milestones are met and kept within budget. Requirements:Education: Ph.D. in Chemistry, Biochemistry, Bioengineering, or related fields.Ideal candidates will excel in bacterial genetic engineering and synthetic biology methods, genome analysis and manipulation of copepods and related organisms, and are well-versed in luciferin biosynthesis.Working knowledge of genetics, gene regulation, and protein engineeringExperience with a variety of biophysical characterization techniques such as protein chromatography and fluorescence spectroscopy.Demonstrated abilities to work independently and creatively to solve critical research problems.Excellent collaboration, organizational, communication (oral and written) and multitasking skills.Willingness to work flexible hours to meet project timelines.Strong evidence of scientific productivity.",Intermedio,Jornada completa,"Ciencias, Diseño, Gestión de productos","Departamento de defensa y del espacio exterior, Industria farmacéutica, Biotecnología",25,None,True,,196,ACTIVELY_HIRING_COMPANY
743,2174230258,2020-10-25,Realogy Holdings Corp.,Senior Big Data Engineer - Remote,"Emeryville, CA, US","Job Description  Senior Big Data Platform Engineer  Join us as we build a next-generation Enterprise Analytics Platform to reengineer a real estate enterprise. As a Senior Big Data Platform Engineer, you will be joining our Enterprise Analytics Platform Team to build EAP platform from ground up to serve agents, brokers, home buyers and sellers.  What We’re Looking For  You’re a talented, creative, and motivated Data Platform Engineer who loves to build data platform tools. Be ready to work with a team of individuals who share your passion. With a related degree and relevant experience you’re ready to take your programming and data knowledge to the next level. You enjoy building tools such as Data Ingestion Platform to ingest data from diverse sources to Data Lake, building data lake tools to ingest data, monitor pipelines, and grant access to data. With your commitment to quality, excellent data/cloud skills, and collaborative work ethic, you’ll do great things here at Realogy AI Lab.  What You’ll Do  You’ll be responsible for designing and building high performance, scalable data solutions that meet the needs of millions of agents, brokers, home buyers, and sellers.  You’ll work with other Data Engineers for build out of Next Generation Data Ingestion Platform.  You’ll design and develop data ingestion pipelines for batch and real-time streaming of data from in-house OLTP systems and third-party data.  You’ll work with team to design and develop Data Lake to store and process 10s of terabyte of data.  You’ll work with team to design Data Lake CLI to manage Data Lake Storage and Access.  You will design and develop ETL pipelines to process data in data lake for descriptive and prescriptive reporting.  You’ll develop ETL data pipelines to build Enterprise Data Models for Property, Agent, Broker, office and other master entities.  You will design and develop CI/CD process for continuous delivery in AWS Cloud.  You’ll design, develop, and test robust, scalable data platform components.  You’ll work with a variety of teams and individuals, including product engineers to understand their data pipeline needs and come up with innovative solutions.   Education And Experience/Special Skills/Technologies/Tools Requirements  When using experience as a requirement, please quantify the number of years required.  Bachelor’s in Computer Science, Engineering, or related technical discipline or equivalent combination of training and experience.  10+ years programming experience: building business logic layers and back-end systems for high-volume pipelines.  2 years' experience with Golang.  2 years' experience with Spark, Spark SQL, and Scala.  2 years' experience using AWS Data Services: any combination of DMS, EMR, Glue, Athena, S3, CloudWatch, Lambda or IAM.  2 years' experience with high-speed messaging frameworks and streaming (Kafka).  1-year exp. with data architecture, ETL and processing of structured and unstructured data.  2 years' experience with DevOps tools (any combination of GitHub, Travis CI or Jira) and methodologies (Lean, Agile, Scrum, Test Driven Development)  Excellent written and verbal communication skills in English.   Employment Type Full-time  Company  Realogy Holdings Corp  About Us  Realogy Holdings Corp. (NYSE: RLGY) is the leading and most integrated provider of U.S. residential real estate services, encompassing franchise, brokerage, and title and settlement businesses as well as a mortgage joint venture. Realogy’s diverse brand portfolio includessome of the most recognized names in real estate: Better Homes and Gardens® Real Estate , Century 21® , Coldwell Banker® , Coldwell Banker Commercial® , Corcoran® , ERA® , Sotheby's International Realty® . Using innovative technology, data and marketing products, best-in-class learning and support services, and high-quality lead generation programs, Realogy fuels the productivity of independent sales agents, helping them build stronger businesses and best serve today’s consumers. Realogy's affiliated brokerages operate around the world with approximately 190,000 independent sales agents in the United States and more than 112,000 independent sales agents in 113 other countries and territories. Recognized for nine consecutive years as one of the World’s Most Ethical Companies , Realogy has also been designated a Great Place to Work and one of Forbes’ Best Employers for Diversity . Realogy is headquartered in Madison, New Jersey. At Realogy, diversity fuels success – for our company and for our employees. We strive to be the preferred company for diverse talent, committed to creating an inclusive environment that encourages everyone to succeed. We pursue talent – strategic thinkers who are eager to innovate, focused on execution and accountable for results. We value diversity – respecting backgrounds, cultures, perspectives. You’ll find our commitment to diversity reflected in our achievements:  Forbes 2020 Best Employers for Diversity.  Recognized on the 2020 Human Rights Campaign Corporate Equality Index .  Recognized for gender diversity on our board of directors by Executive Women of New Jersey and Women’s Forum of New York.  First residential real estate company to endorse the Equality Act and fully support H.R. 1447 amending the Fair Housing Act to include LGBTQ+ as protected classes.  With diversity, we succeed together. We hope you’ll join us. EEO Statement EOE AA M/F/Vet/Disability",Algo de responsabilidad,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Software, Servicios financieros",24,None,False,,248,COMPANY_RECRUIT
744,2242903230,2020-10-01,Michael Page,Senior Data Engineer (Remote interview process confirmed),"Peterborough, GB","Senior Data Engineer (Remote interview process confirmed) Opportunity to join a rapidly expanding teamOpportunity to work in an advanced analytics function  About Our Client  Global Manufacturer / Distributor  Job Description  Global Manufacturer are looking for a Data Engineer to work with software developers, database architects, data analysts and data scientists on strategic data initiatives. The Data Engineer will be responsible for expanding and optimizing data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. As Data Engineer you will be responsible for: Create and maintain optimal data pipeline architecture, Assemble large, complex data sets that meet functional / non-functional business requirements.Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL/Non-SQL and Azure 'big data' technologies Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisitionoperational efficiency and other key business performance metricsWork with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs Keep our data separated and secure across national boundaries through multiple data centres and Azure regions Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader. Work with data and analytics experts to strive for greater functionality in our data systems. For developing, constructing, maintenance and testing of data architectures, such as databases and large-scale processing systemsClean, aggregate, and organize data from disparate sources and transfer it to data storage for analysis. Making sure the companies data technology is operating at its peak results in massive improvements to performance, cost, or both Owning the stability of new products designed, including the on-going robustness, resilience and stability of these products Building and maintaining custom ingestion pipelines Experienced using the following software/tools: Big data tools: Hadoop, Spark, Kafka, etc. Relational SQL and NoSQL databases, including Postgres and CassandraData pipeline and workflow management tools: Azkaban, Luigi, Airflow, etcAWS cloud services: EC2, EMR, RDS, Redshift Stream-processing systems: Storm, Spark-StreamingObject-oriented/object function scripting languages: Python, Java, C++, ScalaData Integration / Archiving / Relational Databases and Data Warehousing MS SQL, Logic Apps, Function Apps, SSIS, SSRS Microsoft Azure DevOps Data Visualisation   The Successful Applicant  Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.Experience building and optimizing 'big data' data pipelines, architectures and data sets.Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.Strong analytic skills related to working with unstructured datasets.Build processes supporting data transformation, data structures, metadata, dependency and workload management.A successful history of manipulating, processing and extracting value from large disconnected datasets.Working knowledge of message queuing, stream processing, and highly scalable 'big data' data stores.Strong project management and organizational skills.  Experienced using the following software/tools: Big data tools: Hadoop, Spark, KafkaRelational SQL and NoSQL databases, including Postgres and CassandraData pipeline and workflow management tools: Azkaban, Luigi, AirflowAWS cloud services: EC2, EMR, RDS, RedshiftStream-processing systems: Storm, Spark-StreamingObject-oriented/object function scripting languages: Python, Java, C++, ScalaData Integration / Archiving / Relational Databases and Data WarehousingMS SQL, Logic Apps, Function Apps, SSIS, SSRSMicrosoft Azure DevOpsData Visualisation  What's On Offer  Opportunity to join a rapidly expanding team Opportunity to work in an advanced analytics function  Contact: James Hobson Quote job ref: 14088200",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Ingeniería industrial o mecánica, Manufactura eléctrica/electrónica",3,None,False,,28,COMPANY_RECRUIT
745,2290357541,2020-10-14,Prima Assicurazioni,UX Researcher (Full Remote possibility),"Milano, IT","Description  We are looking for a UX Researcher to join our team, working directly with Product and IT.  Chi cerchiamo  You are our ideal candidate if you meet these requirements:  3 years experience in user resarch for development and optimization of websites and web platforms, possibly with Enterprise or Business Software, Services, Developer Tools, IT  2 years experience in coordinate and manage On-Site Surveying and interview sessions using Recording / Heatmapping methodologies  experience in creation and facilitation of Design Thinking workshops  experience in Quantitative Research and Experiment Desing  good knowledge of Tracking Tools (such as Content Square, Parsley and Google Analytics)  good experience in User and Consumer Behaviour applied to digital products  Sarebbe fantastico se  We Will Also Evaluate These Skills  bachelor's deegree in Anthropology, IT or equivalente practical experience  ability to create wireframe and prototypes  excellent knowledge of the english language  Come puoi aiutarci  Particularly, You Will Carry Out  In Prima you will join the UX & Design Team and you will take care of planning, handling and analysing the outcome of all the User Resarch activities, using a Human-Centric approach.  Custer Interviews  Focus Groups  User Tests  Etnographic Studies  Creation of Customer Journeys  You will be responsible of gathering quantitative and qualitative data, useful for build up a deep knowledge of our users. You will work close together with Analytics and Product Teams, in order to turn insights into actions to implement on Prima.it  Tipologia contrattuale  Meal vouchers, trainging moments, team bulding events, latest generation hardware and devices: in Prima you will find everything you need to do your job at your best.  Salary and contract type will be evaluated during the interview, in order to offer an adequate pay to the real expertise and competence of every singole person.  It's a full-time employment and our office is in Milan, in piazza Cordusio, but we also consider Full Remote hiring.",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Internet, Seguros",0,None,False,,14,None
746,2216919457,2020-10-18,BetterUp,Data Engineer,"San Francisco, CA, US","BetterUp is a mobile-based coaching platform that brings personalized professional coaching to employees at all levels. We help managers lead better, teams perform better, and employees thrive personally and inspire professionally. Our mission is to help professionals everywhere pursue their lives with greater clarity, purpose, and passion. Our product was developed by a team of leading behavioral scientists, researchers, and technologists to bring evidence-based learning to professionals everywhere. We’re already transforming the way companies approach talent development at high-performing organizations like Genentech, Mars, LinkedIn, and Workday. Let’s build together!  As a Data Engineer at BetterUp, you will be joining a small team responsible for the data systems that power everything from operational efficiency of the business, to personalized product experiences, to cutting-edge behavioral research and organizational analytics. You will be responsible for the end-to-end implementation of the data stack from collection to reporting, with a focus on infrastructure and technical processes. You will be directly responsible for working with stakeholders around the business to ensure their data needs are met, define data strategies, implement data systems, and help infuse data into transformational experiences. In general, you will be responsible for understanding problems intimately, crafting a technical strategy to address problems, and facilitating high-quality technical execution.  We live by three guiding principles regarding data and analytics:  Data Accessibility: Collected data should be accessible, or appropriately inaccessible, to all services, products, and people of the organization.  Data Approachability: Data should be intuitively familiar to the observer.  Data Awareness: Cultivate a community of data-conscious practitioners.   We care very much about empowering and encouraging each and every person with data. We build for the future while delivering on high-value value objectives along the way.  Responsibilities  Data Unifier: Architect, assemble, assimilate, clean, and conform large, complex datasets to deliver business insights and power product experiences. Data Advocate: Weave data into decision-making and drive cross-functional data-oriented approaches and solutions. Data Protector: Design and build reliable, scalable data infrastructure with leading privacy and security techniques to safe guard data. Data Builder: Own the end-to-end data stack including event collection, data governance, data integrations, and modeling.  Data Custodian: Ensure consistency and quality through metrics, documentation, processes, data testing, and training.  If you have some or all of the following please apply:  Experience with analytic databases (e.g. Snowflake). Advanced knowledge of SQL and experience with relational databases. Hands-on experience developing data pipelines. We use (e.g. dbt, Airflow, Stitch Data / Singer specs) . Hands-on experience with event streams and stream processing (e.g. Kafka, Spark, Data Bricks, Segment). Decoupling transactional or source systems from business intelligence reporting (e.g. dimensional modeling). Experience with creating high-quality, fast services and projects in Python.  Experience with modern business intelligence and product reporting tools (e.g. Mode, Looker, Periscope).   Benefits  At BetterUp, we are committed to living out our mission every day and that starts with providing benefits that allow our employees to care for themselves, support their families, and give back to their community.  Access to BetterUp coaching: one for you and one for a friend or family member  A competitive compensation plan with opportunity for advancement Full coverage for medical, dental and vision insurance Employer Paid Life, AD&D, STD and LTD insurance Flexible paid time off Per year:  13 paid holidays  4 BetterUp Inner Work days (https://www.betterup.co/inner-work) 5 Volunteer Days to give back Learning and Development stipend  Holiday charitable contribution of your choice on behalf of BetterUp 401(k) self contribution  BetterUp Inc. provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, disability, genetics, gender, sexual orientation, age, marital status, veteran status. In addition to federal law requirements, BetterUp Inc. complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.",Intermedio,Jornada completa,Ingeniería,Formación profesional y capacitación,132,None,False,,684,ACTIVELY_HIRING_COMPANY
747,2276169630,2020-10-11,Brightside,Senior Data Engineer,"Phoenix, AZ, US","Company Overview:  Brightside is an employee benefit with a brand new approach to personal finance. We offer unique solutions for employees & their families who need help wrangling their finances - solutions that are only available through the Brightside benefit provided by their employer. We take a holistic view of an employee to provide unbiased and confidential assistance through an unmatched blend of products, technology and true human care. Our goal is to make it easier for our clients to understand their options to obtain long-term financial wellness and gain peace of mind when it comes to financial matters.  A bit about this role:  As a Data Engineer on the Data Science & Engineering team, you will be responsible for developing and deploying scalable data pipelines, making data accessible to the rest of our data team. You will be involved in building out our data lake and creating processed data for end-users to consume downstream. This will be an evolving role, where you will have the opportunity to explore new techniques and technologies.  The work you will tackle:   Create and maintain optimal data pipeline and data lake architecture  Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and data tool technologies Build analytics tools that utilize the data pipeline to provide actionable insights into key business performance metrics Identify key metrics that need definition and measurement for meaningful outcomes  Partner with stakeholders and data team member to build out metrics/dashboards Continuously promote data-driven decision-making and actively contribute to organizational development and ongoing optimization  What we're looking for in your background:   B.S Degree in Mathematics, Statistics, Computer Science, Analytics, Economics, or a related quantitative field or extensive relevant work experience 8+ years of professional experience in data engineering Must have hands-on experience with AWS RDS, DocumentDB, Snowflake, Fivetran and Talend Ability to design and build highly scalable data pipelines and data lake infrastructure Experience with AWS service is required in RDS, DynamoDB, EC2, S3 Experience with SQL and NoSQL databases, including MySQL, MongoBD, etc. Experience with data pipeline and workflow management tools in Fivetran and Talend Experience building and optimizing 'big data' pipelines, architectures and data sets Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement Strong analytic skills related to working with unstructured datasets Experience with scripting tools (like JavaScript, Python, Ruby, etc.) Must have the ability to work independently and to collaborate with a larger team Must be eager, self-motivated, and a quick-learner Experience with Establishing PCI standard implementation, automating PCI and HIPAA compliance tasks, Multi Factor Authentication Experience with DevOps practices in CI/CD (Docker, Kubernetes) a big plus  What you bring that makes you a success:   Strong problem-solving and analytical skills Giving & receiving meaningful feedback is part of our growth mind set & culture - both are in your wheelhouse Ability to build and maintain positive working relationships with leadership across the organization Ability to deal effectively with ambiguous situations Results-oriented with a willingness to take initiative and get the job done Proficiency in business requirement elicitation and documentation  Employee Benefits at Brightside:    Medical, Dental & Vision Paid Time Off & Company Holidays  401(k) Short & Long Term Disability To be in an environment to learn and grow your own financial wellness A remote, inclusive work environment  Equal Employment Opportunity Commission:   Brightside is an equal opportunity employer and values diversity. We do not discriminate based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Marketing y publicidad, Software, Internet",None,None,False,,9,ACTIVELY_HIRING_COMPANY
748,2220590977,2020-10-28,"Coalition, Inc.",Senior Data Engineer,"Austin, Texas Metropolitan Area","About Us At Coalition, we bring together cyber tools, data, and deep security expertise to help customers solve cyber risk. We have over 25,000 customers, ranging from small and mid-sized businesses to Fortune 500 companies, and that number is growing fast. The Coalition engineering team is growing rapidly, and we are looking for Data Engineers to work with the various data sources utilized in our business. The ideal candidate would have experience working with data engineering, data analysis, and statistical modeling, in the development of a real-time service. They would have experience working with structured and unstructured data systems, optimizing performance across large, disparate data sets, and streaming data systems. They would be a proficient developer who can deliver production-quality implementations. This is a versatile role that will touch many aspects of data at Coalition, including network security data, actuarial data, and growth analytics data. Our core platform is written mostly in Python with some services in Java and Go. We prefer to use the right tool for the job and make pragmatic decisions about how to scale and decouple systems as we continue to grow. We’re looking for someone who can navigate a cloud environment (AWS) with many moving pieces and systems to help the team understand how they fit into the broader puzzle. Responsibilities Implement risk models for various insurance productsEvaluate, recommend, and implement data pipelines for a variety of data sources used at CoalitionDeliver production-quality software implementations for ETL and streaming pipelinesExplore new data sources and develop insights into existing data sources that improve business efficiency Requirements 3+ years working with large disparate data setsDeep understanding of ETL pipelines, statistical modeling, data analytics, and large scale data streamingExpert-level knowledge of SQL, Python, R, or similar language used for data engineeringA proven track record of successfully automating business value from data insightsExperience with at least one big data search tool, such as ElasticExcellent oral and written communications skills at all levelsBachelor’s degree in Computer Science or a related field preferred Bonus Points Prior experience with insurance or network security technologiesIn-depth knowledge of AWS or other cloud-hosted platforms relevant to data engineeringExperience with data visualization technologies Perks Enjoy a highly fulfilling, mission-driven cultureHealth, dental, and vision benefits for you and your familyLife insurance and disability benefitsPaid Parental Leave401(k) planWellness and commuter benefitsFlexible working hoursOpen vacation daysWe embrace distributed work: some benefits will vary by locationYou are an owner! We offer stock options to each of our employeesMore details at https://www.coalitioninc.com/careers Why Coalition? We are all here to build something we believe in and to make a company that will last. We’re also assembling a team of expert incident responders, threat and malware researchers, and security analysts to protect our customers before, during, and after a cyber incident. Our goal is to harness the power of technology with the safety of insurance, to provide the first holistic solution to cyber risk. Coalition's culture is one that strongly values humility, authenticity, and diversity. We want to work with people of different backgrounds and different paths in life, and we trust our team members to take responsibility, share ownership and work for one another. We are always looking for collaborative, inquisitive and dedicated individuals to join our team. Coalition Engineering Our culture is one of character, humility, responsibility, purpose, and authenticity. We are growing rapidly and that growth is enabled by strong teamwork, communication, and mentorship. We want people who are passionate about becoming experts in both the business and the technologies that support it. Our core platform is written mostly in Python with some services in Java and Go. We prefer to use the right tool for the job and make pragmatic decisions about how to scale and de-couple systems as we continue to grow. We’re looking for someone who can navigate a cloud environment (AWS) with many moving pieces and systems to help the team understand how they fit into the broader puzzle. Recent Press Releaseshttps://news.crunchbase.com/news/coalition-secures-90m-series-c-at-890m-valuation-to-grow-cyber-insurance-platform/https://www.forbes.com/sites/amyfeldman/2020/05/28/next-billion-dollar-startups-2020/ Coalition is proud to be an Equal Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.",Intermedio,Jornada completa,Tecnología de la información,Servicios y tecnologías de la información,36,None,False,,146,ACTIVELY_HIRING_COMPANY
749,133129229,2020-11-07,Fourth Frontier,Senior Data Scientist,"Bengaluru, Karnataka, India","We are a company developing novel solutions for health monitoring using wearable devices. We require a candidate willing to join at the earliest, with the following skills:- 5+ years experience in Data Science- Strong background in Python- Good understanding of MySQL Databases and queries- Experience on AWS functionalisty including management of EC2 instances, Lamda functions- Good understanding of CNN based algorithms- Strong interest in Healthcare applications and health dataPlease have a look at our website at www.fourthfrontier.com.If interested, please get in touch by emailing me at manav@fourthfrontier.com.",Algo de responsabilidad,Jornada completa,None,"Sanidad, bienestar y ejercicio",46,None,True,manav@fourthfrontier.com.,216,JOB_SEEKER_QUALIFIED
750,2268491912,2020-11-02,Interos Inc,Senior UX Researcher,"Arlington, VA, US","Interos, founded by Jennifer Bisceglie, is one of the most transformative technologically advanced platforms that powers the global economy supply chain. By using ML and big data, Interos aspires to dynamically and continuously map all of a company's business relationships to multiple tiers of dependency on a global scale and endeavors to help customers understand risk in their multi-tier, global supply chains. The scope of this value proposition extends across a variety of different technology sectors including risk management, supply chain intelligence, financial intelligence and cyber-security. Interos has raised $26M in total funding from Venrock, led by Nick Beim, and Kleiner Perkins, led by Ted Schlein. We have 70+ employees and are poised to double in size by end of 2020. Our offices are headquartered in Arlington, VA and we have presence in Menlo Park, CA.  We need an extraordinary team member who thrives as part of a fast-paced team and takes pride in their ability to succeed while delivering value to our customers. Be challenged by innovation and grow professionally by solving one of the most interesting challenges impacting businesses across the globe.  The Opportunity:  We are looking for a high-caliber Senior UX Researcher to tackle a new project with strategic significance and high exposure. In this initiative, we will tackle some of the most intriguing problems in the research space, while building a highly scalable service. As the first UX researcher this role requires deep functional expertise, excellent leadership skills, and the ability to hit the ground running. You will be responsible for providing deep customer insights that solve complex user problems transforming the supply chain risk space. If you enjoy designing and building highly innovative customer experiences and solving challenging problems in a new space, come join us!  Essential Functions/duties:   Work with product managers, designers and engineers to assess project needs and develop appropriate research plans to support their objectives. You will be responsible end-to-end for studies from proposing a methodology to delivering results Conduct usability studies, using both in-person and remote testing methods Conduct field studies studying different user personas with customers Conduct and analyze survey results to triangulate with qualitative findings Integrate qualitative research methods with ongoing quantitative research such as surveys, Google Analytics, etc. Assess the need for alternative research methods (e.g., participatory design, card-sorting), and plan accordingly Think strategically about incorporating user research best practices into product development Evangelize best practices for research across the company  Minimum Qualifications:   You have 6 plus years of research experience conducting high quality user experience research, incorporating both qualitative and quantitative methods in a corporate setting You have experience in conducting exploratory research, usability testing, and surveys You have a good understanding of statistics, are a master in survey research from writing surveys to conducting analysis Experience with agile software development and how design research fits within an iterative development framework You are willing to experiment with new ways of conducting user research, and can work well in a fast paced environment You are an excellent presenter and facilitator, have experience presenting your findings to executives and stakeholders You have excellent verbal and written skills. You are able to persuade others of your good ideas. A portfolio that demonstrates insight driven impact in both product and the organization   Preferred Qualifications:   Experience conducting user research for enterprise applications Experience conducting benchmarking studies Experience designing and analyzing large-scale surveys Experience with card sorting or tree testing Experience with cloud-based application software Understanding of consumer-grade experiences Experience in working with remote teams  BENEFITS:   Comprehensive Health & Wellness package (Medical, Dental and Vision) 10 Paid Holiday Days Off Accrued Paid Time Off (PTO) 401(k) Employer Matching Stock Options Career advancement opportunities Casual Dress Hackathons On-site gym and dedicated Peloton room at headquarters Company Events (Sports Games, Fitness Competitions, Birthday Celebrations, Contests, Happy Hours) Annual company party Employee Referral Program  Interos is proud to be an Equal Opportunity Employer and will consider all qualified applicants without regard to race, color, age, religion, sex, sexual orientation, gender identity, genetic information, national origin, disability, protected veteran status or any other classification protected by law.  If you are a candidate in need of assistance or an accommodation in the application process, please contact HR@interos.net",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Internet",10,None,False,HR@interos.net,111,ACTIVELY_HIRING_COMPANY
751,2200195342,2020-10-22,Putnam Recruiting Group,Senior Data Engineer,United States,"We're looking for a highly motivated and talented Senior Data Engineer who is curious and interested in working for a data science firm that is solving engineering and data science problems within media and entertainment. We work in a fast-paced and collaborative environment and we continuously innovate our platforms by applying a critical eye to emerging technology.  Requirements:• Minimum 6+ years of relevant data engineering experience • Knowledge related to relational databases (MySQL, Postgres, etc), cloud data services (AWS), and data warehousing tools (Redshift, Snowflake, etc).• Production experience with modern ETL data pipeline tools • Excellent communication skills and a willingness to collaborate with others",Intermedio,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Marketing y publicidad",39,None,True,,126,ACTIVELY_HIRING_COMPANY
752,2232885524,2020-11-03,HashiCorp,Senior Data Engineer - Cloud Services,"Oklahoma City, OK, US","About HashiCorp  HashiCorp is a fast-growing startup that solves development, operations, and security challenges in infrastructure so organizations can focus on business-critical tasks. We build products to give organizations a consistent way to manage their move to cloud-based IT infrastructures for running their applications. Our products enable companies large and small to mix and match AWS, Microsoft Azure, Google Cloud, and other clouds as well as on-premises environments, easing their ability to deliver new applications for their business.  Engineering at HashiCorp is largely a remote team. While prior experience working remotely isn't required, we are looking for team members who perform well given a high level of independence and autonomy.  Our Team  Cloud Services is an exciting team delivering HashiCorp products as managed services. We work across the company, and with multiple cloud partners, to make using HashiCorp products simple for our customers. We’re a small, but rapidly growing team, making a huge impact.  This Position  Location: Remote  As part of the Cloud Services organization, you’ll be a key part of a newly formed team tasked with building out our Analytics capabilities. This position plays a key role in data collection, processing, and reporting, analytics projects, and influencing key stakeholders with critical insights.  This is a chance to make a large impact across the team and company, by exposing data on our customers and the runtime information of our tools.  In This Role, You Can Expect To  Develop, construct, test, and maintain our Analytics platform. Discover opportunities for data acquisition. Develop data set processes for data modeling, mining and production. Recommend ways to improve data reliability, efficiency and quality. Contribute to the design and implementation of large-scale systems. Interface directly with internal teams, users, and HashiCorp customers. Work with multiple cloud platforms such as AWS, GCP, and Azure. Work with HashiCorp products such as Terraform, Consul, Vault, and Nomad.   You May Be a Good Fit If  You have built or operated a real time analytics pipeline at scale Have experience with tools similar to Segment, Looker, Heap, RedShift, RDS. You are familiar with microservice architectures, and ideally, have seen them in operation at a global scale. You have prior experience working in high performance distributed systems: while we strive to hire at a variety of experience levels, this particular opening is not well-suited for recent graduates. You are able to knowledgeably discuss design and performance tradeoffs in complex systems.   About The Application Process  Please note, as communication is a critical aspect of how we work, a cover letter is a great way to provide a sample of how you communicate. In your cover letter, describe why you're interested in working at HashiCorp, and what draws you to this role in particular.  HashiCorp embraces diversity and equal opportunity. We are committed to building a team that represents a variety of backgrounds, perspectives, and skills. We believe the more inclusive we are, the better our company will be.",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Internet",3,None,False,,18,COMPANY_RECRUIT
753,2241561866,2020-11-05,Storj Labs,Senior Data Engineer - Marketing Technology Specialist,United States,"Storj Overview Storj Labs Inc. is pioneering decentralized cloud storage, along with making object storage more secure, resilient, and faster than other leading cloud storage providers. Our mission is to Build the Decentralized Future, and our vision is to be the storage layer for the decentralized internet. We accomplish this goal by building a team equipped and empowered to propel us forward. Storj Labs is a globally-distributed company. As a remote-first team, we’ve built a culture based on transparency and open communication. To further ensure our team is cohesive and unified, Storj provides the opportunity to gather together (whenever traveling is deemed safe) in an optional week-long retreat several times per year. Storj offers remarkable benefits and empowering culture. In addition to generous healthcare benefits, we offer substantial equity, unlimited PTO, and considerable parental leave.  Senior Data Engineer - Marketing Technology Specialist As a Senior Data Engineer - Marketing Technology Specialist for Storj Labs, you will collaborate with engineering, data science, and product to build and maintain our data infrastructure and analytics tools, particularly for marketing purposes. You will be responsible for the development, support, configuration, and automation of each of our marketing technology tools and the data infrastructure that supports our global marketing strategy with a special focus on customer data. The solutions you build will involve large datasets and system integrations across both on-premise and cloud environments. We are looking for a leader who cares about cross-functional application development and can nurture a relationship with our marketing technology vendors to deliver a high-quality application that addresses our customer and business needs. This role requires strong initiative and great problem-solving skills combined with the ability to explain concepts to both technical and non-technical audiences. You will be making regular individual contributions such as building out features in the backend for customer data, new APIs, maintenance and refactoring, conducting code and design reviews, data QA, data reconciliation, and testing. We hope you have enthusiasm in partnering with the product and marketing teams to identify new opportunities to better understand and serve our customers. You will be expected to become the point person for all things related to marketing technology at Storj Labs.   Responsibilities: Integrate and maximize utilization of our MarTech tools -  i.e. content management system, customer data platforms (e.g. Segment.io), advertising, conversion, email marketing/push/SMS, social media, user A/B testing, and customer service toolsDesign, build, operate, and optimize the data pipelines, mapping, models, and custom software that run our marketing platformsAugment marketing capabilities with new data sets and new data integrations to enhance the omnichannel view of customers.Collaborate closely with engineering, data science, product, and marketing teams.  Requirements: Expertise in data analysis and data pipeline developmentStrong understanding of customer analytics and customer data management, production support, and data enhancementKnowledge of digital marketing (Email, Search-Engine Marketing, Social, Affiliate)Proficiency in SQL and a programming language such as Golang. Bonus if you are familiar with Python or another language popular for data science.  Our Commitment to Diversity, Equity, & Inclusion: At Storj Labs, we celebrate diversity and strive for an inclusive work culture.  More than a statement on our careers page, these concepts are ingrained in our core values: Secure - We believe security and privacy in product, process, and habit is key to everything we do. Together - We inspire, execute, and celebrate as one team, with a commitment to trust, inclusion, collaboration, and accountability. Open - We’re committed to the free and open sharing of software, information, knowledge, and ideas. Resolute - We have the courage to do the right thing, even if it is not the easy thing. We resolve always to treat others ethically, with empathy, understanding, and trust. Empowered - We empower our users to control their data, our teammates to do great work, and our community to build economic value. Different - We think differently, act differently, and always strive to make a difference. We do not make hiring or employment decisions on the basis of race, color, religion, creed, gender, national origin, age, disability, veteran status, marital status, pregnancy, sex, gender expression or identity, sexual orientation, citizenship, or any other basis protected by applicable local, state or federal law. We also consider for employment qualified applicants with arrest and conviction records in a manner consistent with San Francisco’s Fair Chance Ordinance and similar local laws.",Intermedio,Jornada completa,"Tecnología de la información, Marketing",Software,9,None,False,,47,ACTIVELY_HIRING_COMPANY
754,2220728021,2020-10-28,Doximity,"Senior Data Engineer, Manager",United States,"Doximity is transforming the healthcare industry. Our mission is to help doctors be more productive, informed, and connected. As a software engineer focused on our data stack, you'll work within cross-functional delivery teams alongside other engineers, designers, and product managers in building software to help improve healthcare.  Our team brings a diverse set of technical and cultural backgrounds and we like to think pragmatically in choosing the tools most appropriate for the job at hand.   One of Doximity's core values is stretching ourselves. Even if you don't check off all the boxes below we encourage you to apply. Doximity is full of exceptional people that don't fit a mold, join us! About The JobAs a Data Engineering Manager at Doximity, we expect you to support and enable 3-7 data engineers in doing the best work of their careers. You will do this through strong leadership skills combined with technical expertise and product familiarity. Indeed, we expect you to be an excellent manager but also to roll-up your sleeves and make technical contributions. Our belief in technical leaders is so strong that your first six months at Doximity will consist of ramping up as an individual contributor. During this time, you will develop your product context and learn the data team's engineering patterns before tackling any leadership challenges. You will play a liaison role alongside Data, Product, and Engineering teams. Fostering relationships with other engineering managers, product managers and technical leads.You will contribute to the technical direction of software products.You will aid in iteration planning, retrospectives, and devise effective delegation strategies for you and your team.You will review code, write technical proposals, and help your team grow by recruiting, training, and aiding in career progression plans.You will strive to keep the team pragmatic, shipping, and focused on adding business value while maintaining a cohesive software stack.You will be contributing to at least one large or medium-sized data project at any given time. About youYou are a data engineer at heart: excited to roll up your sleeves and help with hands-on data engineering problems.You have at least 2 years of experience as an Engineering Manager for a data-focused team of at least 3 members.You are passionate about helping others improve and grow their career by exercising coaching, mentorship, and delegation.You know what it takes to push major data projects through a development lifecycle.You are passionate about using data to make a large impact on the product and the business.You are fluent in Python and SQL.You have professional experience architecting, developing, and shipping data and ETL pipelines of all sizes. You do so through the lens of treating pipelines themselves as software.You understand the importance of carefully crafting and designing data models using methods like object-relational, entity-relationship, or dimensional modeling.You default to concise and effective written and verbal communication.Your leadership style is servant to the team and starts with empathy: you trust your team to make the right decision and empower them to execute. Benefits & PerksGenerous time off policyComprehensive benefits including medical, vision, dental, Life/ADD, 401k, flex spending accounts, commuter benefits, equipment budget, educational resources and conference accessFamily support and planning benefitsPre-IPO stock incentives.. and much more! For a full list, see our career page About usHere are some of the ways we bring value to doctorsOur web applications are built primarily using Ruby, Rails, Javascript (Vue.js), and a bit of GolangOur data engineering stack runs on Python, Snowflake, MySQL, Spark, and AirflowOur production application stack is hosted on AWS and we deploy to production on average 65 times per dayWe have over 450 private repositories in Github containing our applications, forks of gems, our own internal gems, and open-source projectsWe have worked as a distributed team for a long time: we're currently about 75%+ distributedFind out more information on the Doximity technology blogOur company core valuesOur recruiting processOur product development cycleOur on-boarding & mentorship process We’re thrilled to be named the Fastest Growing Company in the Bay Area, and one of Fast Company’s Most Innovative Companies. Joining Doximity means being part of an incredibly talented and humble team. We work on amazing products that over 70% of US doctors (and over one million healthcare professionals) use to make their busy lives a little easier. We’re driven by the goal of improving inefficiencies in our $3.5 trillion U.S. healthcare system and love creating technology that has a real, meaningful impact on people’s lives. To learn more about our team, culture, and users, check out our careers page, company blog, and engineering blog. We’re growing steadily, and there’s plenty of opportunities for you to make an impact. ﻿Doximity is proud to be an equal opportunity employer, and committed to providing employment opportunities regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex, gender, gender identity, gender expression, pregnancy, childbirth and breastfeeding, age, sexual orientation, military or veteran status, or any other protected classification. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law.",Intermedio,Jornada completa,Análisis,Software,19,None,True,,123,None
755,2234231528,2020-11-02,None,Senior Data Scientist,"San Diego, California, United States","I am working with an exciting New York AI startup who works on creating Artificial Intelligence algorithms that focuses on a variety of industries such as Movies, Fashion, Traveling, and Hospitality. They use deep learning to gain more knowledge on their customers and their interests. For more than 50 years Qloo's AI has mapped endless amount of cultural correlations and entities while offering personalized insight into different cultures. In this role you will be responsible for contributing and improving the data pipeline. In this role you will work alongside the ML teams and make sure the clients are satisfied. This company is transitioning into a period of growth and looking to bring on a Data Scientist with a strong Deep learning background and a PhD. They have a remote friendly environment. The role is full time remote and the company is offering a competitive salary comensurate with experience level and qualifications. Candidates for this role are expected to have experience working with deep learning models.Please feel free to reach out to J.Perez@x4technology.us if you think this role may be for you.",Intermedio,Jornada completa,Tecnología de la información,"Internet, Entretenimiento",69,None,True,J.Perez@x4technology.us,239,JOB_SEEKER_QUALIFIED
756,2260898321,2020-10-06,Shopify,"Sr UX Researcher (Remote, Japan)シニア・ユーザー・リサーチャー（日本）","Tokyo, JP","Shopify is now permanently remote and working towards a future that is digital by default. Learn more about what this can mean for you. At Shopify, we want to make commerce better for everyone, everywhere. Countries differ in many ways in terms of language, culture, and how people engage with commerce. We want to embrace these differences and make Shopify the right platform for all merchants, no matter where they are on the planet. Shopify has 1,000,000+ merchants in more than 175 different countries. We’re focussed on reducing the barriers of entry to entrepreneurship and scaling success by offering commerce solutions to small and medium-sized enterprises, as well as major brands like Simba, GymShark, Spotify, Emma Bridgewater, and Skinny Dip London. Making Shopify better for merchants around the world brings deeply interesting UX challenges across language, behaviours, currency & trade, and ultimately, culture. We’re on the lookout for people who are excited to work on hard problems at a global scale in a friendly and collaborative environment. If this sounds familiar, we’d love to hear from you.  As Senior UX Researcher in Japan on the International Growth team, you will be working remotely in Japan, you will have a special role in building understanding and empathy for merchants in APAC. You will help us build real connections with merchants, and bring these insights into product teams across Shopify. You will work with a multidisciplinary UX team of product designers, content strategists, user researchers, and front-end developers to deliver the best possible experience for our merchants around the world.  The UX Research team guides and informs the company towards designing and building better products and experiences for people using a variety of research methods. Researchers work with teams to incorporate people-centric thinking from problem definition to post-launch iteration. We ask thoughtful research questions, conduct contextual research, frame problems, synthesize insights, evaluate concepts and prototypes, and assist with launches and releases.  In addition to informing product and UX, we also work on broader internal initiatives to cultivate international merchant empathy throughout Shopify (e.g. remote merchant tours of Shopify stores, merchant Q&A panels).  仕事内容 Shopifyは今後も永続的にリモートワークを継続し、「デジタルが原則」となる未来に向けて取り組んでいます。 このことがあなたにとってどのようなことを意味しているのか、より詳しくは こちらをご覧ください 。  Shopifyは、すべての人にとってより良いコマースを実現できるよう目指しています。世界の国々は、言語、文化、人々のコマースへの関わり方など、さまざまな点で異なります。私たちはその違いを尊重し、マーチャントの拠点とする地域が世界中のどこであろうと、Shopifyがすべてのマーチャントにとって適したプラットフォームでありたいと考えています。  世界175か国で100万人以上のマーチャントがShopifyを利用しています。起業の障壁を下げ、ビジネスの拡大を支援するコマースソリューションを提供することにShopifyは注力しており、中小規模の事業者だけでなく、Simba、GymShark、Spotify、Emma Bridgewater、Skinny Dip Londonのような大手ブランドにも採用されています。  世界中のマーチャントにとってShopifyをより良いものにしていくことは、UXの観点からも非常にやりがいがあります。言語、消費者行動、通貨や商取引、そして文化の違いを乗り越える必要があるからです。Shopifyでは、オープンで協力的な環境で、グローバルな視点から積極的に困難な問題に対応できる人材を求めています。共感いただける方はぜひご応募ください。  シニアUXリサーチャーは、International Growthチームに属し、アジア太平洋地域のマーチャントへの理解と共感を深めるという特別な役割を担います。Shopifyがマーチャントと真のつながりを築き、インサイトをあらゆる分野の製品開発に反映できるよう取り組みます。さらに、製品デザイナー、コンテンツストラテジスト、ユーザーリサーチャー、フロントエンドの開発者たちで構成される分野横断的なUXチームと連携し、世界中のShopifyマーチャントに最良のエクスペリエンスが提供できるよう努めることが求められます。  UXリサーチチームは、多様なリサーチ手法を使って、利用者にとってより優れた製品やエクスペリエンスをデザイン・構築できるようShopifyを導き、情報提供を行います。リサーチャーはチームと連携し、問題の定義から製品発売後のイテレーションまで、人間中心設計に取り組みます。リサーチの観点から質問を行い、コンテクストリサーチを実施し、問題をフレームワーク化し、インサイトを統合し、コンセプトとプロトタイプを評価し、ローンチやリリースをサポートすることが求められます。  私たちのチームはプロダクトやUXに情報を提供するだけでなく、社員に対して世界中のマーチャントへの共感を高めるためのさまざまな取り組みを実施しています（Shopifyを利用しているマーチャントを知るためのリモートツアーや質疑応答パネルの主催など）。  You Should Have 応募条件 Proficient in Japanese and English at a business level.Experience with field research in Japan, in a product development context. Hands-on experience scoping and prioritizing research questions, research planning, data gathering, analysis, summarizing, and sharing findings.The ability to identify the best UX research methods and tools to use depending on project objectives and constraints.Experience applying a range of research methods with creativity, scrappiness, and critical thinking.Example research methods may include observations and in-depth interviewing, usability and accessibility testing, diary studies, card sorting, eye and click tracking, surveys.Examples of projects where your research insights led to better-informed design decisions (e.g. to guide product roadmaps, strategy decisions).Familiarity with combining qualitative and quantitative data.The ability to clearly communicate insights and recommendations to different audiences.Proven ability to build relationships between disciplines and cultivate collaboration, especially on distributed or remote teams. ビジネスレベルの日本語および英語。プロダクト開発に関わる日本国内でのフィールドリサーチの経験。質問事項の策定と優先順位付け、リサーチ実施のプランニング、データ収集、調査結果の分析、要約および共有の実務経験。 プロジェクトの目的や制約に応じて、最適なUXリサーチ手法や使用すべきツールを特定できる能力。想像力、応用力、批判的思考を駆使し、さまざまなリサーチ手法を用いてきた経験。行動観察調査、デプスインタビュー、ユーザビリティテスト、アクセシビリティテスト、ダイアリースタディー、カードソーティング、アイトラッキング、クリックトラッキングなどの各種調査やアンケートの実施等の経験。 担当したリサーチで得られたインサイトが、プロダクトのデザインに関わる決定（プロダクトロードマップの構築や戦略的意思決定など）に意味のある影響を与えた経験。定性データと定量データを使い分ける能力。インサイトや推奨事項を異なるオーディエンスに対して明確に伝える能力。 異なる職種から構成されるチーム、特にさまざまな地域で働くメンバーから構成されるチームまたはリモート勤務のチームの中で働き、協力関係を構築してきた実績。  You'll Be Responsible For 職務内容 Helping to define our product roadmap for APAC by understanding and advocating for international merchant needs across language, culture, and local commerce behaviours. While we may share the platform, merchant needs vary greatly around the world.Obtain insights for our team to build new products around international requirements, to serve merchants in new ways on the Shopify platform. We know that language, payments, and shipping products can function fundamentally differently around the world - we need you to help us consider the breadth and depth of these challenges and provide simple, scalable experiences. This may include travel and conducting field research on the ground in-market.Articulating research questions and priorities with multiple teams and using a range of research methods to answer those questions.Collaborating closely with various teams (Product, Design, Culture, Data, etc.) to help make better decisions around culture, collaboration, tools, and product roadmaps.Working with the team to enable the UX Research practice at Shopify to confidently incorporate an international perspective into their work.言語、文化、現地の商慣習に関するマーチャントのニーズを理解し、整理することを通じて、アジア太平洋地域向けのプロダクトロードマップの策定を助ける。Shopifyというプラットフォームは共通ですが、マーチャントのニーズは世界中で多岐にわたります。開発チームが現地の要件を満たす新製品を構築し、Shopifyプラットフォーム上でマーチャントに新たなサービスを提供することを可能にするインサイトを取得する。言語、決済方法、商品の配送は、世界中で根本的に異なるため、シニアUXリサーチャーはShopifyがこのような課題の幅広さと奥深さに対応し、シンプルかつ拡張可能なエクスペリエンスを提供できるようにすることが求められます。そのため、業務には現地への出張や市場のフィールドリサーチが含まれることがあります。複数のチームに働きかけながらリサーチの質問事項や優先順位を明確にし、それらの回答を得るために多様なリサーチ手法を活用する。さまざまなチーム（プロダクト、デザイン、カルチャー、データなど）と緊密に連携し、文化、コラボレーション、ツール、製品ロードマップなどに関するより望ましい意思決定が行えるよう支援する。 確固たるグローバルな視点を開発業務に組み込めるよう、チームと協力してShopify内でUXリサーチを実践できるようにする。   Shopify Can Offer Shopifyが提供するもの A culture of trust and ownership.An international workplace culture.Flexible location within +/- 2 hours of the JST time zone.Flexible work hours and a competitive compensation package (including equity, benefits, and perks)Benefit from a lifestyle spending account - a budget you can spend on a variety of things to help your life run smoothly, including wellness, transportation, and family care related expenses.Plentiful professional growth opportunities, such as conferences, training courses of your choice, books, business trips, etc.The best tech needed for your job信頼と当事者意識の浸透した文化 国際的な企業文化 柔軟な勤務地（日本標準時より時差2時間以内のタイムゾーン） 柔軟な勤務時間と魅力的な給与パッケージ（エクイティ、福利厚生など） ライフスタイル経費（ウェルネス費、交通費、家族にかかる費用など、生活を滞りなく送るために必要なさまざまな出費に充当可能） 豊富なキャリア形成の機会（希望のシンポジウムやトレーニングへの参加、書籍、出張など） 職務に必要な最高レベルのテクノロジー  We know that applying to a new role takes a lot of work and we truly value your time. We are looking forward to reading your application. Regardless of the outcome of your application we will strive to provide an update to you within 3 weeks of your application submission.  At Shopify, we are committed to building and fostering an environment where our employees feel included, valued, and heard. Our belief is that a strong commitment to diversity and inclusion enables us to truly make commerce better for everyone. We strongly encourage applications from racialized people, people with disabilities, people from gender and sexually diverse communities and/or people with intersectional identities. Please take a look at our  2019 Sustainability Report  to learn more about Shopify's commitments.  ↓  Interested, but not ready to apply?  Join the Shopify Talent Community for external candidates to learn more about Shopify by clicking here .",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Software, Internet, Servicios financieros",None,None,False,,74,COMPANY_RECRUIT
757,2221743895,2020-10-20,CrowdStrike,"Data Engineer with Python (Remote, ROU)","Bucharest, RO","At CrowdStrike we’re on a mission - to stop breaches. Our groundbreaking technology, services delivery, and intelligence gathering together with our innovations in machine learning and behavioral-based detection, allow our customers to not only defend themselves, but do so in a future-proof manner. We’ve earned numerous honors and top rankings for our technology, organization and people – clearly confirming our industry leadership and our special culture driving it. We also offer flexible work arrangements to help our people manage their personal and professional lives in a way that works for them. So if you’re ready to work on unrivaled technology where your desire to be part of a collaborative team is met with a laser-focused mission to stop breaches and protect people globally, let’s talk.  About The Role  We are looking to hire a Data Engineer for the Data Engineering team at CrowdStrike. The Data Engineering team operates within the Data Science organization, and provides the necessary infrastructure and automation for users to analyze and act on vast quantities of data effortlessly. The team has one of the most critical roles to play in ensuring our products are best-in-class in the industry. You will interact with product managers and other engineers in building both internal and external facing services.  The role is open for all candidates from Romania. We have colleagues from Brasov, Iasi, Cluj, Timisoara and Bucharest.  You will use Python and Golang. Don’t worry if you don’t know Golang, we will teach you!  Interviewing process: online  What You’ll Need BS degree in Computer Science or related field.5+ years of relevant work experience.Good knowledge of some (or all) of AWS, Python, Kafka, Spark, Airflow, Kubernetes, etc to build infrastructure that can ingest and analyze billions of events per day.Good knowledge of distributed system design and associated tradeoffs.Good knowledge of CI / CD and associated best practices.Familiarity with Docker-based development and orchestration.  Bonus points if you have… Created automated / scalable infrastructure and pipelines for teams in the past.Contributed to the open source community (GitHub, Stack Overflow, blogging). Prior experience with Spinnaker, Relational DBs, or KV Stores.Prior experience in the cybersecurity or intelligence fields.Golang experience  #Stack  Benefits Of Working At CrowdStrike Market leader in compensationComprehensive health benefitsWorking with the latest technologiesTraining budget (certifications, conferences)Flexible work hours and remote friendly environmentWellness programsStocked fridges, coffee, soda, and lots of treatsPeer recognitionInclusive culture focused on people, customers and innovationRegular team activities, including happy hours, community service events  We are committed to building an inclusive culture of belonging that not only embraces the diversity of our people but also reflects the diversity of the communities in which we work and the customers we serve. We know that the happiest and highest performing teams include people with diverse perspectives and ways of solving problems so we strive to attract and retain talent from all backgrounds and create workplaces where everyone feels empowered to bring their full, authentic selves to work.  CrowdStrike is an Equal Opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex including sexual orientation and gender identity, national origin, disability, protected veteran status, or any other characteristic protected by applicable federal, state, or local law.",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Servicios financieros",13,None,False,,250,ACTIVELY_HIRING_COMPANY
758,2283540878,2020-11-05,Tubular Labs,UX Researcher (Mountain View/ San Francisco/remote in CA until summer 2021),"Mountain View, CA, US","About Us   Tubular is a leading platform to provide a modern standard for global video measurement. By processing billions of videos and millions of creators on Facebook, YouTube, Instagram, Twitch and Twitter, we help our global customers get unique insights no other companies are able to provide.  High level responsibilities  You will apply your passion for diving deep into our customers’ needs and interaction with our solution to execute user research, usability tests, interaction flows and storyboarding, as well as collaborating with product managers and designers to continually improve user interaction as well as launching new offerings. You will partner with cross-functional stakeholders from across the company to contribute to the product roadmap, near and long term business objectives.   Day-to-day You Will Be Focusing On  Performing user research studies with end customers for existing offerings, new concepts, and products undergoing alpha/beta testing. Understanding the jobs to be done by a myriad of users including their motivations, emotions, and goals: and translate these user insights into actionable recommendations for the product team.In partnership with product managers, delve into proposed user stories and seek to “humanize” the interaction with Tubular’s offerings through direct interviews with users, determining UX priorities of the collective user base, and influence sprint prioritization as well as usage metrics & goals. Establish the company’s usability / usage goals for our platform and products, including determining our toolset and technologies to perform all aspects of testing and optimizing UX across the lifecycle of all of our products. You will make your contributions visible at the higher levels in the organization, by communicating the results of your research to your stakeholders and executives, through presentations and written reports.   Qualifications And Skills  You have 3+ years of work experience in user research, UX design and usability testing for web-based applications. You are proficient in the use of product analytics, experience in charts, tableau and data visualizations, user feedback platforms, A/B tests, and other tools (such as Heap, GA, Hotjar, etc) to develop hypotheses, tests, measurement and recommendations. You are skilled at data storytelling and storyboarding for analytical workflows using complex data sets (charts, graphs, Tableau prototypes).You are a natural conversationalist and capable of meeting directly with users of all levels including media and brand executives, analysts, content strategists, and social influencers. You are able to appropriately scope and determine a research approach for each project that meets our goals and needs for our roadmap and customer satisfaction. You stay up-to-date on current design trends, themes and technologies.You thrive in a fast-paced environment.Why choose Tubular?  Tubular is riding the tsunami of digital video.  Smartphones, social media and new streaming apps are revolutionizing media and entertainment. Viewers have never had so much great content to choose from, from so many diverse creators, available to watch in so many ways. As advertising, TV and social media converge, new industries will emerge. Tubular is the worldwide leader in online video intelligence. We are guiding firms through the new digital video landscape. We serve the world’s greatest media companies and brands, including top movie studios & TV networks, leading technology companies, and the creme of digital first publishers. We are a team of tech-savvy media enthusiasts. We offer a fast-paced environment with an opportunity to make a real impact on your career, on our company, and the global media industry. With a highly engaged client base, we offer an insider’s view on the rise of the new generation of entertainment.  In terms of culture, you can expect openness, responsibility, paired with flexibility and lots of interesting technical projects to tackle. We encourage open discussions where all opinions are heard. We may disagree but once consensus is reached, we commit to the decision.We love getting things done, winning and having fun together.  We are committed to creating an inclusive and diverse Tubular team. We believe that different perspectives lead to better ideas and more creative solutions that allow us to better understand the needs and interests of our diverse, global community. We welcome people of different backgrounds, experiences, abilities and perspectives, and are an equal opportunity employer.",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Marketing y publicidad, Software, Internet",4,None,False,,66,COMPANY_RECRUIT
759,2233140672,2020-10-23,Canvia,Data Scientist Trainee,"Lima, Perú","Somos Canvia, formamos parte del portafolio de Advent International y contamos con 34 años de presencia en el mercado local. Nuestro propósito es hacer más fácil la vida de las personas, innovando e implementando proyectos de transformación digital de nuestros clientes de manera ágil y segura.  ¡Te invitamos a ser parte de nosotros, postulando a la posición de Data Scientist Trainee!  ¿Qué perfil buscamos? ·        Profesional universitarios de Estadística, Matemáticas, Física (deseable) o carreras afines.   ·        Conocimientos avanzados en Estadística, Deep learning (Keras, TensorFlow, Pytorch).·        Conocimientos preferentemente de Phyton (Pandas, Scikit-Learn), de R o de Scala.·        Conocimiento del panorama actual de herramientas comerciales y Open source relacioandas con Big Data y Analítica.·        Deseable conocimiento de AWS, Azure, Google Cloud o Cloudera.·        Deseable conocimiento de Spark (idealmente PySpark).                                                                                                                                                                                                                                    ¡Nuestros beneficios! • Si deseas tener un seguro privado ¡cubrimos hasta el 81% de tu prima!• Contamos con convenios educativos post-grado con diferentes Institutos y Universidades.• Podrás participar en Talleres y Meet Ups que contribuirán con tu desarrollo.             ¡En Canvia cuentas con Seguro Vida Ley desde tu primer día laboral!                   En esta empresa está prohibida la discriminación – Ley N° 29973",Prácticas,Jornada completa,"Tecnología de la información, Análisis",Servicios y tecnologías de la información,283,None,True,,1732,ACTIVELY_HIRING_COMPANY
760,2246362665,2020-11-05,Gemography,Data Engineer (Remote),Egypt,"Join Gemography and work with top tech startups and engineering teams from New York, LA, San Francisco and Paris on large-scale applications and systems. It's long term, remote and comes with indefinite period employment contract. You will work on:Take ownership and responsibility of data produced by the data pipelines.Maintain and update ETL data pipelines as well as create new ones.Document, identify and automate common data and pipeline operations.Participate in standups/meetings and operate in a team environment with agile methodologies.Monitor the status of data pipelines and act correspondingly.Ensure data produced has the right format/quality and that associated metadata is properly documented. What we are looking for: Experience with data engineering, preferably in Python.You’re a fast learner, can contribute from day one as well as integrate and apply new concepts quickly.You take pride in what you create and passionate about getting the details right, even when no one's looking.You are able to weigh tradeoffs, articulate complex ideas, and have precision about what you know and don't know.You enjoy staying on top of tech trends and hacking new things.Proficiency in written and spoken English.  Bonus points if you have:Hands-on experience in SQL tuning, schema design or analytical programming.Familiar with Docker, Kubernetes, Airflow or similar technologies.A graduate degree in Computer Science or similar discipline. Benefits & PerksCompetitive salaries and performance bonuses.Your own Spotify Premium and Netflix accounts.24-days paid time-off (+ public holidays).Health insurance & pension. Important Resume/cover letter are optional. The job role is fully remote (anywhere in Egypt). It's long term and comes with an indefinite period employment contract.",Intermedio,Jornada completa,Tecnología de la información,Internet,44,None,False,,350,JOB_SEEKER_QUALIFIED
761,2243250075,2020-10-26,Tail Wind Informatics Corporation,Cloud Data Engineer,Greater Minneapolis-St. Paul Area,"Tail Wind is currently seeking candidates for our Cloud Data Engineer position. The position can be full time salaried with benefits, W2 Hourly with benefits or CTC hourly.  We’re seeking experienced Cloud Data Engineers to assist with a cloud migration project. The successful candidates will assist in migrating the data into an AWS S3 data lake. Experience with AWS Glue, SQL Server environments, AWS Redshift are highly preferred. Required SkillsBachelor's degree in Computer Science or Information Technology preferredAWS Glue experiencePython experienceSQL Server experience and SSISCloud data migration experienceExcellent written and verbal interpersonal and communication skills Benefits401k, Health Insurance, Dental Insurance, Long-Term Disability Insurance The Tail Wind Team: A healthy work-life balance. We look for people that love what they do, want to learn, earn and enjoy life to the fullest. To learn more about this opportunity please Apply Now. Thank you! Equal Opportunity Employer - No Agencies Please",Intermedio,Jornada completa,Tecnología de la información,Servicios y tecnologías de la información,62,None,True,,154,JOB_SEEKER_QUALIFIED
762,2289768196,2020-11-02,e-Merge IT Recruitment,Senior Data Engineer - Remote R1.1mil per annum,"Woodstock, ZA","Have you had 5 years' experience working as a Data Engineer? Do you want to join an industry leading digital house, funded by a billion-dollar parent company? This is the opportunity for you. You will be developing, maintaining, and testing infrastructures for data generation. You will work closely with data scientists and are largely in charge of architecting solutions for the team.  Requirements  Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. 5 years' experience in a Data Engineer role Experience with AWS cloud services: EC2, ECS, RDS, Redshift Experience with stream-processing systems: Storm, Spark-Streaming, etc. Experience with object-oriented/object function scripting languages: Python, etc Experience with big data tools: Hadoop, Spark, Kafka, etc. Experience with relational SQL and NoSQL databases, including Postgres and Cassandra. Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc. Reference Number for this position is MH51306. This is a permanent remote role. Budget is in the region of R1.1mil per annum based on experience, skillset and current level. Contact michelle on [Email Address Removed], at e-merge . co . za  Are you ready for a change of scenery? e-Merge IT recruitment is a niche recruitment agency. We offer our candidates options so that we can successfully place the right people with the right companies, in the right roles. Check out the e-Merge IT website for more great positions.  Do you have a friend who is a developer or technology specialist? We pay cash for successful referrals!",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Servicios financieros",0,None,False,,1,None
763,2175452160,2020-11-05,Greylock,Co-Founder (ML / DS),San Francisco Bay Area,"We're looking for a Co-Founder to partner with an accomplished industry veteran we have known for many years for an upcoming AI-first investment of ours, which is still in incubation. While I can't give too many details out yet, it's an autoML company that is looking to create novel algorithms/models dealing with data sparsity issues in the enterprise. If you're an accomplished Data or Machine Learning Scientist and have either founded a successful startup and/or have worked for a market-leading company in AI and would like to help launch a ground-floor opportunity we're really excited about, I'd like to hear from you. Please note: Due to the volume of applicants I typically receive, a follow-up email will not be sent unless a match is identified (sorry). And since this is a stealth opportunity, I will not be able to share too many details about it up front either. About me:I am a full-time, salaried employee of Greylock, and there are no fees associated with any of the work I do. My team provides free candidate referrals/introductions to all of our active investments (one of the many services we provide), and I'm always looking to add new people to our network of talent.",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Internet, Software",251,None,True,,2479,COMPANY_RECRUIT
764,2287630572,2020-10-13,Vee,Data Scientist Internship (REMOTE),"New York City, NY, US","Position: Data Scientist Intern (REMOTE)  Reports to: CTO  Location: Remote  Are you passionate about exploring where, how, and why data can drive business decisions? Interested in how organizations use analytics and data to innovate, grow and transform? Driven to help establish, define, and evangelize how data science can help drive a strategy?   Company Overview  Vee inspires people to align on Purpose so they can unlock their individual and collective human potential. We are an early stage startup poised for dramatic growth. We specialize in developing ways to drive greater strategic alignment to unlock enterprise innovation and growth. After spending considerable time exploring the need for better alignment models across diverse organizations, we have developed a framework and methodology based on insights from extensive research. We are building products to assess gaps and are offering our consulting services to help 21st century leaders develop and implement their organizational and people strategies, along with the capabilities required to operationalize their Purpose as they transform.  Position Overview  Join our fast-growing team! You will help drive intelligent, insightful, and predictive business results to help Vee and Vee's clients drive value in the realms of people, purpose, and performance. You will help build Vee's data capability and data strategy.  General Responsibilities  Research and develop statistical learning models for data analysis Collaborate with Data Engineering, People Science, business partners, and Chief Technology Officer to devise innovative and forward-thinking solutions for our clients' needs Keep up-to-date with the latest technology trends Communicate results and ideas to key stakeholders at Vee Implement new statistical or other mathematical methodologies as needed for specific models or analysis Optimize joint efforts between Data Engineering, business partners, UX, and People Science teams at Vee to drive business results   Core Experience & Requirements  Masters degree in Computer Science, Applied Statistics, Applied math, Data Science, or a related field Practical experience with multiple statistical languages (SAS, R, Pandas), data processing, database programming, and data analytics Solid background in data mining and statistical analysis Experience with programming languages such as Python and R Knowledge of data visualization tools (e.g. Tableau) Strong collaboration skills - you partner well with others to solve problems and actively incorporate input from various sources Excellent oral and written communication skills Working with key stakeholders to drive business results  Profile  Purpose is what drives you. Your passion for your work has led you here. You are ready to combine your experience with ours to help our client companies gain competitive advantage. You bring strong creative thinking skills in addition to superior communication skills, allowing you to develop creative solutions for any challenge that comes your way.  You:  Love what you do, love to be busy, and love to produce by being organized and methodical Work with a sense of urgency and have a strong drive for results Have the resilience and agility to adapt quickly in a fast-paced environment Work independently as well as collaboratively to stretch thinking into creative solutions Have strong verbal and written communication skills Are excited about and suited for a startup, where you'll be wearing a few hats Are smart and fun with an empathetic nature, which will add to our culture   About Vee  Our founders and team have deep expertise in branding, innovation, design, I/O psychology, organization design, digital & data product development, enterprise software and application development complemented by experience with clients ranging from emerging Silicon Valley unicorns to established leaders in government and the public and private sectors including American Express, Bank of America, BMW, Box, HP, Lowe's, Mastercard, Microsoft, Nissan, Pepsico, Procter & Gamble, SAP and The Clorox Company, among others. For more information, check out our website in transition at https://www.letsvee.com/.",Prácticas,Prácticas,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Software, Internet",16,None,False,,85,ACTIVELY_HIRING_COMPANY
765,1991101817,2020-10-26,Conjoint.ly,Quantitative Market Researcher,Chile,"Conjoint.ly is on a mission to automate market research. We offer quantitative research services to big and small companies (mostly in USA and Europe). Through automation, we slash costs and increase speed for our clients, but maintain a human connection and high research quality. As we grow (in number of products that we offer and in clients’ awareness of us), we are looking for a junior to mid-level market researcher to join our team on a remote basis. This job wins over working for a normal market research firm for the following reasons:We aim not to do the same thing twice. If it needs to be repeated, we must automate it.We are recognised as experts in the research methods that we do and clients will listen to your advice.You will have opportunities for professional growth as fast as our operations grow. Your role will not be limited to a single area and will include:Research on projects commissioned by clients. As a key client contact, you will support them from proposal to delivery of results on some of the most complex and interesting custom projectsCustomer support and advice: Helping our users do the best market research on our platform, including consulting them via email and over the phoneProduct development: Preparing documentation, algorithms, and other materials. Requirements:A strong interest in quantitative market researchBachelor's degree or equivalentExcellent skills in statistics. For example, you must be able to write code in R (preferred) or PythonNative or near-native profeciency in both English and Spanish Preferred skills:Experience at a market research agency or in-house data science or insights function, using common market research methodsSeveral years of experience in Excel. Being able to make a client-friendly customised models Application process will consist of the following stages:Apply on LinkedInWe will contact you for two or three interview roundsYou will be invited for IQ tests, practical tasks in Excel and other softwareReference checks Please contact us for any questions about the role. This is a remote, suitable for someone based in Latin America, reporting to a U.S.-based research manager.",Algo de responsabilidad,Jornada completa,"Marketing, Ventas",Investigación de mercado,295,None,True,,1816,None
766,2149716258,2020-11-03,Zscaler,Sr. Threat Analyst and Security Researcher,"Atlanta, GA, US","Description  Position: Sr. Threat Analyst and Security Researcher  Location: Remote   US Citizenship is required **  For over 10 years, Zscaler has been disrupting and transforming the security industry. Our 100% purpose built cloud platform delivers the entire gateway security stack as a service through 150 global data centers to securely connect users to their applications, regardless of device, location, or network in over 185 countries protecting over 4,500 companies and 100 Million threats detected a day.  We work in a fast paced, dynamic and make it happen culture. Our people are some of the brightest and passionate in the industry that thrive on being the first to solve problems. We are always looking to hire highly passionate, collaborative and humble people that want to make a difference.  Responsibilities Identify, analyze, and track emerging threats by reverse engineering advanced malware threats and building automated systems to extract threat intelligence for detection and prevention.Articulate findings through technical reports, blogs, media interviews and speaking engagements with strong writing/speaking skills and be comfortable presenting findings to both internal and external audiences.Leverage Zscaler’s existing data mining tools as well as our cloud based infrastructure to protect our customers.Exercise strong technical knowledge of malware-based threats, and live to identify the next attack vector, no matter how deep it’s hidden.  Qualifications Required 5+ years in static and dynamic analysis malware code reverse engineering.Expert knowledge of debuggers (OllyDbg, WinDbg, or x64dbg) and disassemblers/decompilers (IDA Pro or Ghidra).Proficient in unpacking malware, string and code obfuscation, encryption, and compression algorithms.Experience building automated tools to extract malware configuration information.Profound understanding of network protocols and web application security.Familiar with the development of IDS/IPS (e.g., Snort and Suricata) signatures and Yara rules.Strong scripting skills in languages such as Ruby, Python, or Perl.Professional english writing skills and experience in drafting blogs, technical reports, etc.Proven track record of innovative ideas and an ability to implement them.  Preferred Experience with threats to mobile devices, vulnerabilities, and binary exploitation.Publication of past research and/or speaking engagements.Data mining experience with large security data sets such as IDS, IPS and firewall logs.  Education Bachelor’s or graduate degree from four-year college or university (preferably in Computer Science, Engineering, or a related discipline), or equivalent security industry work experience. Why Zscaler?  People who excel at Zscaler are smart, motivated and share our values. Ask yourself: Do you want to team with the best talent in the industry? Do you want to work on disruptive technology? Do you thrive in a fluid work environment? Do you appreciate a company culture that enables individual and group success and celebrates achievement? If you said yes, we’d love to talk to you about joining our award-winning team.  Learn more at zscaler.com or follow us on Twitter @zscaler. Additional information about Zscaler (NASDAQ : ZS ) is available at http://www.zscaler.com. All qualified applicants will receive consideration for employment without regard to race, sex, color, religion, sexual orientation, gender identity, national origin, protected veteran status, or on the basis of disability.",Algo de responsabilidad,Jornada completa,Otro,"Servicios y tecnologías de la información, Software, Internet",27,None,False,,316,ACTIVELY_HIRING_COMPANY
767,2235769658,2020-11-04,Insight Global,UX Researcher,"Charlotte, North Carolina, United States","Insight Global is looking for a UX Researcher to join a financial company in Charlotte, NC. You will: plan, execute and analyze user research studies with ability to flexibly scale them across desktop and mobile devices. Collaborate with stakeholders to define & refine research objectives and ensure alignment with strategic, business and user goals. Work closely with UX strategists, designers and fellow researchers to provide research expertise and support during workshops and ongoing UX activities. Collaborate with design team to conduct design research to enhance UI Standards & Design Pattern library. Interpret qualitative and quantitative data from web analytics, user research data, trends and patterns to create actionable recommendations at project and portfolio level. Elicit user needs and usability concerns through various research methods, such as interviews, surveys, usability testing, task analysis, contextual inquires, ethnographic studies, & card sorting. Evaluate and evolve user models (personas, scenarios, profiles). Perform heuristic evaluation, accessibility reviews and testing of applications and make concrete recommendations for improving their usability. Provide rapid prototyping support to communicate concepts/designs recommendations based on research conducted. Synthesize research data, summarize findings & present results to management and project teams for both strategic and project level insight.",Intermedio,Jornada completa,Investigación,Servicios financieros,88,None,True,,284,ACTIVELY_HIRING_COMPANY
768,2279583703,2020-11-05,Experis,Data Collection Researcher,"Mountain View, CA, US","Data Collection Administrator (Arabic Speaking)  4 month contract (with potential for extension/conversion) Sunnyvale, CA / Remote (must be local)  We are seeking a highly motivated Data Collection Admin for a 4 month contract role with a leading client in Sunnyvale, CA. Data Collection Admin will need to learn quickly and execute procedures accurately and capture and document any needed information associated to data collection processes and data management systems. The Data Admin will work closely with participants, engineering team, and operations to provide data and analytical support for Data Collection initiatives, root cause investigation of defects, and will provide support to insure compliance requirements.  REQUIRED SKILLS - Experience using MS Office, Excel, Mac OS. - Proven ability to work productively and efficiently in an independent setting - Proven ability to clearly communicate with managers and associates at all levels - 2+ years of experience in customer service, technical support, project management, machine learning, or related field - Troubleshoot and triage any technical issues during the collections and report as needed - Ability to work in field locations as needed - Ability to travel domestically and/or internationally - Able to work flexible schedule including evenings and/or weekends - Comfortable working in a fast paced, highly collaborative, dynamic work environment - A good sense of humor, a positive attitude, and great team work skills - Demonstrated proactive behavior in addressing issues and problems - Willingness to roll up your sleeves to get stuff done and to accept re-prioritization as necessary  PREFERRED SKILLS - Hands-on experience with one-on-one session moderation with participants - Experience in research - Python, bash, or other programming language - Lift 30-40 lbs. of boxes when needed, with or without reasonable accommodation - Excellent communication, interpersonal and problem solving skills - Experience using Confluence, Wiki tools, Jira. - Strong organizational skills and ability to multitask effectively in fast paced, highly collaborative, and dynamic work environment - Ability to follow through, work independently, and take ownership of assigned responsibilities - Experience working with prototype assets - Practical knowledge of machine learning processing needs and trade-offs - Has own transportation   Desired Skills and Experience  - Experience using MS Office, Excel, Mac OS. - Proven ability to work productively and efficiently in an independent setting - Proven ability to clearly communicate with managers and associates at all levels - 2+ years of experience in customer service, technical support, project management, machine learning, or related field - Troubleshoot and triage any technical issues during the collections and report as needed - Ability to work in field locations as needed - Ability to travel domestically and/or internationally - Able to work flexible schedule including evenings and/or weekends - Comfortable working in a fast paced, highly collaborative, dynamic work environment - A good sense of humor, a positive attitude, and great team work skills - Demonstrated proactive behavior in addressing issues and problems - Willingness to roll up your sleeves to get stuff done and to accept re-prioritization as necessary  PREFERRED SKILLS - Hands-on experience with one-on-one session moderation with participants - Experience in research - Python, bash, or other programming language - Lift 30-40 lbs. of boxes when needed, with or without reasonable accommodation - Excellent communication, interpersonal and problem solving skills - Experience using Confluence, Wiki tools, Jira. - Strong organizational skills and ability to multitask effectively in fast paced, highly collaborative, and dynamic work environment - Ability to follow through, work independently, and take ownership of assigned responsibilities - Experience working with prototype assets - Practical knowledge of machine learning processing needs and trade-offs - Has own transportation      ManpowerGroup is an Equal Opportunity Employer (EOE/AA)",Intermedio,Contrato por obra,Tecnología de la información,Electrónica de consumo,14,None,False,,190,ACTIVELY_HIRING_COMPANY
769,2272718097,2020-10-10,Amicus Recruitment,"Senior / Lead Golang Engineer - Remote - £70,000 - £100,000","London, GB","Job DescriptionpSenior / Lead Golang Engineer - Fully remote - £70,000 - £100,000/p pDo you want to work for a company building out a Data driven AI software product to transform the Fintech business? We are proud to be working alongside an AI business who are transforming the way people invest their money. Whether it be personal, or business related, the company are building a real time data driven platform to help./p pFounded last year, they currently employ 10 individuals, with 5 in their current engineering team. Being their first out and out backend developer and working with 3 Frontend Engineers, a Data Scientist, and a hands-on CTO. As the Lead Golang developer, you will build out their product using Golang, AWS with a cutting edge Microservice Architecture. This is one platform that is a complex and extremely scalable. As a Lead Developer, you will be extremely hands on, around 90% initially and one of your first roles is to hire 2 developers whilst building out the architecture. The team will grow further in 6-12 months but as well as being totally responsible for the backend, you will help build out best practice and solve complex engineering problems./p pThe company are currently hiring for 5 positions across their engineering team in the next month which will take the current team to ten. They will allow you to work from there London office or work fully remotely from anywhere in Europe or on a similar time zone to the UK. They have a clear strategy and vision and using AI and work through tens of million / billions rows of data to revolutionise their sector. They are looking for a very seasoned Golang developer and you must have the following skills to be considered:/p ul li5 years' experience building software products/li liGolang experience (Absolutely minimum of 2 years' experience)/li liTDD/li liAWS or cloud experience/li liExperience building Microservice Architecture/li liAny experience of open source databases like Postgres or NoSQL will be highly advantageous/li /ul pThey are offering a great package with a salary between £70,000 - £100,000 plus good equity as well as the ability to work fully remotely indefinitely./pimg src='",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Software,5,None,False,,15,JOB_SEEKER_QUALIFIED
770,2236710455,2020-10-24,Guru (getguru.com),Senior Machine Learning Engineer,"Philadelphia, PA, US","Overview:  Guru is seeking an experienced Machine Learning Engineer to develop, improve, and deliver features powered by ML into our product. This is an awesome opportunity to maximize and grow your software engineering and machine learning skills alongside a team of creative, accomplished data scientists and engineers. To be successful you must be highly collaborative, excited about using ML to tackle real world problems, and have a commitment to show your grit. While we will always celebrate our successes, we embrace the journey by both persevering and learning from our setbacks. If this sounds like you, and you want to work with a diverse team that values all voices, please read on…  At Guru your voice will be heard and respected. One of our core values is 'Learn and Grow' as we seek to reflect on past projects to find opportunities to learn how we can better communicate and work more effectively as a team. We actively promote a healthy work life balance especially during the global pandemic as we realize for many life and work are intertwined more than ever.  This job is not only about how well you develop: it's about how you lend your positivity and presence, combined with your skill set to an energized environment and highly collaborative team. Strong sense of humor required, sarcasm detection skills a plus.  Responsibilities:   Productionize and deploy the ML models prototyped by our data scientists as well-tested Python-based services Build, automate, maintain, and optimize our feature extraction and model training pipelines Collaborate with ML engineers, data scientists, and architects to improve the architecture, scalability, stability, and performance of our ML platform Develop processes, monitoring, and frameworks to ensure data and model quality Collaborate on design and code reviews to ensure high quality software  Requirements:   5+ years of software engineering experience in Python/Scala/Java or similar programming languages to contribute to a Python code base Experience architecting, building and deploying scalable ML systems into AWS cloud using ECS, ECR, Lambda, API Gateway, Sagemaker, DynamoDB, and S3 Experience processing large amounts of data using technologies such as Apache Spark and EMR Experience working with Docker, CI/CD pipelines, and familiarity with infrastructure as code principles Proficient working with SQL, data warehouses, and relational data  Preferred but not required:   Experience with Scala Experience with Natural Language Processing (NLP) Experience designing systems in microservices architectures  Important:  Guru believes embracing diverse experiences, backgrounds, and skill sets make both Guru and our customers stronger and smarter. Even if your experience and skill set doesn't match the requirements perfectly, apply and tell us why you think you are a great candidate to tackle the responsibilities of this position!  Benefits to you:   Competitive salary Employee Stock Option Plan Generous health, wellness, and commuter benefits The chance to contribute to an upbeat, fully engaged culture  About Guru:  Guru is a dynamic, fast growing start-up based in Philadelphia and San Francisco. Our mission is to reinvent the way people connect with meaningful information at work. Guru's knowledge management solution provides customer-facing teams access to expert-verified information where they work and when they need it most. We believe in cultivating a welcoming, inclusive culture that encourages personal growth through working hard and having fun.  Launched in September 2015, our vision is backed by an amazing group of investors including FirstMark Capital, Salesforce, Michael Dell, the Slack Fund, Emergence Capital, Thrive Capital and Accel. As we enter the next exciting stage of expansion, we're searching for passionate individuals to join our rapidly growing team.  This is a full-time position located in Philadelphia, San Francisco, or Fully Remote. Re-location and/or Visa Sponsorship is not included in our hiring package. Applicants will need to be authorized to work in the US.  All are welcome here. At Guru, being inclusive is very important to us. Regardless of race, age, ethnicity, sexual orientation, gender identification, or background. If you have any questions about the application process or need any accommodations, please contact: talent@getguru.com  We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",Algo de responsabilidad,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Software, Internet",9,None,False,talent@getguru.com,104,ACTIVELY_HIRING_COMPANY
771,2283249115,2020-10-12,"FYI - For Your Information, Inc.",Senior Data Engineer - Remote,"Washington, D.C., DC, US","FYI For Your Information, Inc. is one of the fastest growing and most successful woman-owned Federal contractors in the country. We have won awards for being a Great Place to Work and continue to make ground-breaking advancements. We focus on career development and promotion people are the core of everything we do. If you are looking for a career and not just a job, you're in the right place!  FYI For Your Information, Inc., is a Woman-Owned Small Business GSA schedule vendor that is a premier provider of Human Capital, Training, and Information Technology services.  FYI attributes this capacity to deliver quality services to many factors, including FYI's in-house recruiters, senior HR professionals, corporate administrative staff, and agile, committed management resources. FYI's focus on the national, regional and local requirements of its customers, and a corporate organizational structure with sufficient depth of skills and authority to deploy and manage scalable teams, allows FYI to be responsive to the real-time needs of our Federal clients.  FYI's Benefits/Incentives: What is in it for you?  Opportunity to work remotely (per contract requirements). A knowledgeable, high-achieving, experienced, and fun team. A diverse work atmosphere. The chance to be part of a rapidly growing company and the next success story. Team building and innovation. A competitive base salary with a loaded benefits package plus 401K. Personal computer device allowance. Pet Insurance.   Summary Of Position  The Senior Data Engineer will support our software developers, database architects, data analysts and data scientists. They will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products.  Responsibilities  They will work with analytical teams to gather technical requirements for both capabilities and tools, as well as, accessing and prioritizing ingest of data assets. They will work with the infrastructure and enterprise architect teams to develop and build out the enterprise platform. The will advise the CDO on technical solutions and tradeoffs, liaise with the Enterprise Architecture to ensure standards are met, and work closely with the Security and Policy teams to ensure the organization is in compliance with their policies. In addition, they will work closely with the modernization product leads to ensure the data needs for the analytical teams is built into the modernized application.  In addition, they will help establish and implement metadata strategy aligned with EA strategy to ensure clear visibility into mapping of data assets to applications, and understanding of impact of changes to data models  Duties  Oversee the buildout of the enterprise Data Warehouse/API strategy Work with the analytics teams to prioritize data assets Manage contractors and oversee solution delivery Optimizing data ingest and ETL processes to ensure our products have maximum performance Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs. Navigate conflicting priorities and provide recommendations to the CDO when necessary  Experience building and optimizing 'big data' data pipelines, architectures and data sets.  Build processes supporting data transformation, data structures, metadata, dependency and workload management.  Work with the Enterprise Architect to establish modeling standards, data quality standards, data integration patterns or transactional and analytical systems. Prepare polished technical and non-technical status reports and presentations for senior management.  Minimum Qualifications:  12+ years of experience in data management or data architecture Experience managing vendors/contractors Experience with feature/product ownership Experience with Agile Scrum methodology Experience writing clear and effective proposals, policies, research summaries, etc. Development experience with MuleSoft and Informatica preferred: MicroStrategy a plus  Bachelor's degree or equivalent coursework in data management/computer science  We are an equal opportunity employer and value diversity. All employment is decided on the basis of qualifications, merit and business need.",Intermedio,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Consultoría de estrategia y operaciones",0,None,False,,None,None
772,2258234614,2020-10-05,New Signature,Azure Data Engineer - Remote Working - Europe,"Barcelona, ES","Join a team of passionate thought leaders in a dynamic and collaborative environment! New Signature's Data & AI team is growing fast and we're looking for our next Azure Data Engineer to join us.  Role Description  What's the story?  As we continue to scale we're looking for the market's best Azure Data & AI specialists to help us grow our business' fastest growing practice, AppDev & Data. You'll be working with the industry's biggest players, delivering innovative greenfield Data Platform builds, Data Integration programmes and implementing bespoke High-Level Data Architectural designs.  Who we're looking for:  Strong experience using Azure Data components  (ADFv2 , Azure SQL DB, Azure SQL Datawarehouse, Azure Data Lake, Azure Databricks ...) Specific focus Azure Databricks or Databricks platform Excellent knowlegdge of Apache Spark ecosystem (SPARK 2.3x) Databricks Delta Lake  Strong Python programming  Build distributed in-memory applications using PySpark  Spark APIs - RDD, Datasets & Dataframes  Knowledge of C# highly desirable Experience with Power BI Agile methodolgy experience essential CI/CD, Azure DevOps experience, highly desirable  Why do people like working here?  Remote working Flexible hours Training – 80 funded hours a year Variety of projects Paid travel expenses to customer site Tier 1 Clients & Partners Funky Warehouse London Bridge offices Free breakfast Top of the range kit – i7 laptop and Jabra Evolve headset Paid charity days Paid for trips to industry events  Who are New Signature?  We are a Microsoft house, born in the Cloud. The 2017 Acquisition of Paradigm Systems & Dot Net Solutions by New Signature accelerated a suite of capabilities to support the world's most prestigious and recognisable brands, helping them to become digital organisations powered by the Cloud.  We have over 500 people across the UK, US, Canada, South Africa, the Philippines and Australia, with our UK office growing over 70% YoY and headcount more than tripling.  How has this been possible?  Our values of being Generous, Authentic, Innovative and most importantly, Human, has enabled a unique approach to provide outstanding customer experiences, drive transformational results for clients across all company sizes & successfully deliver pioneering solutions that challenge the status quo. We've quickly established ourselves as a recognized expert at the forefront of Microsoft's technology stack with exceptional services to empower our customers, colleagues, and community.  Join us today and be part of the success story!  OUR CORE VALUES  Our employees are driven by our values and know that they make a positive difference every time that they help a customer to solve their challenges. Our focus on delivering great customer experiences empowers our people to build rewarding relationships that contribute to our positive work environment. You can learn more about our culture here:  New Signature Culture  Human  We use our hearts and minds to collaborate for success.  We harness technology to drive business, but we never let that replace our human connections. We use our hearts and minds to collaborate for success and instill confidence in our customers through relationships forged from trust.  Generous  We are giving and respectful.  With our efforts to always be generous, we elevate our service level with empathetic and considerate communications and actions. We always find a way to support our customers and colleagues by giving of our time and talent and equally respecting the time and talent of others.  Authentic  We tell it as it is, with positive intent.  Being authentic helps to nurture our strong and trusted relationships. We are honest, transparent, and reliable. When you partner with New Signature, you are partnering with a group of purposeful, outcome-driven and results-oriented professionals.  Innovative  We push the boundaries at the intersection of people, process and technology.  For us, there are no limit to our dreams. We continually innovate and push boundaries at the intersection of people, process, and technology to bring our customers and colleagues the best solutions first.  EQUAL EMPLOYMENT OPPORTUNITY  As a Global Cloud Transformation Consultancy business, New Signature understands diversity and inclusion in the workplace brings benefits to our customers, our business and most importantly, our people. We are committed to being an inclusive employer and we provide equal employment opportunities to all employees and applicants for employment.  New Signature prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other factors protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including all aspects of the recruiting and employment life-cycle at New Signature.  EMPLOYMENT ELIGIBILITY  New Signature requires candidates to prove eligibility to work in the UK. Offered candidates may be asked to complete a background check as permitted by applicable employment regulations. Depending on the requirements of the job, these record checks may include any or all of the following education verification, employment verification, drug screening, and criminal record check.",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Servicios financieros",3,None,False,,45,ACTIVELY_HIRING_COMPANY
773,2243713673,2020-10-01,Change Healthcare,Lead Data Scientist,"Seattle, WA, US","Transforming the future of healthcare isn’t something we take lightly. It takes teams of the best and the brightest, working together to make an impact.As one of the largest healthcare technology companies in the U.S., we are a catalyst to accelerate the journey toward improved lives and healthier communities.Here at Change Healthcare, we’re using our influence to drive positive changes across the industry, and we want motivated and passionate people like you to help us continue to bring new and innovative ideas to life.  If you’re ready to embrace your passion and do what you love with a company that’s committed to supporting your future, then you belong at Change Healthcare.Pursue purpose. Champion innovation. Earn trust. Be agile. Include all. Empower Your Future. Make a Difference.  Title  Lead Data Scientist  Overview Of Position  The Data Scientist will be responsible for supporting Artificial Intelligence, Machine Learning, and Data Science solutions for Change Healthcare, reporting to an AI Data Science leader under the Chief AI Officer.  We’re looking for data scientists with a passion for artificial intelligence to help drive a new generation of data and machine learning enabled services and products to impact healthcare. You will enjoy working with a highly talented and diverse team of data scientists specializing in deep learning, active learning, and classical machine learning, one of the richest data sets in US healthcare, nearly limitless cloud compute resources including Spark clusters and GPUs, and the ability to see your insights turned into real products.  The ideal candidate will have a background in machine learning, have experience working with large data sets, and have some experience in building and deploying data-driven innovative AI solutions. You are focused on results, a self-starter, able to put the customer first, team first, and have demonstrated success in using data science to develop and deploy AI solutions with a focus on customer impact. You also are able to rapidly prototype new ideas and methods to deliver quality code that is testable and concise.  What will be my duties and responsibilities in this job? Working alongside a team of AI data scientists, AI engineers, behavior scientists, PMs, and with business partners, you are able to focus on the problem at hand and identify new insights from our data with deep understanding of customers’ needs.Working towards a common goal, contribute to the team to deliver new solutions, enhancements, or AI-based products that rapidly deliver impact to the company.Have a focus on projects that have a direct impact while increasing our overall group expertise in new and emerging domains.  What are the requirements needed for this position?  5+ years of experience in Data Science or AI/ML Engineering Passion for learning and innovating new methodologies at the intersection of applied math / probability / statistics / computer science.  Proficient in translating unstructured business problems into an abstract mathematical frameworkPh.D. in Computer Science, Math, Physics, Engineering, Statistics or other hardcore technical fieldsFluency in Python.Spark or Pyspark experience preferred.Ability to write queries in SQL.Expertise in NLU/NLP, Conversational AI.Expertise in Deep Learning.Expertise in Knowledge Graph and personalization.Ability to deliver prototypes in both Jupyter or Zeppelin notebooks, as well as creating packages for cross-team utilization that can be invoked via pip installAbility to initiate and drive projects to completion with minimal guidanceThe ability to communicate the results of analyses in a clear and effective mannerExperience with TensorFlow.Knowledge of common data structures and ability to write efficient code in Python.Experience with large data sets and distributed computing with SparkExperience in AWS or GCP using tools such as EMR, S3, EC2, Deep Learning AMI’s, SageMaker. or customer build AI Platform. What other skills/experience would be helpful to have? Ph.D. with production delivery experienceExpertise and experience in AI solution developmentExtensive expertise in NLU for medical record readingExperience with cloud computing techniques or tools such as S3, EC2, EMR, SageMaker, ECS, Docker, Gitlab CI, Python packaging, Kubeflow, command-line executions and shell scriptingExceptional interpersonal and communication skills, including the ability to describe the logic and implications of a complex model to all types of partners (product managers, engineers, designers, senior executives)Experience in Healthcare Knowledge Graph and patients/providers/payors personalization.Experience in payment integrity and revenue cycle management optimization. What are the working conditions and physical requirements of this job?  General office demands  Join our team today where we are creating a better coordinated, increasingly collaborative, and more efficient healthcare system!   Equal Opportunity/Affirmative Action Statement   Change Healthcare is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, age, sex, sexual orientation, gender identity, genetic information, national origin, disability, or veteran status. To read more about employment discrimination protections under federal law, read EEO is the Law at https://www.eeoc.gov/employers/eeo-law-poster and the supplemental information at https://www.dol.gov/ofccp/regs/compliance/posters/pdf/OFCCP_EEO_Supplement_Final_JRF_QA_508c.pdf .  If you need a reasonable accommodation to assist with your application for employment, please contact us by sending an email to applyaccommodations@changehealthcare.com with 'Applicant requesting reasonable accommodation' as the subject. Resumes or CVs submitted to this email box will not be accepted.  Click here https://www.dol.gov/ofccp/pdf/pay-transp_%20English_formattedESQA508c.pdf to view our pay transparency nondiscrimination policy.  Change Healthcare maintains a drug free workplace and conducts pre-employment drug-testing, where applicable, in accordance with federal, state and local laws.",No corresponde,Jornada completa,Otro,Servicios y tecnologías de la información,4,None,False,applyaccommodations@changehealthcare.com,27,ACTIVELY_HIRING_COMPANY
774,2220514044,2020-10-05,Headspace Inc.,Senior Data Scientist,"Santa Monica, CA, US","Headspace is looking for a Senior Data Scientist, reporting into the Director of Data Science and Analytics.   We are seeking a talented and experienced senior data scientist to deliver impactful insights to teams across the business. Working closely with the director of data science and analytics, the senior data scientist will develop models to solve business problems and improve the member experience. The individual will have the opportunity to inspire and mentor additional members of the team in all things data-related. A successful candidate will be technically strong, proficient in communicating results to a range of audiences, and excited to share their knowledge with other team members.  About The Senior Data Scientist Role At Headspace  Train, test, and tune machine learning models for a variety of problems across the businessManage all aspects of data science projects from start to finish, including early conversations with stakeholders and presenting results to executivesWork with the Director of Data Science & Analytics to pave the way for actionable data science in a high-growth, mission-driven organizationIdentify opportunities to apply data science and machine learning towards unaddressed business problems, or to improve existing aspects our data science infrastructure.  Location: This role is open to remote employees in select US states: California, New York, Florida, Georgia, Texas, Maryland + Washington DC, North Carolina and Washington.  What You’ve Accomplished Bachelor degree in computer science, statistics, applied mathematics, or any scientific or computational degree, Masters/Ph.D. preferred3+ years of experience developing machine learning models and putting them into production3+ years delivering analytical insights to stakeholdersExperience managing data science projects from conception to completionExperience with user behavior, mobile app, and subscription business a plusDeep understanding of statistics, experimental design, and machine learning algorithmsCommitment to using best practices in data scienceStrong programming skills in Python, experience with pySpark is a plusStrong SQL skills, experience with AWS services a plusExcited to share knowledge and mentor other members of the teamStrong ability to communicate complex ideas and results to both technical and non-technical audiences  How To Get Started  If you’re excited by the idea of seeing yourself in this role at Headspace, please apply with your CV and a cover letter that best expresses your interest and unique qualifications.",Algo de responsabilidad,Jornada completa,Otro,"Servicios y tecnologías de la información, Software, Internet",5,None,False,,106,ACTIVELY_HIRING_COMPANY
775,2277630240,2020-10-17,Uptake,Machine Learning Engineer,"Chicago, IL, US","What we do:  Uptake is the premier Industrial AI company, providing a predictive analytics SaaS platform that empowers major industry leaders to optimize performance, reduce asset failures, and enhance safety. At Uptake, we combine our strengths — machine learning, analytics, data visualization, and software development — to deliver actionable insights that make industry more reliable, productive, safe and secure.  What Machine Learning Engineers Do Here  Machine Learning is at the core of what we do at Uptake. Machine Learning Engineers are part of the team working to build the core Machine Learning and AI tools that will power Uptake's future.  Typical day to day tasks for a Machine Learning Engineer might include:  Building and maintaining software libraries used by data scientists to quickly build, evaluate, and deploy machine learning models into production. Evangelizing software engineering best practices across data science teams at Uptake and encouraging best practices by building them into our libraries and tools where possible. Translating customer needs into technical requirements for machine learning model deployment. Collaborating with Data Science, Product, and Engineering stakeholders to define and implement new services to accelerate the ML model deployment lifecycle and other data science tasks. Keeping up to date with new ML concepts and technologies to keep our libraries and tools on the cutting edge of the discipline. Collaborating with the engineering team that maintains our data science platform to improve the entire ML ecosystem at Uptake.   What We Are Looking For  Bachelor's degree or higher in a relevant field Passion for machine learning! We want candidates who love machine learning and are excited about what they do. Some ways previous successful candidates have demonstrated this are by: Writing relevant blog posts and/or articles. Participating in relevant online communities. Participating in Kaggle competitions. Sharing details about personal or professional projects in the machine learning space within a cover letter. Receiving recognition via professional or academic awards (example: Most Valuable Employee, scholastic grants). Expressing detailed knowledge of and genuine interest in Uptake's unique methods, products, data, and technology within a cover letter.  Ability to write production-level machine learning code in Python: or Java, Scala, or similar JVM-based languages. Some ways previous successful candidates have demonstrated this are by: Contributing to influential Open Source Projects like Docker, Kafka, Spark, Kubernetes, sklearn, XGBoost, Tensorflow, pytorch, Elasticsearch etc. Describing a machine learning project they developed that is deployed in a live setting within a resume or cover letter. Making a high quality machine learning project available in a public forum like GitHub or Kaggle. Publishing work in machine learning related journals or conferences.  Familiarity with data science workflows, and concepts like exploratory data analysis, training, and scoring  Nice to Have  2+ years of applied software engineering experience, data science experience, or a combination of the two Experience writing production code in Python as well as Java, Scala, or similar JVM based languages Experience developing and maintaining software packages (particularly Python)  Experience with container technology (like Docker) and container orchestration (like Kubernetes) Experience with stream processing with tools like Kafka or Flink Experience working with web based APIs Experience working on concepts like AutoML or end-to-end learning Experience deploying and maintaining Machine Learning models into production Experience with CI/CD tools like Jenkins Substantive contributions to open source projects in the areas of data science or machine learning  Applicants must be authorized to work in the U.S.  Uptake welcomes and encourages applications from all individuals, without regard to any prohibited ground of discrimination, including from people with disabilities. Accommodations are available upon request for candidates taking part in all aspects of the selection process.",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Software, Internet",11,None,False,,61,ACTIVELY_HIRING_COMPANY
776,1981620523,2020-10-21,"Inscripta, Inc.",Account Executive,"Chicago, Illinois, United States","Inscripta is developing the world's first scalable platform for benchtop Digital Genome Engineering. The company’s advanced CRISPR-based platform, consisting of an instrument, reagents, and software, will offer a fully automated workflow that enables multiplexed, trackable editing of cells at an unprecedented scale. Inscripta’s goal is to empower scientists whose gene editing research is stifled by current technical and licensing limitations. By providing this unique platform and engaging in collaborative business practices, such as making its MAD7 CRISPR nuclease free for research purposes, the company enables scientists to realize a new era of biological discovery. Due to rapid growth Inscripta has an opening for an Account Executive located in the Midwest, United States (Chicago). We are looking for an outstanding, experienced Account Executive to drive sales of Inscripta’s OnyxTM Digital Genome Engineering Platform and its consumables, assays and services. This individual will identify, nurture and develop high value opportunities to closure. They will actively engage in deep market development, technical selling, account planning and rapidly develop a sustainable, growing funnel of qualified opportunities. The Account Executive will work in partnership with local Field Application Specialists (FAS) and the Customer Success Team to provide support for customer applications as well as develop and nurture relationships with Key Opinion Leaders (KOL’s). They will relay voice of customer feedback, including new applications, to Field Support, Applications Development and Marketing/Product Management to optimize the customer experience using our technology. Responsibilities:Act as a sales driver for the Inscripta OnyxTM Digital Genome Editing platform and proprietary consumables by identifying, developing and closing high-value sales opportunities to meet/exceed assigned revenue targets.Develop and implement effective pre-sales educational campaigns and other key growth activities to support assigned revenue goals and expansion of both brand and product awareness in the marketplace, leading to a measurable and sustainable funnel of opportunities. Persuasively deliver customer-facing seminars covering a variety of scientific research topics, products, applications, and data related to Inscripta’s technology.Work as a seamless team with Field Application Scientist(s) to develop action plans for specific customers and ensure the highest level of professional client communication to drive sales. Identify and nurture KOL's in multiple application areas and develop relationships to catalyze the sales and marketing efforts.Act as an internal customer advocate by delivering VOC to the Marketing, Product Management, Applications and other departments related to product feedback, competitive intelligence, market trends, effectiveness of marketing/positioning, and tactics in the field.Work with Director of Marketing to convert/customize marketing plan into tactical action and deliverables, while supporting and exploring new ways of customer interaction.Professionally and proactively communicate with external and internal customers.Develop deep knowledge of accounts, funding, competition in territory leading to recurring accurate forecasting of sales. Other duties, as assigned. Requirements:At least 10+ years of commercial (sales/marketing) experience in one or more of the following areas: CRISPR-based genome editing, functional genomics, synthetic biology, metabolic engineering and/or high-throughput screening.Experience in the sale of sophisticated, high-throughput instrument platforms and allied proprietary consumables. Proven success in selling complex solutions to diverse, consortia-based clientele.Proven successful history of driving new, innovative technology into an established workflow via conversion plans that may include tactics such as cost comparison(s), accuracy of data, time to actionable data, etc. Strong verbal, written and interpersonal communication skills to effectively deliver technical presentations, handle customer issues and work collaboratively to support the efforts of sales and support effort. Bachelor’s degree with 10+ years’ experience and exceptional qualifications. Ph.D. Or Master's degree in a relevant field and relevant lab experience a plus.Ability to learn quickly and work in a highly innovative, fast-paced startup environment, collaborating closely with other cross-functional and geographically-distributed teams.Average 40-50% travel in assigned sales territory. Excellent computer software skills with demonstrable expertise in Excel, Word, PowerPoint, and SalesForce.ComProficiency with verbal and written communication in English.Working language proficiency in French, German, Spanish, Italian, or Chinese is not required but would be a plus.Excellent organizational, analytical, strategic, and interpersonal skills. Inscripta offers a competitive base salary, bonus plan, benefits package and stock options to all team members. Join us and work with a great team of people developing the world's first scalable platform for benchtop Digital Genome Engineering. At Inscripta we don’t just accept difference — we celebrate it, support it, and thrive on it for the benefit of our employees, our innovation, and our community. We are proud to be an equal opportunity workplace because the more inclusive we are as a company, the better our work will be. Inscripta is headquartered in Boulder, CO with offices in Pleasanton and San Diego, CA. This position is located remotely in Chicago (Midwest), United States, within proximity of a major airport..",Intermedio,Jornada completa,"Ventas, Ciencias",Biotecnología,59,None,False,,1351,ACTIVELY_HIRING_COMPANY
777,2235789125,2020-11-04,Creative Circle,Remote User Experience Researcher,"St Louis, Missouri, United States","Our finance client has a HOT need for a User Experience Researcher with 5+ years of experience UX / Design research experience for a 12+ month, 40 hour/week, offsite contract role starting in Mid-October.  The User Experience Researcher must have experience using design thinking to discover and deliver human-centered solutions. In this role, the UX Researcher will lead and executes strategic design and execution of user-centered research that provides actionable insights which influence design and development of multiple departments in the firm.  User Experience Researcher Responsibilities: - Develops, designs and executes user research using qualitative and quantitative methods.- Determines and recommends the most efficient and effective research approaches to solve for business needs and meet agreed-upon objectives- Identifies, influences, supports and partners with multi-disciplinary teams to execute research projects.- Communicates insights and influences business partners to take action by providing thought leadership on how insights impact desired business/project outcomes. User Experience Researcher Requirements: - Bachelor's degree in Human Factors, Human-Computer Interaction, Psychology or relevant field.- Expert in both qualitative and quantitative user experience research methodologies.- Proactively develops self in the field of current and emerging research and technology.- Expert in critical thinking, strategic thinking, process improvement, relationship-building and problem-solving abilities.- Able to expertly research, analyze and consolidate data into trends and share with teams.",Intermedio,Contrato por obra,Investigación,Servicios financieros,57,None,True,,263,ACTIVELY_HIRING_COMPANY
778,2208729587,2020-10-15,Solita,Senior ML Engineer (time series) / Data Scientist (d/w/m),"Munich, Bavaria, Germany","Would you like to focus to enable fast change? How about working with modern, impactful technologies and skillful people making the change possible? We have enabled our clients to become data-driven by implementing hundreds of data-driven solutions for large-scale Nordic companies and organizations. We have both automatized processes with the help of classical Machine Learning and Deep Learning, and helped companies to create new data-based services. The ideal candidate will have hands-on experience in building production level forecasting models using Deep Learning techniques. Should be able to design creative solutions and communicate them well, and be responsible for writing quality code and supporting it in production. Other qualifications include:Strong practical experience with Deep Learning frameworks (Tensorflow or PyTorch) and classic Machine Learning algorithmsProficiency with CNN, LSTM, and Transformers architecturesProficiency with Python, NumPy, Pandas and Scikit-learnProficiency with statistics and hands-on experience in data miningExpertise in visualizing and manipulating big datasetsKnowledge of cloud infrastructures (Azure, AWS) is a plusAcademic or industry research in time series forecasting is a plusEnglish is a must, fluent German is a big plusExperience in building production level ML/DL products is a double plus If you know multiple ways to deal with missing data, are able to explain in non-technical terms the essence of vanishing gradients and understand the advantages of Multi-head attention, you are already on the right side! If you are up to date with recent research in time series analysis and worked on production level solutions (predictive maintenance, dynamic pricing optimization, etc.), do not wait any longer – we are eager to know you ASAP! Solita as a workplaceSolita is a workplace where you will always find a more knowledgeable multi-disciplinary peer to spar with. People join us to become a part of a diverse community of experienced professionals and continuous learners. And people stay for the same reason. At Solita our highly skilled experts are working together to help our clients in all industries, while still maintaining a start-up like, relaxed atmosphere and great culture! Our company culture is very important for us, and we value low hierarchy, independence and responsibility, impactful work, high technical skills, and cool colleagues. Read more about what kind of company we are. All we have is in our people. We offer support for our people both at work and also when life happens. We care. Join us to make an impact that lasts!If you feel up to the challenge, contact us by sending us your application to careers@solita.fi. Your application won’t end in a mystery black box: We contact and communicate with all candidates openly. We hope you will be able to work in our office in Munich. Interviews are held virtually in Teams. Read more about our interviews and onboarding. If you wish to have a chat with us before sending an application, please contact our AI Lead Oleg (oleg.gutyrchik@solita.fi). Advice for headhunters and agencies: We are not actively looking for new partners. Should you have any questions, please contact directly our Recruitment Director Kati (kati.kitti@solita.fi). ABOUT SOLITASolita is a workplace, where you will always find a more knowledgeable multi-disciplinary peer to spar with. People join us to become a part of a diverse community of experienced professionals and continuous learners. And people stay for the same reason.At Solita, everybody can feel comfortable to be themselves with all their perfections. We focus on changing the world, not people. Diversity in all forms is a strength, which we value highly. You will find an easy-going work culture, where you can be yourself.All we have is in our people. We offer support for our people both in work and also when life happens. We care.",Intermedio,Jornada completa,"Tecnología de la información, Análisis",Servicios y tecnologías de la información,105,None,False,"careers@solita.fi., oleg.gutyrchik@solita.fi, kati.kitti@solita.fi",635,ACTIVELY_HIRING_COMPANY
779,2255208098,2020-11-08,Optello,REMOTE Senior Data Engineer REMOTE,"New York City, NY, US","If you are a Senior Data Engineer with fin-tech experience and you're seeking a remote role, please read on!  We are a SaaS start up company directly helping to cut the cost of being an employee, putting money into your pocket. We connect the everyday payroll functionalities seamlessly. 78% of Americans live paycheck to paycheck and more than half have poor credit. We are helping to create a fairer financial system for you and your employer.  Top Reasons to Work with Us top talent, bright teammatescompetitive comp & great benefitsyou can work REMOTE What You Will Be Doing  We're seeking to build our platform from scratch and have the internal stakeholder buy-in to do so. You will heavily influence the architecture, design, and development of the product as a core member of the engineering team.  What You Need for this Position  Python ETL SQL AWS Fundamentally a Data Engineering role, we are seeking someone with a passion for data, ample experience in working with a startup to establish best practices, cultural consistency, and high caliber teams.  If you are a Senior Data Engineer with strong Python and fin-tech experience, please apply today! You can quick apply here or email your resume to remy@Optello.com.  Email Your Resume In Word To  Looking forward to receiving your resume through our website and going over the position with you. Clicking apply is the best way to apply, but you may also:  Remy.Schor@Optello.com Please do NOT change the email subject line in any way. You must keep the JobID: linkedin : RS2-1609988 -- in the email subject line for your application to be considered.*** Remy Schor - Sr. Executive Recruiter - Optello  Applicants must be authorized to work in the U.S.  Optello is proud to be an Equal Opportunity Employer  All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.  Your Right to Work - In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.  Optello will consider for Employment in the City of Los Angeles qualified Applicants with Criminal Histories in a manner consistent with the requirements of the Los Angeles Fair Chance Initiative for Hiring (Ban the Box) Ordinance.",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Construcción, Software, Servicios financieros",2,None,False,"remy@Optello.com., Remy.Schor@Optello.com",38,ACTIVELY_HIRING_COMPANY
780,2276785666,2020-10-11,Loadsmart,Senior Data Scientist (Remote),"São Paulo, BR","Who We Are   Loadsmart aims to move more with less. We combine great people and innovative technology to more efficiently move freight throughout North America. Our focus is on designing and building the best tools for our team and our customers, using machine learning algorithms to connect cargo with trucks. By better matching supply and demand, we reduce wasted fuel and lost time, cutting out empty miles for motor carriers and providing instant booking for shippers.   Who You Are   You believe in game-changing innovations and are excited about reimaging a 700 billion dollar industry. You know how to take ideas, optimize them, and push it into production code using Python.   The Role   We are looking for a Senior Data Scientist to work remotely with experience in Software Development to join us in the Sourcing Automation group in order to analyse, design and implement machine learning algorithms for systems that provide recommendations to source carriers, and that optimize margins of carrier prices.   Key Responsibilities  Model predictive techniques to a variety of logistic problemsDevelop new (and improve existing) machine learning algorithmsImplement, release, and then maintain the algorithms running in productionAnalyse metrics and look for sourcing improvement opportunities   Qualifications  4+ years of experience as a data scientist.Experience in modeling and implementing predictive algorithms (either from scratch or by having used libraries / frameworks):Conducting experiments in production, and evaluating its results:Performing exploratory data analysis.You’re very comfortable communicating in English (both written and spoken) - you will work in an international team with native and non native english speakersCuriosity. You are keen on learning new methodologies, technologies and tools: also, on evaluating their pros and cons. You ask questions: always eager to learn more. But you are also pragmatic.MS or PhD in a technical discipline would be cool, but it is not mandatory.Nice-to-have (not required) qualifications: Professional experience as a software developer:Software development skills in Python (or other programming languages), databases (such as PostgreSQL) and REST APIs:Software design, object-oriented programming, SOLID principles:Automated testing, unit / integration tests, test-driven development.   What You Will Find Here  Generous Stock Option PlanCompetitive SalaryBuilding a Rapidly-Growing Tech CompanyInternational Environment / CareerAbility to Work with Cutting-Edge TechnologyAccess to an Online Learning PlatformBecause we are an international company, we only accept resumes in English.  At Loadsmart, we believe our biggest asset is our people. We are proud to be an equal opportunity employer, hiring and developing individuals from diverse backgrounds and experiences to add to our collaborative culture. Loadsmart treats all candidates and employees with respect and does not discriminate in our recruiting, hiring, and promoting processes, including on the basis of race, color, religion, sex, age, sexual orientation, gender identity and/or expression, national origin, veteran status, or disability.",Algo de responsabilidad,Jornada completa,Otro,"Software, Internet, Servicios financieros",8,None,False,,43,None
781,2199869332,2020-10-22,BMC Software,Principal Data Engineer,"United, LA, US","Description And Requirements  The BMC Innovation Labs brings together customers, partners, and employees to accelerate the development of new and relevant solutions that create value. Our goal with our innovation labs team is to harness new ideas, to anticipate and act on market changes by: Fostering innovation by creating spaces for experimentation Advancing ideas that generate disruptive technologies Accelerating prototyping and development of new capabilities   It is through this collaborative environment that we explore how new technologies can be leveraged to bring market differentiating value to customers through our next generation solutions. We help clients pivot from thinking digital to being digital at the core.  From big data analytics, to cognitive digital twins and data driven strategy consulting and startup acceleration we work to make our customers even more successful. Join us in our accelerated journey.  Position Description  We are looking BMC Is looking for a savvy Data Engineer to join our growing team of data experts. The individual will be responsible for developing solutions that expand and optimize customer’s data pipeline architecture, as well as optimize data flow and collection for cross functional teams.  The Ideal Candidate Should Have These Characteristics Self-starter that requires minimal oversight yet demonstrates consistent involvement with flexibility and good follow-through skills. Enthusiastic about managing challenging projects across multiple teams and locations. Comfortable marshaling large amounts of data to make decisions and build business cases. Shares BMC's passion for the customer Embraces change and works well in a fluid environment Ability to operate and communicate at all business levels Expects, requires and demonstrates continuous innovation Results oriented Ability to think big and to inspire passion in others   Primary Roles And Responsibilities Conceptualizing and generating infrastructure that allows big data to be accessed and analyzed. Assist in the migration of Database platforms Create data pipelines for batch, micro-batch, and real-time data streams. Assemble large, complex data sets that meet functional / non-functional business requirements. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies. Build tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for our data scientist team members that assist them in building and optimizing our product into an innovative industry leader. Create, schedule, maintain, and debug ETL and ELT processes Data cleansing and data wrangling to prepare structured and unstructured data for various modes of consumption including Artificial Intelligence, Machine Learning, statistical models, dashboards, etc.   Must-have Experience/criteria For Role Self-starter requiring minimal oversight, demonstrates consistent involvement with flexibility and good follow-through skills. Excellent problem solver and out-of-box thinker Must have participated in full product development lifecycle of software products (whiteboard to production) and successfully brought deliverables to market. Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. Experience building and optimizing ‘big data’ data pipelines, architectures and data sets. Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. Strong analytic skills related to working with unstructured datasets. Build processes supporting data transformation, data structures, metadata, dependency and workload management. A successful history of manipulating, processing and extracting value from large disconnected datasets. Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.  Fast learner that can quickly synthesize ideas, information, and options into a strategy, plan, or response and effectively communicate it   Technical Skills Big data tools: Hadoop, Spark, Kafka, etc. Relational SQL and NoSQL databases Scripting languages: Python, Java, C++, Scala, etc. Experience working with AWS / Azure / GCP as well as building and optimizing ‘big data’ pipelines, architectures, and data sets A track record of shipping successful software products.   It is the policy of BMC Software to afford equal opportunity for employment to all individuals regardless of race, color, age, national origin, physical or mental disability, history of disability, ancestry, citizenship status, political affiliation, religion, gender, transgender, gender identity, gender expression, marital status, status as a parent, sexual orientation, veteran status, genetic information or other factors prohibited by law, and to prohibit harassment or retaliation based on any of these factors. BMC never asks for payment from individuals seeking employment with the company.  If you need a reasonable accommodation for any part of the application and hiring process, visit the accommodation request page .   < Back to search results",No corresponde,Jornada completa,Tecnología de la información,"Equipos informáticos, Software, Servicios y tecnologías de la información",6,None,False,,79,ACTIVELY_HIRING_COMPANY
782,2279216939,2020-10-11,MinTech Agency ~ Diversity Recruiting,Data Engineer II,"Nashville, TN, US","Remote Data Engineer II We are looking for an exceptional Data Engineer to design scalable, reliable, secure, and extensible data solutions according to our company’s and client’s needs. You will be responsible for developing, testing, improving and maintaining new and existing line of business data platforms, data warehousing, and streaming data solutions to help effectively provide and manage data effectively.  As part of our team, you will work closely with data engineers, software engineers, and quality assurance analysts to ensure system stability, security, and consistency. You will also collaborate with support teams to provide technical support and work with product owners to determine and understand new product requirements. Communication and organizational skills are key to this position along with a problem-solving attitude.  Responsibilities   Build, monitor, and maintain batch and streaming data solutions. Build, monitor, and maintain RDBMS solutions. Ensure performance, security, and availability of data solutions. Design, develop, and optimize data structures, stored procedures, and functions using T-SQL. Analyze existing data structures and data solutions to provide suggestions on performance improvements and alternate approaches. Prepare documentation and specifications. Effectively collaborate with other team members and stakeholders.  Requirements   3+ years strong working knowledge and experience with MS SQL Server databases, query authoring (SQL), T-SQL and schema design to optimize performance. Experience with other RDBMS with platforms such as PostgreSQL, MySQL, Oracle, etc. Experience ingesting, processing, storing, and querying large datasets. Experience writing well-abstracted, reusable code components using languages such as python, C#, Go, etc. Experience with Git and CI/CD tools and paradigms. Understanding of SDLC and Agile development methodologies. Strong written and verbal communication skills. Bachelor’s degree preferred or relevant experience.  Preferred   Experience with NoSql/Document Database platforms such as MongoDb, Casandra, Couchbase, DynamoDb, etc. Experience with stream processing and messaging platforms such as Kafka, Kinesis, SNS/SQS, RabbitMQ, etc. Cloud experience preferably in AWS or Azure. This is a remote position.",Intermedio,Jornada completa,Tecnología de la información,Atención sanitaria y hospitalaria,None,None,False,,3,JOB_SEEKER_QUALIFIED
783,1995017800,2020-10-26,Panasonic North America,Senior Data Engineer,"Denver, CO, US","Panasonic – Senior Data Engineer  Every moment of every day, people all over the world turn to Panasonic to make their lives simpler, more enjoyable, more productive and more secure. Since our founding almost a century ago, we’ve been committed to improving peoples’ lives and making the world a better place–one customer, one business, one innovative leap at a time. Come join our journey.  Click here to learn more about how Panasonic is creating a better life, a better world.   Watch this video to see how our employees are shaping the technologies that move us.  Cirrus: https://na.panasonic.com/us/industries/intelligent-transportation  What You’ll Get To Do  The Smart Mobility Office (SMO) within Panasonic acts as an incubation engine to capture new opportunities and become a gamechanger in the rapidly transforming transportation industry. The Cirrus team, within SMO, is creating disruptive technologies to advance vehicle-to-everything (V2X) technology that transforms each vehicle into a true IoT device and leverages this data to revolutionize traffic management and safety on our roadways.  As our first Sr. Data Engineer, you will help establish what the Data Engineering discipline can be for the Analytics, Research, and Insights team!  You will design, build, and manage data pipelines from many sources to support a wide variety of analysis and stakeholder needs across the organization. You’ll partner with Data Scientists, Researchers, Product Owners, Engineers, and Business/Marketing to understand data use cases and develop innovative solutions. In addition to enabling exceptional data access for stakeholders, you will serve as a data subject matter expert contributing to analyses that can ultimately save lives via the Cirrus/V2X mission.  About you: You are a flexible team player who thrives in ambiguity. You have experience collecting, cleaning, organizing, and moving large data sets to enable machine learning, AI, market insights, and product insights. You love thinking about data engineering problems that includes data streaming, ETL, data warehousing, data lakes, and/or data virtualization. You’re able to lead technical projects autonomously and unlock the value of data. You have a proven track record of establishing Data Engineering processes at previous companies and care deeply about using data to solve business problems. Conceive, lead, and execute projects to manage an exceptional data access solution, supporting user requests from various stakeholder groups.Build data pipelines, including cleaning, sanitizing, or organizing data, and building self-service datalakes or data repositoriesWork with a wide range of business partners, particularly in engineering and product management, to develop innovative analysis solutions that address top outcomes, including feature development/enhancement, system health monitoring, testing, and troubleshooting.Research and assess value of potential new data sources under consideration for the Cirrus/V2X data environment, and present results with clear recommendations to leadership.Lead the strategic growth of this discipline on the Data Science & Analytics team, building strong relationships with stakeholders and mentoring junior team members.  What You’ll Bring  Education & Experience: Advanced knowledge and/or experience in building data pipelines, cleaning, sanitizing, or organizing data, and building self-service datalakes or data repositoriesExpert in programming tools/languages commonly used for data manipulation, especially SQL and Python (a bonus if you know Denodo and Athena)Advanced knowledge and/or experience as a Database Administrator managing user access, ETLs, database performance/monitoring, and documentationAdvanced knowledge and/or experience with data visualization and analysis tools, e.g. Tableau, Spotfire, etc.Preferred experience working in an agile product environmentPreferred experience mentoring junior team members in data and analysis techniques  Competencies Self-starter with a desire to tackle complex business problems by collaborating with both partners and peersA true team player – flexible about your role and ready to do what it takes to get things doneInsatiable curiosity and lifelong learnerComfortable in a fast pace environment with changing or ambiguous requirementsStrong analytical skills and good intuition with numbers, connecting the dots, synthesizing disparate information sources, and finding patternsIs an innovator who wants to improve the world for othersExcellent problem-solving skills with the ability to analyze situations and identify existing or potential problemsRadically candid with the ability to challenge the status quo and current thinkingDesire, willingness, and ability to teach and mentor othersExceptional written, verbal, and visual communication skills: ability to distill complex ideas into concise and accurate narratives that enlighten and inspire.  What We Offer Competitive compensation packageComprehensive benefitsPet InsurancePaid Parental Care LeaveEmployee Referral ProgramEducational AssistanceFlexible Work ProgramVolunteer time OffCasual Dress CodeTotal Well Being Program Panasonic is proud to be an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender identity, sex, sexual orientation, national origin, disability status, protected veteran status, and any other characteristic protected by law or company policy. All qualified individuals are required to perform the essential functions of the job with or without reasonable accommodation. Pre-employment drug testing is required for safety sensitive positions or as may otherwise be required by contract or law. Due to the high volume of responses, we will only be able to respond to candidates of interest. All candidates must have valid authorization to work in the U.S. Thank you for your interest in Panasonic Corporation of North America.",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Servicios financieros",116,None,False,,711,ACTIVELY_HIRING_COMPANY
784,2166035511,2020-10-07,IronNet Cybersecurity,Principal Cyber Data Engineer (Remote/Virtual),"Boston, MA, US","Description  What’s your mission?  IronNet’s mission is simple: To deliver the power of collective cybersecurity to defend companies, sectors, and nations. For decades, companies have been defending against cyber attacks on their own while adversaries have been organizing themselves into sophisticated hacker networks … until now, with IronNet Collective Defense. In 2014, General (Ret) Keith Alexander, former Commander U.S. Cyber Command, launched IronNet to strengthen cybersecurity defense against highly sophisticated adversaries, across all borders and sectors.  In response to cyber adversaries who increasingly collaborate for collective offense, leading organizations in our critical infrastructure are using collective defense strategies and solutions to meet these powerful and ever-changing threats. We believe that collective defense is our collective responsibility and we are leading the charge.  The Opportunity  IronNet’s Analytics team is responsible for building behavioral analytics and event correlation code for our NDR and collective defense products. The team focuses on developing cost effective cloud solutions that are distributed and highly scalable, processing large volumes of events.  We are looking for a senior or principal level Cloud Data Engineer with focus on data pipelines and development of SaaS solutions to join the team.  To be successful in this role, you must be able to . . . Use AWS to provide microservices architectures that are highly reliable, redundant and scalableInterface data transformation, enrichment, and machine learning algorithms to cloud storage and messaging infrastructureUse modern programming languages (Python, Scala, Java, Golang, etc) to develop continuously integrated and deployed production software Architect horizontally scalable analytics and data processing pipelinesTurn proof of concept architectures into production environmentsShare knowledge and assist others in understanding technical topics You may be the person we need if your background aligns with the following . . . Proven experience as a Data Engineer, Machine Learning Engineer, Software Engineer, Cloud Engineer or similar role.Demonstrable expertise in a modern programming language(s) (Python, Scala, Java, Golang, etc.).Experience with SaaS architectures and delivering production software.Experience with Kafka, Spark, and other scalable data frameworks.Experience with cybersecurity event processing including high-volume ETL and analytics.Possess strong analytical, technical, and problem-solving skills.  Personal Profile Passion for championing projects from concept to delivery to customer.Competitive spirit: willingness and ability to “sell” your solution during collaborative team discussions.Desire to be the best and prove it every day.Eagerness to learn and improve your own skills and to make those around you better.Highly attentive to detail and a focus on improving the code base and quality of our tests.Commitment and aptitude to proactively find solutions to ambiguous opportunities.Bring a unique skill set or elevate the results of the teams you are a part of. Recognition & Awards  IronNet is recognized as a representative vendor in Gartner’s “Market Guide for Network Detection and Response (NDR)”, and Forrester recently named IronNet a representative vendor in its “Now Tech: Network Analytic and Visibility, Q2, 2020” research.  Recent Awards  CRN Emerging Vendors Fortress Cyber Security Hot 150 Cybersecurity Companies Fortress Cyber Security EMA Vendor To Watch CRN Security100  More About IronNet  IronNet delivers unmatched collective cyber threat detection for enterprise on-premise, cloud, and hybrid networks. We do this through the application of advanced behavioral analytics, AI, and machine learning techniques. Our team combines the tradecraft knowledge of the best offensive and defensive cyber operators in the world with world-class mathematicians and data scientists to engineer solutions that empower companies to defend against advanced threats.  Our founder and Co-CEO, General (Ret) Keith Alexander, is a recognized cybersecurity innovator and a frequent speaker about current cyberthreats and effective defenses. We have a leadership team with deep government and commercial cyber experience, and the company is advised by a board of esteemed security and venture investment professionals, including Jan Tighe Retired Vice Admiral, Former Deputy Chief of Naval Operations for Information Warfare and Director, Naval Intelligence, US Navy: and Jack Keane Chairman, Institute for the Study of War, Retired Four-Star General, Former Vice Chief of Staff, US Army.  Benefits Of Working At IronNet  IronNet strives to provide and takes pride in being able to offer comprehensive, essential and affordable benefits for our employees and their families. We offer an unlimited PTO plan, 401(k) match as well as Medical, Dental, Vision, and Disability Insurance.  All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, or protected veteran status, or any other legally protected basis, in accordance with applicable law.  Follow us on LinkedIn",Algo de responsabilidad,Jornada completa,Ingeniería,"Servicios y tecnologías de la información, Software, Seguridad del ordenador y de las redes",0,None,False,,14,None
785,2238052859,2020-10-12,Homeward,Data Engineer,"Austin, TX, US","Data Engineer  Austin, TX  We're seeking a Data Engineer to help us build a simpler, more customer-centric home buying and selling experience in partnership with real estate agents.  Our offering  We give homeowners the freedom to buy the home they want before selling their current one. Customers tell us about their home and financial situation, then we provide them with funds to confidently secure their next home with a competitive all-cash offer. This saves them stress from having to list their house without knowing where they're going next, and makes the process of buying and selling a home as predictable and easy as it should be.  About Us  Homeward was started in 2018 by Tim Heyl, a 10-year industry veteran and owner of one of the fastest growing agent teams in the U.S. We're passionate about our mission to empower customers and their agent partners to buy before they sell while making the entire experience more convenient and certain. We've attracted a strong customer base in Texas, Colorado, and Georgia, and are growing our team to help us deliver our unique solution, and continue evolving our business.  Homeward is backed by top-tier venture investors like Adams Street, Javelin, and LiveOak. We've raised over $25 million in equity and secured over $100 million in debt to buy homes for our customers. Our leadership team includes experts from the real estate, mortgage, and technology spaces.  Values  Golden Rule  'Treat others how you want to be treated.' We're building our company culture and customer experience with this as the guiding principle. It's a simple rule, but emphasizes that we don't prioritize money or growth over people.  Calm Focus  We don't chase every opportunity and rush from urgent task to urgent task. We relax, stay calm, and focus on our company-wide objectives. If something is out of scope, we say 'no'. If something feels rushed we slow down and think it through so we can avoid unnecessary rework later. We don't bombard each other with notifications expecting instant response times. We block off time for deep work so we can get into the flow and create solutions our customers love. Multi-tasking isn't effective or enjoyable.  Cross Functional Collaboration  We look at our customers' experience holistically and recognize that improving it requires support from multiple functions. Given this, we're excellent collaborators. No function is more important than another and we're eager to work as a team to solve our customers' toughest problems. We value strong internal alignment, and take pride in understanding and considering our teammates' perspectives before expressing our own.  In this role, you will:  Work with the engineering team to design and implement the next evolution of our data infrastructure, including our event streaming platform, data pipeline, and data lake / warehouse.  Contribute to and refine our overall platform strategy and architecture.  Work with product managers and analysts to design and build solutions that fulfill operational and reporting needs throughout the company. Assist the rest of the engineering organization in determining and implementing best practices for event management and data hygiene. Work collaboratively across the organization to understand business needs, and use those to drive technology decisions. Assess the tradeoffs between picking off-the-shelf software and building something in house, be able to clearly communicate the rationale behind that decision, and help drive execution of delivering on business needs with either approach. Work alongside the rest of the engineering team to help automate and optimize our workflows.   What you'll bring:  5+ years experience designing and building durable, high-availability systems, while still optimizing for delivering value as quickly as possible. Experience working with data streaming platforms (such as Kafka, Pulsar, Kinesis, GCP Pub/Sub, etc.). Advanced working knowledge of SQL and familiarity with a variety of relational and non-relational databases (including analytics-focused options). Experience with cloud-based PaaS and IaaS offerings (most notably AWS, GCP, and Heroku). Experience working on a small, tight-knit, high-performing engineering team.",Sin experiencia,Jornada completa,Tecnología de la información,"Banca, Servicios financieros, Bienes inmobiliarios",9,None,False,,151,ACTIVELY_HIRING_COMPANY
786,2238665375,2020-09-30,Third Republic - Recruitment Solutions for Digital Transformation,Azure Data Engineer (REMOTE) - US,"Redmond, WA, US","Azure Data Engineer (REMOTE) - US - Redmond  Who is hiring?  If you’re interested in designing modern cloud database solutions on Microsoft Azure and love helping customers solve complex problems related to Business Intelligence, Advanced Analytics, and Data Science, we’d like to hear from you!  We're looking for a versatile Azure Data Engineer whocan design and implement modern architecture for a diverse set of customers and industries. The ideal candidate would have deep experience in designing enterprise data warehousing solutions utilizing, SQL Server, Azure SQL DW and Big Data platforms (i.e. Azure Data Lake, Azure Data Factory).This position will be responsible for leading customer conversations, creating and presenting project architecture, and leading delivery.  What will you be doing?  Primary Responsibilities Interfacing directly with clients to solve broad business goals with databasesolutions.You will be responsible for gathering requirements, designing solutions, and overseeing the development and execution of projects.This role will be directly involved in the business development process: specifically delivering customer demos to show the value of how data can drive business goals.Be able to build pilot solutions andproof-of-conceptswith minimal direction.Provide support to project manager through developing tasks, estimates, and dependencies to meet expectations  Required Ability to appropriately architect complex data solutions utilizingSQL Serverarchitecture. This includes storage, replication, server tuning, upgrading, backup/restore, security, etc.Ability to write complex SQL queriesTSQL knowledge, DML/DDL, triggers, CTE's, query tuning, etc.Strong knowledge ofSSIS: script tasks, checkpoints, recordset objects, package vs. project deployment.Practical knowledge of how to design complexSQL Server Integration Services(SSIS) packagesKnowledge ofAzure SQL, and other Azure offerings centered around Data and Analytics (Azure Machine Learning, Data Lake, Data Factory, Streaming Analytics, Table Storage,Hadoop, etc.)BS or MS in Computer Science, Engineering or Mathematics or Equivalent field  Preferred Strong understanding of parallel processing utilizing Azure SQL Data Warehousing for both structured and unstructured data sources.Experience writing U-SQL and Azure Data Lake AnalyticsExperience with HDInsight, Spark, and HadoopExperience with Teradata  Why you shouldn’t miss this opportunity?  Who You Are Excels with ambiguity and able to design a clear path to meet end goalsHave a broad understanding of BI and data technologies and how to match the right technologies to solutions.Have proven experience with both the customer-facing and solution engineering skill set Data Science(Head of Data Engineering),Azure, Big Data",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Servicios financieros",3,None,False,,27,ACTIVELY_HIRING_COMPANY
787,2283645616,2020-11-04,8K Miles Software Services Ltd,"Immediate Job Opening for Full Time Oppertunity for DevOps Engineer, Java Full Stack Developer, Data Engineer and .Net Developer Remote Position","California City, CA, US","Hi All, Hope you are doing good...! We have a Immediate job opening for Java Developer and .Net Developer for our In-House Project. If you are interested, Kindly share your recent resume with your contact details  Java Developer (Immediate Requirement) .Net Developer (Immediate Requirement) AWS DevOps Engineer (Immediate Requirement) Data Engineer (Immediate Requirement)  Location  Multiple Locations Project  Long Term (Remote)  Thanks  Regards, Harshad ndash US IT Consulting",No corresponde,Jornada completa,Otro,"Servicios y tecnologías de la información, Software, Dotación y selección de personal",0,None,False,,3,ACTIVELY_HIRING_COMPANY
788,2283601682,2020-11-06,Unite Us,Data Engineer,"New York City, NY, US","Job Title: Data Engineer  Department: Engineering  Who We Are:  Unite Us is reinventing the delivery of health and human services. We connect service providers on a common platform, enabling scalable, accountable and measurable delivery of wraparound care. Our technology provides the collaborative infrastructure for these communities. We care deeply about the work we do and the communities our software benefits. We're looking for people to join our team who share that passion for our mission to reinvent Health & Human Services and aspire to make a lasting difference for future generations. No matter how large our team grows, we will always be family. Unite Us prides itself on offering a competitive salary, full benefits, and the opportunity to change the world. Come to Unite Us and together we can build healthier communities for everyone.  Description:  Unite Us has experienced rapid growth over the past couple of years. As we have grown, our clients' skills and requirements around data have grown more sophisticated. Data has long been a foundation of our system. Now, we need to start taking the data that exists within our platform and transform it into an actionable source of information for our clients in order to assist them in better understanding the impact that Social Determinants of Health are having on those they help. To do this, we need to build an experienced team of data technologists who want to have an impact on healthcare across the entire country.  The impact of SDoH data is revolutionizing the healthcare industry. As we continue our rapid pace of growth, we want to build a solid data platform that can serve the needs of our clients and shape the way the industry thinks about and relates to social determinants of health. We are looking for a strong technical individual contributor who has experience building data warehouses, lakes and pipelines to help us continue growing our impact on the healthcare industry and the lives of people around the country.  What You'll Do:   Execute a data architecture and infrastructure to meet business objectives Work closely with Solutions Architects and Product Managers to make sure that the technical infrastructure can support client requirements Develop ETL and data pipeline solutions to load data warehouse Test internal data pipelines for reliability and performance   What's Required:   Experience as a Data Engineer in which you set up data pipelines Experience using and building solutions to support various reporting and data user tools (Chartio, Tableau, Looker, etc) Experience with Spark using Scala and Python. Experience working with data warehouses, data lakes and ETL pipelines (Snowflake, Infomatica, Redshift, Postgres, SQL, etc) Experience setting up an maintaining databases within AWS Experience working on applications serving large enterprise clients Experience working on healthcare and/or social determinants of health data products A focus on building performant systems Ability to think forward and build a scalable solution that satisfies various needs of enterprise clients with dedicated data teams   Environmental Job Requirements and Working Conditions:   This position is remote  Unite Us is committed to building a diverse team and fostering an inclusive culture, and is proud to be an equal opportunity employer. We embrace and encourage our employees' differences in race, religion, color, national origin, gender, family status, sexual orientation, gender identity, gender expression, age, veteran status, disability, pregnancy, medical conditions, and other characteristics",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Atención sanitaria y hospitalaria",12,None,False,,55,ACTIVELY_HIRING_COMPANY
789,2242372469,2020-10-01,Skiltrek,Sr. Data Scientist - Claims - REMOTE,"Dallas, TX, US","Position Title: Sr. Data Scientist Location: Jacksonville FL or ( Open to 100 % Remote ) Job Type: Contract Work Auth: GC/USC/GCEAD Salary Method: W2 Client Type: Healthcare Insuance Job Duration: Long Term Contract - 12 months + Rate: $126,000-$170,000 /year  Job Description  This a niche skillset and not just any data scientist. Candidate must have worked in Claims and used Machine Learning models to gain for efficiencies in Prepay / Post Pay reviews ** Data Scientists produce innovative solutions driven by exploratory data analysis from complex and high-dimensional datasets. Apply knowledge of statistics, data modeling, and advanced mathematics to recognize patterns, identify opportunities, pose business questions, and make valuable discoveries. Use a flexible, analytical approach to design, develop, and evaluate predictive models. Generate and test hypotheses. The Data Scientist proactively seeks to develop their skillsets and provide value-added support within the Data Science team.  Essential Functions  Communication & Project Ownership  Support large projects, and manage smaller projects in their entirety Partner with senior team members to assess customer needs and define business questions. Emerging ability to influence customers to take action on analytical insights. Communicate results and insights, both verbally and written (including visual graphics), in a clear and concise manner to a non-technical audience. Identify and communicate roadblocks. Work on multiple concurrent projects and accommodate frequent interruptions and changing priorities Effectively participate in meetings with customers and emerging ability to guide discussion and decision making. Data Analysis  Acquire and bring structure to data so that it can be used in existing and new data systems. Build tools that help you and the other Data Scientists translate insights into action at scale. Identify, define and translate business needs/problems into analytical questions. Design and execute experiments, models, algorithms, and visualizations Understand data sources and limitations, warehousing system and the impact of the data on business decisions. Identify, retrieve, and manipulate data from internal and external datasets. Apply statistical and computational methodologies to provide actionable insights and identify opportunities that optimize quality, consumer experience, and healthcare costs. Develop scalable, efficient, and automated processes for large scale data analyses and model development, validation, and implementation. Reporting & Other  Contribute to technical reports, white papers, and publications. Stay current on new processes and technology in Data Science and communicate findings to team Perform all other tasks as assigned Job Requirements  Strong programming experience in R, or Python Requires expert proficiency in SQL Strong analytical and problem-solving skills Experience in supporting large projects, and manage smaller projects in their entirety Ability to partner with senior team members to assess customer needs and define business questions. Emerging ability to influence customers to take action on analytical insights. Ability to communicate results and insights, both verbally and written (including visual graphics), in a clear and concise manner to a non-technical audience. Must have applied experience with advanced analytics e.g. predictive analytics models Must have applied experience in Machine Learning Experience in Big Data - e.g. s3/presto is a plus Business Intelligence tool development Other programming experience - Java, Perl, UNIX/Linux scripting Healthcare, medical, or pharmaceutical work experience Experience with analysis around quality, consumer experience, and healthcare costs Experience in consumer analytics Experience in business analytics Required Experience  5-8 years related work experience in advanced analytics or equivalent combination of transferable experience and education  Minimum Five Years' Experience As a Data Scientist  PhD or Masters in a quantitative discipline: Computer Science, Statistics, Applied Mathematics, Operations Research, Engineering Working knowledge of health care systems and healthcare terminology Expert in various healthcare datasets. Expert in analyzing large complex, multi-dimensional data sets with a variety of tools Ability to thrive and demonstrate constant applied learning in highly complex, interdisciplinary, and dynamic work environment Design anomaly detection models to detect and eliminate FWA in claim payments. Experience in implementing Machine Learning Models to gain efficiencies in Claims Prepay / Post Pay reviews  Required Education  Related Bachelor’s degree in Data Science, Applied Mathematics, Computer science (e.g. specialization: Machine learning/Artificial Intelligence /Visualization, databases, and Big Data), Statistics, Epidemiology, Health Services Research, or closely related field with Data Science specialization or additional related equivalent work experience  This person can work 100% remotely even after Covid-19!",Sin experiencia,Jornada completa,Tecnología de la información,"Sanidad, bienestar y ejercicio",3,None,False,,37,None
790,2185759960,2020-10-22,"Synack, Inc.",Senior Data Engineer,"Cheltenham, England, United Kingdom","Imagine a world dedicated to Security Without Compromise. Synack, headquartered in Silicon Valley with regional offices around the world, protects leading global organizations by reducing companies’ security risk and increasing their resistance to cyber attack. How do we do this? By utilizing the world’s best and most trusted team of ethical hackers who test through our powerful and controlled platform to deliver real security without compromise. At Synack, we aren’t afraid to think outside the box or take on big challenges. Backed by top-tier venture capital firms including Kleiner Perkins Caufield & Byers, Microsoft, and Google Ventures, Synack's mission is to leverage global security talent coupled with advanced technology to help enterprises discover security vulnerabilities before they become business problems. Discover the possibilities at Synack! We are looking for an experienced and innovative Senior Data Engineer to build products that will revolutionize cyber security. Working in the Cloud and using DevOps, you will process data to improve visibility into our Red Team’s activity, and enhance the ratings method measuring the security standing of our Clients. Join us! Here’s what you’ll do Build data high availability processing pipelines using Cloud Functions, Cloud Composer, BigQuery, Data Studio and other Google Cloud Platform capabilitiesSupport existing production products including Kubernetes, APIs, relational databases and NoSQL document storesBuild innovative analytics and proof of concept ideas and the development of dashboards and interactive applications using Apache SupersetMake use of a wide variety of tools, data storage solutions and programming languagesCollaborate with engineers across the companyContribute to the development of Data Analytics, Machine Learning models and application of AI to real world problemsDeliver new capabilities as part of journey teams to build new products and participate in Agile ceremonies Here's what you'll need 5+ years of experience designing and building dynamic production solutions3+ years of experience in a Python or Java development environmentExperience using various database systems such as PostgreSQL and NoSQL document storageExperience architecting and leading application development effortsExperience working with GCP Cloud services or other Cloud Computing platformsExperience with unit and integration tests, and Agile software development practices using Git Bonus Points Contribution to open source projectsExperience with Apache AirflowUnderstanding of Machine Learning/AI techniques and experience in applying to real world problemsExperience in DB management and optimizationUnderstanding of Google Cloud Platform and Kubernetes/Docker It’s all hands on deck, it’s hard work, it’s winning, it’s Synack. Join us!﻿Synack is committed to embracing diversity. Our people are our strength. Each addition to our team is an opportunity to grow and diversify our ideas, experiences, and viewpoints. We strive to be inclusive of Race, Ethnicity, Religion, Sex, LGBTQ+, Veterans, Disabilities, and Age. Synack welcomes you!",Intermedio,Jornada completa,Ingeniería,"Seguridad del ordenador y de las redes, Software, Servicios y tecnologías de la información",5,None,False,,153,ACTIVELY_HIRING_COMPANY
791,2280296073,2020-11-05,Patel Consultants Corporation,Medical Review Physician,"Summit, New Jersey, United States","Experience Required: - MD required (or x-US equivalent) functional assignment as Clinical Trial Physician - Five or more years industry experience in clinical trials required Qualifications: - Expertise in using the scientific method to test hypotheses, including statistical design, analysis, and interpretation - Knowledge of the drug development process - Knowledge of the components needed for an effective clinical plan and protocols - Strong leadership skills with proven ability to lead and work effectively in a team environment Expected Areas of Competence: - Matrix management responsibilities across the internal and external network - Manages Phase 1 – Phase 3 studies and manages multiple complex studies with demonstrated decision making capabilities - Provides medical and scientific expertise  - Ability to present clearly in scientific and clinical settings Scope of Responsibility: 1. Medical Monitoring: - Contributes to and is key member of a high performing Study Delivery Team (SDT) and may be a member of the Clinical Development Team (CDT) - Conducts medical data review of trial data, including eligibility review. - Responsible for site interactions in partnership with the Clinical Scientist for medical questions and education (including safety management guidelines - Responsible for assessment of key safety-related serious adverse events in partnership with GPVE and oversees safety narratives. - Inputs into protocols, providing medical strategic oversight in protocol development (input on inclusion/exclusion criteria and other safety-related clinical considerations). - Fulfills GCP and compliance obligations for clinical conduct and maintains all required training for same  2. Clinical development expertise & strategy: - Designs and develops clinical plans and protocols with a strong strategic focus based on knowledge of the asset/drug, disease area and relevant science in order to meet regulatory and disease strategy targets. Leads the analysis of benefit/risk for clinical development protocols in a matrix team environment working in partnership with Clinical Scientists (CS). - Provides input into overall clinical development plan strategy - Provides medical accountability and oversight of a group of studies - Partners with CS to support executional delivery of studies (eg, site activation, enrollment status, as well as adjudication for protocol violations, significant, non-significant deviations etc). - Identifies and builds relationships with principal investigators. Identifies and cultivates thought leaders (TLs) in order to gain their inputs on emerging science in drug and biomarker research, disease knowledge and design of clinical development studies and programs. - Maintains a strong medical/scientific reputation within the disease area. Has in depth knowledge of etiology, natural history, diagnosis, and treatment of the disorder. Keeps up-to-date in the disease area via attendance at scientific conferences and ongoing review of the literature. - Keeps abreast of development and regulatory issues related to other competitive or relevant compounds in development and how our portfolio fits into the competitive landscape - Provides ongoing medical education in partnership with CS, protocol specific training, to support study team, investigators, and others. - Provides strategic input into broad functional best practices and process improvement efforts.",Intermedio,Contrato por obra,"Consultoría, Investigación",Dotación y selección de personal,8,None,True,,59,ACTIVELY_HIRING_COMPANY
792,2197063152,2020-10-20,CarMax,Senior Software Developer,United States,"CarMax, the way your career should be! Senior Software Developer – CheckoutYour expertise shapes our digital businessAt CarMax, we want to disrupt our industry by empowering customers to buy a car on their own terms – allowing them to transact with us anytime, anywhere. As a Senior Software Developer on the Checkout team, you'll be working on a product team focused on building the complete car buying experience online.You are: Able to balance customer needs with business goals and know how to deliver technical solutions that enhance business value. Creative, curious and highly analytical, you never stop learning and thrive on constant change in the digital marketplace.  From inception to completion, you will develop tools and technology, learning quickly from our spirit of experimentation. Overall, you will have a direct impact on improving the performance of our business and ensuring customers can buy the vehicles they want in a way that’s right for them.We are: A team of experts (such as a Product Manager, Lead Developer, UX Designer, Quality Engineer, Delivery Manager, Analyst/Data Scientist, and other Software Developers), working in a fast-paced, highly collaborative, and customer-focused environment to bring a seamless online shopping experience to life. Together we’ll be:  A passionate technology team, developing ground-breaking products. Working collaboratively and creatively as part of a close-knit product team, you will be part of the development process from end to end: consulting users, carrying out experiments, tackling complex business problems and implementing new products. What technologies you'll be working withThis role requires hands-on work in technologies such as Azure PaaS (Functions, App Services, App Insights, Structured/Unstructured data storage, Redis, and others), .NET Core, TeamCity or Azure DevOps for CI/CD, automated testing tools like Selenium / Browserstack, React, Javascript, Splunk and API management systems. But more importantly, at CarMax we are always learning, so our tool set will evolve as you do.What you will do – Essential responsibilities Hands-on development on the products that your team is continuously iterating on, including creating new experiences while ensuring high resiliency, availability, and speedCollaborate with colleagues in product design, product management and systems architecture to develop experimental solutions and bring great ideas to lifeMarket your new ideas internally and evolve them according to feedback and critique within an agile environmentStay on top of industry trends and best practice to ensure our customer experience is the best it can be while delivering software quickly with high quality Qualifications and requirements At least five years of application development experienceFull-stack experience in some of the following preferred: Microsoft.NET (C#), JavaScript (ES6/ES7), CSS best practices, REST APIs, and React (or equivalent experience)Working knowledge of cloud platforms such as Azure or AWS preferredUnderstanding of DevOps capabilities such as automated testing, continuous integration, and continuous delivery preferredA degree in Computer Science or a related discipline or equivalent experienceUpon an applicant's request, CarMax will consider reasonable accommodation to complete the CarMax Job Application.",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información, Diseño",Venta al por menor,35,None,False,,191,ACTIVELY_HIRING_COMPANY
793,2207178143,2020-10-23,Once Upon A Time SA,Data Engineer / Data Analyst (Expert in Facebook API-Google API),India,"Job DescriptionData Engineer / Data Analyst (Expert in Facebook API-Google API) Key Responsibilities- Analyse requirements together with the business stakeholders of our clients and internal Data Analysts- Design, develop, and document end-to-end data pipelines / ETL processes- (Unit)-Testing and monitoring of data pipelines to ensure data quality- Continuous improvement in delivery, applying engineering best practices to development, monitoring, and data quality of the data pipelines- Creating data models and DWH / Database structures- Create deployment pipelines for test- and production system Competencies- Excellent knowlegde of Python3- Excellent knowledge of Facebook API - Google API- Advanced experience in utilizing Amazon Web Services (AWS) The followings are a plus:- Excellent knowledge of other social networks' API (Twitter, TikTok, ...)- Excellent knowledge of front-end and back-end languages (HTML, CSS, JS: Django, PHP)- Excellent knowledge of version control systems (Git/GitHub)- Excellent knowledge of ML on Python (Scikit-learn, Theano, TensorFlow, ...)- Excellent knowledge of mathematical Python packages (Numpy, Pandas, ...) We offer an interesting and challenging environment,empowerment to make contributions and suggestions, room to grow and the ability to continuously learn new things.",Sin experiencia,Jornada completa,Tecnología de la información,Servicios y tecnologías de la información,83,None,True,,523,JOB_SEEKER_QUALIFIED
794,2234598415,2020-11-04,komoot,Senior Backend Developer / Data Scientist,Germany,"***Note : We are a fully remote team and this role can be done from any location within the UTC-1 to UTC+3 timezone.*** Millions of people experience real-life adventures with our apps. We help people all over the world discover the best hiking and biking routes, empowering our users to explore more of the great outdoors. And we're good at it: Google and Apple have listed us as one of their Apps of the Year numerous times - and, with more than 15 million users and 100,000 five-star reviews - komoot is on its way to become one of the most popular cycling and hiking apps. Join our fully remote team of 65 people and 40+ freelancers and change the way people explore! To help us continue to grow, we ‘re looking for an experienced backend developer with knowledge in data science.Komoot possesses a unique dataset of user-generated content, ranging from GPS data from tours, uploaded photos, and tips, to implicit and explicit user feedback. To get the biggest value from this raw data, we need your excellent software and analytical skills. The challenges include automatic evaluation and classification of our user-generated content as well as innovative approaches to assembling them into consumable inspiration for users (e.g. auto-generated tour suggestions tailored to users' sport and location). You'll wrap up your algorithms into clean and scalable microservices in our modern cloud environment. We believe that innovations based on data science will reinforce and extend our leadership in the outdoor market and your role will be decisive for komoot's success. ---Team: BackendEmployment Type: Full - Time: PermanentLocation: Remote (UTC-1 to UTC+3)--- What you will do Work closely with our data scientists, web and mobile developers, designers, copywriters and product managersDiscuss product improvements, technical possibilities and road mapsInvestigate and evaluate data science approaches for product enhancements (you can count on the support of experienced data scientists)Turn prototypes into resilient and scalable REST APIs and background workersDeploy and monitor your code in our AWS Cloud Why you will love it You'll be challenged with a wide range of tasks for which there are no standard solutionsYou'll have full ownership: from concept, prototypes, and building, to deploying and monitoringYou'll deal with diverse datasets (location data, social network, user content (images, text), external data sources like OSM, product analytics, ...)You'll contribute to a product with a vision to inspire more people to go outdoorsYou'll work in a fast-paced startup with strongly motivated and talented co-workersYou'll enjoy the freedom to organize yourself the way you wantWe let you work from wherever you want, be it a beach, the mountains, your house, a coworking center of your choice, our HQ in Potsdam or anywhere else that lies in any time zone situated between UTC-1 and UTC+3You'll travel together with our team to amazing outdoor places several times a year to exchange ideas, learnings and go for hikes and rides You will be successful in this position if youHave a passion for finding pragmatic and smart solutions to complex problemsHave 3+ years of professional experience in backend development in the cloudHave 2+ years of professional experience in Kotlin/Java/ScalaHave 2+ years of professional experience in PythonKnow SQL and NoSQLHave a solid understanding of math and statisticsHave a solid understanding of data science fundamentalsMaster Jupyter, pandas, NumPy, matplotlib/seaborn, scikit-learnBonus: BigData experience (Spark, Presto, Hadoop)Bonus: Infrastructure as CodeBonus: Deployment, CI and monitoringHave strong communication and team skillsHave a hands-on attitude and are highly self-driven Sounds like you?Then send us the following:Your CV in English highlighting your most relevant experienceA write-up explaining who you are and why you are interested in working at komootExamples of your work (e.g. GitHub Repositories, PDFs, Slideshare, etc.)Feel free to send us something that shows us a little more about what you're interested in, be it your Twitter/Instagram account, a blog or something else",Intermedio,Jornada completa,"Tecnología de la información, Ingeniería",Servicios y tecnologías de la información,9,None,False,,85,None
795,2288431880,2020-11-07,Wiley Job Network,Data Scientist II (Remote Work Location Available),"San Antonio, TX, US","Purpose of Job We are currently seeking a talented Data Scientist II for San Antonio Home Office II/III or Remote Work Location Available.  This role is designated for a Data Scientist who has proficient knowledge with applying modern advanced analytics methods (predictive modeling, Machine Learning, and optimization), as well as a solid grasp of the mathematics used for each method and strong Python coding skills to develop numerical models. The Data Scientist is expected to demonstrate the ability to effectively communicate (written and oral) complex analytical and technical concepts to both technical and non-technical employees. The Data Scientist for this role is expected to have experience working with time series/forecasting models.  Within defined guidelines and framework, uses techniques that integrate traditional and non-traditional datasets and method to enable analytical solutions. Applies predictive analytics, machine learning, simulation, and optimization techniques to generate management insights and enable customer-facing applications: participates in building analytical solutions leveraging internal and external applications to deliver value and create competitive advantage. Translates complex analytical and technical concepts to non-technical employees.  Job Requirements Identifies and manages existing and emerging risks that stem from business activities and the job role. Ensures risks associated with business activities are effectively identified, measured, monitored, and controlled. Follows written risk and compliance policies and procedures for business activities. In partnership with SMEs, learns to define the business problem and works with experienced data scientists to select the appropriate model.Extracts features from structured and unstructured data (internal and external).With guidance, conducts advanced analytics: predictive modeling, Machine Learning, and optimization. Works with Data Engineering/IT partners to develop architectures for new products, services and features.Explains complex models and outcomes to colleagues who are not data scientists.  Minimum Education Bachelor's degree in Computer Science, Applied Mathematics, Quantitative Economics, Statistics, or related field or 4 additional years of related experience beyond the minimum required may be substituted in lieu of a degree.  Minimum Experience 2 years of related experience and accountability for complex tasks and/or projects.Proficient knowledge of the function/discipline and demonstrated application of knowledge, skills and abilities towards work products.Proficient level of business acumen in the areas of the business operations, industry practices and emerging trends.Strong coding skills in the dominant scripting language (such as Python).Deep academic understanding of model assumptions. Solid grasp of statistics and mathematics.Proficient knowledge of Data Science principals and experience with data science methodologies.  *Qualifications may warrant placement in a different job level*  When you apply for this position, you will be required to answer some initial questions. This will take approximately 5 minutes. Once you begin the questions you will not be able to finish them at a later time and you will not able to change your responses.  Preferred Experience Proficient knowledge with applying modern advanced analytics methods (predictive modeling, Machine Learning, and optimization).Experience with Time Series/Forecasting Modeling.Solid grasp of mathematics, with a strong foundation in calculus, linear algebra, probability, and statistics.Strong Python coding skills to develop numerical models.Demonstrated ability to effectively communicate (written and oral) complex analytical and technical concepts to both technical and non-technical employees.  The above description reflects the details considered necessary to describe the principal functions of the job and should not be construed as a detailed description of all the work requirements that may be performed in the job.  At USAA our employees enjoy one of the best benefits package in the business, including a flexible business casual or casual dress environment, comprehensive medical, dental and vision plans, along with wellness and wealth building programs. Additionally, our career path planning and continuing education will assist you with your professional goals.  USAA also offers a variety of on-site services and conveniences to help you manage your work and personal life, including seven cafeterias, two company stores and three fitness centers .  Relocation assistance is not available for this position.  For Internal Candidates  Must complete 12 months in current position (from date of hire or date of placement), or must have manager's approval prior to posting.  Last day for internal candidates to apply to the opening is 11/03/20 by 11:59 pm CST time.",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Dotación y selección de personal, Consultoría de estrategia y operaciones",2,None,False,,8,None
796,2248118641,2020-11-06,Bookbyte,"Data Engineer, Warehouse","Salem, Oregon, United States","Summary This is a fully remote position. Bookbyte is the largest 3rd party provider of product rentals on Amazon. Our remote-first organization is focused on real-time analysis of available market data to perform tens of thousands of pricing operations each minute. Bookbyte is looking for a Warehouse Data Engineer to help architect and develop our evolving data platform. The Warehouse Data Engineer role will be part of our growing data team, interfacing closely with software engineering. If you are a highly independent worker and have excellent organizational and problem-solving skills, this is the job for you. Working at Bookbyte also means full benefits, a competitive salary, and a friendly work environment. While Bookbyte is based out of Oregon, we are a remote-first company. As a member of a small but growing data team, you will be working closely with business partners, and software engineering teams playing a vital role in the design, build, and maintenance of OLTP data stores: providing timely, accurate, and reliable information to all aspects of the business. As we incrementally improve and expand our company, you will be building new systems from the ground up or replacing legacy systems outright, free from supporting legacy code bases. Duties and Responsibilities ·        Development, construction, and maintenance of data models within Data Warehouse(s) (Dimensional modeling/Kimball)·        Conduct testing on large scale data platforms·        Handle error logs and build robust data pipelines·        Ingest and transform structured and semi-structured data into data models·        Administration of Data Warehouse(s)·        Manage data lake(s)·        Translate business requirements into technical specifications·        Participate in all design reviews and requirement sessions, as required·        Understand database design, programming concepts, cloud architecture patterns, and data modeling·        Communicate ideas to both technical and non-technical people in all levels of the organization·        Create or update technical documentation for transition to support teams, including data flows and transformations·        Develop automated data audit, testing, and validation processes·        Stay up to date on ever-evolving technologies Minimum Job Requirements ·        3+ years of data warehousing experience·        Expert SQL skills and database ETL/ELT·        Proficient with GIT·        Experience with public cloud solutions (i.e., AWS (preferred), Azure, GCP)·        In-depth knowledge of relational databases (e.g. PostgreSQL, MSSQL) Preferred Qualifications ·        Experience in delivering solutions based on Agile principles·        Experience with DBT·        Experience with Snowflake·        BS in Computer Science, Engineering, or related field, or equivalent job experience",Intermedio,Jornada completa,Tecnología de la información,Internet,14,None,True,,69,JOB_SEEKER_QUALIFIED
797,2246313145,2020-11-04,"Anderson Young Associates, Inc.",Email Marketing Specialist,"Lincoln, Nebraska Metropolitan Area","Please Remember to attach resume** Our client, a Global Financial Services company ,seeks an Email Marketing Specialist  The specialist role is broken up into equal parts technical, creative and analytical – ready toconceptualize and write creative emails, and also consistently test and analyze data driven experiments on our email program. The EMS will create a significant volume of emails on behalf of the company and will play an integral role in supporting internal and external communication,partner programs and customer engagement that will have a sizable impact on revenue growth.Reports To: VP of Marketing  Key ResponsibilitiesProject Management• End-to-end conceptualization and implementation of email campaigns that include but are notlimited to internaland external brand communication, partner programs, promotions and customer engagementcampaigns for allAmur Equipment Finance.• Building the email flow logic, writing creative error-free copy, collaborating with key stakeholderson each project,and implementing into our marketing automation platform, Pardot.• Work with Data Scientist to create accurate email lists, manage customer database within Pardot.Measuring Success• Tracking success by monitoring performance of campaigns on a daily and weekly basis includinghow people areengaging with the email program and how it’s driving marketing key metrics.• Work with Salesforce engineer and systems teams to properly sync and track performance across all platforms.",Algo de responsabilidad,Jornada completa,"Finanzas, Ventas",Dotación y selección de personal,56,None,True,,172,JOB_SEEKER_QUALIFIED
798,2239742867,2020-11-03,Analytic Recruiting Inc.,Sr Data Scientist - Water Analytics Consulting,United States,"Leading professional services companies operating in the global market sectors of water, energy and transportation is seeking a Sr Data Scientist with Cleaning Water Analytics experience. This employee will participate in new product development from conception through deployment. Candidate will build data pipelines, implement ML-based analytical algorithms, and work closely with market leaders to deliver the next-generation analytics. 60% Consulting40% Hands on analytics regarding cleaning water RESPONSIBILITIESDevelopment and implementation of data-intensive machine learning software for IoT, Water Analytics and Predictive Analytics.Develops, designs, and refines key business metrics and drive robust analysis to identify performance strengths, weaknesses, and opportunities, while evaluating possible alternatives and recommending appropriate actions and business metrics to Water Utilities Clients.Leads the design and development of analytical tools and techniques to understand key business behaviors that drive and optimize operations.Develop and implement cloud-based analytics to identify leaking infrastructure, decrease energy consumption, predict incoming organic loads, and assist with a wide range of other operational challengesPrototyping and validating advanced ML and Deep Learning (DL) models and algorithms that transform big data into actionable informationProviding data insight from massive amounts of data using data cleaning, data visualization, and statistical analysis tools and techniquesSetting up and maintaining databases supporting analytics research and feature prototyping. QUALIFICATIONSMS or PhD in in any mathematical sciences (Computer Science , Statistics, Econometrics, Operations Research, Mathematics, Engineering or equivalent fields) with 5+ years hands-on industry work experience as Data Scientist or Senior Machine Learning EngineerExperience with CONSULTING And Cleaning water analyticsStrong understanding of machine learning algorithms & principles (regression analysis, time series, probabilistic models, supervised classification and unsupervised learning), and their application.Expert in data mining, machine learning, deep learning, statistical modeling and data visualization techniques using data-oriented tools and languages such Python or R with data analysis libraries (pandas, sklearn, numpy, scipy, dash and matplotlib)3+ years hands-on industry work experience designing and building large-scale data, machine learning, and analytics applications and pipelines that are well-designed, cleanly coded, well-documented, operationally stable, and timely deliveredStrong mathematical background (linear algebra, calculus, probability and statistics).Experience with scalable ML (MapReduce, streaming).Experience with deep learning algorithms and techniques, including but not limited to: CNN, LSTM, RNN, TensorFlow, Keras, Caffe, PyTorchExperience setting up and using large-scale distributed data-processing frameworks such as Apache Spark and Hadoop Map-ReduceExperience working with enterprise-grade cloud computing platforms such as Azure. Contact ilana@analyticrecruiting.com",Director,Jornada completa,"Consultoría, Análisis",Servicios públicos,47,None,True,ilana@analyticrecruiting.com,215,ACTIVELY_HIRING_COMPANY
799,2200100532,2020-10-21,Meow Wolf,Digital Analytics Lead,United States,"DescriptionDigital Analytics LeadMeow Wolf Inc.Status: Full-timeDivision: Attraction OpsSub-Division: AdministrationDepartment: Core servicesWork Location: RemoteReports to: Director, Digital OpsProject Hire: NoJob Description:Meow Wolf is seeking a digital analytics lead/data analyst to join a cross-functional team that is building new and amazing enhancements to Meow Wolf’s customer experiences. We are building next-generation products and experiences that integrate cutting edge technology into the broader Meow Wolf ecosystem and we need someone who is highly data and metrics-driven and thrives on finding patterns in chaos that will be meaningful to our business.Who you are:You are a SQL expert (JOINs and aggregate functions delight you) with exposure to digesting eCommerce analytics, and have experience ideating and running A/B testing. You also have a broader perspective on the business impact of your work, but can zoom into the details and execute against the big picture just the same. You are familiar with both the Web and App ecosystems/data paradigms, as well as the fundamentals of digital tracking/measurement and statistical analysis. You have experience using cloud-based data warehousing and visualization software (we use BigQuery and Domo), as well as working on a team using Github and code review processes. Job Responsibilities:Advise product teams on data ingestion, interpretation, and implementationAssist in the design, implementation, and analysis of A/B testing with a product manager and other stakeholdersCreate and update automated reports on an ad hoc basisCreate new insights and recommendations for product and business implementationReasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. Required Qualifications:1 to 3 years of relevant experience working as a BI/data analyst/Data scientist or similar roleExperience working with relational databases (SQL preferred)Exposure to big data tools and cloud technologies such as GCPStrong written and verbal communication skills with an analytical approach to problem-solvingSelf-motivated, highly organized, and able to prioritize and manage multiple tasksDesired Qualifications:The following are not required but are pluses:BigQueryDomo or TableauGoogle AnalyticsAgile / ScrumWork Environment and Physical DemandsTo perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed must be representative of the knowledge, skills, minimum education, training, licensure, experience, and/or ability required.Work Environment: The position will be in an office space and have the option to work remotely.Physical Demands: There are no physical demands for this position.The employee will comply with company and OSHA standard workplace safety protocols. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. Work ScheduleThis is a full-time position, and hours of work and days are Monday through Friday, 9 a.m. to 5 p.m. or 10 a.m. to 6 p.m. Occasional evening and weekend work may be required as job duties demand. Supervisor ResponsibilitiesThis position does not require supervisory responsibility TravelTravel is not required for this position. Other DutiesPlease note this job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee for this job. Duties, responsibilities and activities may change at any time with or without notice.",Algo de responsabilidad,Jornada completa,Análisis,Entretenimiento,36,None,False,,351,None
800,2289228174,2020-11-08,None,Junior Data Scientist - Remote / London,"East Carleton, GB","Avanti Recruitment have partnered with a Global Data Analytics and Information provider to support them in growing their Data Science team in London.  Our client has a huge global presence with locations all over the world in over 50 locations and an annual revenue of c.£4bn per year. A lot of their business is done with companies within the Transport, Finance and Energy sectors and they are always looking to expand their offering, which is why they are building out their Data Science team in London to help support this.  They are looking for bright, hungry and dedicated junior Data Scientists to come in and work closely with the existing team. There is loads of training on offer that ranges from online courses, mentoring from senior members of the team, 'future leaders’ training as you develop your career and industry specific expert training from thought leaders within the sector. This is a great opportunity for someone to further develop their career, with clearly defined career progression available that will see you develop from junior level right through to senior, principal, Team Lead and management and Senior Leadership positions within the business.  Experience That Interests Them Includes  Python PySpark Machine Learning experience Experience with Data Visualisation Management of Big Data Exposure to AWS or other Cloud based technologies Experience in the areas above would be hugely beneficial, but they will consider candidates with similar experience in other areas providing they have an interest in learning and developing their knowledge in the areas mentioned.  Our client is offering a salary of £30k - £35k as well as a host of brilliant additional benefits that I am happy to share if you are interested in learning more.  If you are interested in the role or want further information, please get in touch or apply now for immediate consideration.",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Software, Dotación y selección de personal",14,None,False,,44,JOB_SEEKER_QUALIFIED
801,2249352418,2020-11-05,"ASK Staffing, Inc",Medical Review Physician,United States,"Company Description Ask IT Consulting Inc, backed by a $500 million Microtek group company, provides an industry leading blend of technology, business consulting, and outsourcing services. Ask IT is a minority-owned enterprise: it has been founded on providing the highest quality possible and on the devotion to customer satisfaction. ASK IT consulting is an equal opportunity employer, which is a global staffing, consulting and technology solutions company, offering industry-specific solutions to fortune 500 clients and worldwide corporations. Title: Medical Review PhysicianDuration: 6 months with possible extensionRemote Myeloid (AML/MDS) and Hematology experience required. Experience Required:- MD required (or x-US equivalent) functional assignment as Clinical Trial Physician- 5 or more years Industry experience and/or clinical trials experience requiredQualifications Desired:- Subspecialty training in applicable therapeutic area- Expertise in using the scientific method to test hypotheses, including statistical design, analysis, and interpretation- Knowledge of the drug development process- Knowledge of the components needed for an effective clinical plan and protocols- Strong leadership skills with proven ability to lead and work effectively in a team environmentExpected Areas of Competence:- Matrix management responsibilities across the internal and external network- Manages Phase 1 – Phase 3 studies and manages multiple complex studies with demonstrated decision making capabilities- Provides medical and scientific expertise to cross-functional Client colleagues- Ability to present clearly in scientific and clinical settingsScope of Responsibility:1. Medical Monitoring:- Contributes to and is key member of a high performing Study Delivery Team (SDT) and may be a member of the Clinical Development Team (CDT)- Conducts medical data review of trial data, including eligibility review.- Responsible for site interactions in partnership with the Clinical Scientist for medical questions and education (including safety management guidelines- Responsible for assessment of key safety-related serious adverse events in partnership with GPVE and oversees safety narratives.- Collaborates with CS and inputs into protocols, providing medical strategic oversight in protocol development (input on inclusion/exclusion criteria and other safety-related clinical considerations).- Fulfills GCP and compliance obligations for clinical conduct and maintains all required training for same 2. Clinical development expertise & strategy:- In collaboration with the CDL, designs and develops clinical plans and protocols with a strong strategic focus based on knowledge of the asset/drug, disease area and relevant science in order to meet regulatory and disease strategy targets. Leads the analysis of benefit/risk for clinical development protocols in a matrix team environment working in partnership with Clinical Scientists (CS).- Provides input into CTP and overall clinical development plan strategy- Provides medical accountability and oversight of a group of studies- Partners with CS to support executional delivery of studies (eg, site activation, enrollment status, as well as adjudication for protocol violations, significant, non-significant deviations etc).- Identifies and builds relationships with principal investigators. Identifies and cultivates thought leaders (TLs) in order to gain their inputs on emerging science in drug and biomarker research, disease knowledge and design of clinical development studies and programs.- Maintains a strong medical/scientific reputation within the disease area. Has in depth knowledge of etiology, natural history, diagnosis, and treatment of the disorder. Keeps up-to-date in the disease area via attendance at scientific conferences and ongoing review of the literature.- Keeps abreast of development and regulatory issues related to other competitive or relevant compounds in development and how our portfolio fits into the competitive landscape- Provides ongoing medical education in partnership with CS, protocol specific training, to support study team, investigators, and others.- Provides strategic input into broad functional best practices and process improvement efforts.3. Health authority interactions & publications :- Contributes to key Health Authority interactions and advisory board meetings as Clinical Trial Physician- Authors/drafts clinical content for CSRs, regulatory reports, briefing books and submission documents to support closure, clinical narratives, reporting and filing of the study in partnership with CSs.Reporting and Developmental Value:- Reports to Clinical Development Lead (CDL) or CTP who partners with GPV&E physicians in the ongoing review of safety data and potential safety signals, particularly clinical safety data arising from active and completed clinical trials- Broad experience in management of and participation in functional and cross functional based matrix teams- Gain a broad perspective of the pharmaceutical development process and the company's development strategy- Hands-on exposure in the development and execution of clinical development plans",Intermedio,Contrato por obra,"Investigación, Ciencias","Industria farmacéutica, Biotecnología, Investigación",8,None,True,,106,ACTIVELY_HIRING_COMPANY
802,2213002184,2020-10-26,Volt - International,Bioinformatician,United Kingdom,"An opportunity has arisen to provide high calibre bioinformatics research to support external researchers and industrial partners for a renowned UK based organisation.. Enabling analysis and facilitating access to datasets. You will understand datasets and how to analyse clinical and genomic data and use tools and services to realise the maximum value from accessing the data. Role·     Development of Bioinformatics datasets, resources, and scripts that will enable downstream analyses for users of the research environment·     Carrying out complex custom computational analyses·     Provide high quality consultancy services in a variety of projects·     Continuously scan the scientific literature to identify new approaches to genome analysis that can be implemented to improve capabilitiesRequirements Postdoctoral level (or equivalent) in a strongly computational and statistical discipline such as statistical genetics, machine learning, computational biology. ·     A background in statistical genetics, statistical bioinformatics, Biostatistics, or a related strongly quantitative discipline, with postdoctoral experience in fields related to statistical genetics or genomics·     Strong statistical analysis skills and experience of bioinformatics research and analytics using large human genomic datasets alongside clinical data·     Excellent communication skills, both written and verbal and excellent facilitation, influencing and presentation skills·     Proven ability to communicate with key customer and internal stakeholders from diverse backgrounds (e.g. management, IT, R and D, biology, bioinformatics)·     Excellent team working skills and comfortable working as part of matrix teams and as part of external teams to ensure delivery.·     Experience with cloud-scale data processing and high-performance computing. HPC·     Demonstrated knowledge and competence in relevant programming languages and applications (e.g. R, Python) and experience of using a suite of bioinformatics tools to problem solve and answer research questions.  If you have PostDoc industry, not academic, experience as a Bioinformatician or Data Scientist within a computational and statistical discipline such as statistical genetics, machine learning, computational biology please get in touch. (Ideally some technical writing experience with a strong publication record in a relevant field)  Remote working available",Algo de responsabilidad,Jornada completa,"Investigación, Análisis, Tecnología de la información","Biotecnología, Investigación, Industria farmacéutica",68,None,True,,350,ACTIVELY_HIRING_COMPANY
803,2248110128,2020-11-06,UnitedHealth Group,"Hands-On Manager, Machine Learning Data Scientist (899820)",United States,"The Data Science Transformation team seeks a hands-on Manager/Principal Machine Learning Data Scientist to join our team. You should be an exceptional disciplined and self-motivated Data Scientist with predictive modeling and machine learning advanced analytics experience and a passion for working with healthcare data (relevant experience with data from other industries of interest as well: financial, retail, telco, etc), experience using various computational approaches, and a portfolio of projects you can show and talk about.  Primary Responsibilities:A leader. You’re a hands-on Machine Learning leader who challenge conventional thinking and work with stakeholders to identify and improve the status quo. You independently identify significant opportunities in an ambiguous area and builds consensus around roadmaps and how to evaluate success.People Manager. You have experience leading and growing a team of M/L data scientists. You have a passion for mentoring members of your team to achieve strong results and continued engagement.Innovative. You continually research and evaluate emerging technologies. You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them.Technical Leadership. You are proficient at performing hands-on coding including reviews through all phases of development, from design through training, evaluation, validation, backtested and implementation. You know how to interpret a confusion matrix or a ROC curve. You have experience with clustering, classification, sentiment analysis, time series, and deep learning.A “Big data” guru. You have the skills to retrieve, combine, and analyze data from a variety of sources and structures. You know understanding the data is often the key to great data science.Partner with a cross-functional team of data scientists, software engineers, IT, data architect and product managers to deliver machine learning products customers love.Pilot and build out data science custom projects into repeatable and scalable data science productsDevelop a rigorous ML Ops data science culture, including best practices on pipeline creation, model building in productization, enabling consistent and high-quality deliveryWork with a great deal of autonomy to find solutions to complex problemsYou effectively communicate complex technical concepts/results to business partners and non-technical audiences You’ll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in. Required Qualifications:MS or PhD in Applied Mathematics, Physics, Computer Science, Statistics or related technical field.5+ years of hands-on experience developing analytics with machine learning, deep learning, NLP, and/or other related modeling techniquesExperience designing a data science roadmap and executing the vision behind it.Demonstrated history of leadership in managing high impact data science and engineering projectsExperience directly managing a team of data scientists (role is 50/50)Experience working in an environment where the end product is a software solutionStrong proficiency in advanced data science tools such as Python, Spark and H2O, Tensorflow etc. and distributed computing systemsDemonstrated ability to communicate complex technical concepts to non-technical audiencesFamiliarity with wrangling large datasets with big data tools such as Hadoop, Hive and Spark.Experience applying computational algorithms and statistical methods to structured and unstructured dataExpert ability to breakdown and clearly define problemsStrong ability to communicate highly technical results to a diverse audienceAvailable location: Eden Prairie, MN: Boston, MA or Basking Ridge NJ. Telecommute maybe considered for the right candidate. Preferred Qualifications:Experience with deploying ML models in Azure, AWS, and/or Google CloudExpertise in healthcare data, e.g. medical and pharmacy claims, EMR/clinical data, lab data, etc.Experience with agile product development Careers with Optum. Here's the idea. We built an entire organization around one giant objective: make health care work better for everyone. So when it comes to how we use the world?s large accumulation of health-related information, or guide health and lifestyle choices or manage pharmacy benefits for millions, our first goal is to leap beyond the status quo and uncover new ways to serve. Optum, part of the UnitedHealth Group family of businesses, brings together some of the greatest minds and most advanced ideas on where health care has to go in order to reach its fullest potential. For you, that means working on high performance teams against sophisticated challenges that matter. Optum, incredible ideas in one incredible company and a singular opportunity to do your life's best work.(sm) *All Telecommuters will be required to adhere to UnitedHealth Group’s Telecommuter Policy. Diversity creates a healthier atmosphere: UnitedHealth Group is an Equal Employment Opportunity/Affirmative Action employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law. UnitedHealth Group is a drug-free workplace. Candidates are required to pass a drug test before beginning employment.",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Atención sanitaria y hospitalaria,3,None,False,,61,ACTIVELY_HIRING_COMPANY
804,1926264517,2020-10-28,TrueAccord,Chief Scientist,"San Francisco, California, United States","Why TrueAccord? TrueAccord is a category-defining company. We combine machine learning with a human-based approach to transform debt resolution and to get people on the path towards financial health. Every year, more than 70 million Americans have negative experiences dealing with debt. We are changing this by providing personalized digital experiences that guide lenders and consumers through this challenging financial process.  With a world-class leadership team, passionate team members, and proprietary predictive models trained on years worth of transactional data, TrueAccord is well-positioned to deliver on a huge opportunity: helping millions of consumers to regain and keep their financial footing while lowering the cost of doing business for creditors across many industries. Your Role: TrueAccord is building a world-class Data Science team to help Americans safeguard their financial health. We are looking for a Chief Scientist to lead it. This is a unique opportunity to use your experience, knowledge, and passion to transform a trillion-dollar industry and bring financial peace of mind to tens of millions of people many of whom had been harassed and abused by commission-driven collections agencies for years. You will join a multi-functional engineering team dedicated to creating a data-driven culture and improving the efficiency of the way we make and implement decisions. As a Chief Scientist, you will act as a visionary who leads technology development for optimizing TrueAccord’s automated debt collection strategies. You will also be the scientific face of TrueAccord to the outside world. We’re looking for someone who is known for research in machine learning and is capable of transforming it from theory to practical algorithms. Responsibilities: Formulate and implement technical vision and strategy around Machine LearningDevise a world-class Machine Learning platform for the debt management industry Continuously improve business impact of our production Machine Learning systemsHunt for quality datasetsRepresent TrueAccord in the Machine Learning communityMentor and guide the Data Science teamWork closely with product leadership, other TrueAccord stakeholders, and clients on models, datasets, and insightsExplain complex Machine Learning concepts to audiences of varied technical backgrounds Qualifications:﻿PhD in Computer Science with specialization in Machine LearningRecent experience in building and managing a strong, impactful data science teamEntrepreneurial mindsetTrack record of significant business lift from Machine Learning in fintechCurrent on all recent advances in the fieldIndustry presence: published research, blogging, conferences, meetups, open source contributionsFluent proficiency in PythonAbility to quickly prototype and test new ideasDeep understanding of cost-effective tradeoffs in large-scale production systemsStrong passion for research and development with experience in solving hard analytical problems What TrueAccord offers you + Culture & BenefitsTrueAccord is distributed company with a major presence in the San Francisco Bay area and Lenexa, KS. We offer a healthy work environment that continuously builds an inclusive and diverse culture where everyone is able to develop the best version of themselves. We are a dynamic group of people who are subject matter experts with a passion for change. We offer:*** Generous paid time off*** Paid training*** We promote work/life harmony*** Paid holidays*** Health, dental and vision benefits*** 401K with matching Our teams are crafting solutions to big problems every day. If you’re looking for an opportunity to do impactful work, join TrueAccord and make a difference. Our Dedication to Diversity & InclusionTrueAccord is an equal opportunity employer. We promote, value, and thrive with a diverse & inclusive team. Different perspectives contribute to better solutions and this makes us stronger every day. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",Director,Jornada completa,"Tecnología de la información, Otro, Ingeniería","Servicios financieros, Servicios y tecnologías de la información",65,None,False,,938,COMPANY_RECRUIT
805,2021958543,2020-10-27,The Adecco Group,Senior Data Scientist (US-Permanently Remote),United States,"We are seeking an enthusiastic and experienced Senior Data Scientist with a proven track record in data science applied to large-scale real-world problems. In this role, you will provide advisory and implementation expertise to different business stakeholders including identification, assessment, development and deployment of advanced data science and automation use cases. You will apply statistical approaches to analytical problems to execute analyses on structured and unstructured data including data preparation, analytical predictive modelling (machine learning, deep learning, NLP, etc.), optimization, evaluation and deployment of the solution. The role requires working in a fast paced environment, handling multiple assignments, being self-driven and will include the translation of complex analytical and technical concepts to non-technical employee.  Required Work Experience/Skills : Master Degree in Math, Statistics, Physics or Engineering (preferably with a PHD)Minimum 5 years of experience in data scienceExcellent Machine Learning skillsVery good Automation skillsVery Good Deep Learning knowledgeStrong NLP skillsGood Knime knowledgeStrong programming skills in PythonStrong programming skills in SQLExcellent Data Visualization skillsFluent in EnglishGood RPA (Robotic Process Automation) knowledge  Nice to have Experience/Skills:MicroStrategy, Power BIBlueprismChat BotRJavaJavaScriptBig Data knowledge (Hadoop, Spark) COMPANY OVERVIEW: Adecco Group North America, through an impressive portfolio of staffing industry leading brands including Accounting Principals, Adecco General Staffing, Adia, Ajilon, Entegee, Lee Hecht Harrison, Modis, Paladin, Parker+Lynch, Pontoon, Special Counsel and Soliant is the world’s leading provider of Human Resources solutions. We are the workforce experts delivering staffing and career service solutions to organizations and individuals across all industries. Collectively we harness the power of some of the greatest talent in the world. That talent and expertise allows us to do business globally and act locally with deep knowledge in niche areas. Every day, we have more than 100,000 associates on assignment, 30,000 colleagues working internally to support more than 10,000 clients in the United States and Canada. Ensuring our business units are prepared to deliver outstanding service to our associates and clients, the Adecco Group North America team provides a strong infrastructure through our corporate and shared services teams. Equal Opportunity Employer Minorities/Women/Veterans/DisabledThe Company will consider for employment qualified applicants with arrest and conviction record",Director,Jornada completa,"Ingeniería, Finanzas, Tecnología de la información","Servicios financieros, Ingeniería industrial o mecánica, Servicios y tecnologías de la información",380,None,True,,1338,ACTIVELY_HIRING_COMPANY
806,2281006525,2020-10-12,Syrinx Consulting,Sr. Data Engineer (REMOTE),"New York City, NY, US","Who We Are  Working with the leader in digital performance solutions, improving the impression quality and audience impact of digital advertising. Built on best practices, our solutions create value for media buyers and sellers by bringing transparency and accountability to the market, ensuring ad viewability, brand safety, fraud protection, accurate impression delivery and audience quality across campaigns to drive performance.  This is a great opportunity to get in a remote role!! Please apply directly to ldavis@syrinx.com  Headquartered in New York City, DoubleVerify’s investors include JMI Equity, Institutional Venture Partners, Blumberg Capital, First Round Capital and Genacast Ventures. Learn more at doubleverify.com.  Overview  DoubleVerify is seeking a data slayer, a one in a thousand DBA that loves to ask questions and be on the cutting edge of Big Data technology. The team is responsible for all technical data aspects of the company’s products. The company’s system is comprised of an extremely scalable, highly-available and rapidly-developing architecture, and includes big-data stores of all types – relational, massively-parallel-processing, and NoSQL. This individual will join a small yet highly capable and motivated team in order to maintain the system’s databases, and develop, integrate and deploy complex new modules – quickly and at scale.  What You Will Do  Develop and maintain Big Data system (Hadoop, Kafka, Hive, Spark) Maintain the system’s databases (Vertica, SQL Server, MongoDB) Develop, integrate and deploy complex new modules (TSQL, Python, Splunk) Design and support Database infrastructure, with consideration for performance, availability, and specific application requirements. Work closely with other departments on the implementation and deployment of new initiatives   Who You Are  5+ years of database development and/or administration. 5+ Experience with Hadoop Big Data eco system and experience with Vertica is a must Software development experience is preferred Fast learner, creative thinker, problem solver. Must love BIG data! Accountable, dedicated and willing to be on-call as needed AdTech experience is a plus!",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Servicios financieros",0,None,False,ldavis@syrinx.com,1,ACTIVELY_HIRING_COMPANY
807,2273371932,2020-11-04,Coda,"Growth Marketing Manager, Engagement & Retention","Mountain View, CA, US","The Opportunity  Coda is looking for a highly structured thinker to start our Growth Marketing team. This team will oversee our user journey and develop the programs for how we drive Retention and Engagement in our product. You'll be working in a revenue-facing function, which means that you'll get excellent exposure to the point where our product interacts with customers and drives our business forward. The ideal candidate will use a combination of data, testing, and a high degree of customer empathy to drive activation, engagement, retention, conversion, and expansion. Since Coda is used across a diverse set of customers and use cases with many potential points to drive engagement, this is a unique role for an analytically-inclined person to be both creative and drive measurable results.  Coda reimagines documents, spreadsheets, and how 'applications' are developed. While documents and spreadsheets have remained relatively unchanged for the last 40 years, their paradigms still dominate how businesses and people operate. We're taking a fresh approach at what these fundamental surfaces are ー empowering anyone to start with something as simple as a document that can easily evolve into a powerful, connected application. We've seen customers make docs to plan product launches, manage marketing campaigns, coordinate country-wide remote education opportunities, and to run their business full stack (to name a few).  As the founding member of the team, your fingerprints will be all over the process, culture, and company we build in the years to come.  Responsibilities:   Work with product and marketing teams to develop and implement a cohesive Retention and Engagement strategy. Drive engagement, retention, conversion, expansion, and resurrection across our customer base by crafting personalized campaigns and in-app experiences. Develop lifecycle marketing campaigns across email and in-app messaging channels. You'll help drive the adoption or build-out of advanced customer engagement tooling. Explore, test, validate, and refine potential new engagement and growth channels. Work with product teams to craft and launch experiences to onboard and activate users to new product features. Deeply understand, research, and segment our users to deliver customized experiences to the right audience. You'll understand the data driving our customer actions and A/B test your way to better experiences. Maintain a rigorous and organized view of the experiences and communications we are delivering across our key customer segments.  You are:   A highly structured thinker who is able to craft a cohesive customer journey across a very horizontal product experience. Not necessarily a marketer by trade, but interested in all aspects of the customer journey - retention, engagement, conversion, and everything in between. You are invested in how customers move through and experience a product - and how you can help get them there. Analytically-driven and rooted in high Emotional Intelligence. Experienced with SQL - you don't need to be a Data Scientist, but you need to be self-sufficient. Obsessed with A/B testing, iteration, and finding insight. You love scaling your findings to adjacent areas. Aware of how brand assets and creative efforts are perceived, and hold your customer-facing work to a high standard of quality. You can design and create professional-looking communications independently. Eager to roll up your sleeves with a fast-growing startup and can plan ahead to let your efforts scale down the line. Experienced with the latest marketing and engagement tools and excited about the opportunity to add new ones to our tech stack. Proven collaborator with strong ability to communicate and drive process with a wide range of stakeholders.",Intermedio,Jornada completa,Otro,"Marketing y publicidad, Software, Internet",34,None,False,,178,COMPANY_RECRUIT
808,2287483104,2020-10-13,Sept Lieues,H/F Data Engineer - Possibilité Remote,"Paris, FR","L'ENTREPRISE  Entreprise leader européen sur le marché de la data électorale qui développe des outils afin de comprendre et convaincre l'opinion à un niveau local.  LE POSTE / LES MISSIONS  Le data engineer participera à la mise en place et l'enrichissement du pipeline du traitement de donnée. Intégrant une équipe pluridisciplinaire (produit/dev/data) dans le but de développer les produits. Les missions sont les suivantes :  Travail en collaboration avec les data-scientist afin de mettre en production de manière robuste et scalable des algorithmes de NLP et de machine learning Conception, Implémentation et automatisation en Python Contribution à la conception et implémentation d'une architecture de traitement et de stockage des données performante et résiliante Aide à l'architecture des données afin qu'elles soient exploitable par l'équipe tech-product Participation à la mise en place de l'infrastructure cloud 80% Conception et implémentation python / data 20% Infra / devops  PROFIL RECHERCHÉ  Bac +5 ou équivalent en informatique. Vous avez un minimum de 2 ans d'expérience professionnelle avec idéalement une première expérience de Data Engineer sur des architectures complexes. Vous avez déjà travailler sur des problématiques de traitement de gros volumes de données (architecture de données, collecte, transformation...)  Vos Compétences Techniques Sont Les Suivantes  Python et son écosystème Conception et implémentation de micro-services / API Expérience sur des use-cases qui impliquent la manipulation de donnée non structurée  Base de données Optimisation et performances BDD relationnelles Les + :  Connaissances en Infra / DevOps Conception et implémentation de systèmes de collecte de donnée (scraper/crawlers) Architecture Serverless",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Internet",None,None,False,,3,JOB_SEEKER_QUALIFIED
809,2283365075,2020-11-06,Medix™,Associate Data Engineer,Atlanta Metropolitan Area,"Medix is currently seeking an Associate Data Engineer for an exciting contract / contract to hire opportunity with one of our top healthcare clients, headquartered in Atlanta!  Please note that this role is 100% remote, and will continue to be remote in the future. About our client / About this role:Our client is a Healthcare Analytics firm that specializes in Population Health Management.  This Data Engineer will be joining a team, and will be responsible for the back-end Data Engineering supporting a large healthcare datawarehouse platform.   We are seeking individuals who have 2-5 years of experience in extracting, transforming,  loading and integrating data.  Experience with both Microsoft SQL Server and Oracle-based systems is required.  Prior healthcare industry is a big plus!  The primary responsibilities for this Data Engineer will include: Understanding the requirements for the data flowParticipating in developing ETL solutions - from creating ETL Packages, to automating the processes. Working with the Actian DataConnect ETL ToolExtracting, manipulating and integrating healthcare data from a variety of source database platforms - including Healthcare EMR / EHR Platforms, Microsoft SQL Server, NoSQL, etc, into an Oracle DatawarehouseCreating shell scripts (Perl, Powershell, etc) to automate basic manipulations such as file and/or directory informationPreparing specifications for changes needed to the ETL maps and/or database procedures as neededUpdating documentation as neededAssisting with data validation and unit testing methods to ensure data quality across all systems and applications. Required Experience / Technical Qualifications Required Bachelor of Science in a Computer Science or related field2-5 years of professional experience Hands-on experience with both SQL Server and Oracle Database SystemsExperience with an ETL Tool (Actian DataConnect, Informatica PowerCenter, SSIS, etc)Prior Healthcare Industry experience is preferred Position Type: W2 Contract / Contract to Hire Compensation Range: $38 - $42 / hour  (Annual salary $70,000 - $80,000)Duration: 6 Months Benefits: Medix offers an impressive Talent Benefits Package, which includes Medical/Dental/Vision insurance options, prescription drug, short/long-term disability and life insurance.  There is accrued paid time off (PTO) in addition to a 401K Retirement Savings Plan with Medix Matching.  Please note that talent must be authorized to work for any employer in the US, without the need for visa sponsorship now or in the future.",Algo de responsabilidad,Contrato por obra,Tecnología de la información,Atención sanitaria y hospitalaria,43,None,True,,163,ACTIVELY_HIRING_COMPANY
810,2151216760,2020-10-15,MBN Solutions,Data Engineer,"Glasgow, Scotland, United Kingdom","Senior Data Engineer (Azure) – Glasgow 45,000 - 55,000 + Package  MBN are exclusively partnering with an amazing tech startup who are building their brand new tech centre in Glasgow. The organization have created an Azure based AI platform which is set to revolutionise the digital professional services industry, specifically through the adoption and use of corporate data. In this role you will help the business continue its design and development of their Azure Data Lake, ensuring that it is robust and scalable to keep up with the growth of the business. You will also be responsible for building data pipelines using Data Factory and help with mentorship and development of two other Data Engineers. Key Skills & Experience required:﻿·        Experience across the Microsoft Azure Data Stack, including Azure Data Lake, Azure Data Factory, Azure Data warehouse, Microsoft Power BI ·        Proven track record and strong background in Big Data Engineering ·        Building, maintaining full ELT/ETL workflow lifecycle from data ingestion to output·        Strong experience in maintaining and optimizing the Azure SQL Data Warehouse to maximize performance (T-SQL). ·        Experience implementing Azure functions into Data Factory pipelines – Advantageous ·        Experience in implementing containers in Azure using AKS /Docker – Advantageous  For more information or to apply, please send across your CV to Kris@mbnsolutions.com",Intermedio,Jornada completa,Tecnología de la información,Servicios y tecnologías de la información,146,None,True,Kris@mbnsolutions.com,547,ACTIVELY_HIRING_COMPANY
811,2282144688,2020-11-05,Kubikware,"Ref:Immediate C2H Data Scientis (Python, SQL, Spark)-Santa Ana, CA (Remote)","New York City, NY, US","We are Kubikware, an Inc 500 honoree digital agency with more than 15+ years of experience in the software development and recruiting market. One of our clients, a leading global technology services provider is looking to connect with Data Scientists in LA/OC/SD, for an immediate contract opportunity (C2H) with an enterprise healthcare client.  Where is the work to be performed?  Santa Ana office, when in-office resumes. Remote otherwise. Prefer someone locally (Santa Ana, CA, however, open for the full-time remote. Term: 6 months C2H  The Top Responsibilities For This Position Analytic data modeling development Data exploration/research while quality testing of output from other developersTechnical documentation of logic and results Presentation of logic and results to team and stakeholders   Top 3 Skills 3-4 years of experience as a Data Scientist of building and supporting predictive data models and code transformation and ad hoc analysis SQL, Python, Spark experience with a minimum of 3 -4 years of data modeling with linear regression, clustering Preferably Matplot or Tableau for visualization, with neural networks and graph computation for analytics In-line Edit  If you believe this role could be a great fit, please submit your profile, and let´´s stay in touch!.  Aptitudes y experiencia deseadas           PYTHON,SQL,Spark",Intermedio,Contrato por obra,Ingeniería,Software,2,None,False,,6,None
812,2287782158,2020-11-04,"Medable, Inc",Data Scientist - REMOTE,"London, GB",Job DescriptionExplore machine learning opportunitiesInvestigate and compile new sources of medical dataProvide clinical input to refine existing machine learning architectureDevelop and integrate machine learning algorithms for data processing and analysisBuilding models to address business problemsPresenting information using data visualization techniquesUndertake preprocessing of structured and unstructured dataAnalyze large amounts of information to discover trends and patternsBuild predictive models and machine-learning algorithmsPropose solutions and strategies to business challengesCollaborate with engineering and product development teamsOther duties as assigned,Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información",Servicios y tecnologías de la información,2,None,False,,25,ACTIVELY_HIRING_COMPANY
813,2275831237,2020-11-04,Eliassen Group,Python Data Engineer,Miami-Fort Lauderdale Area,"Python Data Engineer  Responsiblities: 5+ years of Python server development using Django, Flask, Bottle or other python frameworks Ability to write unit-tested and maintainable code Expertise working with and building RESTful APIs Knowledgeable in cloud platforms (preferable AWS: both traditional EC2 and serverless Lambda), micro-services architecture, CI/CD solutions (including Docker), DevOps principles, message queue systems, and background task management. Experience with API security frameworks, token management and user access control including OAuth, JWT, etc. Solid foundation and understanding of relational and NoSQL database principles. Ability to work in an Agile /SCRUM environment.     For immediate consideration, email your updated resume to Dan Malta at dmalta@eliassen.com",Intermedio,Contrato por obra,"Tecnología de la información, Desarrollo empresarial, Negocios","Servicio de información, Servicios y tecnologías de la información, Administración gubernamental",83,None,True,dmalta@eliassen.com,252,ACTIVELY_HIRING_COMPANY
814,2277516146,2020-11-05,KDR Recruitment Ltd,Senior Data Engineer,United Kingdom,"My client, based in London, specialise in building tools in risk analysis and data modelling. They help their clients identify the financial risk of working with other business’/directors. Their mission is to work with their clients to develop specialised products and analytics that can help them manage the risk. What sets them apart is the fact they are true to analytics, rather than your typical financial services company. They have a relatively small sized team that work mostly in data-related positions, it is the heart of what they do. The employees are really driven and passionate about giving the actual insight to their clients rather than just providing information. As a Senior Data Engineer, you will be joining a small but hugely expanding organisation who are looking to build their data architecture to work on the requirements of data science & other stakeholders. Your role will be to work on a greenfield project, migrating their SQL Data Warehouse over to Google Cloud. What skills will you need to join the team?SQL experienceData Modelling (conceptual, physical, logical)Data Warehousing - if you have worked on greenfield projects – great!Cloud technologies –AWS, Azure, GCP, BigQuery, Redshift etc… (or) You will need to be self-motivated, passionate and a keen learner to be a part of this team My client is looking for super passionate individuals, who take analytics seriously & thrive in collaborative environments, communicate well with stakeholders & help the companies mission go even further. In return, you will have the opportunity to work with different technologies with a highly effective team & reap the rewards of progression and growth in your career. Key responsibilities will include…Working with other data engineers and data scientistsManage the data ecosystem, ensuring it is cost effective and meets the business’ requirementsBuilding and maintaining the flow within ETL & analysis pipelinesTaking ownership of the data modelling In return, you can expect – Between £65,000 and £80,000 depending on how much experience you have with the above skillsQuarterly bonusEnd of year bonus based on company performanceremote working/2 days in the office post COVID. If you have GCP experience already, this role can be fully remote for the length of the positon25 days holiday, plus bank holidays & more! If you’d like to hear more about this role, please get in touch with me. Do not worry if you do not have a CV, I’m here to help!",Intermedio,Jornada completa,"Tecnología de la información, Finanzas","Servicios y tecnologías de la información, Software, Servicios financieros",30,None,True,,103,ACTIVELY_HIRING_COMPANY
815,2199804784,2020-10-21,Harnham,Machine Learning Engineer,San Francisco Bay Area,"THE COMPANYAre you interested in working with the leading video streaming provider? Are you advanced at following agile practices? The team is seeking an ML Engineer who is able to support company product and take ownership of a subsystem within the product. This role focuses on design, creating, coding, and testing models .You need to be able to work with Data Scientist and have an understanding of Machine Learning or Natural Learning Processes.RESPONSIBILITIES·   Work independently on validating models·   Take and run a subsystem, help oversee integration and architecture·   Automate manual data flows for repeated use and scalability within Spark SKILLS·    Skilled SQL databases (athena, presto)·    Deep experience with Cloud - AWS·    Expert level with Python and PySpark·    Experience with API developmentSALARY60/hr HOW TO APPLYPlease register your interest by sending your CV via the Apply link on this page. For further details or to inquire about other roles, please contact Chandler Davis-Strickland at chandlerdavis-strickland@harnham.com",Intermedio,Contrato por obra,"Tecnología de la información, Diseño, Gestión de productos",Atención sanitaria y hospitalaria,143,None,True,chandlerdavis-strickland@harnham.com,509,ACTIVELY_HIRING_COMPANY
816,2231245285,2020-11-01,Branch International,Machine Learning Engineer,"Portland, OR, US","Branch's Engineering Team builds products for customers in 4 markets and is distributed across 3 continents. Our team in the US works closely with teams in Africa and India on our existing products as well as new product initiatives. In the long term, we envision the US team as the team responsible for some of the most important foundational building blocks that enable us to rapidly build and improve products across multiple markets.  You will work closely with other Engineers, Product Managers, and Data Scientists to develop, improve, and deploy machine learning models and to solve other optimization problems. We make extensive use of machine learning in our credit product, where it is used (among other things) for underwriting and loan servicing decisions. We are also actively exploring other applications of Machine Learning in some of our newer products, with the ultimate goal of improving the user experience.  Machine Learning sits at the intersection of a number of different disciplines: Computer Science, Statistics, Operations Research, Data Science, and others. At Branch, we fundamentally believe that in order for Machine Learning to be impactful, it needs to be closely embedded into the rest of the product development and software engineering process, which is why we emphasize the importance of software engineering skills and experience for this role.  Qualifications  You excel at software engineering and programming in Python and SQL. You have 5+ years of experience working on Machine Learning systems in a production setting. You have a diverse range of data skills including experimentation, statistics, and machine learning, and have used these skills to inform business decisions. You have a keen eye for detail and a healthy skepticism for data before relying upon it. You are highly entrepreneurial. You teach yourself new skills. You take the initiative to solve problems before they arise. You know that startups are a team sport. You listen to others, speak your mind, and ask the right questions. You are a great collaborator and teacher. You are driven by making an impact on customers’ lives.  Project Examples  Credit Decisions - Core to our business is understanding and building signals from unstructured and structured data to identify good borrowers  Customer Service - Using machine learning, automate customer service interactions and provide context to our customer service team  Fraud Prevention - Identify patterns of fraudulent behavior and build models to detect and prevent these behaviors  Product Growth - Understand user experiences, test ideas, and improve conversion rates through experimentation  Paid Growth / Marketing - Use external and internal data sources to measure and optimize marketing spend  Benefits of Joining  Mission-driven and fast-paced, entrepreneurial environment  Competitive salary and equity package  99% coverage of insurance costs (health, dental, vision) Unlimited PTO Flexible working hours Discretionary trips to our offices around the globe (when it's safe to travel!) Pre-tax commuter and 401(k) programs Weekly team meals and quarterly team building events (virtual for now!) Generous child bonding leave policy  Location  We are primarily looking for candidates located (or willing to relocate to) the United States, ideally in the Pacific Time zone.  Branch International is an Equal Opportunity Employer. The company does not and will not discriminate in employment on any basis prohibited by applicable law. We’re looking for more than just qualifications -- so if you’re unsure that you meet the criteria, please do not hesitate to apply!  The salary range for this position is $190,000 - $250,000",Algo de responsabilidad,Jornada completa,Ingeniería,Software,20,None,False,,205,COMPANY_RECRUIT
817,2243511885,2020-11-06,Южный Федеральный Университет (бывший Ростовский Государственный Университет),Postdoctoral Researcher,"Rostov, Russia","Department of Innovative and International Management of Southern Federal University, Russia seeks a postdoctoral researcher for a collaborative project 'Reproductive function of human capital in the context of the innovative digital transformation of the spatial and economic system of the South of Russia'. The aim of the project is to form a methodological basis and making a concept and an economic and mathematical model for a comprehensive analysis of human capital, conditions, mechanisms and tools for using its elements in the interests of developing the socio-economic system in the specific conditions of the southern Russian macro-region. Among the expedient research objectives are: 1) generalization and comprehension of fundamental and applied aspects of the study of human capital as an integrated resource of innovation-oriented development of the economy and society: 2) the formation of a model of innovation-oriented regional management in the field of accumulation and use of human capital resources, as one of the priority factors in the improving of the region's welfare. Job Requirements•   The successful candidate should hold a recent PhD in economics and management (academic degree), computer science and mathematics (diploma of education) and be fluent in English (not lower than upper intermediate). Knowledge of other foreign languages is encouraged, incl. Russian. •   The candidate should also have proven experience of independent research from 1 year, the presence of analytical skills (preferably on the topic of the project), high academic potential, the ability to develop a plan and conduct research of high quality.•   Research performance indicators (in Scopus system): the number of publications on the project topic and / or in related fields is at least 3. •   Applicants are expected to have a work experience in international research team. ﻿What we offerEmployment contract for 3 years, available since December 1, 2020.The postdoc will have the possibility of individual research work within the framework of individual research tasks, obligatory participation in joint research activities on the project, research of the project objectives on the materials of the native country or country of residence, publication of the results in journals with a high rating (at least two annually), presentation of research results at national and international conferences: periodic online seminars to discuss current tasks and research results, a detailed report every six months. How to ApplyInternational candidates are welcome to apply.The application is sent to elazareva@sfedu.ru / el_lazareva@mail.ru Interested applicants should submit a motivation letter, a full curriculum vitae, list of publications or related projects in the research field, a recommendation letter. Enquires should be made to: Prof. Elena I. Lazareva elazareva@sfedu.ru / el_lazareva@mail.ru Details: https://www.sfedu.ru/www/stat_pages22.show?p=JO/N13515/P",Sin experiencia,Contrato por obra,"Investigación, Análisis, Tecnología de la información",Enseñanza superior,5,None,True,"elazareva@sfedu.ru, el_lazareva@mail.ru, elazareva@sfedu.ru, el_lazareva@mail.ru",72,None
818,2261244604,2020-10-31,NBCR Rekrutacja IT Sp. z o.o.,Senior Data Engineer (Cloud Expert)- 100% remote,"Warsaw, PL","NBCR Sp. z o.o. is a company with an established position in the market specializing in the recruitment of specialists in the IT industry (Certificate No. 14492). For over a dozen years, we have been helping our clients in providing highly qualified specialist staff, thanks to which they can work and grow and we accompany them as a reliable partner.  We Are Currently Looking For Candidates For The Position  Senior Data Engineer (Cloud Expert)- 100% remote  Responsibilities  We focus on the finance, retail, and healthcare sectors with use cases like investment optimization, semi-automated data mapping, lead scoring. We conduct internal webinars to share knowledge in the fields of Machine Learning and Data Engineering. We’re building an ML-Ops culture within our department and we want to extend that to the Data Engineering area. We use AWS and GCP as our cloud providers. We encourage our team members to share their knowledge and experience at external conferences. We cooperate closely with the Machine Learning team. Requirements  3+ years of DE experience, Strong experience with S3 + Athena/Presto and Redshift/Redshift Spectrum, Hands-on experience with at least 2 of the following: AWS Glue/EMR or Kinesis/Kafka or ELK stack or Lambdas. Experience in designing data lakes - from structuring to managing and optimization, Knowledge of data storage formats (Parquet, ORC, AVRO, etc.), Experience with Python and Linux and shell scripting, Familiarity with relational databases like Oracle, PostgreSQL, MySQL, Advanced SQL writing skills. Nice-to-haves  Experience with: Airflow / Luigi MongoDB / ElasticSearch / Cassandra Kubernetes We Offer  attractive salary Generous private health insurance package with dental care. Optional life insurance for you and your family. A growth budget for your educational plan. Masterbenefit: discounts on car leasing. Discounts on Apple products. Various internal initiatives: webinars, knowledge sharing sessions, internal conferences.",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Internet",0,None,False,,24,None
819,2277727275,2020-11-05,Altitude Networks - Cloud Native DLP,Customer Success Director,"San Francisco, CA, US","Job Description  As the customer service director you will be the first dedicated customer service role and focus on pre and post sales customer success. This player/coach role will be hands on working directly with existing Altitude Networks customers and also playing a strategic role as the structure and team of the customer success organization grows alongside the growth of the company. This role is ideal for an individual that loves and has a deep appreciation for security technology and wants to be at the forefront of working directly with customers to understand and solve their security objectives. This role requires coordination with multiple teams including sales, product development and engineering and the ability to translate requirements and needs appropriately for each audience.  Responsibilities  Establish a customer success program that begins prior to sales and engages with the customer throughout their entire lifecycle with Altitude Networks. Develop key customer success strategy and build the function from the ground up, delivering high touch, consultative experience to customers Collect comprehensive feedback from key customer stakeholders to drive company roadmap with the product team Plan and drive requirements for internal tooling to build a world class customer success organization Maintain a deep understanding of the product and current product health through ownership of the product portion of the demo environment Understand and surface trends for customer via product or backend data review that can be tested for customer interest and lead to future features Work with customer and product to validate, recreate, and report bugs or feature requests   Requirements  8+ years of customer service experience 4+ years within the cybersecurity industry  3+ years experience managing customer service teams  Strong knowledge of cybersecurity risks & threats facing SMB, mid market and enterprise customers Strong communication skills with ability to effectively navigate business/security objectives with C-Suite and engineers/IT  Expert at building relationships and establishing effective communication channels with customers Experience driving requirements and best practices for internal tooling for customer management, health monitoring, performance tracking Ability to translate customer feedback into product feature requests or bug reports  Ability to perform basic sql queries for high level data review  Great organization skills  Previous experience in SaaS cybersecurity products a plus Previous experience in security startups a plus   Location  This role is remote friendly throughout the United States with the expectation of a 6 hour working overlap with the Pacific time zone and quarterly travel to the San Francisco Altitude Networks office.  About Altitude Networks  Altitude Networks provides companies with the data security they need to safely use collaboration SaaS (GSuite, Office365, Box, Dropbox, etc) without the threat of data loss, theft or inadvertent sharing with unauthorized individuals. Altitude Networks is founded by Michael Coates, former CISO of Twitter and 15 year veteran in the information security space, and Amir Kavousian, Stanford PhD and former data scientist from CapitalOne ML fraud team. We are a BusinessInsider Top 30 CyberSecurity Startup in 2019, backed by prominent Silicon Valley Venture Capital.  At Altitude Networks, we use a modern architecture that is designed to optimize development efficiency and velocity. We use a serverless architecture and advanced CI/CD tools that enable all team members to quickly develop, deploy, and maintain code in production in AWS cloud.  Altitude Networks is proud to offer the following benefits: Health, Dental, Vision, PTO, Parental Leave Policy, 401K, Commuter/Parking Benefits, Short/Long Term Disability, Friday Team Lunch, and One Medical Membership, Unlimited Coffee & Kombucha",Director,Jornada completa,Otro,"Servicios y tecnologías de la información, Software, Internet",30,None,False,,166,None
820,2225816146,2020-10-30,Kumu,Senior Data Engineer,Philippines,"As Kumu's Senior Data Engineer, you will be working alongside a growing team of engineers and data scientists, to help further rapidly scale the Kumu environment. Along with other senior members of the team, you will be taking charge of designing and deploying scalable big data analytic solutions to help support Kumu's data-drive organization. You will be responsible for: Maintenance of existing data warehouse infrastructureSpearhead and participate in all aspects of developing and optimizing a data warehouse system, beginning from designing, development, testing, deployment and up to the maintenance of the data warehouse.Integrate with external data sources to pull data and dump into data warehouse - including API services, flat files, unstructured dataClean & transform data into the form needed by various stakeholders - data scientists, data analysts & other department stakeholdersSpearhead plans for optimization of data operations in terms of efficiency and costEnsure a full-stakeholder approach in building big data solutions by coordinating with multiple cross-functional teams, including Product, Engineering and Business Intelligence Teams. Be a gatekeeper of our data and provide the necessary access only to the relevant stakeholders (data analysts, data scientists, business team etc.) for convenient data accessibility, but with strong data security.Documentation of technical specs of all the data infrastructure being used - data warehouse, pipelines, catalog, etc.Participate in code reviews of peer engineers and maintenance of code repositories And we need you to have: Basic understanding of business metrics for app analyticsStrong communication skills to be able to coordinate between various stakeholdersBasic knowledge of architecture / pipeline diagrams and documentationStrong preferences for familiarity working with these types of data: Event streaming, Image / Video live streaming, Transactional, ECommerceExperience in designing and deploying scalable big data analytic solutions Alongside the following: Strong programming knowledge in Python for developing ETL componentsStrong understanding of SQL for data analysis and table transformationsMulti-Cloud Platform Experiences - AWS, GCP or AzureExperience working with modern high performance analytical databases and computation engines like Spark, Flink, Presto, Synapse, BigQuery, Elasticsearch, Greenplum and othersExperience working with various data storage and object structures including, but not limited to structured SQL records, NoSQL documents and unstructured media files.",Intermedio,Jornada completa,"Tecnología de la información, Ingeniería","Medios de comunicación en línea, Servicios y tecnologías de la información, Software",24,None,True,,130,ACTIVELY_HIRING_COMPANY
821,2291078226,2020-10-23,Kelly,"Sr. UX Designer/Researcher - Alpharetta, GA/Remote","Alpharetta, GA, US","PLEASE NOTE: Must be legally authorized to work in the U.S. for any employer without sponsorship.  Kelly Services is hiring a Sr. UX Designer/Researcher to join their team for a top human resources management software and services company in Alpharetta, GA/Remote. Below are the details and required skills. For immediate consideration, please email your resume directly to: regan.brown@kellyit.com as well as apply online.  Sr. UX Designer/Researcher ~12 Months (contract to perm – W2) Pay Rate: TBD  Short Description  Designs, develops and implements cross-browser and cross-platform user interface, such as graphics and multimedia, for web applications, web pages and web components.  Complete Description  Designs, develops and implements cross-browser and cross-platform user interface, such as graphics and multimedia, for web applications, web pages and web components. Maintains and enhances user interface of existing web applications, web pages and web components.  Why Kelly  As a Kelly Services employee, you will have access to numerous perks, including:  Exposure to a variety of career opportunities as a result of our expansive network of client companies. Career guides, information and tools to help you successfully position yourself throughout every stage of your career. Access to more than 3,000 online training courses through our Kelly Learning Center, including accredited courses to obtain IT certifications, as well as PDU-approved courses. Weekly pay. Group-rate insurance options available immediately upon hire.*  Apply today! Refer a friend! Available for purchase and administered by a designated third-party vendor. (115) Why Kelly ® ? As a worker today, it’s up to you to take charge of your career and look for opportunities to learn, grow, and achieve your potential. Helping you find what’s next is what we’re all about. We know what’s going on in the evolving world of work—just ask the nearly 500,000 people we employ each year. Connecting with us means getting the support, guidance, and opportunities needed to take your career where you may have never imagined.  About Kelly ®  At Kelly , we’re always thinking about what’s next and advising job seekers on new ways of working to reach their full potential. In fact, we’re a leading advocate for temporary/nontraditional workstyles, because we believe they allow flexibility and tremendous growth opportunities that enable a better way to work and live. Connecting great people with great companies is what we do best, and our employment opportunities span a wide variety of workstyles, skill levels, and industries around the world. Kelly is an equal opportunity employer committed to employing a diverse workforce, including, but not limited to, minorities, females, individuals with disabilities, protected veterans, sexual orientation, gender identity. Equal Employment Opportunity is The Law. #KellyGTS ]]",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Construcción, Servicios financieros, Atención sanitaria y hospitalaria",0,None,False,regan.brown@kellyit.com,1,ACTIVELY_HIRING_COMPANY
822,2265047208,2020-10-17,Crowdskout,Behavioral Scientist,"Raleigh, NC, US","Crowdskout is a platform for advocates to create, power, and cultivate communities at local and national levels. We provide mobilization and data tools to non-profits, issue advocacy groups, electoral groups, and corporate social impact teams. We are building capabilities that live beyond a 4-year election cycle, and outside of a traditional 'Red/Blue' partisan paradigm.  We are looking for a Behavioral Scientist to join our growing Research Team. You will help Crowdskout to design, implement and analyze experiments and evidence-based interventions. As part of a cross-functional team, you will be involved in research collaborations within product, across client organizations and more broadly in society.  If you are highly motivated, super passionate about democracy, and want to join a close-knit team that is looking to build great things for regular people, Crowdskout may be for you. This is a full-time position in Durham, NC: Salt Lake City, UT: Austin TX: Washington, DC: New York City, NY, or fully remote.  Responsibilities:   Be an in-house expert in the principles and mechanisms of behavior change  Design, implement and analyze quantitative behavioral experiments (A/B tests, RCT, etc.) across Crowdskout. products and for client engagements. Work closely with User Researchers to understand user needs, goals, and experiences to create product features and content and Product Analysts to design and implement quantitative validation studies for new products and features.  Elucidate data-driven insights for product and content development for Crowdskout and clients and quickly learn from experiments to put forward new hypotheses, including identifying opportunities to improve the behavior change potential of products across the platform and organization. Conduct literature reviews and maintain up-to-date knowledge of academic research and market trends related to advocacy, civic engagement, voting, policy, campaigning, etc. Contribute to the development of quantitative survey instruments and user discussion guides  Develop behavioral and societal-level metrics and conduct appropriate statistical analysis of impact   Collaborate to develop and implement hands-on workshops, seminars, and other educational activities for Crowdskout focused on applied behavior analysis and design Improve data literacy across the organization and drive a culture of data-driven decision making   Must-haves   Deep experience in applied behavioral science: ideal candidate has a Master's Degree (or higher) in behavioral economics, experimental psychology, political science, applied behavior analysis, or closely related field 4+ years experience using evidence based behavior change interventions  Extensive training in statistical analysis and data management with demonstrated ability to use syntax-based statistical packages (e.g. R, SAS, Stata, MATLAB, etc.)  A love of experimentation and expertise with experimentation tools Excellent communication, collaboration, and interpersonal skills Strong project management skills  Nice-to-haves:    Understanding of political processes and campaign culture 2+ years proven experience working on product teams Exposure to the technical aspects of analytics, data science and data visualization software tools (Google Analytics, Mixpanel, SQL, Tableau etc.) Knowledge of technology and how to use technology and online tools in innovative ways    Crowdskout is an equal opportunity employer that encourages diversity across all spectrums in its hiring, without regard to race, gender, age, color, religion, national origin, marital status, disability, sexual orientation, or any other protected factor. With that being said, we wouldn't be able to accommodate candidates in need of work sponsorship at this time since we are a small company. If you find this role interesting and you hit on the elements above, please apply!",Algo de responsabilidad,Jornada completa,"Investigación, Análisis, Tecnología de la información","Servicios y tecnologías de la información, Software, Internet",3,None,False,,65,ACTIVELY_HIRING_COMPANY
823,2252763314,2020-10-04,Jefferson Frank,AWS Data Engineer / Remote,"London, GB","Data Engineer / Remote (UK Based)  Up to £65,000  London  AWS Cloud Platform | Remote Interview / Working (2 days in the office every 3 - 4 weeks) | Progression Opportunities | Relaxed Working Environment | Fin-Tech Start-Up  A new fintech start-up is on the lookout for a new data engineer to join their in-house team.  You'll be joining as a key member of the engineering team and working on a new enterprise-grade platform. You'll be working on microservices architecture with analytics, AI and ML capabilities to leading SAAS platforms.  What you'll be working on?   Developing and designing solutions for new data pipelines and features Improvement of existing features Working on data architecture alongside Data Scientists Researching new tech to be at the forefront of modern development!  The techy part…  Have knowledge of   Strong Python Knowledge Working knowledge of AWS services e.g AWS Batch, Lambda, S3 Working with relational SQL and no-SQL databases Experience building and optimizing data pipelines, data sets and architectures Exposure to ETL pipeline building and tools  If you think this is the next exciting opportunity for you - apply today!  THIS ROLE DOES NOT PROVIDE SPONSORSHIP AND YOU MUST HAVE THE RIGHT TO WORK WITHIN THE UK  Jefferson Frank is the Amazon Web Services (AWS) & DevOps recruiter of choice. We work with organisations worldwide to find and deliver the best AWS & DevOps professionals on the planet. Backed by private equity firm TPG Growth, we have a proven track record servicing the AWS permanent and contract recruitment market and, to date, have worked with over 30,000 organisations globally from our offices in North America, Europe, and Asia-Pacific.",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Dotación y selección de personal, Recursos humanos",None,None,False,,12,ACTIVELY_HIRING_COMPANY
824,2245544831,2020-10-27,Acute Change,Data Engineer,United Kingdom,"Data Engineer | Big Data EngineerLondon Data Engineer needed!! Our client, who are in the property sector, are looking for an experienced Data Engineer to join their strong, growing team. They are a large innovative property company in the UK with healthy financials. They are well respected in the property space and they serve thousands of customers every year. They are looking for a talented data professional to join them on their exciting journey ahead… Key ResponsibilitiesExperience designing and building data pipelines.Working with large, complex data sets.Working with key stakeholders in the data team and externally.Secure data both on prem and cloud based.Working with a variety of databases. Skills RequiredBig data tools: Hadoop, Spark, Kafka etc.2+ years’ experience with Cloud based services: AWS - EC2, RDS Data pipeline and workflow management toolsSQL and NoSQL databases experienceExperience with scripting languages: Clojure, Scala, Java, etc.",Intermedio,Jornada completa,Tecnología de la información,Consultoría de estrategia y operaciones,62,None,True,,261,JOB_SEEKER_QUALIFIED
825,2281859167,2020-10-14,Brightloom,Sr. Data Scientist I,"Seattle, WA, US","The Role   Brightloom is creating an entirely new category of software-as-a-service for consumer brands -- the Customer Growth Platform. This first-of-its-kind platform enables automated digital engagement and personalized loyalty programs to transform customer experiences while delivering predictable and repeatable lifetime value growth for brands.  As a Sr. Data Scientist I on our Customer Growth Platform, you'll develop predictive data products, such as product demand forecasts, customer lifetime valuation, personalized product recommendations, and more. Then you'll develop optimization algorithms based on these predictive data products, for brands to use in their marketing and offers so they can efficiently maximize growth. The experimentation solutions you develop should prove the value of our suggestions, as well as help train future predictive models about what products and offers will drive customer engagement.  What You'll Do  Data platform design: work your way up the Data Science Hierarchy of Needs. You'll partner with software engineering and product management counterparts to design our data and machine learning infrastructure, including collection, storage, processing, experiment design, modeling, and finally automated optimization. Data normalization and integrity: we'll be importing highly heterogeneous data from a variety of customers across thousands locations with millions of customers. This will require clever solutions to ensure the data they send us is readily available, easy to use and reliable. Predictive modeling and data products: you'll be the primary contributor on the models that power our forecasting and recommendations, which are at the core of this role and our Customer Growth Platform offering. Experimentation & impact analysis: outbound marketing automation, including paid media, product discounts and loyalty reward offers, often costs consumer brands real money. Through rigorous experiment design, including power analysis, and execution you will prove to our customers that our predictions are accurate and our optimizations deliver impact. When experimentation isn't an option, you'll develop causal inference models to measure impact. Data visualization & reporting: you'll partner with our product management team to define and build proof-of-concept dashboards, analysis and reporting for the data we receive from customers, the predictive data products we produce from it, and the automated optimization and experimentation we run based on those.   About You  MS in a quantitative discipline such as Statistics, Mathematics, Data Science, Business Analytics, Economics, Finance, Engineering, or Computer Science 3+ years of demonstrated success using complex data analysis or machine learning model development to solve business needs Expertise in at least one statistical software package or language such as R, Stata, Matlab, or Python Expertise using big data infrastructure and tools, such as Spark, SageMaker, Athena, Redshift  Bonus Points  PhD in a related quantitative discipline Experience with causal inference, applied time series modeling or machine learning forecasting applications Experience with iterative software development practices such as Agile Strong written and oral communication skills   About Us  At Brightloom (formerly eatsa), we are working to revolutionize restaurants through innovative technology and design. We are disrupting an industry worth $900 billion globally with partnerships in North America, Asia, and soon other continents.  Led by our CEO, industry veteran and former Starbucks and J.Crew executive Adam Brotman, our unique, world-class team combines software and hardware engineers, designers, and industry experts to push the boundaries on re-engineering every aspect of the restaurant experience.  We believe any restaurant brand should be able to engage customers digitally using a seamless combination of mobile, omni-channel ordering and loyalty offerings. Up until now, only a select few brands could afford, or knew how to put together a top-notch digital engagement and ordering platform. With key Starbucks technology components integrated into our platform, Brightloom will now allow any restaurant brand to create their own version of a world-class digital flywheel ecosystem. Brightloom's configurable technology suite combines convenience (digital ordering channels), personal connection (personalized marketing) and engagement (loyalty) for restaurant brands in today's new digital era.  What We Offer  Fun, creative and collaborative remote work environment  Competitive pay and equity/stock options Health, Dental & Vision Insurance Coverage Life Insurance, Short-Term Disability, Long-Term Disability Phone/Internet Reimbursement  Home Office Refresh Reimbursement  Employee Assistance Program Flexible Spending Account & Health Savings Account Flexible Time Off 401(k)  Brightloom is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability and protected veterans status or any other characteristic protected by law.",Algo de responsabilidad,Jornada completa,Otro,"Servicios y tecnologías de la información, Software, Internet",None,None,False,,7,ACTIVELY_HIRING_COMPANY
826,2275176234,2020-10-21,Alpha Signal,Machine Learning Engineer (NLP) + Remote,"Palo Alto, CA, US","Modifying and optimizing our current NLP models * Tune models to the constant inflow of ... Flexible work hours * 401(k) plan Company Description Alpha Signal is an AI-powered service that ...  PLEASE NOTE: This is a job supplied by a trusted partner. In order to read the full job description please click the 'apply now' button. If you are a registered site member you will be passed straight through. If not, then you will be asked to register a free account with us",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Manufactura eléctrica/electrónica, Marketing y publicidad, Internet",33,None,False,,120,JOB_SEEKER_QUALIFIED
827,2291069821,2020-10-14,"SecureShot, LLC",Social Network Analysis/Graph Theory Data Engineer-REMOTE,"Alexandria, VA, US","Our partner is seeking a Social Network Analysis/Graph Theory Data Engineer to provide support to a Department of Defense (DoD) Office of Inspector General (OIG) customer. The Data Engineer will provide data engineering, analysis, and visualization support, including graph-theory based algorithm development and social network analysis. This individual will also assist project teams with identifying, gathering, and understanding relevant data to support analysis, as well as, assess relative quality and reliability of the data. The Data Engineer will examine large data sets using social network analysis and graph-theory based algorithms to identify trends, develop charts, and create visual presentations.  The Engineer will integrate as part of a team focused on developing data efficiencies to facilitate the OIG's ability to discharge its oversight role of identifying waste, fraud and abuse across the DoD enterprise, as well as help lead the architecting of a new framework and solution to efficiently and effectively track large amounts of data relevant to the OIG's oversight function, with particular implications for supply chain security across DoD.  This position is eligible for remote work, with quarterly meetings anticipated at client site in Alexandria, VA.  Responsibilities Maintain proficiency in Datawalk and/or NEO4JAssist with creation, troubleshooting, and deployment of analytical processes that utilize social network analysis and graph-theory algorithms, including Datawalk and/or NEO4JAssist with regular training sessions and maintain open office hours for teams to directly ask for analytics software supportApply various techniques to produce large scale optimization solutions, including data pre-processing, indexing, blocking, field and record comparison and classificationDevelop, refine and oversee data management standards, including establishing and enforcing governance procedures and ensuring data integrity across multiple functionsOwn data quality metrics and meeting defined data accuracy goals according to industry best practiceCollaborate with data science team in the development of predictive models using machine learning, natural language and statistical analysis methods.  Qualifications Active DoD Secret ClearanceBachelor's Degree in Computer Science or Engineering and 6+ years of relevant work experience, or a Master's Degree with 5+ years of relevant experience10+ years of relevant work experienceDirect experience creating sustainable, automated processes for data analysis.Expert at understanding and creating high-level architectural specifications.Advanced technical expertise with programmatically manipulating data.",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Departamento de defensa y del espacio exterior, Software",0,None,False,,None,None
828,2174480488,2020-10-12,Gazelle Global,Data Engineer,"Madrid, Community of Madrid, Spain","Data Engineers (Junior-Senior) are needed for a software development and software consultancy based in Poland. We're currently looking for Data Engineers at all levels to join this international team on a 6 to 12 months contract. These positions are all FULLY REMOTE, therefore you can be based anywhere as long as you are within or close to the CET time zone. The ideal Data Engineers will have the following skills and experience:4+ years of experience in Data EngineeringExperience with Python is a mustAWS and DWH experience is a must Nice to have skills:SQL Server database developmentExperience with ETL processesExta storage formats (like Parquet, ORC, etc.)Data pipelines (Luigi, Airflow, etc.)Data processing (Presto, Spark, etc.)Experience with Redshift, BigQuery, and/or SnowflakeExperience working with structured and unstructured dataExperience moving data from databases of different kinds and from external data sources What my client offers:Attractive hourly rateFlexible working hours and remote workPhone & laptop This is an amazing opportunity to work for a market leader. If interested, APPLY NOW for immediate consideration or contact me for more information at petra@gazellegc.com.",Intermedio,Jornada completa,Tecnología de la información,Servicios y tecnologías de la información,128,None,True,petra@gazellegc.com.,768,ACTIVELY_HIRING_COMPANY
829,2203382135,2020-10-23,Canva,Machine Learning Engineer (Python),"Brisbane, Queensland, Australia","Designing with Canva involves making many choices, out of our incredibly large content pool of over 75M+ templates, photos, videos and elements. The Content Recommendations team is building machine learning-driven recommendations and a personalised content experience, helping to narrow down these choices, and make design easier, smarter, and more magical.  We're looking to grow the team to continue to scale the impact of recommendations across Canva. You'll be joining a fast moving team, rapidly building and shipping machine learning-driven recommendations to users, and making it effortless for users to discover the most relevant content for them. ResponsibilitiesHypothesis-driven development of recommendation features across Canva.Engineering implementation: developing and implementing ML models and features, as well as using third party APIs and pre-trained models when appropriate.Running offline and online recommendations experiments.Investigating and spiking applications of recommendations across the Canva product, considering tradeoffs between different approaches and rapidly shipping.Contributing to the full life cycle of ML/data models: data analysis, data preprocessing and pipeline, modelling, tuning and productization.Improving the scalability, speed and performance of existing models.Working alongside data specialists, software engineers and product owners to identify business and growth opportunities.Designing and creating new data workflows and deploying these workflows to users. Sharing and articulating statistical analysis, modelling, experiment and results to technical and non-technical audiences. RequirementsPrevious experience in the machine learning / data science domain.Experience building and deploying machine learning models, ideally recommendations models. Strong understanding of end-to-end machine learning pipelines and components.Coding proficiency in Python, interviews will be in Python. Experience in Scala is preferred. Strong understanding of Computer Science/Engineering fundamentals and first principles covering system design, data structures, architecture, and design patterns.Familiarity with big data tools: Apache Spark, Hadoop, MapReduce. SQL experience preferred.Strong research skills: the ability to dig through deep learning literature and translate this into product and value for users.Bachelor's degree in Computer Engineering / Science or Mathematics.Excellent collaboration and communication skills. Perks and BenefitsFlexible daily working hours, we value work-life balanceBreakfast and lunch prepared by our wonderful Vibe teamOnsite-Gym and Yoga MembershipEnd-of-Trip Facilities: Bicycle parking and showersGenerous parental (including secondary) leave policyPet-friendly officesSponsored social clubs, team events and celebrationsRelocation budget for interstate or overseas individuals (see below for visa information) Want to experience Canva for yourself?Check out what life is like at Canva on Instagram.Check out what our users are saying about us on Twitter.Learn how we work from Dave, our CTOGet to know our Chef, ChrisMeet our CEO, MelanieFinally, give Canva a go! If you're seeking professional growth and enjoy working on large, distributed, cloud-based applications that delight our millions of individual and business users alike - then apply now to be considered for the position! If you require visa sponsorship, you must ensure you have at least two (2) years of post-University commercial experience as a Software Engineer and meet the mandatory sponsorship requirements laid out by Department of Home Affairs. We will not accept or review any CVs from external recruitment agencies.",Intermedio,Jornada completa,"Tecnología de la información, Investigación","Servicios y tecnologías de la información, Software",84,None,False,,558,COMPANY_RECRUIT
830,2235761037,2020-11-04,who... a staffing company,Sr. Data Engineer (Azure Data Lake and Data Bricks a MUST!),"Baltimore, Maryland, United States","SENIOR DATA ENGINEER: COCKEYSVILLE, MD Who Staffing is looking for a Senior Data Engineer for a fulltime, direct hire opportunity with our client in Cockeysville, Maryland. Our client is looking for a Senior Data Engineer to join their team! This role is a mix of software development and analytics so either of the following backgrounds is acceptable: a software developer with experience in data interpretation and desire to focus on the analytics space or a business analyst with experience in software development, especially focused on process automation.  Job Skills & Experience:  Familiar with the modern cloud data platforms (Azure preferred but AWS is ok). In particular, experience in some of the following is preferred: Azure Data Lake (Analytics and Storage), Data Warehouse / Synapse Analytics / Amazon Redshift, Data Factory, Logic Apps, Data BricksOther preferred technologies include: Advanced T-SQL (SQL Server), REST API concepts, Powershell, SSIS, PowerBIExperience in database design, architecture and warehousingExperience creating ETL/ELT processes to move data between internal and external sources using APIs, ETL.Fundamental understanding of Data Lakes, Data Catalogs, Hardware and Network TopologyExperience with Object-Oriented Programming Languages such as Python, JavaScript, Java, C#, etc.Experience using data reporting and visualization tools (e.g. Cognos, SSRS, Qlik, Data Studio, Power BI, Tableau, etc.) A little more about the responsiblities of the role: Algorithmic concepts from at least one information-centric discipline (e.g. statistics, machine learning, information processing, natural language processing, etc.)Gathering data requirements from stakeholdersEvaluating data collection for accuracyData Governance conceptsMindful of practices, procedures and legal guidelines that govern PII and other sensitive dataAbility to tackle complex problems with creative solutions when the path may not be clear.",Intermedio,Jornada completa,Tecnología de la información,Medios de difusión,22,None,True,,96,ACTIVELY_HIRING_COMPANY
831,2280440865,2020-11-04,SysMind LLC,Natural Language Processing (NLP) Data Engineer | Remote - Secaucus,"Secaucus, NJ, US","Position  Natural Language Processing (NLP) Data Engineer  Duration  12+ Months  Work Experience  Minimum 8 years of experience as an Analytics Developer with and around 4 years of experience with NLPAI implementation experience.  3-5+ years' developing Machine learning based algorithms and models.  3-5+ years' experience with medical terminology (Hospital andor diagnostics industry experience)  3-5+ years' experience AWS cloud architecture  At least 2-3 implementation experience with NLP tools like AWS Comprehend, Linguamatics, cTakes or other NLP Tools is required.  Experience in data lake implementations with EMR a plus.  SYSMIND LLC is an Equal Employment Opportunity employer. All qualified applicants will receive consideration for employment without any discrimination. We promote and support a diverse workforce at all levels in the company. All job offers are contingent upon completion of a satisfactory background check and reference checks. Additionally passing the drug test may also be required. All contractors intending to work on SYSMIND's W2 are 'at will' employees.",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Dotación y selección de personal",None,None,False,,6,ACTIVELY_HIRING_COMPANY
832,2220597162,2020-10-28,Which?,Senior Researcher/Writer (Sustainability)(Fixed Term),"London, England Metropolitan Area","We have an opportunity for two great senior researcher/writers to help us deliver a stepchange in our coverage of sustainability - from use of plastics to sustainable motoring: from recycling to green energy.  We have big ambitions to give consumers the information they need to make sustainable choices, while also putting pressure on businesses and policy makers through our findings. We would love to hear from people who can help us deliver - if you have a deep interest in sustainability, coupled with research skills to dig beneath the surface and writing skills to bring issues to life through compelling content. You will be using in-depth primary research techniques to seek out areas of confusion, or demonstrate where there are more or less sustainable choices to make. You'll be translating this into online and print articles to help people make the right choices, whether buying groceries, upgrading their tech or considering a holiday. If you want to make a difference to consumers' lives through the research you do, the detriment you uncover and the advice you give,you'll be working with a team of 35 like-minded colleagues including investigative researchers, data journalists, consumer researchers and market analysts.These fantastic roles will suit senior researcher/writers with a passion for helping people negotiate the trickiest consumer decisions through great advice. What we offer?We're all about working with our researchers to make them the best they can be – including sharing expertise within a hugely experienced team. We're currently working remotely as an organisation. However, when we're back in the office you'll find it modern, relaxed and friendly (before lockdown we enjoyed fresh fruit, a subsidised canteen, great facilities for cyclists and lunchtime runners, two free healthy meals per week and a roof terrace to enjoy them on). Read our candidate pack to find out more about the amazing benefits on offer! What you'll be doing?You'll be organising original research-based investigations such an assessment of packaging of popular branded groceries, myth-busting ‘green' claims or analysing data from our testing of cars to expose which cars are poorest for emissions. You'll be turning your research into compelling content - for our website and our magazines, and working with teams across the organisation, such as our press team to PR the best stories.Alongside this, you'll be delivering fast turnaround responsive news and advice content, to help build Which? as the go-to place for advice on how to be a sustainable consumer.The quality of your research, analysis and content will play a vital role in upholding our well-deserved reputation for fairness, thoroughness and reliability. What you will ideally have?You need to have a track record in research and great writing skills, with understanding of writing for a consumer audience. Ideally you would have experience of writing about environmental issues, but more important than that is a strong interest and enthusiasm for the topic. These are fixed term positions, with ambitions to deliver a lot over the period of the roles, so you need to be able to confidently get to grips with new challenges and ways of working quickly, and be full of ideas from the start.  We'd like you to have:Experience of managing multiple short and long term projects effectivelyStrong analytical and research skills and good attention to detailProven writing skills with the ability to write for a consumer audienceUnderstanding of environmental consumer issues, with ideas for how to translate this understanding for Which?Ability to work effectively as part of a team, and build strong relationships with a range of colleagues quickly. To apply please attach your up to date CV and covering letter outlining why you feel this role would be great for you and what you can offer. Applications close Wednesday 11th November 2020. At Which? we value diversity and we're committed to creating an inclusive culture where everyone is able to be themselves and to reach their full potential. We want to receive applications from all regardless of age, gender identity, disability, marriage or civil partnership, pregnancy or maternity, religion or belief, race or ethnic origin, sex, sexual orientation, transgender status, social economic background etc. We believe that a diverse workforce helps us to understand and create a positive impact for consumers. We want to ensure that everybody can apply and be part of our recruitment processes, and therefore when required we make reasonable adjustments to accommodate our candidates.",Algo de responsabilidad,Contrato por obra,"Investigación, Redacción y revisión","Publicaciones, Gestión de organizaciones sin ánimo de lucro",64,None,False,,590,ACTIVELY_HIRING_COMPANY
833,2234528041,2020-10-09,PokerStars,Azure Data Engineer (BG remote),"Sofia, BG","The role Azure Data Engineer We are looking for an Azure Data Engineer to join our lively and dynamic Business Intelligence - Data Platform team!  Our tech teams work remotely within Bulgaria, occasionally you’ll need to come to the office in Sofia. Not often, but up to 4-5 times a month and of course, we’ll cover all related expenses. Working as a team is what makes us great and spending quality time together is essential for keeping us mission-aligned. Why we need you  We’re on the lookout for an Azure Data Engineer to contribute to the Stars Group growing data and analytical needs. Be part of the team that looks to build out our next-generation hybrid data platform, using new technologies and techniques to improve the value out of our data assets and empower employees to innovate.  The Azure Data Engineer is responsible for the successful delivery of business intelligence solutions to the entire organization and is experienced in BI development and implementations, data architecture and data warehousing.  You`ll be choosing the right technology and proper data design and implementation in various projects and solutions. You`ll demonstrate hands-on skills in processing large data sets, expertise in data structure, data access patterns, Big Data concepts, cloud computing and optimization techniques. You`ll build robust end-to-end systems with long term maintenance and support of the application in mind. You`ll use reusable code modules to tackle problems across the team and organization. The Framework you`ll build will be of significant complexity and an internal team of data engineers (both full-time associates and/or third-party resources) will be there to help you achieve this. Who we're looking for  3+ years of experience in implementing large scale data projects within the cloud environment (Azure). 3+ years of experience with Cloud databases – Azure Synapse (Azure SQL DW) or similar. 3+ years of experience in developing data ingestion, data processing and analytical pipelines for Big Data, relational databases, NoSQL, data lake solutions in Azure Data Platform. You will need to demonstrate strong programming skills using Python.  Experience with developing Streaming and batch mode processes. As the ideal candidate, you will have  Experience in high volume systems. Experience with streaming technologies such as Kafka. Experience with data migration to cloud based environment. Experience with Databricks/Spark. Microsoft certification will also be considered a strong advantage. What’s in it for you? Our experience-based salaries are competitive. Plus, there’s a discretionary annual performance bonus. And we provide advice and dedicated assistance to those moving to Bulgaria. Your package will include health and dental insurance for you, your partner and your children (if you all live at the same address)a personal interest allowance to let you learn something new or pursue a hobby1000 BGN as congratulations if you have a baby whilst you work for usin-house training and development to develop your skills, progressing your careerfree fresh fruit, snacks and drinks in the officecontribution towards your transportation and lunch expensesrelaxation areas around the office, including a PlayStation and Pool tablesports program and social events: including our sensational summer and Christmas partiesWhat happens next? If you're what we're looking for, we'll invite you for a short Zoom interview. And if that goes well, we'll organize a second, more in-depth technical interview. The Group PokerStars is part of Flutter Entertainment Plc, a global sports betting, gaming and entertainment provider headquartered in Dublin and part of FTSE 100 index of the London Stock Exchange, which brings together exceptional brands, products and businesses and a diverse global presence in a safe, responsible and ultimately sustainable way.  We are an equal opportunity employer that values diversity. We do not discriminate on any protected characteristic as defined by applicable law.  We will look to provide reasonable accommodation for applicants with disabilities to participate in the job application or interview process. If you need assistance, please contact  talent@starsgroup.com .  Please note we cannot accept general applications: this inbox is just for providing support to those who need it.",No corresponde,Jornada completa,Tecnología de la información,"Videojuegos, Apuestas y casinos, Medios de comunicación en línea",None,None,False,talent@starsgroup.com,17,ACTIVELY_HIRING_COMPANY
834,2187588969,2020-10-16,Focus GTS,Machine Learning Engineer,Atlanta Metropolitan Area,"ML Engineers shall provide the following functions and deliverables: Develop custom data models and algorithms to apply to data sets.ML Ops experience. Experience with doc classification and extractionUse predictive modeling to increase and optimize customer experiences Coordinate with different functional teams to implement models and monitor outcomes.Develop processes and tools to monitor and analyze model performance and data accuracy.Work with data sets and build models for document classification and OCR.Present insight into the working of relevant algorithms and models. The key difference between our ML Engineers and Data Scientists is that the former has more experience putting models into production and experience/familiarity with things like AWS Lambda, AWS Step Functions, CI/CD pipelines, using Git for version control, while the latter(Data Scientists) have more focus on model tuning, hyperparameter search, Python notebooks,etc.  Again, both types need to know all the above, but the relative focus and experience is the differentiator.",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información","Servicios financieros, Banca, Consultoría de estrategia y operaciones",194,None,True,,431,ACTIVELY_HIRING_COMPANY
835,2275769457,2020-10-10,Simon Data,Senior Data Engineer,"New York City, NY, US","About Us  Simon Data was founded in 2015 by a team of successful serial entrepreneurs. We are an enterprise customer data platform that empowers marketers to create personalized data-driven experiences for the customers. We're scrappy problem solvers who believe in tackling big challenges with disruptive thinking and giving our customers the support they need to deliver great next-generation experiences at scale.  Simon Data is a data-first customer experience orchestration platform, designed to disrupt the marketing technology and marketing cloud category. Simon's platform empowers businesses to use enterprise-scale data and machine learning to power customer communications across every channel. Our unique approach allows brands to develop one-to-one relationships with their customers without building a bespoke in-house data infrastructure.  At Simon, we firmly believe that business success starts and ends with people. We all do our best work when we are surrounded by other friendly top performers who want to succeed together. This attitude is core to our values. When you trust your team, invest in their development, and give them ownership, great things happen.  The Role  Does your ideal job involve working with petabytes of data or constructing data pipes that operate over widely diverse industries? Are you passionate about how your work has a tangible impact on the bottom line for each of our clients?  As a Senior Data Engineer at Simon, you'll immediately dive into a system of multiple streaming and batch pipelines. You'll use your readiness to seek complete solutions with a passion for building fault-tolerant and highly available systems.  The Simon Data pipes are the backbone of our platform and critical to our clients' success. You will play a pivotal role in our ability to sustainably and rapidly move the data that powers our platform to engage with hundreds of millions of customers -- sending over billions of messages annually.  What You'll Do  Build, scale, and own data pipelines using batch and streaming tools like Python, Spark, Kinesis, Redshift, Snowflake, and Elasticsearch or using new technologies to achieve the desired outcome Architect and develop new data products for clients like new reporting capabilities or data transformation tooling  Construct the platform and tools for our clients to self serve their data engineering needs on the Simon system Contribute to an ecosystem to address evolving requirements of scale! Develop expertise in profiling and debugging AWS services to define performant usage patterns Collaborate daily with a group of your peers, all of whom are passionate about quality, staying ahead of the curve, and continuous improvement Participate in team-wide discussions ranging from architecture to developer efficiency to security  Be a part of establishing our mark in Open Source Software as well as promoting and sharing it at conferences locally and nationwide   Qualifications  At least 4 years of demonstrated ability crafting, deploying and owning several substantive data engineering or analysis projects with company-wide impact Minimum of 2 years proven experience working with various functional owners in your company (spanning product management, program management, as well as Dev/Tech Ops) Proficient in SQL and at least one mainstream programming language (Python, Java, Scala, C#, Ruby, etc.)  Visa sponsorship for this role is currently not available.  Diversity  We're proud to be an equal opportunity employer open to all qualified applicants regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or expression, Veteran status, or any other legally protected status.",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Marketing y publicidad, Software, Internet",0,None,False,,11,ACTIVELY_HIRING_COMPANY
836,2236689968,2020-09-29,SemanticBits,Senior Data Engineer (Scala/Spark) - Remote - VA0001919116,"Herndon, VA, US","Job Title: Senior Data Engineer (Scala/Spark) - RemotePosition SummarySemanticBits is looking for a talented Data Engineer who is eager to apply computer science, software engineering, databases, and distributed/parallel processing frameworks to prepare big data for the use of data analysts and data scientists.iiYou will use Spark to build data processing pipelines that derive information from large sets of government data. You will be a subject matter expert for Spark, the Spark Engine, and the Spark Dataframe API. You will use their knowledge of Spark to teach others, inform design decisions, and debug runtime problems.iTools and TechnologySpark, Hadoop, Scala, Python, and AWS EMRJupyter and ZeppelinAirflow, Jenkins, and AWS Step FunctionsAWS S3, AWS Redshift, and TeradataGSuite, Slack, Jira, Confluence, Git, and GithubiResponsibilitiesBuild scalable data processing pipelines in SparkDebug Spark jobs and do performance tuningWrite unit and integration tests for all data processing codeWork with DevOps engineers on CI, CD, and IaCRead specs and translate them into code and design documentsPerform code reviews and develop processes for improving code qualityiRequired Qualifications:Highly Competent with Scala, Spark, the Spark Engine, and the Spark Dataframe APIExperience with Agile methodology, using test-driven development.Excellent command of written and spoken EnglishCandidate must reside in the United StatesBachelor's degree in Computer Science strongly preferred and a minimum of 5 years of relevant experience or a Masteris degree with a minimum of 3 years experienceFlexible and willing to accept a change in priorities as necessaryPhysical and emotional requirements for the job:This position is to be performed remotely from an individualis home office and involves sedentary work. Employees in this role can be expected to exert up to 10 pounds of force on occasion in order to lift, carry, push, pull or otherwise move standard electronic equipment. Employees are expected to make decisions in a timely manner and display emotional intelligence during occasional stressful situations.iBenefits:Generous salaryThree weeks of PTOExcellent health benefits program (Medical, dental and vision)401k retirement plan. We contribute 3% of base salary irrespective of employee's contribution100% paid short-term and long-term disability100% paid life insuranceFSACasual working environmentFlexible office hoursiSemanticBits, LLC is an equal opportunity, affirmative action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other characteristic protected by law. We are also a veteran-friendly employer.",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Atención sanitaria y hospitalaria",0,None,False,,7,ACTIVELY_HIRING_COMPANY
837,2228993225,2020-10-06,Veeva Systems,Senior Data Scientist (Remote),"Frankfurt am Main, DE","At Veeva, we build enterprise cloud technology that powers the biggest names in the pharmaceutical, biotech, consumer goods, chemical & cosmetics industries. Our customers make vaccines, life-saving medicines, and life-enhancing products that make a difference in everyday lives. Our technology has transformed these industries: enabling them to get critical products and services to market faster. Our core values, Do the Right Thing, Customer Success, Employee Success, and Speed, guide us as we make our customers more efficient and effective in everything they do.  The Role  As a senior data scientist, you will be responsible for designing best in class processes and techniques for statistical analysis and improving our Big Data capabilities.  Also, you should develop creative ideas on how to detect trends and patterns and apply machine learning to implement them.  Implementing and deploying new mechanisms and tools to increase performance and efficiency of our data analytics platform is also part of this job.  What You'll Do Work as part of our big data processing team to bring our platform to the next levelEnhance our data analytics platform to extract relevant business informationDevelop, train and implement machine learning modelsDevelop new analytical scores in collaboration with other teamsDeliver statistical models for determining impact of various entities in the health care industry.Create reports for senior management  Requirements Eligible to work in Germany and willing to re-locate to Frankfurt am Main5+ years of experience as data scientistSkills in scripting languages like Python or RExperience with various DBMS, relational and document basedExperience with business intelligence tools like TableauExperience with machine learning frameworksFluent in English  Nice to Have Previously worked in agile environmentsExperience working with cloud based software and infrastructureExperience working with big data and technologies like Hadoop, Oozie, Hive, etc.Experience with rule based expert systemsExperience with web scrapingJava development skills  Perks & Benefits Veeva supports a healthy lifestyle for employeesHealth / Fitness reimbursementSupplemental contribution of up to 300€ per month for health and life insuranceVeeva covers personal development of free choiceVeeva Tuesday – a weekly team lunchHealthy snacks and fruits, water and the best coffee / espresso in FrankfurtVeeva cares about the community and team spirit Veeva Giving – Charity support of your choiceMonthly social events organized by our teams Extra paid days off for new parentsModern open space office in Frankfurt close to the ECB  Veeva’s headquarters is located in the San Francisco Bay Area with offices in more than 15 countries around the world.",No corresponde,Jornada completa,Otro,"Software, Servicios y tecnologías de la información, Industria farmacéutica",7,None,False,,71,COMPANY_RECRUIT
838,2289125766,2020-11-08,SR2 - Socially Responsible Recruitment,"Data Engineer London / Remote Up to £75,000","London, GB","This diverse and forward-thinking company have a mission to transform the world of banking, and their mission is well underway! With not one, not two, but three opportunities for Data Engineers to join their busy team based in London, this is a truly fantastic opportunity to join a business who genuinely care about their customers, banks, and society, as well as getting to really immerse yourself in transformational end-to-end architecture. You'll work alongside leaders in banking and wider financial services, to help deliver new digital solutions for their growing number of clients.  If you are a self-starter with a creative edge to the way you work, and you enjoy coming up with imaginative solutions to challenges within communication, then you will thrive. If you have a good understanding of machine learning concepts, and you've worked in an agile environment, even better!  In this role, you will have a direct impact on the way their data platform is used by their clients, and you'll be working on improving the capabilities of this, alongside taking a lead in the coaching and mentoring of more junior members of the team. You'll also have the opportunity to show off your design skills by working closely with the Data and Analytics team lead, to solve complex issues around Data Engineering together.  Essential Skills   Excellent programming experience in Java  Recent experience with Kafka or similar technologies  Experience with big data technologies  Proficient and recent experience in being responsible for code running in production  Comfortable and competent with AWS or other cloud platforms   This role will be mainly remote, with the opportunity to work from their London office 1-2 times a week, in line with Covid restrictions.  If this sounds up your street then please don't hesitate to get in touch with Gina from SR2!",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Dotación y selección de personal",6,None,False,,46,ACTIVELY_HIRING_COMPANY
839,2210712215,2020-10-24,"Okta, Inc.",Data Scientist Architect (San Francisco) (Remote Eligible),"San Francisco, CA, US","This is an opportunity to join our fast-growing Security Intelligence Platform team to help develop cutting-edge machine learning models to better protect our users from malicious actors and attacks. We are looking for a hands-on engineering leader with deep data science and software engineering expertise who can help architect and own the platform for deploying and tuning the machine learning models used to protect user authentication and security. They will also own the pipeline which needs to process hundreds of millions of events per day and provide results back to the authentication system to make real-time risk evaluation during user authentication. This project has a directive from engineering leadership to make OKTA a leader in the use of data and machine learning to improve end-user security.  We hope you will share our passion and great pride in the work we do and will join an engineering team that strongly believes in automated testing and an iterative process to build high-quality next-generation cloud platforms.  Our elite team is fast, innovative, and flexible. We expect great things from our engineers and reward them with stimulating new projects and emerging technologies.  Job Duties And Responsibilities  Overall ownership of the architecture, platform, and pipeline for developing, deploying, and running new machine learning models in production. Work with Data Scientists to analyze security event data, develop ML models and evaluate model performance. Work with Data Scientists to help improve their productivity and implement their ideas. Design and maintain data processing pipelines to support new decision and scoring models. Analyze performance metrics and logs to identify inefficiencies and opportunities to improve scalability and performance.   Minimum Required Knowledge, Skills, And Abilities  C-level communication skills, 10+ combined years of Data Science and Data Engineering experience 5+ years of experience in production SaaS deployment C-level communication skills Expert-level understanding of relational databases (columnar and row-based), and NoSQL including mongo, Cassandra or similar 5+ years experience with streaming systems: MQ, Kafka, Storm, Spark, etc. 5+ year experience with the AWS data toolchain: EMR, Kinesis, Redshift, Glue Working knowledge of AWS Sagemaker, Lambda, and API Gateway including production deployment 5+ years Python development 5+ years of Java or OOP language development  Okta is an equal opportunity employer  Okta is rethinking the traditional work environment, providing our employees with the flexibility to be their most creative and successful versions of themselves, no matter where they are located. We enable a flexible approach to work, meaning for roles where it makes sense, you can work from the office, or from home, regardless of where you live. Okta invests in the best technologies and provides flexible benefits and collaborative work environments/experiences, empowering employees to work productively in a setting that best and uniquely suits their needs.",No corresponde,Jornada completa,"Ingeniería, Tecnología de la información","Seguridad del ordenador y de las redes, Software, Servicios y tecnologías de la información",6,None,False,,197,ACTIVELY_HIRING_COMPANY
840,2279401275,2020-11-05,"Techaxis, Inc",Senior Big Data Engineer,New York City Metropolitan Area,"The opportunityYou will help our clients navigate the complex world of modern data analytics. We’ll look to you to provide our clients with a unique business perspective on how Big Data analytics can transform and improve their entire organization – starting with key business issues they face. This is a high growth, high visibility area with plenty of opportunities to enhance your skill set and build your career. Your key responsibilitiesYou’ll spend most of your time working with a wide variety of clients to deliver the latest big data technologies and practices to design, build and maintain scalable and robust solutions that unify, enrich and analyze data from multiple sources.   Skills and attributes for successDesigning, Architecting, and Developing solutions leveraging cloud big data technology to ingest, process, and analyze large, disparate data sets to exceed business requirementsUnifying, enriching, and analyzing customer data to derive insights and opportunitiesLeveraging in-house data platforms as needed and recommending and building new data platforms/solutions as required to exceed business requirementsClearly communicating findings, recommendations, and opportunities to improve data systems and solutionsDemonstrating a deep understanding of big data technology, concepts, tools, features, functions, and benefits of different approachesSeeking out information to learn about emerging methodologies and technologiesClarifying problems by driving to understand the true issueLooking for opportunities for improving methods and outcomesApplying a data-driven approach (KPIs) in tying technology solutions to specific business outcomesCollaborating, influencing, and building consensus through constructive relationships and effective listeningSolving problems by incorporating data into decision making           To qualify for the role you must have A bachelor's degree and approximately three years of related work experience: or a master's degree and approximately two years of related work experienceAt least three years of hands-on experience with various Cloud and Big Data technologies At least two years of experience in implementing, automating, and integrating Big Data infrastructure resources like S3, Redshift, Aurora, Kinesis, Kafka, EMR, Lambda, SNS, Azure Blob Storage Account, SQL Data Warehouse, Microsoft Event Hubs, HDInsights, Azure Databricks, Azure Functions, Event Grid, Data Lake Analytics in an ephemeral/transient and in an elastic mannerIaC & Config Management: Tools like Chef, puppet, CloudFormation ,terraform, ansible, boto3 and/or Azure/GCP equivalentHands-on experience of core Operating systems like Linux RHEL, Ubuntu, System administration tasks including shell scripting Network Engineering/Admin (vpc, subnet, security groups, VPC-Endpoints, nat/route tables, etc)Experience with container technology like Docker, Kubernetes, etc.Security tools/concepts like At Rest and in transit Encryption, IAM, key and certificate management, etc.CI/CD pipeline management like git/bitbucket, and code deployment tools like Jenkins, sonar cubeCommunication is essential, must be able to listen and understand the question and develop and deliver clear insights.Outstanding team player.Independent and able to manage and prioritize workload.Ability to quickly and positively adapt to change.A valid driver’s license in the US: willingness and ability to travel to meet client needs. Ideally, you’ll also haveBachelor’s Degree or above in mathematics, information systems, statistics, computer science, or related disciplines",Intermedio,Jornada completa,Ingeniería,"Consultoría de estrategia y operaciones, Servicios y tecnologías de la información",9,None,True,,44,ACTIVELY_HIRING_COMPANY
841,2256779980,2020-10-30,EPAM Systems,Remote Lead Data Scientist,"Kremenchuk, UA","Striving for excellence is in our DNA. Since 1993, we have been helping the world’s leading companies imagine, design, engineer, and deliver software and digital experiences that change the world. We are more than just specialists, we are experts.  A remote Lead Data Scientist is needed. This job is about turning (big) data into actionable knowledge, which requires a blend of scientific, problem solving, analytical, technical, and communication skills. In this role, you will be the leading subject matter expert driving the business enablement both on the client side defining the architectural choices during all stages of exciting presales opportunities for world leading companies and on delivery side implementing them, as well as providing thought leadership within the fast-growing BI and Big Data Solution Practice and Competency Center.  This position is a part of our new EPAM Anywhere program for remote workers. EPAM Anywhere offers a variety of IT jobs for remote workers. Join us to work on ambitious and long-term projects, get a stable workload, and enjoy a work-life balance!  Responsibilities Lead strategic planning, development and implementation of medium-to-large data science solutions or a component of a larger solution, including predictive modeling, unsupervised and supervised learning, and machine learning techniquesLead on all stages of presales activities for such projects, owning the whole presale process from the Competency Center perspective when required. Manage the delivery of architectural POCs, where requiredInteract with clients, advise and drive the translation of business requirements and models into appropriate architectural designs to ensure that business needs are metWork directly and collaboratively with clients, external data providers, and other key stakeholders to ensure that the solution’s concept/vision is understood and agreed uponActively participate in project review and planning sessions. As needed, lead the solution development, drive and supervise end-to-end development cycle (SDLC) or participate in the projects start-upBe accountable for applications-related quality, performance, availability, scalability, security, and integrity, ensuring application usability, for instance, through a high-quality functional interface to applications. Identify and mitigate risks associated with specific solution in known contextsBe accountable for ensuring architectural consistency of recommended technology and its integration with the client’s applications and infrastructure. Identify and mitigate risks associated the implemented solution in all relevant contexts of the project and wider programManage the architectural knowledge transfer from the project development team to the post-go-live support team. Oversea or effect the creation of architectural case study for EPAM’s repository of reusable assetsDrive strategic visioning activities for the practice and competency center. Develop reusable assets, development methods, processes, best practices to accelerate delivery. Coordinate SA pool on those activitiesDrive the program of evaluating the hardware and software platforms, benchmarking of alternative solution architectures, supervise a defined process for provision of structured, reusable results. Coordinate the direction of R&D activities by SA poolKeep pace with the innovative technologies and consider possibilities of creating relevant solution offerings. Coordinate architects in developmental direction choiceConsult and supervise all team members, share knowledge. Participate in the assessment of the candidates for SA position. Mentor other solution architects in practical SA activities. Provide technical guidance and career-planning assistanceWrite broad topic and strategic white papers in the course of industry and technology research. Maintain high competency visibility by regular posting in internal newsletters, blogs as well as speaking at internal and external conferences and other events: create blueprints on customer request. Create technology roadAnalyze large data sets to discover trends, identify performance metrics, and uncover optimization opportunitiesApply machine learning algorithms and statistical methods to large sets of raw dataContinuously improve algorithms and develop best practice for instrumentationWork to acquire enterprise architecture theoretical knowledgeShould be able to  Requirements RDBMS/SQL knowledgeProgramming experience (Python preferred)Data analysis tools and libraries such as Python (NumPy / SciPy / scikit-learn / pandas / matplotlib), R, SAS, SPSS, MATLAB, etc.Big Data stack: Spark / MLlibProficiency with at least one of the Cloud providersExperience with Data Science solutions productionalizationData visualization skillsNLP/text miningBachelor’s/Master’s Degree in Computer Science, Math, Applied Statistics or a related fieldA few years of experience in data mining, statistics or machine learningIn-depth domain understanding and ability to acquire new domain knowledgeAptitude for problem solvingData focused applied mathematics (statistical analysis, machine learning)Decent communication / presentation skills (including working English fluency) Nice to have Platforms: Linux, WindowsProgramming Languages: Python, R, SQLPython libraries: scikit-learn, pandas, NumPy, SciPy, matplotlib, seabornDeep Learning: Keras, TensorFlow, PyTorchBig Data: Spark, Hadoop, HiveCloud: AWS/Azure/GCP - Storage: Compute: Networking: Identity and Security: Notebooks: Data CatalogsCI/CD principles and tools (e.g. Jenkins)Version Control Systems (e.g. Git, SVN) We offer Competitive compensation depending on experience and skillsWork in enterprise-level projects long-termFull-time remote work (you can work from anywhere you are)Unlimited access to learning courses (LinkedIn learning, EPAM training courses, English regular classes, Internal Library)Community of 30,100+ industry’s top professionals  This is a remote position and we welcome applications from anywhere in Ukraine.",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información","Software, Servicios y tecnologías de la información",None,None,False,,14,ACTIVELY_HIRING_COMPANY
842,2246787436,2020-10-02,Nigel Frank International,GCP Data Engineer - Remote - UK Based,"London, GB","Data Engineer - London Based - Remote  up to £65,000  My client based in London would like to speak to Data Engineers in London and surrounding areas that are looking to join a fast-growing team that is always at the forefront of working with the new technologies. You will be surrounded and supported by a great team that always has a can-do attitude.  They are looking for people who help create cutting-edge, durable, and loved data solutions. While also having fun at the same time. This is a great environment to be around.  Skills & Qualifications Google Cloud PlatformStrong Programming & Architectural experience,Building Big Data solutionsPassionate about Data and AnalyticsExperience with ETL toolsHadoop-based technologies   Benefits 25 days holiday plus bank holidaysGreat pension schemeHardwareSocial events and team offsitesNetworking events, Mentoring events & conferencesExposure to expertsExplore the latest tools/technologies  This would be a great time to join this team as they are looking to expand even further and increase their client portfolio.  Do you not have all the skills mentioned above? I'd still like to hear from you.  If you are looking for an excellent salary, flexible working with minimal travel, private medical care, ongoing training, and career progression then this is the job for you.  Office Line: 0191 338 7667 Email: d.manzini@nigelfrank.com  LinkedIn: 'Dee Manzini'  Rest assured, anything discussed will remain completely confidential and fully compliant with GDPR.",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Dotación y selección de personal",0,None,False,d.manzini@nigelfrank.com,9,ACTIVELY_HIRING_COMPANY
843,2211862182,2020-10-16,Big Cloud,Data Engineer,"Chicago, Illinois, United States","Are you an experienced data engineer? Are you available for an initial 6-month contract? One of the worlds biggest healthcare companies is seeking to recruit a Data Engineer for an initial 6-month contract. As a Data Engineer, you’ll be designing developing and maintaining scalable data models and pipelines, collaborating across all analytics teams to develop efficient end products and building data architecture. Other responsibilities: Implements processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processesWrites unit/integration tests, contributes to engineering wiki, and documents work.Works closely with other data scientists and engineers to develop a strategy for long term data platform architectureSupporting issue analysis and fix activities during test phases, as well as production issue resolution.Contribute to project planning and implementation to ensure that solutions are delivered on time and on requirementsCollaborate and actively contribute in discussions to help define technology and development approach within the team You’ll need: 2+ years data engineering experienceMinimum bachelors degreeStrong experience in PythonCloud experience – ideally Azure or Google CloudProficiency in data modelling, database technologies (both SQL and NoSQL)Data Architecture and data pipeline design experience",Intermedio,Contrato por obra,"Tecnología de la información, Ingeniería","Atención sanitaria y hospitalaria, Seguros",119,None,True,,313,ACTIVELY_HIRING_COMPANY
844,2243136220,2020-10-21,Syfter,"Big Data Engineer opportunity with Financial Services client! Virtual Interview, Immediate Remote Start!","Alpharetta, GA, US","Our Financial Services client is seeking a qualified Big Data Engineer with the followingDetailed knowledge of data warehouse technical architectures, infrastructure components, ETL ELT and reportinganalytic tools.Experience with very large data warehousing environment, data modeling concepts, and Python development experienceExperience in Big Data stack environments (EMR, Hadoop, Glue, Hive)Experience with Kafka, Flume and AWS tool stack such as Redshift and Kinesis are preferredExperience using software version control tools (Git, Jenkins, Apache Subversion)Demonstrated strength in architecting data warehouse solutions and integrating technical componentsGood analytical skills with excellent knowledge of SQL.Excellent communication skills, both written and verbal Syfter is a staffing firm headquartered in Manhattan, NY, that provides creative solutions for clients and talent nationally. Our team of experts works tirelessly to create great connections industry-wide, and after decades in the industry, we deliver best-of-breed methodology for the best hiring experience.",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Software, Servicios financieros",None,None,False,,15,JOB_SEEKER_QUALIFIED
845,2284657393,2020-11-07,Sub-K IMPACT Solutions Ltd,Data Engineer,"Hyderabad, Telangana, India","Founded in 2010, Sub-K IMPACT Solutions Limited started with a vision to provide financial access to the underserved by leveraging technology and local entrepreneurship. Sub-K serves as a bridge between financial service providers and customers at the last mile: they help banks build their customer base on the provision of savings, payments, and credits, and help customers better access these financial service offerings. The company has partnered with over 10 private and public banks, is operational in 27 states, and serves a customer base of over 5 million with a bouquet of financial services through a network of 8,000+ customer service points and a 2,000-strong employee base. As of July 2020, Sub-K has mobilized ₹20 billion in savings and facilitated around ₹35 billion in loans on behalf of various banks.Sub-K recognizes that the future lies in digital transformation, and they have been working towards digitizing every aspect of their services. Starting from creating a paperless onboarding mechanism, they have enabled 100% cashless disbursements and piloted cashless collections. Title:  Data Engineer ResponsibilitiesDesign, build and operationalize large scale enterprise data solutions and applications using one or more of AWS data and analytics services in combination with 3rd parties - Spark, EMR, DynamoDB, RedShift, Kinesis, Lambda, Glue, Snowflake.Analyze, re-architect and re-platform on-premise data warehouses to data platforms on AWS cloud using AWS or 3rd party services.Design and build production data pipelines from ingestion to consumption within a big data architecture, using Java, Python, Scala.Design and implement data engineering, ingestion and curation functions on AWS cloud using AWS native or custom programming.Perform detail assessments of current state data platforms and create an appropriate transition path to AWS cloud. Job briefThe AWS Data Engineer would need to have at least 3+ years of experience. The AWS data engineer possesses 3+ years of experience developing and architecting with AWS solutions and is responsible for the development of AWS solutions utilizing network, storage, operating systems, virtualization, RDBMS and NoSQL databases, Hadoop, mid-tier technologies that include application integration, in-memory caches, and security.You must be well experienced in the AWS platform and a motivated technologist with a proven track record of delivering results in software/technology consulting. Recommended Top SkillsAt least 2-4 years of experience in “on premise to Cloud” migrations or IT transformationsPreferably, experience in Oracle and Snowflake DatabaseWell versed and hands on expertise in implementing AWS stack such asArchitectureRedShift modeling and performance tuning techniqueswith Snowflake Data WarehouseExperience in migrating On-Prem relational databases to AWS Aurora, Redshift, Dynamo DB (or similar) in implementing AWS Lambda Architecture, Elastic search.-AWS and Data Platform experience with the following: Kinesis, Redshift, Glue, S3-ETL Tools – Informatica, Talend, etc.Replication – Attunity Replicate, Golden Gate, etc., RequirementsProven experience of at least 3 years as a Data Engineer or similar role(preferably, in financial institution)Bachelors Degree in Computer Science, Information Technology or other relevant field Location : HyderabadUSP of role: Opportunity to work ongroundbreaking ideas which impact millions of householdsRemuneration : Market rateStart Date:  Immediate Interested?Send in your credentials at earliest to radhadevi.a@subk.co.in and CC to aakash.sharma@subk.co.in",Sin experiencia,Jornada completa,Tecnología de la información,Servicios financieros,53,None,True,"radhadevi.a@subk.co.in, aakash.sharma@subk.co.in",257,ACTIVELY_HIRING_COMPANY
846,2249336447,2020-11-05,Oliver Bernard,Data Engineer - £70K - £90K,"London, England, United Kingdom","Data Engineer - £70K - £90K   Spark - SQL - Python - Scala  Our client is a leading challenger bank and FinTech.   Based in the City of London (remote working at present though) they’re hiring for a brand-new team to design and develop a new data platform for the bank.   This is key to their strategic vision and you’ll have a lot of visibility and ownership.   You’ll work with Spark, SQL, multiple Cloud platforms and a variety of languages – Scala, Python and even R. You’ll focus on real engineering, not just one language or tool.  This is a unique opportunity for a strong Data Engineer to join a world-leading bank and technology company and create innovative, greenfield solutions – not to be missed!   Requirements:  - Excellent experience in a similar Data Engineering position  - Very good knowledge of Spark - Good SQL experience  - Great coding skills with Python, Scala and / or Java - Good Cloud experience (Azure, AWS and / or GCP) - Knowledge of messaging systems and event architecture would be ideal  - A focus on automation, CI/CD and testing in your work",Intermedio,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Servicios financieros, Banca",50,None,True,,192,ACTIVELY_HIRING_COMPANY
847,2283392051,2020-11-06,Net2Source Inc.,Snowflake Data Engineer,"Glendale, California, United States","Net2Source is a Global Workforce Solutions Company headquartered at NJ, USA with its branch offices in Asia Pacific Region.We are one of the fastest growing IT Consulting company across the USA and we are hiring ' Cloud Migration Architect (Azure) ' for one of our clients. We offer a wide gamut of consulting solutions customized to our 450+ clients ranging from Fortune 500/1000 to Start-ups across various verticals like Technology, Financial Services, Healthcare, Life Sciences, Oil & Gas, Energy, Retail, Telecom, Utilities, Technology, Manufacturing, the Internet, and Engineering.  Company            : One of Our ClientsPosition              : Snowflake Data EngineerLocation              : Glendale, California Duration             : Fulltime Job Description:Snowflake Certified- good to have (Screen the candidate properly before sending. Purpose:The Senior Data Engineer will design, build, and deliver highly visible and innovative reporting solutions. This role will model and ELT (Extract/Load/Transform) data into a cloud repository (Snowflake) for report consumption. This position works with domain experts to architect, design and build data models and semantic layers based on business rules. Essential Activities:Migrate data and tools (modernize) from on premise to Cloud technologiesDesign and create data models/semantic layersDesign, develop, automate, monitor and maintain ELT/ETL applications using preferred tools and techniquesPerformance tune ELT/ETL to manage high volume batch data transfer to and from internal and external system locationsRecommend solutions and lead team through the processInteract with cross-functional teams, project managers and agile teams to estimate development efforts and ensure complete delivery of solutions and accurate requirement fulfillmentInfluence the business and leadership on processes and procedures that will drive value within the business and across the technical landscapeCommunicate effectively and efficiently both written and verbally Requirements:Bachelor's Degree (BA/BS/BFA) or Equivalent7-10 years related work experienceExperience with AWS technologies with, preferably, Snowflake, Teradata, Sql Server, DB2 as the backendExtensive experience with delivery using ETL/ELT tools and techniques (i.e., Informatica, DataStage, SSIS, Talen, Airflow, Fivetran etc)Expert understanding of data warehouse and master data management approaches, ELT industry standards and best practicesExperience building Data Vault and/or Star Schema modelsExperience with BI reporting tools a plus such as Tableau, Cognos, MicroStrategy or LookerPossess strong communication skills and the ability to work with technical teams and business teams About Net2Source, Inc.Net2Source is a total talent management solutions company with its presence in 50+ countries.Our creative solution service offerings aim at becoming your one stop destination for hiring talent needs globally.Want to read more about Net2Source? Visit us at www.net2source.com Equal Employment Opportunity CommissionThe United States Government does not discriminate in employment on the basis of race, color, religion, sex (including pregnancy and gender identity), national origin, political affiliation, sexual orientation, marital status, disability, genetic information, age, membership in an employee organization, retaliation, parental status, military service, or other non-merit factor. Net2Source Inc. is one of the fastest growing Global Workforce Solutions company with a growth of 100% YoY for last consecutive 3 years with over 4100+ employees globally and 30+ locations in US and operations in 50+ countries. With an experience of over a decade we offer unmatched workforce solutions to our clients by developing an in-depth understanding of their business needs. We specialize in Contingent hiring, Direct Hires, Statement of Work, Payroll Management, IC Compliance, VMS, RPO and Managed IT Services. Fast Facts about Net2Source:·        Founded in 2007·        100% Minority Owned, Debt Free, Private·        4100+ consultants globally·        2550 consultants placed in the US·        750+ team of in-house staffing team·        30+ sales offices in the US, and 50+ Offices globally·        Operations in 20 countries (US, Canada, Mexico, APAC, UK, UAE, Europe, , Europe, Latin America, Japan, Australia) Awards and Accolades:1.   2020 Fast 100 Asian American Businesses by the US Pan Asian American Chamber of Commerce Education Foundation (USPAACC 2019)2.   2019 & 2018 Ranked 21stFastest Growing Staffing Company in USA by Staffing industry Analysts3.   2019 & 2018 Fastest 50 by NJ Biz (Ranked (9th and 27th ).4.   2019 Top 100 Fastest companies to grow in Dallas by Dallas Business Journal.5.   INC 5000 Fastest growing for 8 consecutive years in a row.6.   America's Most Honored Businesses (Top 10%)7.   2019 Dallas Top 100 by Dallas Business Journal8.   2019 Proven Supplier of the Year by Workforce Logiq9.   2019 Spirit of Alliance Award by Agile110. 2018 Best of the Best Platinum Award by Agile111. 12018 TechServe Alliance Excellence Awards Winner12. 2017 Best of the Best Gold Award by Agile1(Act1 Group) Regards,Zuber Khan Sr. Technical RecruiterNet2Source Inc.Global HQ Address – 7250 Dallas Pkwy, Suite 825 Plano, Texas 75024Cell:: (201) 676-3195 | Fax: (201) 221-8131| Email: zuberk@net2source.comWeb: www.net2source.com | Social: Facebook | Twitter | LinkedIn",Intermedio,Jornada completa,"Recursos humanos, Desarrollo empresarial, Otro",Dotación y selección de personal,7,None,True,zuberk@net2source.comWeb,38,ACTIVELY_HIRING_COMPANY
848,2288483785,2020-11-03,"Fetch Rewards, Inc.",Data Scientist - Clients - Remote,"Remote, OR, US","Who We Are  We reward shoppers for digitizing their shopping experience. Our mission is to delight the world’s shoppers with a free smartphone app that is easy, smart and fun.   Why Join the Fetch Family?  We make it better for users even when that's difficult for us We empower people with information and trust We challenge ideas, not people We think bigger and keep building We find ways to bring the fun to Fetch! We're committed to building an empowered and inclusive community of innovative and passionate people. As a growing organization, we need team players who can go above and beyond their individual responsibilities to help our company build towards its vision. If you are a creative, hard-working, and fun-seeking person interested in working with a close-knit group of highly talented people, this is the right place for you.  Fetch Rewards is an equal employment opportunity employer.   The Role!  The Data Science & Analytics team embodies these values and works with a laser focused objective to enable data driven decision making for both internal stakeholders and external partners. We are looking for a  Data Scientist - Clients to contribute to this vision and reap the rewards of joining an exciting company in the high growth phase.  You will create analytical solutions and machine learning models that help Fetch teams leverage and monetize actionable insights from our unique data. This is a challenging and high visibility position, responsible for creating these solutions as well as guiding technical direction. Success in this role requires the ability to take on challenging problems and design & develop an amazing solution with little to no assistance.  You Possess  Hands-on experience in developing / deploying machine learning models that are tied to business value. At bare minimum, a good grasp of machine learning techniques, and their application in the real world.  Ability to create SQL/Python programming modules for custom insights required by our clients. Leverage statistical analysis to understand what is “acceptable” versus “outliers”.  Ability to successfully collaborate with both business users and engineers for effective analytical solution development and deployment  Passion to drive actionable insights from data and present them to external and internal clients through Tableau / Powerpoint / Excel in a compelling manner.  Knack for conducting the apt Data Exploration needed to enhance the cleanliness and effectiveness of our data sources.  Discipline to create well documented coding and analytics packets to ensure reusability as the team expands.  Master’s or PhD in Statistics, Mathematics, Computer Science or any other Quantitative field  2+ years of experience in data science workstream Bonus Points For  Experience in  CPG/Retail domain and/or analytics at app-based B2C companies  Familiarity with Big Data frameworks like Snowflake, Spark and AWS services  Familiarity with Tableau or any other visualization tools  Effective communication, ability to translate and explain technical issues to non-technical team members  Love of Dogs! . . . Or just tolerance. We're a very canine-friendly workplace",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Software, Internet",2,None,False,,19,ACTIVELY_HIRING_COMPANY
849,2276644494,2020-10-11,SlashData,Data Storyteller (Remote - EMEA based),"Stirling, GB","SlashData is the leading research company in the developer economy: We help the world understand developers and developers understand the world. We survey 40,000+ developers annually - across mobile, IoT, desktop, cloud, AR/VR, web, games, data science, and machine learning - to help clients such as Microsoft, Facebook, Google and Amazon understand who developers are, what tools they love or hate and where they are going next.  We’re now looking for a full-time, Data Storyteller to help drive insights out of a wealth of data points relating to developer activity. You’ll be working based in Europe or MEA, working from home or a co-working space to support our distributed team.  Who We’re Looking For  As a Data Storyteller, you will have 2-5 years working experience in data analysis, data visualisation, and data journalism. You will be fearless in data crunching and keen to unearth meaningful patterns, actionable insights and intriguing stories from the data.  You will have undertaken many data analysis projects where your novel insights and attention to detail would impress. You will have a proven record of communicating your findings to a non-technical audience, eloquently narrating the story behind the numbers. You might not have worked in the software industry before, but you have a passion for software, and wanting to figure out what makes the software economy tick - based on data.  If you’re that person, we’d love to talk.  Requirements  As a Data Storyteller you will be:  Based in EMEA region (UK time ±4hrs) Performing data analysis using any scripting language (e.g. Python, R), and Excel. You‘ll be working on several data projects, extracting insights in the context of market trends, behavioural analysis, population forecasting, segmentation and profiling. Writing up your findings in short and long reports including visually appealing graphs and deep insights based on your analysis, answering the “why” behind the “what”. Tracking the latest trends in the software developer ecosystem. Helping shape our research agenda and asking developers and data scientists the right questions. Interacting with clients to provide insightful answers to tough data problems, and to support them in custom data insights projects. Helping clients identify key business questions and translate them into research questions and projects. Delivering briefings and webinars, and presenting our insights in conferences, meetups and events. Supporting the rest of the analyst team in their data and research quests as needed.   What Skills We Are Looking For  A data scientist who is also into data journalism, with a background in statistics, applied mathematics or computer science. An ability to tell signal from noise in the data, and answer the ‘so what?’ question behind the observed numbers and patterns. An ability to author data stories, comprehensively and in an unbiased way, with proven previous experience in authoring insights reports, blog posts or other published writing. Excellent writing skills (English), with the ability to communicate complex insights to non-technical audiences. Advanced Excel skills. At least basic programming skills, preferably in Python including Pandas. At least a basic grasp of clustering and classification methodologies and models. Ability to visualise data effectively, producing eye-catching and easy-to-understand graphs. Very good presentation skills. Comfortable working as part of a distributed team across four continents.  Bonus Points for  Having software development experience as a hobby or past work. Advanced Python skills. Advanced data modelling skills. Past experience of working with complex survey data. Past experience of consulting clients on data projects. A passion for technology, and thorough understanding of how it’s impacting people’s lives.  Key success metrics  You will be successful in the role if in the first 6 months you have:  Actively contributed in shaping the research agenda and questionnaire of the upcoming Developer Economics survey. Authored at least two research reports, carrying out all data analysis and background research as needed. Authored at least one blog post based on our survey data, showcasing our research and/or promoting our surveys. Delivered at least one client briefing or webinar to our high standards. Actively supported the rest of the analysts team, by reviewing other authors’ reports. Supported our developer outreach and sales teams, promptly responding to any requests relevant to your work. Become a dependable team mate.   Benefits  What we offer  Opportunity to make a difference as part of the leading research company in the developer economy Part of an entrepreneurial company that's raising the bar, and calling the trends of the developer economy Opportunity to work with some of the biggest tech brands in the world International team, great work atmosphere & flexible working environment Competitive salary + bonus twice yearly based on performance Come to work in a t-shirt, shorts and flip flops, or tie and a suit - we don't mind! You will never work on your birthday - we automatically give you this day off Annual training budget to develop your skills and career Monthly book allowance from Amazon, on any book you like Spotify Premium subscription or Netflix vouchers",Sin experiencia,Jornada completa,"Marketing, Relaciones públicas, Redacción y revisión","Servicios y tecnologías de la información, Investigación de mercado, Software",6,None,False,,79,None
850,2243917308,2020-11-06,"Coalition, Inc.",Data Engineer - Data Clusters,San Francisco Bay Area,"About Us Coalition’s Insurance and Cybersecurity offerings come together to provide a comprehensive shield from cyber risk. We believe the task of locking down every system and keeping up with every vulnerability is challenging and while being proactive is important, it’s not enough because breaches and other compromises happen, even to the vigilant. While we proactively help our customers understand active risks and shut them down, when all else fails, we are there for them financially and with services to help mitigate damage and come back stronger after an incident. Help us protect the world against cyber risk and give business owners a trusted support system and fighting chance. We have over 25,000 customers, ranging from small and mid-sized businesses to Fortune 500 companies. Founded in 2017, Coalition has raised $125M from a number of top tier global investment firms including Ribbit Capital, Greenoaks Capital, Valor Equity Partners, Felicis Ventures, and Vy Capital. Headquartered in San Francisco, Coalition’s team is distributed across more than 15 locations globally, including Austin, Washington DC, Denver, Canada and Portugal. Coalition Engineering Our culture is one of character, humility, responsibility, purpose, and authenticity. We are growing rapidly and that growth is enabled by strong teamwork, communication, and mentorship. We want people who are passionate about becoming experts in both the business and the technologies that support it. Our core platform is written mostly in Python with some services in Java and Go. We prefer to use the right tool for the job and make pragmatic decisions about how to scale and de-couple systems as we continue to grow. We’re looking for someone who can navigate a cloud environment (AWS) with many moving pieces and systems to help the team understand how they fit into the broader puzzle. Responsibilities Triage and prioritize application security vulnerabilities.Develop internal application security testing pipeline and review processes.Build and conduct secure coding training for all developers.Mentor and train engineers to build secure productsImplement automated, proactive security measures (e.g., SAST/DAST).Develop Secure SDLC process and communicate process to Engineering.Building Application security metrics Your Background At least 3-5 years of direct experience either working on or leading an application security team.Experience conducting application security reviews.Experience with building/measuring metrics and KPIs to track application security issuesExperience with source code repositories, CI/CD pipelines, and associated security tooling (e.g., GitHub, Drone, Buddy).Experience developing SDLC processes.Experience working with SAST/DAST and tools (e.g., Synopsys, Veracode, GitLab Secure, GitHub Advanced Security, etc.).Experience with threat modeling methodologies (e.g., STRIDE).Experience with Java, Go and Python secure coding assessments.Experience in API design and system architecture Bonus Points Experience in bug bounty managementTeaching experience Why Coalition? We are all here to build something we believe in and to make a company that will last. We’re also assembling a team of expert incident responders, threat and malware researchers, and security analysts to protect our customers before, during, and after a cyber incident. Our goal is to harness the power of technology with the safety of insurance, to provide the first holistic solution to cyber risk. Coalition's culture is one that strongly values humility, authenticity, and diversity. We want to work with people of different backgrounds and different paths in life, and we trust our team members to take responsibility, share ownership and work for one another. We are always looking for collaborative, inquisitive and dedicated individuals to join our team. Recent press releases: https://news.crunchbase.com/news/coalition-secures-90m-series-c-at-890m-valuation-to-grow-cyber-insurance-platform/https://www.forbes.com/sites/amyfeldman/2020/05/28/next-billion-dollar-startups-2020/ Coalition is proud to be an Equal Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Servicios y tecnologías de la información,7,None,False,,68,ACTIVELY_HIRING_COMPANY
851,2235799114,2020-11-04,Lookout,Senior Staff Security Researcher,Canada,"We are open to candidates across North America to work remotely.﻿Lookout is a cybersecurity company that makes it possible for individuals and enterprises to be both mobile and secure. With 100 million mobile sensors fueling a dataset of virtually all the mobile code in the world, the Lookout Security Cloud can identify connections that would otherwise go unseen -- predicting and stopping mobile attacks before they do harm. The world’s leading mobile network operators, including AT&T, Deutsche Telekom, EE, KDDI, Orange, Sprint, T-Mobile and Telstra, have selected Lookout as its preferred mobile security solution. Lookout is also partnered with such enterprise leaders as AirWatch, Ingram Micro and MobileIron. Headquartered in San Francisco, Lookout has offices in Amsterdam, Boston, London, Sydney, Tokyo, Toronto and Washington, D.C. To learn more, visit www.lookout.com We are looking for Researchers to join our Device Security Intelligence team, a group of world-class mobile researchers who work on device compromises and other mobile platform-based threats. As a member of this team you will hunt and neutralize threats to mobile devices, research system vulnerabilities, work with exploit code, and contribute to an extensive arsenal of detection tools and technologies. Responsibilities Reverse engineer system code, exploits, and applications to determine how they work. Apply the results to improve the way Lookout detects threats and gathers telemetry.Contribute to the long-term design of our telemetry analysis, data stores, mobile client, and tooling.Hunt down and classify new threats and vulnerabilities before they affect our users.Identify and device detection schemes for current and future attacks on user privacy and device security, using telemetry data from our Mobile Threat Network. Required Qualifications & Skills﻿Experience in reverse engineering of software including system / kernel code.Able to read C, C++, Java, and assembly language.ARM assembly and Objective C experience are assets.XNU experience desirable but not required.Able to write proof-of-concept code in C / C++.Able to code in Python or Ruby or Java.Experience using some of the following tools: IDA Pro, Hopper, gdb, Frida.A desire to help build a diverse team of researchers with different backgrounds.Build and maintain positive relationships with security and developer communities.",Intermedio,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Internet",7,None,True,,60,ACTIVELY_HIRING_COMPANY
852,2203301543,2020-10-22,Prospect 33,Bootcamp 33 - Data Science in Financial Services Bootcamp,New York City Metropolitan Area,"Are you a skilled Data Scientist looking to Fast Track your career? Is your lack of real-world experience holding you back from getting the job you graduated for? Our clients are looking for Data Scientists with deep domain experience to reinvent the way banks handle, manage, model, and analyze their data.  There can be no doubt that banking and financial services represent the most complex data & domain environment in existence today. Due to a lost decade brought on by the financial crisis in 2008, today’s banks are only now starting their data journey. Over the coming decade the sector will change inexorably. The challenges of helping achieve this change will be led by an elite group of data scientists who start their careers over this period.  Bootcamp 33 will give you the opportunity to take a deep dive into the full project life cycle and work in this complex domain & data environment. You will gain real-world experience and gain critical domain knowledge. This is not a training course: this is a real-world project training environment designed to overcome the critical challenge of preparing a group of junior data scientists to become the Future Leaders of tomorrow.  Our program combines our deep domain knowledge with real-world data science solutions in an immersive three month program. During the project, you will work in our simulated cloud environment using the latest big data and data science tools and techniques to help solve real-world problems. Successful graduates from our program become members of our exclusive group of Prospect 33 Future Leaders, acknowledged across the world as being the best career accelerator in the industry of financial services.  Take our preliminary quiz to test if you have what it takes to attend and request a spot in Bootcamp 33: https://form.typeform.com/to/ejGtf7pS  BOOTCAMP 33 - INTRODUCTORY IMMERSION BOOTCAMP 2 DAYS (NOV 19th & 20th, 2020)Expand your capabilities in this intensive 2-day bootcamp that will give you real insight into the Financial industry and complexities of this market. We will give you a 360° perspective of what it is like to work as a Data Scientist in the Financial Services industry today. Hear from leading industry experts, meet other like-minded individuals, and ultimately determine if you have what it takes to be the best of the best. BOOTCAMP 33 - PROJECT SIMULATION BOOTCAMP 3 MONTHS (START DATE NOV 30th, 2020)Successful participants from the Immersion Bootcamp will be invited to enter our project immersion training program. This program was specifically designed to enhance your data knowledge, get real project experience, and accelerate your career.  Over the course of the 3 months, you will be immersed in deep domain exercises. You will explore the financial services industry as a whole and learn about the ongoing data initiatives in major financial institutions. You will research and present on multiple topics as well as gain insider knowledge into this complex industry and its intricate data environment. You will plan, lead, and execute a large change program. You will also work with your peers and mentors to build a viable proof of concept (POC) for machine learning software to solve Anti-Money Laundering (AML) and Know Your Client (KYC) issues that financial institutions are facing right now.  HOW WILL BOOTCAMP 33 ACCELERATE YOUR CAREER?ENHANCE YOUR DATA KNOWLEDGEGain insider knowledge into a complex industry with intricate dataUse the foundational data science skill set, such as SQL, python, and pandas, to solve problems around AML & KYCExperience common tools for ETL, data warehousing, and data governancePractice using different models and feature engineering methods to solve real-world problems GET REAL PROJECT EXPERIENCEPlan, lead and execute large change initiatives in our simulated environmentStrategically implement end-to-end data management solutionsExperience real-world agile software developmentTake a deep dive into the full project life cycleACCELERATE YOUR CAREERBecome a data expert in the most complex data environmentMentored by industry leaders and subject matter expertsBoost your resume with valuable project experience and an AI software solution to Anti-Money Laundering (AML), Anti-Financial Crime (AFC), Know Your Client (KYC), and the complex matter of Client Lifecycle Management (CLM)Prospect 33 is the leading project consultancy in the Capital Markets and Investment Banking sector today.   Knowledge, Skills, and Education Requirements Bootcamp Attendees will have:A master's degree in Data Science, Data Analytics, Business Analytics, Computer Science, or other related fields OR an equivalent combination of education and experience or other credible Data Science BootcampsIf not in a program that is specifically related to data science then you must have significant data science project experience and/or 2 years of relevant work experienceMust be strongly capable with SQL, Python and associated Data Science librariesTime to dedicate to a 2-day Bootcamp that requires attendance for the entirety of both days 0900-1800 ESTTime to dedicate to the programme should you be successful at Bootcamp (8-12 hours per week) HOW DOES OUR PROGRAM DIFFER FROM OTHER BOOTCAMPSOther Bootcamps are oriented toward teaching Data Science. Our program assumes that you have that knowledge. We have a high regard for some of the other programs out there, but (from what we’ve seen) none of the other programs out there (excellent as some are) even attempt to tackle the issues we focus on.  We passionately believe that the only way to be an expert data scientist is to have a deep understanding of the domain environment in which you work. In Banking and Finance, this is more essential than in any other industry due to the complex nature of the highly regulated and massively broad spectrum of domain skills that make up the industry. In Capital Markets and Investment Banking, especially, Client Lifecycle, IBOR, Derivatives and Structured Financial Products, Trade Lifecycle, Compliance, and Risk are just a few of the areas to understand.  We focus on teaching you these essential skills and do so in the most productive way possible by running a real project to help solve real-world problems. Over the course of our 3-month program, you will be educated on a broad spectrum of essential domain matters to ensure that you have a thorough understanding of the sector and are well prepared for your career in the industry.  This is not a data science course. We will not teach you the fundamentals of data science. You should know that already. For those who do, we will make you a productive and well rounded professional with the right skills and knowledge to get your career started with confidence.  https://www.prospect33.com/jobs/1733-bootcamp-33-data-science-in-financial-services-bootcamp",Sin experiencia,Jornada completa,"Finanzas, Análisis, Consultoría","Servicios financieros, Banca, Banca de inversiones",31,None,False,,303,ACTIVELY_HIRING_COMPANY
853,2268613316,2020-11-06,RomAnalytics,Engagement Managers,"Princeton, New Jersey, United States","RomAnalytics is recruiting this position on behalf of a rapidly growing cutting edge Healthcare Analytics company powered by AI/ML & Technology, deep Domain expertise in Pharma & Biotech, as well as a High Touch Consultative relationship based approach. Role Description:Leads client engagement and project management from the delivery standpoint. Responsible for proactively identifying opportunities and for scoping projects by translating client business questions into an analytical framework. Partners closely with stakeholders, manages and executes projects successfully, communicating milestones and results.Responsible for day to day project needs of the client with the ability to provide quick analytical solutions. Incumbent may work as an individual contributor and/or manage a project team with on site and off-shore support. Ability to manage and prioritize across multiple deadlines and projects and excellent client management and project management skills are a must.Works actively in partnership with Sales lead to identify and generate cross sell and upsell opportunities within client organization/s. Builds and maintains relationships across cross functional teams and partners with client teams to deliver client satisfaction Functions and Responsibilities:Manage & Execute projects in areas of Marketing, Sales & Market Access related Commercial AnalyticsBusiness Analytics projects including Performance trackers and dashboards, analytics on KPIs and related data metricsPatient Insights & Analytics projects include Analytics include Patient Finder Analysis, Claims Data Analysis. Patient Journey Analysis and require gaining knowledge in a given therapeutic area and market dynamics within it. Predictive analytics projects using claims data and/or specialty pharmacy data.Create insightful summary and deck (storyboarding) in order to provide strategic recommendations to clients and other stakeholders.Maintain seamless communication with client, get necessary clarifications and resolve outstanding issues proactively. Qualifications / Requirements:Deep understanding of Pharma and Biotech industry trends and organizational structure and business functions. Past experience in multiple therapeutic areas: primary care, oncology, specialty etc.Ability to translate business problems into powerful analytical solutions and concrete project plans.Articulate and engaging professional, a self-starter and problem solver.Strong Analytics background and working knowledge of datasets and data sources in the Pharma/Biotech space including Claims, EMR/EHS, Specialty Pharmacy data, Remit Data, Lab/Diagnostics data.Working knowledge of one or more of programming tools such as SAS, SQL, R, or Python preferred (not required).Proven experience and Ability to manage combination of on site and offshore Project teams internally and externally at the client end.Ability to build relationships across hierarchy and at senior levels within client organizations.Ability to identify cross sell and up sell opportunities at the client organization by being aware of and engaging in their core day to day business issues.Ability to set and manage expectations and deliver on them to maintain high client satisfaction.Strong project management skills, analytical skills & communication skills.6-12 years’ experience in Business Analytics and or as a Data Scientist.Bachelor of Science Degree required.",Director,Jornada completa,"Marketing, Desarrollo empresarial, Investigación",Consultoría de estrategia y operaciones,49,None,True,,410,JOB_SEEKER_QUALIFIED
854,2281496667,2020-11-06,Modis,Sr Data Engineer - SQL,United States,"Senior Data Engineer - Gaming Industry We are looking for a dedicated Senior Data Engineer to help grow my client's business intelligence services for their Playa Vista Studio premier mobile game titles, including Avatar: Pandora Rising and MARVEL Strike Force. Responsibilities• Design, implement, debug, document, test, and maintain code and systems for ingestion, transformation, storage, and consumption of data from multiple games and millions of players• Collaborate with game teams, product managers, data analysts and technical stakeholders to craft the best solutions for our data driven business• Estimate engineering effort to contribute to sprint planning and keep our delivery on track• Ensure data quality is delivered on a timely and consistent basis with active alerting and notifications for escalation Qualifications• Bachelor’s degree in computer science or other analytical field or equivalent workexperience• Very strong analytical SQL database skills (data warehouse, analytic SQL functions, etc.)• Excellent communication skills• Knowledge of the Linux command line: some exposure to Bash or other shell scripting• One or more of the following:• Docker container deployment on Kubernetes• Experience in games industry or a fast-paced company such as growth-phase startup• Experience with large data volumes Preferred Qualifications• Experience with data warehouse architecture and data modeling best practices• NoSQL database experience, such as MongoDB• Experience with BigQuery, Git, GitHub, Perforce, Jenkins, Splunk• Programming skills in a language such as Python, Node.js/JavaScript, Golang, Java, C#, orC/C++• Infrastructure management on Amazon Web Services and Google Cloud Platform• Some understanding of functional and object-oriented programming",Intermedio,Contrato por obra,Tecnología de la información,"Servicios y tecnologías de la información, Videojuegos",56,None,True,,164,COMPANY_RECRUIT
855,2275634853,2020-10-10,Cloudbeds,Data Engineer (Remote),"Madrid, ES","Cloudbeds is a travel SaaS technology company that works to make the world a more welcoming place. Heavily leveraging Amazon Web Services (AWS), we build advanced cloud-based hospitality software for hotels, hostels, vacation rentals, and groups that manages reservations and guests, distributes room availability, sells inventory, and collects payments. Our hundreds of team members are globally distributed across over 40 countries and, altogether, we speak 20+ languages. How do we do it? On a #remotefirst platform that allows every member of our team to work from wherever they are around the globe. We’re looking for people who want to disrupt the travel industry and love to travel as much as we do.  As a Data Engineer at Cloudbeds, you will implement our company-wide data strategy across all teams and departments to deliver a best in class data experience to our customers and partners in over 150 countries, as well as internally within Cloudbeds. You will work closely with our Business Intelligence, Reporting, and Infrastructure teams to progress and optimize our data lake architecture and drive the data transformation lifecycle to process terabytes of platform and industry data from multiple databases and origins in an automated and serverless fashion. The right candidate will be very experienced using Amazon Web Services (AWS) tools enabling data lake, warehousing, and processing capabilities. As a Data Engineer at Cloudbeds, you will have endless opportunities to innovate and drive the industry leading, comprehensive, and global data experience for travel.  Location: Europe (Remote)  What You Will Do:  Code ETL data transformations in PySpark/Spark.Design and manage processing pipelines via AWS Glue and/or EMR clusters.Manage ingestion and replication via DBMS from cloud MySQL databases.Process external sources like Salesforce via Appflow or kaggle datasets.Manage AWS Athena views and endpoints for consumption.Creation, modification, and maintenance of data infrastructure (Redshift [with Spectrum], S3 Parquet data, DBMS, Notebooks, etc.)Implement logging and debugging approaches in a standardized fashion.Collaborate with Business Intelligence, Analytics, and Infrastructure teams on a daily basis.Develop a framework for future extensions through standardized modern workflows. You’ll Succeed With:  Bachelor’s degree in computer science or related field, or equivalent experience.3+ years experience as a Data Engineer.2+ years experience working with Amazon Web Services.Expert knowledge and experience developing efficient ETL data pipelines having multiple sources using PySpark/Spark and DataFrames.Strong knowledge and experience developing workflows with AWS Glue, EMR, Redshift, Athena, and LakeFormation.Strong knowledge of modern data lake, data warehousing, and ETL/ELT concepts.Strong knowledge of how to compose and implement structural data models.Experience molding fresh environments into efficient mature data platforms.Experience with performance optimization for processing and storage via data partitioning and indexing techniques.Ability to take a consultative approach to data strategy.Ability to work in an Agile Scrum environment.Ability to thrive in a fast-paced environment.Ability to work remotely and manage your own time in an international team.Exceptional written and verbal communication in English.  Our company culture supports flexible working schedules with an open PTO policy and the opportunity to travel and work remotely with great people. To make it easy for our team to travel we offer 2 corporate apartment accommodations near our San Diego and Sao Paulo offices. At Cloudbeds we dedicated to your personal and professional development. You will have access to over 10,000 courses within LinkedIn Learning when you join our team for your unique individual growth! If you think you have the skills and passion, we’ll give you the support and opportunity to thrive in your career. If you would like to be considered for the role, we would love to hear from you!  Company Awards to Check Out!  Best Startup Employers in 2020 | ForbesBest Places to Work | HotelTechReport (2018, 2019, 2020)Deloitte’s North America Technology Fast 500 (2019)Inc. 500 Fastest Growing Companies (2018 & 2019) Inc. Best Places to Work (2017 & 2018) Best Places to Work | Inc Magazine (2017 & 2018)Start-Ups to Watch in 2018 | ForbesConnect MIP Award (Technology) Powered by JazzHR  kcPaqNoUc4",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Internet",4,None,True,,52,ACTIVELY_HIRING_COMPANY
856,2025115715,2020-10-16,dunnhumby,Insights Consulting Director,United States,"Most companies try to meet expectations, dunnhumby exists to defy them. Using big data, deep expertise and AI-driven platforms to decode the 21st century human experience – then redefine it in meaningful and surprising ways that put customers first. Across digital, mobile and retail. For brands like Tesco, Coca-Cola, Procter & Gamble and PepsiCo.  Dunnhumby is seeking a Client Lead who expects more from their career. You will be a trusted advisor for our retail and CPG clients, working side-by-side with them to ensure their success. Using customer insights derived from our data platform, you will own and develop a client plan that delivers recognizable value, client satisfaction and return on investment. You will be responsible for driving collaboration between business partners, understanding key business challenges, and embedding a Customer 1st approach into decision making.   What we expect from youBachelors degree in a relevant subjectManage assigned Retail or CPG client relationships and workplansSupport team effort to instil a Customer 1st approach and process to managing their businessBecome an expert and teacher of our Data Science, Software, and approachesSupport sales and renewal efforts with your Retail or CPG client stakeholderUndertake projects, partnering with Data Scientist colleagues, to dive deep into client data and make recommendations to clients to achieve positive business results and an improved customer experienceManage implementation of new processes, tools, and solutions with the client and as part of a large team environment4-6 years relevant experience * This role will be remote until spring 2021. There is an expectation to work onsite in the future.   What you can expect from us We won’t just meet your expectations. We’ll defy them. So you’ll enjoy the comprehensive rewards package you’d expect from a leading technology company. But also, a degree of personal flexibility you might not. Plus, thoughtful perks, like early finish Friday and your birthday off.  You’ll also benefit from an investment in cutting-edge technology that reflects our global ambition. But with a nimble, small-business feel that gives you the freedom to play, experiment and learn.  And we don’t just talk about diversity and inclusion. We live it every day – with thriving networks including dh Women’s Network, dh Proud, dh Parent’s & Carer’s, dh One and dh Thrive as the living proof. Everyone’s invited.  Our approach to Flexible Working  At dunnhumby, we value and respect difference and are committed to building an inclusive culture by creating an environment where you can balance a successful career with your commitments and interests outside of work.  We believe that you will do your best at work if you have a work / life balance. Some roles lend themselves to flexible options more than others, so if this is important to you please raise this with your recruiter, as we are open to discussing agile working opportunities during the hiring process.",Intermedio,Jornada completa,"Ventas, Desarrollo empresarial","Marketing y publicidad, Venta al por menor, Artículos de consumo",323,None,True,,1181,ACTIVELY_HIRING_COMPANY
857,2272943666,2020-11-04,Toptal,Data Engineer,United States,"Toptal is an elite network that matches the world's top talent with the world's top organizations. One of our Enterprise clients is looking for an expert Python Developer/Data Engineer to join their talented Data Onboarding Engineering team. In this role, you'll contribute to building robust data pipelines that ingest over 30TB of data each day. Technical Requirements: 3+ years of full-time work experience as a Data Engineer. Experience developing data workflows and a good operational understanding of data operations, including processing, storage, quality, and management. Experience building ETL pipelines. Experience with Python programming. This is a mid-term, remote contract opportunity in the US, which requires a 40-hour per week availability (Full-time engagement). If you think this role would be a good fit, please apply to learn more.",Intermedio,Contrato por obra,"Tecnología de la información, Ingeniería",Internet,116,None,True,,309,ACTIVELY_HIRING_COMPANY
858,2254571817,2020-10-29,Facebook,"Data Scientist, Product Analytics","Menlo Park, CA, US","Facebook's mission is to give people the power to build community and bring the world closer together. Through our family of apps and services, we're building a different kind of company that connects billions of people around the world, gives them ways to share what matters most to them, and helps bring people closer together. Whether we're creating new products or helping a small business expand its reach, people at Facebook are builders at heart. Our global teams are constantly iterating, solving problems, and working together to empower people around the world to build community and connect in meaningful ways. Together, we can help people build stronger communities - we're just getting started. We’re looking for Data Scientists to work on our core and business products (ex. Instagram, Messenger, FB App, Ads, What's App, Integrity, etc.) to help shape the future of what we build at Facebook. You will enjoy working with one of the richest data sets in the world, cutting edge technology, and the ability to see your insights turned into real products on a regular basis. You should have a background in a quantitative or technical field, experience working with large data sets, and experience in data-driven decision making. You are focused on results, a self-starter, and have demonstrated success in using analytics to drive the understanding, growth, and success of a product.Apply your expertise in quantitative analysis, data mining, and the presentation of data to see beyond the numbers and understand how our users interact with both our consumer and business productsPartner with Product and Engineering teams to solve problems and identify trends and opportunitiesInform, influence, support, and execute our product decisions and product launchesThe Data Scientist Analytics role has work across the following four areas:Product OperationsForecasting and setting product team goalsDesigning and evaluating experimentsMonitoring key product metrics, understanding root causes of changes in metricsBuilding and analyzing dashboards and reportsBuilding key data sets to empower operational and exploratory analysisEvaluating and defining metricsExploratory AnalysisProposing what to build in the next roadmapUnderstanding ecosystems, user behaviors, and long-term trendsIdentifying new levers to help move key metricsBuilding models of user behaviors for analysis or to power production systemsProduct LeadershipInfluencing product teams through presentation of data-based recommendationsCommunicating state of business, experiment results, etc. to product teamsSpreading best practices to analytics and product teamsData InfrastructureWorking in Hadoop and Hive primarily, sometimes MySQL, Oracle, and VerticaAutomating analyses and authoring pipelines via SQL and Python based ETL frameworkBachelors/Masters/PhD4+ years of experience doing complex quantitative analysis and working with distributed (i.e. Hive, Hadoop or similar databases) or highly complex datasets4+ years of experience with data querying languages (e.g. SQL), scripting languages (e.g. Python), or statistical/mathematical software (e.g. R, SAS, Matlab)4+ years of experience with applied statistics or experimentation (i.e. A/B testing) in an industry setting2+ years of experience communicating the results of analyses to leadership teams to influence the strategyExperience in a consumer technology company6+ years of experience in all the above minimumsFacebook is proud to be an Equal Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law.   Facebook is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.",Algo de responsabilidad,Jornada completa,Tecnología de la información,Internet,52,None,False,accommodations-ext@fb.com.,538,COMPANY_RECRUIT
859,2222668259,2020-10-29,SDL plc,Korean Freelance Planner/Strategist/Researcher – Gaming Industry,South Korea,"Korean Freelance Planner/Strategist/Researcher – Gaming Industry Korean speaker (native-level), home-based  SDL (LSE: SDL) is the leader in global content management and language solutions. With more than 20 years of experience, SDL helps companies build relevant digital experiences that deliver transformative business results on a global scale. Seventy-nine of the top hundred global brands trust SDL to simplify the complexity of managing content across multiple brands, websites, languages, and devices. Go global faster with SDL. Learn more at SDL.com and follow us on Twitter, LinkedIn and Facebook. SDL: Marketing Solutions practice was formed in 2016 to productize new offerings from SDL’s existing language and rich media content management and adaptation services. The mission for SDL Marketing Solutions is to create broader solutions for existing and new SDL clients – marrying SDL’s well established language skills and our geographic footprint with visual content management expertise to adapt, manage and activate global marketing communications. We are currently looking for project-based, in-market freelance planners/strategists/researchers to join our fast-growing international pool of talent. The successful candidates will have the opportunity to work with leading brands. We are looking for people who are passionate about what they do and that have a genuine interest in helping brands speak across cultural borders. People who are happy working off-site but who are happy to be an extension of our in-house teams, bringing their creative and local market know-how to be a part of our clients´ success.  Requirements: • Excellent command of English• Native Korean speakers• Based in Korea• Minimum 3 to 5 years proven experience as planner/strategist/researcher in an agency environment or in-house • Experience/knowledge in gaming industry/culture in Korea and/or a strong personal interest in gaming• Experience gathering attitudinal and behavioral insights from research activity and an ability to find out the ‘what if’ • Able to develop communication strategies for advertising campaigns• Experience and confidence writing up reports and creative/strategy briefs• Wide knowledge of/interest in local culture, advertising regulations, and keeps on top of global trends and the changing media landscape (including awareness of emerging digital channels)• High level of awareness of brand strategy• Highly creative – able to bring new dimensions to projects  The Candidate: • Open-minded and curious about the world around them• Solutions-oriented, consumer-focused and able to challenge the client brief to find the right solution • An insight-hunter who is able to present and distil the ‘what if’/key insights concisely and with clarity• Approachable, with a can-do attitude• Excellent presentation, interpersonal and communication skills • Excellent attention to detail and accuracy• Flexible, with ability to prioritize and adapt quickly• Works well with an international/multi-location team• Able to work under pressure and prioritize effectively• Never fails to meet a deadline• Ability to take onboard and respect feedback• If/when applicable able to attend conference calls and client meetings to discuss brief and feedback If this sounds like you, then please email your CV in English to Onusa Paul at opaul@sdl.com .",Intermedio,Contrato por obra,"Marketing, Publicidad, Estrategia/planificación","Servicios y tecnologías de la información, Marketing y publicidad, Producción multimedia",28,None,True,opaul@sdl.com,228,COMPANY_RECRUIT
860,2215731132,2020-10-26,Cognizant,Python/AWS Developer,"Plano, TX, US","Cognizant is looking for Python/AWS Developer to join our Artificial Intelligence and Analytics practice (AIA) for a remote project. As a trusted advisor, responsible for providing an approach for the overall project. As a domain specialist, you will drive technology discussions and analyze the existing gaps in addressing business needs. You are a thought leader-comfortable challenging the status quo to enhance our current services and technologies.  About AI & Analytics: Artificial Intelligence (AI) and the data it collects and analyzes will soon sit at the core of all intelligent, human-centric businesses. By decoding customer needs, preferences, and behaviors, our clients can understand exactly what services, products, and experiences their consumers need. Within AI & Analytics, we work to design the future—a future in which trial-and-error business decisions have been replaced by informed choices and data-supported strategies.  By applying AI and data science, we help leading companies to prototype, refine, validate, and scale their AI and analytics products and delivery models. Cognizant’s AIA practice takes insights that are buried in data and provides businesses a clear way to transform how they source, interpret, and consume their information. Our clients need flexible data structures and a streamlined data architecture that quickly turns data resources into informative, meaningful intelligence.  Cognizant Technology Solutions will not be able to provide sponsorship for this role now or in the future.  Responsibilities Create and maintain optimal data pipeline architecture, assemble large, sophisticated data sets that meet functional / non-functional business requirementsIdentify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘Big Data’ technologiesBuild analytics tools that utilize the data pipeline to deliver impactful insights into customer acquisition, operational efficiency, and other key business performance metricsWork with partners including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needsCreate data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader  Qualifications 5+ years of experience in a Data Engineer role, who has attained a Bachelor’s degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field3+ years of experience of Python programming experience with object-oriented/object function scripting languages (Scala is plus)3+ years of experience with Big Data tools: Hadoop, Apache Spark, Kafka, etc.1+ years of experience with AWS cloud services: S3, EC2, EMR, RDS, Redshift1+ years of experience with relational SQL, Snowflake and NoSQL databases, including Postgres and CassandraExperience with stream-processing systems: Storm, Spark-Streaming, etc. (nice to have)  Why Choose Cognizant?   It takes a lot to succeed in today’s fast-paced market, and Cognizant Technology Solutions has become a leader in the industry. We love big ideas and even bigger dreams! We stand out because we put human experiences at the core. Our associates enjoy robust benefits and training opportunities from our industry recognized, award winning Academy team. You will have access to hundreds of technical training to keep your skill sets fresh and have opportunities to acquire certifications on the latest technologies.  Everything we do at Cognizant we do with passion—for our clients, our communities, and our organization. It’s the defining attribute that we look for in our people.  If you love ambiguity, excited by change, and excel through autonomy, we’d love to hear from you!  www.cognizant.com  #CB  IND123  Employee Status : Full Time Employee  Shift : Day Job  Travel : No  Job Posting : Oct 26 2020  About Cognizant  Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 194 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @USJobsCognizant.  Cognizant is recognized as a Military Friendly Employer and is a coalition member of the Veteran Jobs Mission. Our Cognizant Veterans Network assists Veterans in building and growing a career at Cognizant that allows them to leverage the leadership, loyalty, integrity, and commitment to excellence instilled in them through participation in military service.  Cognizant is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law.  If you have a disability that requires a reasonable accommodation to search for a job opening or submit an application, please email CareersNA2@cognizant.com with your request and contact information.",Sin experiencia,Jornada completa,Otro,"Servicios y tecnologías de la información, Consultoría de estrategia y operaciones",22,None,False,CareersNA2@cognizant.com,275,COMPANY_RECRUIT
861,2218497649,2020-10-19,ASTEK Polska,Data Engineer (Big Data),"Gdynia, Woj. Pomorskie, Polska","Aktualnie, dla klienta branży bankowej poszukujemy doświadczonych Data Engineerów Lokalizacja: docelowo Gdynia, obecnie praca zdalnaStawka (w zależności od doświadczenia i umiejętności):➡ B2B: do 1075 PLN netto + VAT / dzień,➡ UoP: do 16.500 PLN brutto / miesiąc Oczekiwania:solidne, komercyjne doświadczenie w programowaniu w Scalimin. 3-letnie doświadczenie w pracy z Apache Sparkdoświadczenie w pracy z Hadoopemdoświadczenie w pracy z Apache Oozie Osoby zainteresowane zachęcam do kontaktu: mgapinska@astek.pl",Intermedio,Jornada completa,Tecnología de la información,Servicios y tecnologías de la información,29,None,True,mgapinska@astek.pl,165,ACTIVELY_HIRING_COMPANY
862,2287836667,2020-11-04,LAAgencia,Data Scientist (Remote) - Mexico City,"Mexico City, MX","Hello!  Â¡We are looking for a Data Scientist to work remotely in Mexico City!  Our Team  Our expectations are pretty high for Data Scientist positions. The Data Science team plays a leading role in solving our most challenging problems and guiding the decisions that we take around product.  Impact  Build, implement, and maintain machine learning systems in technology products. Lead engineering best practices for scaling ML and designing/building software that is reliable, scalable, and secure  Be responsible for the implementation, testing, and release of a range of models, both for existing and 'œto-be-invented' use cases  Work closely with Machine Learning scientists to design, code, train, test, deploy, iterate and own state-of-the-art systems for executing ML models  Building end-to-end data pipelines to train, maintain, and track performance of our Machine Learning and Operations Research products  Requerements 2+ years as Data ScientistAdvanced englishPython, R, SQL Benefits Negotiable salary100% remote Powered by JazzHR",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Software, Internet",3,None,False,,22,JOB_SEEKER_QUALIFIED
863,2276395824,2020-11-03,Additional Resources,Senior Data Engineer - Remote (ETL/AWS/SQL/Agile),"London, GB","Senior Data Engineer - Remote (ETL/AWS/SQL/Agile) - London  £85k to £90k  My client, an award-winning Media House, is looking for an experienced Snr Data Engineer to work from home. You will own their datasets, defining how they instrument, organise, store and manage data.  The Snr Data Engineer will be joining the Digital Product - Engineering department aimed to implement their Customer Data Platform using integrations, data sets, tools, governance processes, and more.  Responsibilities  You will be joining a critical and challenging project whose main goal is delivering a single view of the customer across their multiple data silos, in order to increase customer engagement.  You are comfortable and passionate working with business intelligence tools, can model large event datasets, and can partner with other people in the company to answer key business questions.  You will have the opportunity to display your skills in the following areas:  Design and implement a scalable and durable data model for our specialized datasets.  Develop the end-to-end automation of data pipelines, making datasets readily-consumable by visualization tools and notification systems through APIs and web services to integrate both, internal and third party production systems.  Create automated alarming and dashboarding to monitor data integrity.  Create and manage capacity and performance plans.  Act as the subject matter expert for the data structure and usage.  Requirements  Expert knowledge of SQL and of relational database systems and concepts as well as NoSQL databases, and modern storage tools like Athena, Redshift and BigQuery  Experience building big data infrastructure, data ingestion and modeling pipelines (AWS ideally: CodePipeline, Cloudformation, Step functions, Glue jobs, Lambda, Athena, S3, DynamoDB.)  Experience with modern data processing tools (i.e. Hadoop, Spark, Hive, or equivalents)  Experience developing in Scala, Typescript/Javascript, Python, or another similar language.  Experience designing and building scalable APIs  Important Information: We endeavour to process your personal data in a fair and transparent manner. In applying for this role, Additional Resources will be acting in your best interest and may contact you in relation to the role, either by email, phone or text message. For more information see our Privacy Policy on our website. It is important you are aware of your individual rights and the provisions the company has put in place to protect your data. If you would like further information on the policy or GDPR please contact us.  Additional Resources Ltd is an Employment Business and an Employment Agency as defined within The Conduct of Employment Agencies - Employment Businesses Regulations 2003",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Dotación y selección de personal, Servicios financieros, Atención sanitaria y hospitalaria",2,None,False,,11,ACTIVELY_HIRING_COMPANY
864,2183080498,2020-11-05,Intelletec,Lead Data Scientist - Large Healthcare Company,"Boston, Massachusetts, United States","My client with one of the US Leading Healthcare firms. They are going through a massive transformation and are looking for a Lead Data Scientist to join their team.  If you want to make a difference in healthcare in the US and beyond this could be a great opportunity!  The Lead Data Scientist will have a broad impact and true ownership: driving business decisions and mentoring junior team members to provide technical advice. As a Lead Data Scientist you will:Develops complex algorithms and statistical predictive models and determines analytical approaches and modeling techniques to evaluate scenarios and potential future outcomes.Performs analyses of structured and unstructured data to solve multiple and complex business problems. utilizing advanced statistical techniques and mathematical analyses and specialized expertise in the organization and/or industry.Applies analytical rigor and statistical methods to analyze large amounts of data, using advanced statistical techniques.Manages large and complex analytical projects from data exploration, model building, performance evaluation and testing.Collaborates with business partners to develop technical /business approaches and new or enhanced technical tools.Interacts with internal and external peers and management to share highly complex information related to areas of expertise and/or to gain acceptance of new or enhanced technology/business solutions. SKILLS:5-10 or more years of progressively complex related experience.Bachelor's degree or equivalent work experience in Mathematics, Statistics, Computer Science, Business Analytics, Economics, Physics, Engineering, or related discipline.Master’s degree or Ph.D. preferred.Excellent analytical and problem-solving skills.Strong organizational, management, and leadership skills.Deep knowledge of advanced analytics tools and languages to analyze large data sets from multiple data sources.Strong skills to effectively communicate and negotiate across the business and in the external health care environmentDemonstrates proficiency in all areas of mathematical analysis methods, machine learning, statistical analyses, and predictive modeling and advanced in-depth specialization in some areas.Demonstrates a strong ability to communicate technical concepts and implications to business partners.Solid understanding of the healthcare industry, products, and systems is a plus.  ON OFFER:Very competitive pay, bonus, full medical, dental & vision benefits and moreA tight-knit team of passionate people and a tech-first businessAutonomy and end-to-end ownershipOpportunity for fast growth & promotion For more info please reach out to theodore@intelletec.com",Intermedio,Jornada completa,Otro,Dotación y selección de personal,164,None,True,theodore@intelletec.com,500,ACTIVELY_HIRING_COMPANY
865,2184340585,2020-10-15,Dropbox,"Design Researcher - SSB Files, Surfaces - Location Flexible","Remote Lake, MN, US","Company Description Dropbox is now a Virtual First company, which means work outside of an office will be the primary experience for all employees. The location listed on the job description is simply so our jobs get picked up by job boards as they require a specific location. Being Virtual First means, location is flexible, so please feel free to apply to any position regardless of the location listed. Final location will be determined, by teams and individuals as the hiring process unfolds.    Dropbox is the world’s first smart workspace that helps people and teams focus on the work that matters. With more than 600 million registered users across 180 countries, we’re on a mission to design a more enlightened way of working. Dropbox is headquartered in San Francisco, CA, and has 12 offices around the world. Team Description Our Design team crafts delightful experiences that make people's lives easier. We're a close-knit, collaborative group, guided by a highly iterative user-centered design process. Combining research, data, and thoughtful critique, we're discovering needs and solving fundamental problems that impact work and life for millions of people around the world.  Role Description  Surfaces is a unique team init’s ensuring that desktop and web platforms and surfaces evolve to meet growing business needs without compromising the user experience. We have the responsibility to ensure that core Dropbox flows are easy to use, consistent, and optimized for solving key customer needs. Responsibilities You will conduct high velocity and high impact strategic research across SSB, in particular with the Surfaces TeamYou will identify and execute research that impacts product team immediate roadmaps and longer term strategiesYou will implement multi-method research studies that incorporate both qualitative and quantitative dataYou will socialize research within SSB Files and across the company in innovative and engaging waysYou will mentor members of our team in methods, communication, and socialization Requirements 5+ years of UX-related work experienceBroad experience with a wide variety of research methods applied across the product development processStrength in a particular research specialty: design strategy, generative and exploratory research, surveys, statistical modeling, analytics/visualization, etc.Demonstrated skills for collaborating closely with other researchers, designers, product managers and engineersClear, compelling presentation and communication style Benefits and Perks 100% company paid individual medical, dental, & vision insurance coverage401k + company matchMarket competitive total compensation packageFree Dropbox space for your friends and familyWellness ReimbursementGenerous vacation policy10 company paid holidaysVolunteer time off Company sponsored tech talks (technology and other relevant professional topics) Dropbox is an equal opportunity employer. We are a welcoming place for everyone, and we do our best to make sure all people feel supported and connected at work. A big part of that effort is our support for members and allies of internal groups like Asians at Dropbox, BlackDropboxers, Latinx, Pridebox (LGBTQ), Vets at Dropbox, Women at Dropbox, ATX Diversity (based in Austin, Texas) and the Dropbox Empowerment Network (based in Dublin, Ireland).",No corresponde,Jornada completa,"Ingeniería, Tecnología de la información","Software, Servicios y tecnologías de la información, Internet",10,None,False,,102,COMPANY_RECRUIT
866,2253810428,2020-11-06,Applause,CX Researcher (U.S. East Coast),New York City Metropolitan Area,"Customer experience studies are an Applause core service offering. We have a prolific banking client in New York running a long-term UX research program utilizing Applause services and can utilize the full-time capacity of an experienced CX Researcher to conduct their studies. Role: CX Researcher (1099 contract)Location: U.S. East Coast residency: possible onsite visits to NYC client at 6 month intervals, post lifting of COVID restrictionsDuration: 6 months, to be renewed upon reviewCapacity: 30-40 hours per week, Monday-Friday during Eastern standard business hours Responsibilities:Defining, planning and conducting user researchDelivering compelling insights to the Product and Design teamsProviding actionable feedback to guide Product and Design decisionsDeveloping, innovating and evangelizing user research best practices Qualifications:3+ years in a Customer Research or UX Research role or relevant professional experience2+ years of consulting experienceBanking domain expertise/knowledge preferredSubmission of a UX Research portfolio or undertaking a mock UX studyBachelor's Degree in Human Computer Interaction, Psychology, related field or similar work experienceBroad experience in qualitative research methods, especially remote moderated and unmoderated methodsComfortable with metrics: able to synthesize quantitative data with qualitative user researchProficiency in planning, scoping, conducting, analyzing and communicating researchVery collaborative with a demonstrated ability to work effectively in a dynamic, creative and remote environmentMust be flexible to change and capable of managing multiple deadlines and prioritiesEffective communicator",Intermedio,Contrato por obra,"Tecnología de la información, Investigación","Servicios y tecnologías de la información, Banca, Servicios financieros",21,None,True,,181,ACTIVELY_HIRING_COMPANY
867,2268185636,2020-10-08,"Georgia IT, Inc.","DataStage Data Engineer.-Remote/ Plano, TX","Plano, TX, US","DataStage Data Engineer. Location: Remote/ Plano, TX Duration: 7 Months Rate: Market Rate  Visa Independent Candidates only  Description  Experience in working Data Integration teams on Data Analytics and Data Warehousing engagements. Minimum of 5 years Data Integration experience working in medium to large sized projects Strong understanding of data warehousing, data integration, reporting and advanced analytics technologies. Strong communication skills. Experience managing client relationship and expectations. Specific knowledge of DataStage 9.X/11.x and UNIX Prior Data integration experience with the following IBM software products.  SQL Server UNIX scripting Scheduling tool Control-M.  Experience in Unix/Linux/Redhat. Experience leading Technical teams. Experience with ETL tool DataStage",Sin experiencia,Contrato por obra,Tecnología de la información,Servicios y tecnologías de la información,2,None,False,,10,None
868,2287633520,2020-10-13,Stone,[DIGITAL] Data Engineer,"Rio de Janeiro, BR","Já conhece a Stone Co.?   A Stone nasceu com o desejo de transformar o mercado de pagamentos! Nosso propósito é fazer diferente e criar soluções tecnológicas com impacto de verdade na vida de quem empreende. Crescemos em ritmo acelerado e hoje somos uma das 6 empresas unicórnios do Brasil.  A Stone se propõe a desenvolver quem cuida do negócio. Somos transparentes, trabalhamos em equipe, temos foco em nossos clientes e sempre com a tecnologia como referência! Somos mais que a maquininha verde no balcão, somos a Stone Digital!  Conheça mais sobre a nossa empresa aqui!  #Sobre a vaga   Desenhar e modelar novas soluções de arquitetura de dados seguras, confiáveis, disponíveis e escaláveis: Montar arquiteturas de Big Data, com processamento de dados em batch e streaming: Conhecimento em Data Lakes e Data Warehouses: Criar e definir modelagens de repositórios de dados tais como (Bases não relacionais e relacionais): Desenvolver estratégias de aquisição de dados, recuperação de informação, implementação de pipelines de processamentos de dados e armazenamento de dados: Planejar e gerenciar atividades da equipe de engenharia de dados, observando interesses de negócio e assegurando prazo e qualidade das entregas: Planejar e gerenciar novos projetos inerentes às soluções de dados: Trabalhar em conjunto com os Analistas de Dados e Cientistas de Dados:  #Não pode faltar:   🧾 Ter forte conhecimento em SQL, Arquitetura de dados e modelos de dados relacionais e não relacionais  🧠 Excelente conhecimento em trabalhar com sistemas distribuídos em ambientes de produção  💻 Projeto e execução de arquiteturas de dados, como Cloud Functions e streaming  🧾 Proficiente em Python, Java ou linguagem semelhante  ☁️ Conhecimento em soluções em nuvem (preferencialmente GCP e/ou AWS)  📈 Conhecimento em design de processos ETL  💻 Experiência com ecossistema Hadoop  📚 Experiência no funcionamento e manutenção de banco de dados NoSQL (tais como: Cassandra, HBase, MongoDB, CouchDB, entre outros)  #O que aumenta as suas chances:  🧠 Experiência em construção e gerenciamento de Data Lakes e Data Warehouses  💻 Ter experiência com Airflow, Kafka e/ou Spark  ☁️ Ter experiência com Cloud Functions e/ou Lambda Architectures:  📈 Banco de Dados Search Engine (ElasticSearch)  📚 Ter conhecimento em Terraform Infrastructure  💻 Frameworks de aprendizado máquina (tais como: TensorFlow, Scikit-Learn, PyTorch, Keras)  #O que oferecemos:  🩺 Plano de Saúde e Odontológico Bradesco (sem coparticipação)  🚌 Vale transporte  🥗 Vale Refeição e/ou Vale Alimentação  💚 Seguro de Vida  💪 Gympass  👶 Auxílio Creche  🕗 Horário flexível  #Etapas do nosso processo seletivo:  ✍️ Inscrição  📞 Phone Screening | Entrevista com o time de People  🤝 Entrevista com a liderança  🎬 Apresentação do desafio técnico  🏁 Feedbacks e/ou contratação  E aí, deu match? Se candidate!   Na Stone Co., nós acreditamos na pluralidade das ideias, respeitamos as individualidades, valorizamos as vivências e temos disposição para estabelecer diálogos para a construção de uma empresa mais diversa. Todas as nossas vagas são elegíveis a pessoas com deficiência e/ou reabilitados.   Nos acompanhe nas nossas redes sociais:",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Internet, Servicios financieros",0,None,False,,5,ACTIVELY_HIRING_COMPANY
869,2259612891,2020-10-31,Civis Analytics,"Senior Applied Data Scientist, Government","Washington, D.C., DC, US","What We Do  At Civis, we take a science-first approach to solving business problems using person-level data. With a blend of proprietary technology and statistical advisory services, we help public and private sector organizations find, understand and connect with the people they care about, so they can stop guessing and start using mathematical proof to guide decisions. We know others use 'data science' and 'analytics' as buzzwords, but at Civis we don't stand for fluff, and we will always deliver scalable products and technologies — not PowerPoints — to drive your business forward. Learn more about Civis at www.civisanalytics.com.  Our mission  Our mission is to bring objective, data-driven truth to organizational decision-making – all the way from the boardroom to the world's largest social causes.  About The Role  The Applied Data Science (ADS) Team is the advisory arm of Civis Analytics, working closely with governments, companies, nonprofits, and campaigns to help solve their toughest challenges with data science. They are critical components of the project team and are expected to take leadership in understanding how to design and implement data science solutions for each client's unique situation. This position will be part of the ADS Public Sector team, which most commonly works with state and local governments, federal agencies, and public utilities.  As a Senior Applied Data Scientist, you will structure hard problems, define our methodological approach, build predictive models, collaborate in cross-functional teams, and be responsible for project milestones and presentations. You will also be a mentor to other data scientists, potentially managing newer hires, contributing to internal assets, and fostering learning and collaboration. You will work closely with our Applied Data Science Leads and our Managing Director to develop relationships, partnerships, and proposals for new governmental work, and may take responsibility for entire projects or accounts as you grow in your role.  Due to the uncertainty of COVID-19, all Civis offices are closed and all employees are remote for the foreseeable future. This is being closely monitored as things change and it's likely our offices will reopen. Because of this uncertainty, we want to ensure candidates are open to relocating to one of our offices in the future, but other locations may be negotiable.  Responsibilities  Work with colleagues to scope out and define our approach to complex client problems Enhance, find patterns in, and build predictive models on large data sets Work with other Applied Data Scientists, as well as other departments within Civis, to derive clear, actionable, and timely insights from analyses Work with the Applied Data Science Lead to create deliverables such as data assets, pipelines, dashboards, and presentations that are client-ready, clear, and error-free Work with the Applied Data Science Lead to develop business opportunities, proposals, and pitches for new work throughout the public sector market   Minimum Qualifications  Bachelor's degree in an analytical subject (statistics, math, economics, sociology, psychology, physics, etc.) or equivalent Minimum of 4 years of related work experience Proven business results using both SQL as well as either R or Python Experience with machine learning techniques Experience with persuasive writing and presentation Demonstrated ability to work independently and in teams Excellent interpersonal and communication skills   Preferred Qualifications:  MA or MS in an analytical subject Experience leading projects, including managing the work of colleagues Proven affinity for and experience mentoring teammates Experience with analytics for the public sector or for utilities Experience with collaborative coding tools including Docker and Github Significant experience fielding and analyzing web panel surveys  Why join our team?  The opportunity to be part of a growing tech startup focused on solving interesting and meaningful problems, invested in internal promotion, and committed to fostering a diverse, equal and inclusive workplace.  Competitive benefits, including unlimited PTO, 401K match with immediate vesting, health, dental, and vision benefits, fully paid parental leave, breastfeeding support including breastmilk shipping services for traveling moms, commuter benefits, wellness initiatives including weekly group meditations, monthly on-site massage therapy, and pet insurance.  To support employees in our now fully remote work environment, we also have expanded our virtual journal and book clubs, Donut Pals (organized virtual coffee meet-ups), Lightning Talks (5-minute presentations on anything you'd like), Lunch-and-Learns, and HR Open Discussions (bi-weekly meet-up where we discuss ideas and topics of the day in a casual format). We are also able to support and accommodate flexible work from home schedules to help employees juggle responsibilities at home.  Civis Analytics embraces the individuality of our employees and we celebrate each other's differences. Our products, services, and culture benefit from and thrive on the unique perspectives brought by each person in our community. We're proud to be an equal opportunity workplace, and we are committed to equal employment opportunity regardless of race, age, sex, color, ancestry, religion, national origin, sexual orientation, gender identity, citizenship, marital status, disability, or Veteran status. If you have a disability or special need that requires accommodation, please contact internalrecruiting@civisanalytics.com  In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States.  EEO IS THE LAW  EEO Supplement  Pay Transparency",Algo de responsabilidad,Jornada completa,Otro,"Marketing y publicidad, Software, Internet",10,None,False,internalrecruiting@civisanalytics.com,61,ACTIVELY_HIRING_COMPANY
870,2255485844,2020-10-21,TipTopJob,Snr Data Engineer : Remote (ETL/AWS/SQL/Agile),"London, GB","Snr Data Engineer : Remote (ETL/AWS/SQL/Agile) : London GBP 80k My client, one of UKs largest news publisher, is looking for an experienced Snr Data Engineer to work from home. You will own their datasets, defining how they instrument, organise, store and manage data. The news publisher sells 600 million newspaper each month, with 6 million readers monthly and 8 billion page views per year. The Snr Data Engineer will be joining the Digital Product and Engineering department aimed to implement their Customer Data Platform using integrations, data sets, tools, governance processes, and more.  Responsibilities  You will be joining a critical and challenging project whose main goal is delivering a single view of the customer across their multiple data silos, in order to increase customer engagement. You are comfortable and passionate working with business intelligence tools, can model large event datasets, and can partner with other people in the company to answer key business questions. You will have the opportunity to display your skills in the following areas: Design and implement a scalable and durable data model for our specialized datasets. Develop the end:to:end automation of data pipelines, making datasets readily:consumable by visualization tools and notification systems through APIs and web services to integrate both, internal and third party production systems. Create automated alarming and dashboarding to monitor data integrity. Create and manage capacity and performance plans. Act as the subject matter expert for the data structure and usage.  Requirements  Expert knowledge of SQL and of relational database systems and concepts as well as NoSQL databases, and modern storage tools like Athena, Redshift and BigQuery Experience building big data infrastructure, data ingestion and modeling pipelines (AWS ideally: CodePipeline, Cloudformation, Step functions, Glue jobs, Lambda, Athena, S3, DynamoDB.) Experience with modern data processing tools (i.e. Hadoop, Spark, Hive, or equivalents) Experience developing in Scala, Typescript/Javascript, Python, or another similar language. Experience designing and building scalable APIs Important Information: We endeavour to process your personal data in a fair and transparent manner. In applying for this role, Additional Resources will be acting in your best interest and may contact you in relation to the role, either by email, phone or text message. For more information see our Privacy Policy on our website. It is important you are aware of your individual rights and the provisions the company has put in place to protect your data. If you would like further information on the policy or GDPR us. Additional Resources Ltd is an Employment Business and an Employment Agency as defined within The Conduct of Employment Agencies and Employment Businesses Regulations 2003 :",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Construcción, Dotación y selección de personal, Servicios financieros",0,None,False,,8,None
871,2207118939,2020-11-02,QUOR,Data Engineer - Web Crawler,India,"A full-time long-term project with an exciting venture-funded startup out of the US (Silicon Valley, NYC, Tel Aviv, and India) and a giant media/tech Partner building a new type of solution that has the potential of changing the way we search and consume content online. The project was initially tested successfully in Wall Street and now we are taking it mainstream.  Job Responsibilities : As a Web Crawler, your role is to apply your knowledge set to fetch data from multiple online sources. Develop a deep understanding of our vast data sources on the web and know exactly how, when, and which data to scrap, parse and store this data. Develop frameworks for automating and maintaining constant flow of data from multiple sources.  Skills and Qualifications : Having 2+ years for experience in building crawler/web-scrapping application using Python. Strong knowledge of Scrapy and Selenium. Coding experience (Python or C#), with emphasis on APIs and Multithreading.  Experience in large scale architecture (in particular in web crawling), as we download and parse huge amounts of data.  Strong algorithmic skills. (For example, we develop algorithms to detect and remove the surplus 'clutter' (boilerplate, templates) around the main textual content of a web page.) Experience in databases, preferably MySQL and Redis.  Proficient knowledge in Python language with hands-on experience around Database integrations. Experience with data parsing, data mining and data analytics etc. Experience with data visualization is preferred  If you are a workaholic, love coding, can communicate clearly and effectively, responsible, can work easily and quietly from home, can attend sprint planning, and enjoy working remotely with other developers, product managers and designers (in the same and different time zones) - then this can be your new long term job.",Sin experiencia,Jornada completa,Tecnología de la información,Internet,66,None,True,,219,JOB_SEEKER_QUALIFIED
872,2280447037,2020-11-05,DISYS,Sr Data Engineer (Python),United States,"312658 – Sr Data Engineer – 100% Remote – 2m C2H  We are looking for a senior data engineer in a small dynamic group that requires the ability to see a solution from source, to the data warehouse and the final customer reports. The role will require an individual that is comfortable translating senior staff and department business needs to actual deliverables. The engineer will require demonstrable skills working in the Cloud and traditional data centers. Duties for this role – ﻿·        20% Analyze users’ needs and then design, test, and develop Tableau reports, SQL and Python feeds·        20% Upgrade Tableau Server, Postgres and Linux servers for customers’ existing and new programs and systems·        20% Design each piece of our data lake and systems and plan how the integrate the various existing and new sources via traditional RDBMs, APIs, etc.·        5% Create a variety of models and diagrams (such as flowcharts) that show customers and developers via LucidChart or Visio·        20% Ensure that our code, feeds and ETL continue to function normally through software maintenance and testing·        5% Document every aspect of an our ETL, applications and systems as a reference for future maintenance and upgrades·        10% Collaborate with the various teams such as developers, devops, marketing and finance to maintain and create new reports Requirements – ·        MS/BS in Computer Science or related field·        5+ years of industry experience·        3+ years of experience with Python·        Tableau (Nice to Have) ·        Ability to create and tune complex SQL·        Expert development skills in Python for Cloud and RESTful APIs·        Ability to create and work with complex shell scripts (Bash etc)·        Hands-on experience with schema and scalable data design·        Experience and in depth understanding of ETL development·        Experience with Agile methodology using Jira·        Experience with source control tools and healthy development guidelines (Github)",Intermedio,Contrato por obra,Tecnología de la información,Servicios y tecnologías de la información,33,None,True,,101,ACTIVELY_HIRING_COMPANY
873,2283698651,2020-11-04,"Logic20/20, Inc.","Data Engineer - Python, Databricks & Azure (Remote/Contract) - Seattle","Seattle, WA, US","Data Engineer - Python, Databricks & Azure (Remote/Contract)About the role. . .In order to continue and accelerate our growth, we are looking for a Data Engineer with Cloud Solutions background to add to our Seattle, Washington-based team.The engineer is responsible for building a large-scale data pipeline in cloud platform. This may involve in automation of manual processes to cloud environment. Candidate would direct the initiatives for creation of data sets. Delivering client value and ensuring high client satisfaction.Core responsibilities for this position include, but are not limited to the following:* Extracts data from various databases* Perform exploratory data analysis, cleanses, massages, and aggregates data* Productionize ETLs, schemas, and databases* Employs scaling & automation to data preparation techniques* Researches relevant emerging tools and techniques* Possesses in-depth business knowledge in order to initiate and drive discussions with business partners to identify business issues needing analytic solutions* Leads innovative packaging and presentation of insights to business and broader analytics community* Develops processes to automate and scale insights operationalization* Establishes brand and team as subject matter experts in advanced analytics across departments.Required Qualifications:* Experience with Azure Databricks and Spark preferred* Minimum 5 years hands-on experience with Python* Proficient in SQL* Knowledgeable of relational database and ETL practices* Experienced in the software development lifecycle* Demonstrated experience in a cloud-based computing environment such as AWS, Azure, or Google Cloud* Big data processing techniques, preferred* Can work independently in ambiguous environmentAbout Logic20/20. . .Logic20/20 is one of Seattle's fastest-growing consulting firms. We hire remarkable people to create simple, efficient solutions for complex problems.Although we make it look like magic, our success is due to our approach (methodical and structured) and the people we hire (smart, motivated, and team oriented). Together, these enable us to consistently exceed client expectations-and our reputation is growing.For the past five years, we've placed in the top ten of Seattle Business magazine's 'Best Companies to Work For'. From engaged leadership and wide-ranging benefits to career mentorship and diverse internal opportunities, we pride ourselves on being one of the best companies to work with and work for.We hire people that are self-motivated, comfortable conceiving strategies on the fly, and enjoy working individually and as part of a team. Our work is high-energy and demanding, but new hires will quickly feel at home among colleagues as friendly and focused as they are. We bring our best to every opportunity, driving change in industries across the West Coast. Join us and you can, too.",Sin experiencia,Contrato por obra,Tecnología de la información,"Servicios y tecnologías de la información, Software, Internet",0,None,False,,8,ACTIVELY_HIRING_COMPANY
874,2269867835,2020-10-09,ClassDojo,Senior Data Scientist / Product Analyst,"San Francisco, CA, US","ClassDojo's ultimate goal is to create an education system that gives every child on Earth an education they love. We are doing this by bringing together communities of teachers, children and families, and then helping them get learning experiences their children love. Last school year, we served over 40 million children—with a team of just 45.  Data is core to how ClassDojo makes decisions. As our third Data Scientist / Product Analyst, you'll help build a global consumer education business reaching tens of millions of parents, teachers, and children by creating, monetizing and analyzing products,. You'll grow ClassDojo to our next major milestone: reach 100 million+ active families, and 100 million+ in revenue, while deepening our brand love.  As a data science team, we work closely with partners across product, engineering, design, research and marketing to develop business insights and inform product and company strategy. We're looking for high-performing generalist data scientists, with experience in product and/or business analytics, to come work alongside us to take on some of the most interesting and impactful problems in education.  You'll drive high impact product and business decisions as part of a high performing, cross-functional team, where we value learning quickly to build a modern education system for hundreds of millions of teachers, children and families. You'll pursue a variety of problems ranging from understanding our users, to ensuring we invest in the right growth strategies in each of the 180+ countries we operate in, to growing our community, to empowering teams to find their own answers. You'll work with colleagues across the business to uncover insights, design experiments and measure the impact, and ultimately help influence decision-making across the entire company.  What you'll do:  Help the company grow from 10M+ to 100M+ users and $10M+ to $100M in revenue through rigorous quantitative insights  Build a company-wide discovery and delivery culture informed by rigorous quantitative insights Partner with company leadership, product managers, engineers, marketers, designers, and operators to define product and business strategy and direction Develop analytical frameworks to monitor business and product performance, including growth and engagement Identify opportunities for growth by designing and analyzing product experiments, working with cross-functional teams to translate insights into action   Relevant Skills / Experience  6+ years of industry experience in a data science or analytics role Proven track record of using data to identify & drive high leverage product or business opportunities Ability to write structured and efficient SQL queries on large data sets Experience designing AB/multivariate tests and drawing actionable conclusions Ability to visualize and communicate insights to stakeholders Americas timezones Bonus: Experience with data pipelines: transforming raw production and external data into user-friendly tables.   About ClassDojo  ClassDojo's mission is to bring communities together, and help them create an education experience their children love. Founded in 2011 (ImagineK12 / Y Combinator) and based in San Francisco, California, ClassDojo started as communication app: a simple way for teachers, families, and children to share the magic of the school day through photos, videos, and messages. It creates a close-knit classroom community, and exciting, inspiring and creative classrooms and homes for kids. We're one of the fastest growing education companies of all time, used and loved by tens of millions of teachers, families and children in 90% of K-8 schools in the US, and 180 other countries.  You can read more about our vision to change education from the ground up here: https://medium.com/@samchaudhary/https-medium-com-samchaudhary-how-to-change-education-from-the-ground-up-f82b8f3e4b95.  The Team  We believe focused, talented, non-hierarchical teams can achieve a surprising amount: https://blog.ycombinator.com/its-surprising-how-much-small-teams-can-get-done-sam-chaudhary-of-classdojo/. Our team is made up of engineers, designers, and educators from around the world, with deep backgrounds in education, as well as from leading consumer internet organizations like Instagram, Netflix, Dropbox, Uber, Y Combinator and more. We're building a company that will transform education, and one that is the kind of place we've all always wanted to work. We believe you'll do the best work of your life here.  Diversity  ClassDojo's vision is to give every child on Earth an education they love. We strongly feel the best way to do this is to work with people from diverse backgrounds that truly reflect the world. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. In accordance with the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records. We are happy to accommodate any disabilities or special needs. We hire both locally in San Francisco, and distributed teammates around the world.  If you're excited about having an impact in education at massive scale, we'd love to hear from you.",Algo de responsabilidad,Jornada completa,Otro,"Servicios y tecnologías de la información, Software, Internet",2,None,False,,13,COMPANY_RECRUIT
875,2152097944,2020-10-31,CrowdStrike,Data Engineer - Cloud (Remote),"Sunnyvale, CA, US","At CrowdStrike we’re on a mission - to stop breaches. Our groundbreaking technology, services delivery, and intelligence gathering together with our innovations in machine learning and behavioral-based detection, allow our customers to not only defend themselves, but do so in a future-proof manner. We’ve earned numerous honors and top rankings for our technology, organization and people – clearly confirming our industry leadership and our special culture driving it. We also offer flexible work arrangements to help our people manage their personal and professional lives in a way that works for them. So if you’re ready to work on unrivaled technology where your desire to be part of a collaborative team is met with a laser-focused mission to stop breaches and protect people globally, let’s talk.  About The Role  The data engineer in the cloud security product group will take a pivotal role in a hyper-scale data platform and pipeline for real-time security detections. This is a hands-on data engineering role that spans design and development for both sql and no-sql databases as a foundation of core cloud security capability.  Job Responsibilities Design, develop and maintain a data platform that data pipeline at scale. Participate in technical reviews of our products and help us develop new features and enhance stabilityContinually help us improve the efficiency of our services so that we can delight our customersHelp us research and implement new ways for both internal stakeholders as well as customers to query their data efficiently and extract results in the format they desire  Qualifications For Data Engineer  We are looking for a candidate with a BS and 5+ years or MS and 3+ years in Computer Science or related field. They should also have experience with the following software/tools - A solid understanding of algorithms, distributed systems design, and the software development lifecycleExtensive experience with Graph Data design and development. Solid background in Java/Scala and hands-on experience of building large data streaming pipelines (i.e., Spark, Kafka or others)Extensive experience with the Apache Hadoop ecosystem including Hive, Presto, etc.Extensive experience with relational SQL including Postgres. NoSQL including Cassandra.Experience with AWS or GCP tools (i.e., EMR, BigQuery, EC2, Lambda, S3, etc.) is a plus.Good test-driven development disciplineReasonable proficiency with Linux administration toolsProven ability to work effectively with remote teams  Experience With The Following Tools Is Desirable KubernetesJenkinsParquetProtocol Buffers/GRPC  Benefits Of Working At CrowdStrike Market leader in compensation and equity awardsCompetitive vacation policyComprehensive health benefits + 401k plan Paid parental leave, including adoptionFlexible work environmentWellness programsStocked fridges, coffee, soda, and lots of treats  We are committed to building an inclusive culture of belonging that not only embraces the diversity of our people but also reflects the diversity of the communities in which we work and the customers we serve. We know that the happiest and highest performing teams include people with diverse perspectives and ways of solving problems so we strive to attract and retain talent from all backgrounds and create workplaces where everyone feels empowered to bring their full, authentic selves to work.  CrowdStrike is an Equal Opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex including sexual orientation and gender identity, national origin, disability, protected veteran status, or any other characteristic protected by applicable federal, state, or local law.  CrowdStrike participates in the E-Verify program.  Notice of E-Verify Participation  Right to Work",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Servicios financieros",97,None,False,,781,ACTIVELY_HIRING_COMPANY
876,2289766219,2020-10-14,ClearedJobs.Net,Big Data Engineer - Remote Work,"Herndon, VA, US","Big Data Engineer  Location: Remote  You should be able to effectively communicate with both technical and business stakeholders for requirements analysis, and will be highly proficient in the technical architecture, design, and development of database design. You must be a driver and help clients truly understand the data and how it moves.  Essential Duties & Responsibilities  Design and perform all activities related to big data architecture solutioning components between environments during development and deployment.Work with Business Analysts and leads to transition the functional understanding of development assignments to themselves and developers they supervise.Design, code and component test Hadoop components using Nifi and Kylo.Provide Project, ITE, ODTR and Production support including analyzing incidents and identifying root cause.Update status of assignment in sprint plan tool.Work with Data Lake development leads along with Business Analyst Lead and Reporting lead to manage sprint plan and backlog.Work closely with Contractor Program Manager, Lead Business Analyst and Lead Tester to size and plan work.Other duties as assigned.Work with Data Scientist to curate datasets for AI/ML initiatives.  Knowledge, Skills, And Abilities  Experience with Big Data technologies including Hadoop, Hive, Nifi, Spark, Databricks and/or Kylo.Exhibit exceptional technical skills in database architecture, database design and ETL/ELT. Displays knowledge of the proper way to adhere to the Software Development Life Cycle (SDLC). Demonstrate tool expertise in front end and backend tools.Excellent analytical and problem-solving skills to quickly recognize, isolate, and resolve technical problems.Hands-on experience with implementation and support of a business intelligence reporting suite.Understand business requirements and able to create/propose solutions. Knowledge of SQL and Python.Infrastructure as a Service (IaaS), Platform as a Service (PaaS), and/or Software as a Service (SaaS) Ability to work independently, prioritize tasks appropriately and adapt quickly to project changes.  Education, Experience, & Certifications  Minimum of 7-10 years of experience.Bachelor’s degree in Engineering, Mathematics, Computer Science, Information Systems, Economics or Business, or equivalent.Hold appropriate certifications.  Benefits  Great Culture focused on our customers and team membersVHB offers a compensation plan consisting of a competitive base salaryEmployee Health coverage with Dental options401k plan offeringsPaid holidays and vacation Hold appropriate certifications.  Privacy Policy  VHB Global, Inc. is an industry leader, providing professional services including but not limited to: training specialists, linguists and field subject matter experts, in addition to operational and training support customers in the defense, intelligence, federal and commercial sectors.  VHB Global, Inc. is an Equal Opportunity Employer and supports diversity in the workplace. Applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability, veteran status, marital status or sexual orientation.  Due to Federal Contract Regulations, U.S. Citizenship is required for these positions.",No corresponde,Jornada completa,"Ingeniería, Tecnología de la información","Manufactura eléctrica/electrónica, Construcción, Departamento de defensa y del espacio exterior",0,None,False,,None,None
877,2250273464,2020-10-19,Interos Inc,"Senior Data Engineer, Kafka","Arlington, VA, US","Interos, founded by Jennifer Bisceglie, is one of the most transformative technologically advanced platforms that powers the global economy supply chain. By using ML and big data, Interos aspires to dynamically and continuously map all of a company's business relationships to multiple tiers of dependency on a global scale and endeavors to help customers understand risk in their multi-tier, global supply chains. The scope of this value proposition extends across a variety of different technology sectors including risk management, supply chain intelligence, financial intelligence and cyber-security. Interos has raised $26M in total funding from Venrock, led by Nick Beim, and Kleiner Perkins, led by Ted Schlein. We have 70+ employees and are poised to double in size by end of 2020. Our offices are headquartered in Arlington, VA and we have presence in Menlo Park, CA.  We need an extraordinary team member who thrives as part of a fast-paced team and takes pride in their ability to succeed while delivering value to our customers. Be challenged by innovation and grow professionally by solving one of the most interesting challenges impacting businesses across the globe.  The Opportunity:  Looking for expert technical leadership to help us design, build, and iterate our next generation platform. As someone who has successfully implemented a significant Kafka based machine learning or data analytics pipeline you can help us make the right choices and avoid mistakes as we build a scalable, reliable, and fully automated supply chain risk management system for our exponentially growing customer base. You will be working with a collaborative team of highly skilled and constantly learning software engineers and data scientists who value good ideas and the ability to create quality solutions.  Essential Functions/duties:  Lead Kafka topic topology design Own Kafka message schema evolution Write Kafka producers and consumers in Python Guide data and machine learning engineers on best practices regarding Kafka Design and build near real-time data analytics pipelines Pitch in wherever needed to meet team goals and deliver a quality product  Minimum Qualifications:  Strong Python coding skills Real world experience with production Kafka event streaming pipeline Experience with Kafka topic topology design Experience with Kafka streams Ability to communicate clearly and willingness to share knowledge and collaborate Minimum years of relevant experience: 5+ years software engineering experience Minimum education level: Bachelor's Degree, Computer Science or related field or equivalent  Preferred Qualifications:  Comfortable working with Docker and Kubernetes Experience with cloud services in general and AWS in particular   Benefits  Comprehensive Health & Wellness package (Medical, Dental and Vision) 10 Paid Holiday Days Off Accrued Paid Time Off (PTO) 401(k) Employer Matching Stock Options Career advancement opportunities Casual Dress On-site gym and dedicated Peloton room at headquarters Company Events (Sports Games, Fitness Competitions, Birthday Celebrations, Contests, Happy Hours) Annual company party Employee Referral Program   Interos is proud to be an Equal Opportunity Employer and will consider all qualified applicants without regard to race, color, age, religion, sex, sexual orientation, gender identity, genetic information, national origin, disability, protected veteran status or any other classification protected by law.  If you are a candidate in need of assistance or an accommodation in the application process, please contact HR@interos.ai",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Internet",0,None,False,HR@interos.ai,12,ACTIVELY_HIRING_COMPANY
878,2226322667,2020-10-05,Horizontal Talent,Senior Data Scientist,"Santa Ana, CA, US","Projects The Candidate Will Be Working On  1) Field Team Modernization/Intelligent Decision Management - build and support of new predictive data models  2) Coding Transformation - build and support of new/existing predictive data models  3) Ad hoc data analysis   Team And Team Size  Individual contributor within Decision Intelligence team.   Top Responsibilities  Analytic data model development  Quality check of output from other developers  Data exploration/research  Documentation of logic and results  Presentation of logic and results to team and stakeholders.   Skills/attributes  Programming: SQL, Python, Spark, Hive  Libraries: Scikit-Learn, Numpy  Analytics: Regression, Classification, Clustering, (Decision Trees, SVM, Linear Regression, Logistic Regression, KNN, KMeans)  Visualization: Matplot  Systems: UNIX, Windows  Soft: Integrity, strong verbal and written communication, teamwork, creativity  Experience: 3-4 years related field.   Nice To Have  Analytics: Neural Networks, Graph Computation, Approximate Nearest Neighbors, Time Series, NLP  Visualization: Tableau, Plotly, Excel  Infrastructure: Big Data, Cloud Computing, High Performance Computing (GPUs)  Experience: 5+ years related field .  ,",Algo de responsabilidad,Jornada completa,Otro,"Marketing y publicidad, Servicios y tecnologías de la información, Software",13,None,True,,32,ACTIVELY_HIRING_COMPANY
879,2271529849,2020-10-16,Amber Resourcing,Amber Resourcing: Machine Learning Engineer (Remote),"Buckinghamshire, GB","Machine Learning Engineer | £60,000 £85,000 (Remote)Deep Learning | Machine Learning | Video | Python | Signal ProcessingWant to get involved with a Deep Learning specialist?This deep learning ...  PLEASE NOTE: This is a job supplied by a trusted partner. In order to read the full job description please click the 'apply now' button. If you are a registered site member you will be passed straight through. If not, then you will be asked to register a free account with us",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Software, Internet",2,None,False,,11,JOB_SEEKER_QUALIFIED
880,2289166283,2020-11-07,Rishabh Software,Director of Data Science Remote - Rishabh Software Pvt. Ltd,"Alabama, AL, US","Title: Director of Data Science  Location: Remote  Notes  Need strong Python/R and Spark experience with backgrounds in ML/AI (SciKitLearn, XGBoost, PyTorch/TensorFlow) in addition to team management skills.  If and as we see strong Data people with backgrounds in SaaS specific products alongside the other needed skills pass along for your review as well. Director level Data Scientist: about half manager/half technical do-er. The CEO is a programmer and a highly technical person, that paints the picture.   Summary  We are seeking an ambitious, well-rounded Director of Data Science to run a Data Science department for an award-winning, venture-backed, fast-growing company. This role will play a key role in our growing Data Science team and provide strategic insights on how best to operate this side of the business.  This role offers a unique opportunity to work on very large data sets and solve challenging business problems focused on recommendation systems, machine learning, deep learning, and NLP. If this sounds intriguing, then we would like to talk to you about this key role leading our technical team.  This position is half manager and half technical individual contributor. It is a roll-up the sleeves management role, responsible for a team of 7 technical personal and engineers.  Responsibilities  You'll join a team of ML Engineers and Applied Research Scientists to make recommender systems as simple as possible.  You are able to lead in a collaborative fashion as well as advise and interact with the Product team and C-Level stakeholders. You possess strong communication skills and can clearly communicate a vision, and drive innovation. You will have a demonstrated history of implementing ML solutions into a production environment. you will possess exceptional knowledge of Python or R (using libraries and writing custom code), and Artificial Intelligence. Experience with Natural Language Processing (NLP) is also considered an asset   Required Skills And Experience  10+ years of experience leading a multi-faceted technical data science team As the ideal candidate, you will have multiple degrees in Computer Science, Statistics, Mathematics, Engineering, or Computational Science as well as a history of solving difficult problems using a scientific approach. Strong experience and knowledge in Machine Learning (ML), or Artificial Intelligence (AI) Experience with feature engineering and storing (Spark, dataflow, etc.) A deep understanding of algorithms and evaluation methods used in production-grade content recommender systems. Experience deploying recommender systems into production across a range of models and platforms. Hands-on practice of ML using machine learning libraries and frameworks such as SciKitLearn, XGBoost, PyTorch/TensorFlow. Excellent interpersonal skills are required, along with the ability to work in a dynamic, product-oriented, global team. You understand the entire lifecycle of machine learning product development, from inception to production.  provided by Dice",Director,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Software, Internet",0,None,False,,4,None
881,2247059646,2020-10-02,Socure,Sr. Data Engineer - Data Platform,"New York City, NY, US","Socure is looking for a Senior Data Engineer to join our US engineering team and build our data platform.  In our mission to become the single, trusted source of identity verification and eliminate identity fraud from the internet, data is at the core of what we build. It's how we innovate and how we offer the most accurate Identity Verification on the market.  With the company growing very fast and our customer needs even faster, the only way for us to succeed in our mission is to significantly scale how we work with data.  We are in the early days of designing a data platform to accelerate all our data operations and unlock the creation of our future products, and we'd love you to join us and lead the way  What You'll Be Doing:   You will work in close collaboration with our Engineering, Data Science, Infrastructure and Product teams to design and deliver core parts of our data platform. Own the end-to-end delivery of projects related to our data platform initiative, from conception and design to development and production monitoring. Enable our Data Scientists to perfect our products and expand our offering and offer easy and secure access to data for engineering teams to deliver faster. You will democratize access to data and aim to automate operations of large amounts of sensitive data efficiently, securely and reliably.  What You'll Bring:   You are comfortable working cross-functionally to ensure technical alignment. You like to think at scale and design, develop and operate production data stores, pipelines and services that meet goals of low latency, high availability, resiliency, security and quality. You develop with an empathy for people and how they use your work. You have experience designing data pipeline systems, ETLs or setting up large scale datastores and have used technologies like: Hadoop, HBase, S3, Kafka, Spark, DynamoDB, Hudi or Delta Lake, Elasticsearch. You use your technical experience to educate your peers in data engineering technologies, best practices and platform thinking. Exposure or familiarity of data privacy & regulations eg. GDPR, CCPA (CA) or PII. 3+ years of practical experience in building high scale, production distributed systems.   Who we are:  Founded in 2012, Socure is the leader in high-assurance digital identity verification technology. Named to Forbes' 2019 AI 50 list as one of America's most promising AI companies, a recent winner of API World's Best Data API and named to Inc. Magazine's Annual List of Best Workplaces 2020: Socure's technology applies artificial intelligence and machine learning techniques with trusted online/offline data intelligence from email, address, phone, IP, social media and the broader Internet to verify identities in real-time. Our fast growing list of customers include three of the top five U.S. banks, seven of the top 10 U.S. card issuers, as well as the majority of leading digital banks, lenders and insurers across the U.S. We are funded by some of the world's best investors and entrepreneurs including Scale Venture Partners, Commerce Ventures, Work-Bench, Santander InnoVentures and Two Sigma Ventures.  Perks & Benefits:   Competitive base salary Equity - every employee is a stakeholder in our enormous upside A tech-first company culture driven by entrepreneurial thinking and talent A great team working in unison towards the same mission Transparency is what our product is built on—and so is our culture Generous medical, dental and vision benefits for employees and their dependents Flexible PTO 401K with company match Free meals",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Internet",None,None,False,,19,ACTIVELY_HIRING_COMPANY
882,2290851370,2020-10-14,Springboard,Mentor - Data Engineering Course (Part-Time/Remote) - San Francisco,"San Francisco, CA, US","The Opportunity Springboard runs an online Data Engineering Career Track in which participants learn with the help of a curated, project-based curriculum and 1-1 guidance from an expert mentor.Our mentor community - the biggest strength of our programs - comprises experts from the best organizations in the world. The Data Engineering Career Track will have Data Engineers, Data Developers, and other leading data experts at premier companies (e.g. Uber, Pandora, LinkedIn, Apple) and top-notch startups.If you are as passionate about mentoring as you are about Data Engineering, and can give a few hours per week in return for an honorarium, we would love to hear from you.Questions? Please write to us at mentors@springboard.com   The Program  Completely online and self-paced  Designed to be completed in 6 months  Coursework is made up of 450+ hours curated curriculum in collaboration with leading Data Engineering subject matter experts (SMEs)  Participants in this course are working professionals and college students from all over the world looking to become Data Engineers or apply Data Engineering to advance their careers  Students learn about Data Engineering with the help of a curated online curriculum, project-based deliverables and a personal mentor  Students have a weekly 30-minute video call with their mentor to discuss questions, projects, and career advice!  You  Are as passionate about teaching Data Engineering as about Data Engineering itself  Have at least 3 years of experience as a Data Engineer or Data Developer or related fields (Machine Learning, Data Scientist, etc)  Professional experience with SQL and an OOP language like Python or Java  Have an excellent understanding of fundamental data engineering skills, tools, and concepts including working with Big Data (Hadoop, Spark), Cloud platforms (AWS, Azure), building data pipelines (batch/streaming, APIs), orchestration (Airflow), and containerization (Kubernetes, Docker).  Have at least 3 years of experience solving real-life data engineering problems, and are comfortable working with large data sets  Are available for weekly, 30-minute video check-ins with students to help them set and achieve learning goals, answer subject matter questions, provide feedback on projects, and career advice  Are able to provide some limited support outside of calls to answer questions and review projects   Are empathetic and have excellent communication skills, able to break down complex concepts for beginners, and provide meaningful career guidance Benefits  Membership in a rich community of expert mentors from great companies like Apple, Uber, and Pandora  Change the lives of students in our program  Help us revolutionize online education and inspire career changers into Data Engineering!  Receive a monthly per-student honorarium  Work at your convenience We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.The Springboard team of 180 works out of offices in the heart of San Francisco and Bengaluru. We’re backed by top investors, including Costanoa Ventures, Reach Capital, Learn Capital, Pearson Ventures, and the founders of LinkedIn and Princeton Review.Working with us, you’ll enjoy competitive compensation, health insurance coverage (for employees based in California, our base plans are fully covered by Springboard: for employees based outside of California, we offer low-premium coverage), a 401k plan, a generous learning budget, team lunches and snacks, and an opportunity to impact thousands of lives alongside a fun, dedicated and mission-driven team. To learn more about our team and culture, follow us on Instagram !We are an equal opportunity employer and value diversity at our company. We welcome applications from all backgrounds, and do not discriminate on the basis of race, religion, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",Algo de responsabilidad,Media jornada,Otro,"Software, Internet, Servicios financieros",0,None,False,mentors@springboard.com,1,JOB_SEEKER_QUALIFIED
883,2247067075,2020-10-05,Vee,NLP Data Scientist Internship (REMOTE),"New York City, NY, US","Position: NLP Data Scientist Intern (REMOTE)  Reports to: CTO  Location: Remote  Are you passionate about exploring where, how, and why data can drive business decisions? Interested in how organizations use analytics and data to innovate, grow and transform? Driven to help establish, define, and evangelize how data science can help drive a strategy?   Company Overview  Vee inspires people to align on Purpose so they can unlock their individual and collective human potential. We are an early stage startup poised for dramatic growth. We specialize in developing ways to drive greater strategic alignment to unlock enterprise innovation and growth. After spending considerable time exploring the need for better alignment models across diverse organizations, we have developed a framework and methodology based on insights from extensive research. We are building products to assess gaps and are offering our consulting services to help 21st century leaders develop and implement their organizational and people strategies, along with the capabilities required to operationalize their Purpose as they transform.  Position Overview  Join our fast-growing team! You will help drive intelligent, insightful, and predictive business results to help Vee and Vee's clients drive value in the realms of people, purpose, and performance. You will help build Vee's data capability and data strategy.  General Responsibilities  Design and execute Natural Language Processing experiments to help advance Vee's strategy  Research and run topic analysis on targeted content  Scrape targeted content from social media and open Web sources Collaborate with Data Engineering, People Science, business partners, and Chief Technology Officer to create robust NLP pipelines using AWS Comprehend Communicate results and ideas to key stakeholders at Vee   Core Experience & Requirements  Masters degree in Computer Science, Applied Statistics, Applied math, Data Science, or a related field Previous experience running NLP projects, ideally in a corporate or startup context  Practical experience with multiple statistical languages (SAS, R, Pandas), data processing, database programming, and data analytics Solid background in data mining and statistical analysis Experience with programming languages such as Python and R Knowledge of data visualization tools (e.g. Tableau) Strong collaboration skills - you partner well with others to solve problems and actively incorporate input from various sources Excellent oral and written communication skills Working with key stakeholders to drive business results  Profile  Purpose is what drives you. Your passion for your work has led you here. You are ready to combine your experience with ours to help our client companies gain competitive advantage. You bring strong creative thinking skills in addition to superior communication skills, allowing you to develop creative solutions for any challenge that comes your way.  You:  Love what you do, love to be busy, and love to produce by being organized and methodical Work with a sense of urgency and have a strong drive for results Have the resilience and agility to adapt quickly in a fast-paced environment Work independently as well as collaboratively to stretch thinking into creative solutions Have strong verbal and written communication skills Are excited about and suited for a startup, where you'll be wearing a few hats Are smart and fun with an empathetic nature, which will add to our culture   About Vee  Our founders and team have deep expertise in branding, innovation, design, I/O psychology, organization design, digital & data product development, enterprise software and application development complemented by experience with clients ranging from emerging Silicon Valley unicorns to established leaders in government and the public and private sectors including American Express, Bank of America, BMW, Box, HP, Lowe's, Mastercard, Microsoft, Nissan, Pepsico, Procter & Gamble, SAP and The Clorox Company, among others. For more information, check out our website in transition at https://www.letsvee.com/.",Prácticas,Prácticas,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Software, Internet",63,None,False,,324,ACTIVELY_HIRING_COMPANY
884,2272715526,2020-10-10,Amicus Recruitment,"Senior Golang Engineer - London / Remote in UK - £90,000","London, GB","Job DescriptionpSenior Golang Engineer - London / Remote in UK - £65,000 - £90,000/p pDo you want to work with a health-tech business who are building a platform to save lives? If so, we are delighted to be exclusively working with a health-tech cash rich start-up who are looking for a Senior Golang Engineer./p pThe business founded 3 years ago, already have their SaaS in use with several NHS trusts and private hospitals, currently employ 20 people with 12 in their current technical team. Their platform is extremely complex with many different components to it and are looking for a Senior Backend Engineer to take ownership of their backend system. You will work alongside their engineering team of 12, consisting of 4 mobile developers, 3 front end developers, 1 data scientist, 2 testers, 2 designers and a very hands-on technical CTO. They have a brilliant mission as a company and a fantastic long-term aim which is to save millions of lives, using their cutting-edge technology platform./p pThey have a brilliant culture, with communication being so important whether that is on Slack, face to face or video calls. As they have a distributed team, with some of the current development team based in Asia, you have the option to work remotely anywhere in the UK providing you can come into the office every 3-4 weeks for a team meeting and for a team catch-up./p pThey work with a very cutting-edge tech stack, with the system built in Microservice architecture on distributed systems, with a real angle of Machine learning. Whilst you do not have to have any machine learning experience, this is something you could get great exposure to. They are hosted on GCP and the system is all deployed on Docker and Kubernetes, where you will be able to have a real influence on the technology stack as the company evolves and grows. As the first Senior hire on the backend side, you will help grow the team to 3-4 backend engineers over the next 12 months and help the business solve some extremely challenging engineering problems. To be considered for the role you will be expected to have the following skills and experience:/p ul li4 years software engineering experience/li li18 months experience with Golang/li liExperience with Microservice architecture/li liGood exposure to Devops tools like Docker, Kubernetes, Terraform etc/li /ul pIf you have a passion and desire to learn machine learning and have experience with CI/CD, this will be considered highly advantageous./p pThey have fantastic package with starting salary between £65,000 - £90,000 Doe as well as good equity options, private healthcare plus many more./p pIf you want to be work for a business where you can have real influence and build a platform that will save lives, then please do reach out to be considered for immediate interview slots./p pSenior Golang Engineer - London / Remote in UK - £65,000 - £90,000/pimg src='",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información",Software,None,None,False,,8,ACTIVELY_HIRING_COMPANY
885,2279217690,2020-10-11,MinTech Agency ~ Diversity Recruiting,Sr. Data Engineer,"Nashville, TN, US","Remote Sr. Data Engineer  We are looking for an exceptional Data Engineer to design scalable, reliable, secure, and extensible data solutions according to our company’s and client’s needs. You will be responsible for developing, testing, improving and maintaining new and existing line of business data platforms, data warehousing, and streaming data solutions to help effectively provide and manage data effectively.  As part of our team, you will work closely with data engineers, software engineers, and quality assurance analysts to ensure system stability, security, and consistency. You will also collaborate with support teams to provide technical support and work with product owners to determine and understand new product requirements. Communication and organizational skills are key to this position along with a problem-solving attitude.  Responsibilities   Build, monitor, and maintain batch and streaming data solutions. Build, monitor, and maintain RDBMS solutions. Ensure performance, security, and availability of data solutions. Architect, Design, develop, and optimize data structures, stored procedures, and functions using T-SQL. Analyze existing data structures and data solutions to provide suggestions on performance improvements and alternate approaches. Prepare documentation and specifications. Effectively collaborate with other team members and stakeholders. Mentor Junior Engineers.  Requirements   6+ years strong working knowledge and experience with MS SQL Server databases, query authoring (SQL), T-SQL and schema design to optimize performance. Experience with other RDBMS with platforms such as PostgreSQL, MySQL, Oracle, etc. Experience with NoSql/Document Database platforms such as MongoDb, Casandra, Couchbase, DynamoDb, etc. Experience ingesting, processing, storing, and querying large datasets. Cloud experience preferably in AWS or Azure. Experience writing well-abstracted, reusable code components using languages such as python, C#, Go, etc. Experience with Git and CI/CD tools and paradigms. Understanding of SDLC and Agile development methodologies. Strong written and verbal communication skills. Bachelor’s degree preferred or relevant experience.  Preferred   Experience with Data Warehouse technologies such as Snowflake, Redshift, etc. Experience with stream processing and messaging platforms such as Kafka, Kinesis, SNS/SQS, RabbitMQ, etc. Experience using infrastructure as code to manage cloud services using tools such as Terraform, CloudFormation, Azure Resource Manager templates, etc. Experience with docker and serverless API’s. This is a remote position.",Intermedio,Jornada completa,Tecnología de la información,Atención sanitaria y hospitalaria,0,None,False,,2,JOB_SEEKER_QUALIFIED
886,2289175438,2020-10-22,inspHIRE Talent Solutions,Remote Sr. Data Scientist (SAS & Python expertise) - Contract,"Alpharetta, GA, US","3 - 4 month project with possible extension: Remote After many years on the SAS platform, our client is in the process of migrating 70-80 solutions/artifacts to Python and Google Cloud Platform (GCP). Current state is SAS and Hadoop for data wrangling, exploration, profiling, attribution, and modeling.Amongst other tasks, you will help our client's team of data scientists migrate from SAS to a Python and R based platform. You will help them develop the best approach and tools to use to speed up the migration activity. Work with the existing SAS owners/users to understand current process (reverse engineer) and develop the right approach to move the solution from SAS to Python/GCP.Other tasks include developing some of the new solutions in Python on GCP.Ideal candidate is SAS developer who has transitioned to Data Sciences (Python).  Required Skills Expert/senior advisor who can guide team in developing the best approach to migrate off of SAS and into the GCP environment.Excellent communication and customer service skills: team player.3+ years SAS3+ years as a Data Scientist3+ years Python1+ years Cloud (Google Cloud Platform/GCP is preferred)  Preferred Skills HadoopFinancial Services  CANDIDATES MUST BE EMPLOYABLE AS W2 CONSULTANTS. NO C2C, 3RD PARTIES, VISA SPONSORSHIP/TRANSFER ***",Algo de responsabilidad,Contrato por obra,Otro,"Marketing y publicidad, Software, Internet",0,None,False,,1,JOB_SEEKER_QUALIFIED
887,2166034571,2020-10-07,IronNet Cybersecurity,Principal Cyber Data Engineer (Remote/Virtual),"Los Angeles, CA, US","Description  What’s your mission?  IronNet’s mission is simple: To deliver the power of collective cybersecurity to defend companies, sectors, and nations. For decades, companies have been defending against cyber attacks on their own while adversaries have been organizing themselves into sophisticated hacker networks … until now, with IronNet Collective Defense. In 2014, General (Ret) Keith Alexander, former Commander U.S. Cyber Command, launched IronNet to strengthen cybersecurity defense against highly sophisticated adversaries, across all borders and sectors.  In response to cyber adversaries who increasingly collaborate for collective offense, leading organizations in our critical infrastructure are using collective defense strategies and solutions to meet these powerful and ever-changing threats. We believe that collective defense is our collective responsibility and we are leading the charge.  The Opportunity  IronNet’s Analytics team is responsible for building behavioral analytics and event correlation code for our NDR and collective defense products. The team focuses on developing cost effective cloud solutions that are distributed and highly scalable, processing large volumes of events.  We are looking for a senior or principal level Cloud Data Engineer with focus on data pipelines and development of SaaS solutions to join the team.  To be successful in this role, you must be able to . . . Use AWS to provide microservices architectures that are highly reliable, redundant and scalableInterface data transformation, enrichment, and machine learning algorithms to cloud storage and messaging infrastructureUse modern programming languages (Python, Scala, Java, Golang, etc) to develop continuously integrated and deployed production software Architect horizontally scalable analytics and data processing pipelinesTurn proof of concept architectures into production environmentsShare knowledge and assist others in understanding technical topics You may be the person we need if your background aligns with the following . . . Proven experience as a Data Engineer, Machine Learning Engineer, Software Engineer, Cloud Engineer or similar role.Demonstrable expertise in a modern programming language(s) (Python, Scala, Java, Golang, etc.).Experience with SaaS architectures and delivering production software.Experience with Kafka, Spark, and other scalable data frameworks.Experience with cybersecurity event processing including high-volume ETL and analytics.Possess strong analytical, technical, and problem-solving skills.  Personal Profile Passion for championing projects from concept to delivery to customer.Competitive spirit: willingness and ability to “sell” your solution during collaborative team discussions.Desire to be the best and prove it every day.Eagerness to learn and improve your own skills and to make those around you better.Highly attentive to detail and a focus on improving the code base and quality of our tests.Commitment and aptitude to proactively find solutions to ambiguous opportunities.Bring a unique skill set or elevate the results of the teams you are a part of. Recognition & Awards  IronNet is recognized as a representative vendor in Gartner’s “Market Guide for Network Detection and Response (NDR)”, and Forrester recently named IronNet a representative vendor in its “Now Tech: Network Analytic and Visibility, Q2, 2020” research.  Recent Awards  CRN Emerging Vendors Fortress Cyber Security Hot 150 Cybersecurity Companies Fortress Cyber Security EMA Vendor To Watch CRN Security100  More About IronNet  IronNet delivers unmatched collective cyber threat detection for enterprise on-premise, cloud, and hybrid networks. We do this through the application of advanced behavioral analytics, AI, and machine learning techniques. Our team combines the tradecraft knowledge of the best offensive and defensive cyber operators in the world with world-class mathematicians and data scientists to engineer solutions that empower companies to defend against advanced threats.  Our founder and Co-CEO, General (Ret) Keith Alexander, is a recognized cybersecurity innovator and a frequent speaker about current cyberthreats and effective defenses. We have a leadership team with deep government and commercial cyber experience, and the company is advised by a board of esteemed security and venture investment professionals, including Jan Tighe Retired Vice Admiral, Former Deputy Chief of Naval Operations for Information Warfare and Director, Naval Intelligence, US Navy: and Jack Keane Chairman, Institute for the Study of War, Retired Four-Star General, Former Vice Chief of Staff, US Army.  Benefits Of Working At IronNet  IronNet strives to provide and takes pride in being able to offer comprehensive, essential and affordable benefits for our employees and their families. We offer an unlimited PTO plan, 401(k) match as well as Medical, Dental, Vision, and Disability Insurance.  All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, or protected veteran status, or any other legally protected basis, in accordance with applicable law.  Follow us on LinkedIn",Algo de responsabilidad,Jornada completa,Ingeniería,"Servicios y tecnologías de la información, Software, Seguridad del ordenador y de las redes",0,None,False,,17,None
888,2265009603,2020-10-07,Paige,Senior Data Engineer,"New York City, NY, US","Paige is on a mission to accelerate and transform the diagnosis and treatment of cancer. Paige is creating a digital platform for pathologists to transform their workflow and is developing a new class of computational diagnostics positioned to drive the future of pathology. A career at Paige is deeply mission-driven where you will work with state-of-the-art technologies alongside leaders in the field and to improve cancer care every day. We reach high, help each other succeed, and believe in creativity, curiosity, and creating amazing products.  We're seeking a Senior Data Engineer who will be working the development and support of software applications, tools and data management pipelines for research and clinical purposes. Following modern product development practices, you will also assist in the design, implementation and maintenance of tools that extract and manipulate data from various sources, including in-house and external databases. This is an extraordinary opportunity to be part of a high-performing team and to pursue a life-changing mission with unique technical challenges!  This position can be fully remote for U.S. based applicants.  Responsibilities  Work on Data Warehouse, Data Lake and BI projects and architectures at Paige. Create and implement ETL pipelines that enables the extraction, transformation and transfer of large amounts of structured and unstructured data from various filesystems and databases, that are destined for the development of computation pathology algorithms. Handle the challenges that come with managing terabytes of data. Build tools to manage, automate and monitor our data and data processing infrastructure. Design and develop software tools into existing resources. Be responsible for design, coding, testing, packaging, debugging, documentation and deployment of software systems. Work independently to produce required functional, technical, and user documentation (e.g., business requirements, functional and technical specifications, system architecture, data flows, end-users training requirements) on assigned projects. Work and collaborate with data engineers, scientists, engineers, IT operations and medical doctors to build tools manipulating data in order to build a new generation of artificial intelligence applications for cancer detection and treatment.   Requirements  Experience in architecting, implementing and testing data processing pipelines (e.g. Spark, Beam, ...) and data mining / data science algorithms either on-premise or on a cloud environment. Experience in administrating and ingesting data into standard data warehouses (e.g. Amazon Redshift, Microsoft SQL Server, Google BigQuery or Snowflake). Experience architecting data warehouses and/or data lakes for large amounts of structured and unstructured data. Experience with data lakes and expertise with designing and maintaining a BI solutions. Experience with workflow management tools and platforms, such as Airflow. Extensive experience in Python programming, or related languages. Experience with RDBMS and NoSQL databases (e.g. MongoDB). Experience in packaging and deploying applications on-premise and in the cloud (e.g. AWS). Familiarity with modern development practices and DevOps. Interest in building non-standard medical software applications, in collaboration with medical partners. Cross-disciplinary and strong analytic skills. Master's degree in computer science or a related field, or equivalent years of experience. 6+ years of industry experience as a software/data engineer.",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Atención sanitaria y hospitalaria",0,None,False,,16,ACTIVELY_HIRING_COMPANY
889,2190068323,2020-10-17,HashiCorp,Senior Data Engineer - Cloud Services,"Nashville, TN, US","About HashiCorp  HashiCorp is a fast-growing startup that solves development, operations, and security challenges in infrastructure so organizations can focus on business-critical tasks. We build products to give organizations a consistent way to manage their move to cloud-based IT infrastructures for running their applications. Our products enable companies large and small to mix and match AWS, Microsoft Azure, Google Cloud, and other clouds as well as on-premises environments, easing their ability to deliver new applications for their business.  Engineering at HashiCorp is largely a remote team. While prior experience working remotely isn't required, we are looking for team members who perform well given a high level of independence and autonomy.  Our Team  Cloud Services is an exciting team delivering HashiCorp products as managed services. We work across the company, and with multiple cloud partners, to make using HashiCorp products simple for our customers. We’re a small, but rapidly growing team, making a huge impact.  This Position  Location: Remote  As part of the Cloud Services organization, you’ll be a key part of a newly formed team tasked with building out our Analytics capabilities. This position plays a key role in data collection, processing, and reporting, analytics projects, and influencing key stakeholders with critical insights.  This is a chance to make a large impact across the team and company, by exposing data on our customers and the runtime information of our tools.  In This Role, You Can Expect To  Develop, construct, test, and maintain our Analytics platform. Discover opportunities for data acquisition. Develop data set processes for data modeling, mining and production. Recommend ways to improve data reliability, efficiency and quality. Contribute to the design and implementation of large-scale systems. Interface directly with internal teams, users, and HashiCorp customers. Work with multiple cloud platforms such as AWS, GCP, and Azure. Work with HashiCorp products such as Terraform, Consul, Vault, and Nomad.   You May Be a Good Fit If  You have built or operated a real time analytics pipeline at scale Have experience with tools similar to Segment, Looker, Heap, RedShift, RDS. You are familiar with microservice architectures, and ideally, have seen them in operation at a global scale. You have prior experience working in high performance distributed systems: while we strive to hire at a variety of experience levels, this particular opening is not well-suited for recent graduates. You are able to knowledgeably discuss design and performance tradeoffs in complex systems.   About The Application Process  Please note, as communication is a critical aspect of how we work, a cover letter is a great way to provide a sample of how you communicate. In your cover letter, describe why you're interested in working at HashiCorp, and what draws you to this role in particular.  HashiCorp embraces diversity and equal opportunity. We are committed to building a team that represents a variety of backgrounds, perspectives, and skills. We believe the more inclusive we are, the better our company will be.",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Internet",3,None,False,,39,ACTIVELY_HIRING_COMPANY
890,2244089429,2020-11-05,"Pinnacle Group, Inc.",Senior AWS Data Engineer / Architect,Dallas-Fort Worth Metroplex,"Job Description Design and develop best in class AWS cloud-based data management solutionsPlan and execute secure, good practice data integration strategies and approaches in AWSStudy existing technology landscape and understand current application workloads to optimize performance and identify cost saving opportunities within AWS environmentHands on development acquiring, ingestion, and processing data from multiple sources and systems into AWS and Snowflake data platformsCreate, deploy and manage data environments in the AWS cloudManage and document data footprint within the Data WarehouseLeverage information security principles to ensure compliant handling and management of dataDevelop architecture blueprints and detailed documentation in the AWS cloud environmentImplement AWS Cloud Services such as EC2, S3 EMR and data pipeline, etc.Architect and hands on implementation of solutions to improve current environmentsWork with insights and analytical team members to understand data requirementsProvide team leadership to data integration team membersHands on solution development leveraging relevant data management and integration technologiesArchitect MDM solutions & componentsLead, manage and guide technical project teams on all technical design and componentsOwn and drive strategic technical direction with team in AWS environmentDevelop, document and ensure adherence to standards and best practices and facilitate technology/solution checkpoints Requirements:﻿7+ years’ experience working on projects in a global setting, often working on multiple projects simultaneously5+ years’ experience designing cloud solutions incorporating Information Security principles and best practices to ensure designs are in accordance with regulatory data security and data governance principlesExperience leading teams of developers both onshore and offshoreExperience translating and documenting business requirements into conceptual, logical, and physical data modelsFull lifecycle solution development and deployment best practices for the AWS cloud environment5+ years’ experience with cloud data management technologies such as AWS Redshift and Snowflake5+ years’ experience with Python, SQL, and AWS servicesAWS certification a plusExperience with Snowflake a plusExperience with data replication, ELT or ETL tool(s) a plus",Intermedio,Jornada completa,Tecnología de la información,Servicios y tecnologías de la información,20,None,False,,121,ACTIVELY_HIRING_COMPANY
891,2163585664,2020-11-05,Panasonic North America,Senior Market Researcher,"Denver, CO, US","Panasonic – Senior Market Researcher  Every moment of every day, people all over the world turn to Panasonic to make their lives simpler, more enjoyable, more productive and more secure. Since our founding almost a century ago, we’ve been committed to improving peoples’ lives and making the world a better place–one customer, one business, one innovative leap at a time. Come join our journey.  Click here to learn more about how Panasonic is creating a better life, a better world.   Watch this video to see how our employees are shaping the technologies that move us.  Connected mobility technology is poised to radically transform the safety, efficiency, accessibility and long-term financial viability of the transportation industry. Panasonic’s Smart Mobility Office is developing cutting edge data aggregation and insights platform capabilities dedicated to manage public resources for the public good through a commitment of data standards and open source software housed in the Cloud that brings together the digital and physical worlds to make mobility safer, efficient and more accessible. As government agencies look for new and innovative ways to positively impact the safety of pedestrians, cyclists and drivers, Panasonic’s SMO tests, develops and launches technology that provides real-time situational awareness such as crashed and disabled vehicles, adverse weather events, and much more.  The Panasonic Smart Mobility Office is poised to leverage our work in connected mobility services to co-develop in partnership with public agencies data collection and aggregation systems to test and operationalize modern transportation revenue generation systems based on use of the publicly funded transportation assets, primarily roads.  What You’ll Get To Do  As a Senior Innovation Researcher, you will be on the cutting edge of exploring new and emerging opportunities for the Smart Mobility Office.  You will conduct market research studies to identify and understand emerging transportation markets, being vigilant to new business opportunities. You will gather, analyze, and present actionable consumer, market, and competitor insights to a wide variety of stakeholders. Your work will shape the strategic direction of our business by providing strategic recommendations that inform our marketing, business strategy, and product development decisions.  About You  You love innovation. You love research and insights. You ask a lot of questions… always. You are a flexible team player who thrives in ambiguity. You aren’t afraid to “roll up your sleeves” and get things done. You value intellectual honesty and are not afraid to stand behind your insights. You believe a lot can be learned from qualitative research. You love technology and innovation (and probably geek out when new things get released). You have experience conducting generative and exploratory research studies that have helped companies launch new products or services. You love learning about new things and have experience conducting interviews in the B2B space. You have a knack for distilling complex and ambiguous things into clear and compelling visualizations.  This position will be accountable to the Director of NextLab, but will report to the Director of Analytics, Research, and Insights.  Independently conceive, lead, and conduct qualitative studies that drive strategic and tactical marketing, business, and product decisions Create clear and compelling market research storylines that are strategically sound and emotionally provocative to inform business strategy, the development of product roadmaps, enhance marketing efforts, drive engineering efforts, and provide early warning for strategic course corrections:Develop a deep understanding of the transportation landscape including, but not limited to, products, markets, competitors, etc., and develop frameworks to synthesize this understanding into insights for the business, e.g. segmentation models, competitive analysis, etc.Lead innovation and design workshops with cross-functional partners to convert insights into action.Develop comprehensive research plans designed to explore, and subsequently validate, business or product opportunities.Identify and explore white space opportunities in the connected mobility space.  What You’ll Bring  Education & Experience: A Bachelor’s Degree in Market Research, Psychology, Social Science, or related field (bonus for a Master’s):Minimum of 5 years of experience conducting market research in a technology-related field:Demonstrated ability to conduct end-to-end research studiesDeep understanding, and experience with, leading-edge qualitative research methodologies and technologies to deliver consumer and market insights:Market research, consumer insights, or related experience in either a supplier-side or client-side environment strong consumer focus:Experience conducting B2B market research a plus:Experience with Design Thinking:Experience managing vendors relationships a plus:Proficient in methodological design (including approach, protocol, survey/questionnaire and output/deliverables)Demonstrated ability to forge strong relationships across an organization to align insights to each line of business and ensure research projects meet today and future business needs.It would be a bonus if you understand and are able to implement the “Jobs to be Done” framework to articulate opportunities and business strategies within existing customers and future ones, grounded in data and insights  Competencies Excellent analytical, decision-making, project management, written/verbal communication, and presentation skills:Strong business acumen:Self-starter—always looking for opportunities to improve something and will jump in to fix things without being asked:An expert storyteller with the ability to influence business decisions:An independent, strategic, and creative thinker who is a strong team player (no job is too small or too large) and willing to take on additional responsibilities as necessary:Flourishes in ambiguity:Exceptional interpersonal and communication skills:Ability to think both analytically and creatively—balance left and right brain—people person as well as data person.  Other Requirements Majority of team sits in Denver, Colorado. Will consider remote candidates.Travel for research post-Covid up to 35%.  What We Offer Competitive compensation packageComprehensive benefitsPet InsurancePaid Parental Care LeaveEmployee Referral ProgramEducational AssistanceFlexible Work ProgramVolunteer time OffCasual Dress CodeTotal Well Being Program Panasonic is proud to be an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender identity, sex, sexual orientation, national origin, disability status, protected veteran status, and any other characteristic protected by law or company policy. All qualified individuals are required to perform the essential functions of the job with or without reasonable accommodation. Pre-employment drug testing is required for safety sensitive positions or as may otherwise be required by contract or law. Due to the high volume of responses, we will only be able to respond to candidates of interest. All candidates must have valid authorization to work in the U.S. Thank you for your interest in Panasonic Corporation of North America.",Algo de responsabilidad,Jornada completa,"Marketing, Ventas","Servicios y tecnologías de la información, Software, Servicios financieros",96,None,False,,607,ACTIVELY_HIRING_COMPANY
892,2256138422,2020-10-05,New Signature,Azure Data Engineer,"Warsaw, PL","Join a team of passionate thought leaders in a dynamic and collaborative environment! New Signature's Data & AI team is growing fast and we're looking for our next Azure Data Engineer to join us.  Role Description  What's the story?  As we continue to scale we're looking for the market's best Azure Data & AI specialists to help us grow our business' fastest growing practice, AppDev & Data. You'll be working with the industry's biggest players, delivering innovative greenfield Data Platform builds, Data Integration programmes and implementing bespoke High-Level Data Architectural designs.  Who we're looking for:  Strong experience using Azure Data components  (ADFv2 , Azure SQL DB, Azure SQL Datawarehouse, Azure Data Lake, Azure Databricks ...) Specific focus Azure Databricks or Databricks platform Excellent knowlegdge of Apache Spark ecosystem (SPARK 2.3x) Databricks Delta Lake  Strong Python programming  Build distributed in-memory applications using PySpark  Spark APIs - RDD, Datasets & Dataframes  Knowledge of C# highly desirable Experience with Power BI Agile methodolgy experience essential CI/CD, Azure DevOps experience, highly desirable  Why do people like working here?  Remote working Flexible hours  Who are New Signature?  We are a Microsoft house, born in the Cloud. The 2017 Acquisition of Paradigm Systems & Dot Net Solutions by New Signature accelerated a suite of capabilities to support the world's most prestigious and recognisable brands, helping them to become digital organisations powered by the Cloud.  We have over 500 people across the UK, US, Canada, South Africa, the Philippines and Australia, with our UK office growing over 70% YoY and headcount more than tripling.  How has this been possible?  Our values of being Generous, Authentic, Innovative and most importantly, Human, has enabled a unique approach to provide outstanding customer experiences, drive transformational results for clients across all company sizes & successfully deliver pioneering solutions that challenge the status quo. We've quickly established ourselves as a recognized expert at the forefront of Microsoft's technology stack with exceptional services to empower our customers, colleagues, and community.  Join us today and be part of the success story!  OUR CORE VALUES  Our employees are driven by our values and know that they make a positive difference every time that they help a customer to solve their challenges. Our focus on delivering great customer experiences empowers our people to build rewarding relationships that contribute to our positive work environment. You can learn more about our culture here:  New Signature Culture  Human  We use our hearts and minds to collaborate for success.  We harness technology to drive business, but we never let that replace our human connections. We use our hearts and minds to collaborate for success and instill confidence in our customers through relationships forged from trust.  Generous  We are giving and respectful.  With our efforts to always be generous, we elevate our service level with empathetic and considerate communications and actions. We always find a way to support our customers and colleagues by giving of our time and talent and equally respecting the time and talent of others.  Authentic  We tell it as it is, with positive intent.  Being authentic helps to nurture our strong and trusted relationships. We are honest, transparent, and reliable. When you partner with New Signature, you are partnering with a group of purposeful, outcome-driven and results-oriented professionals.  Innovative  We push the boundaries at the intersection of people, process and technology.  For us, there are no limit to our dreams. We continually innovate and push boundaries at the intersection of people, process, and technology to bring our customers and colleagues the best solutions first.  EQUAL EMPLOYMENT OPPORTUNITY  As a Global Cloud Transformation Consultancy business, New Signature understands diversity and inclusion in the workplace brings benefits to our customers, our business and most importantly, our people. We are committed to being an inclusive employer and we provide equal employment opportunities to all employees and applicants for employment.  New Signature prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other factors protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including all aspects of the recruiting and employment life-cycle at New Signature.  EMPLOYMENT ELIGIBILITY  New Signature requires candidates to prove eligibility to work in the UK. Offered candidates may be asked to complete a background check as permitted by applicable employment regulations. Depending on the requirements of the job, these record checks may include any or all of the following education verification, employment verification, drug screening, and criminal record check.",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Servicios financieros",None,None,False,,26,JOB_SEEKER_QUALIFIED
893,2234540129,2020-11-03,Headspace Inc.,Senior Design Researcher (Remote),"Santa Monica, CA, US","About The Senior Design Researcher At Headspace  Headspace is building a team of researchers who are passionate about improving the health and happiness of the world, and with more than 30 million users in over 190 countries, we are well on our way. At Headspace, you’ll have a chance to tackle challenging and complex problems through research, working on cross-functional teams with other researchers, designers, behavioral scientists, data analysts, product managers, engineers, customer experience specialists, and more.   About  We’re at an exciting time in our history — we’re essentially creating new verticals (meditation, sleep, and beyond) and our lofty goals need great people who are excited about  This is a rare opportunity to work with a talented and diverse team on one of the world’s most loved apps.  Exploring the topic of health & happiness in great depth, using mixed methods research   Working with designers and behavioral scientists to craft emotional experiences that support healthy routines   Helping shape our product, content, and business strategy as we explore new opportunities and audiences  Leveraging research to facilitate innovation beyond the app (AI, voice, healthcare, airlines, etc.)  Location: This role is open to remote employees in select US states: California, New York, Florida, Georgia, Texas, Maryland + Washington DC, North Carolina and Washington.   How your skills and passion will come to life at Headspace: Inform and participate in product decisions from definition to launch (and after), working at both a strategic and tactical levelConduct practical and impactful research across the product cycle, from formative to evaluative and everywhere in betweenBring insights about users by a variety of methods whether it be surveys, interviews, log analysis, usability studies, diary studies, ethnographic observation, or a new method you inventShare findings with designers, engineers, product managers, and others, creating a smarter, more informed and more empathetic product teamParticipate in outreach to the company by teaching, telling stories, and creating experiences  What You’ve Accomplished 5+ years of experience in product research, user experience research, or market research in a fast-paced product environmentExpert in a range of qualitative research methods, including, but not limited to: survey design, semi-structured interviews, ethnography, observation, concept evaluation, card sorts, usability testing, participatory design, etc. (Added bonus if you have familiarity/experience using research platforms like UserTesting.com , SurveyMonkey, dScout, or Lookback. )Expert storytelling and communication skillsProven ability to influence product or business strategy through researchA genuine interest in health & wellnessEducational background in Human Factors, Psychology, Anthropology, Sociology, Public Health, or Cognitive Science Past experience working in healthcare or educationBonus: Data analysis experience, including Natural Language Processing to deepen qualitative insights  How We Feel About Diversity & Inclusion  Headspace is committed to bringing together humans from different backgrounds and perspectives, providing employees with a safe and welcoming work environment free of discrimination and harassment. We strive to create a diverse & inclusive environment where everyone can thrive, feel a sense of belonging, and do impactful work together. As an equal opportunity employer, we prohibit any unlawful discrimination against a job applicant on the basis of their race, color, religion, gender, gender identity, gender expression, sexual orientation, national origin, family or parental status, disability*, age, veteran status, or any other status protected by the laws or regulations in the locations where we operate. We respect the laws enforced by the EEOC and are dedicated to going above and beyond in fostering diversity across our workplace.  Applicants with disabilities may be entitled to reasonable accommodation under the terms of the Americans with Disabilities Act and certain state or local laws. A reasonable accommodation is a change in the way things are normally done which will ensure an equal employment opportunity without imposing undue hardship on Headspace.  Please inform our Talent team if you need any assistance completing any forms or to otherwise participate in the application process.  How To Get Started  If you’re excited by the idea of seeing yourself in this role at Headspace, please apply with your CV and a cover letter that best expresses your interest and unique qualifications.",Algo de responsabilidad,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Software, Internet",86,None,False,,556,ACTIVELY_HIRING_COMPANY
894,2288438792,2020-11-07,Wiley Job Network,Data Scientist II (Remote Work Location Available),"Adkins, TX, US","Purpose of Job We are currently seeking a talented Data Scientist II for San Antonio Home Office II/III or Remote Work Location Available.  This role is designated for a Data Scientist who has proficient knowledge with applying modern advanced analytics methods (predictive modeling, Machine Learning, and optimization), as well as a solid grasp of the mathematics used for each method and strong Python coding skills to develop numerical models. The Data Scientist is expected to demonstrate the ability to effectively communicate (written and oral) complex analytical and technical concepts to both technical and non-technical employees. The Data Scientist for this role is expected to have experience working with time series/forecasting models.  Within defined guidelines and framework, uses techniques that integrate traditional and non-traditional datasets and method to enable analytical solutions. Applies predictive analytics, machine learning, simulation, and optimization techniques to generate management insights and enable customer-facing applications: participates in building analytical solutions leveraging internal and external applications to deliver value and create competitive advantage. Translates complex analytical and technical concepts to non-technical employees.  Job Requirements Identifies and manages existing and emerging risks that stem from business activities and the job role. Ensures risks associated with business activities are effectively identified, measured, monitored, and controlled. Follows written risk and compliance policies and procedures for business activities. In partnership with SMEs, learns to define the business problem and works with experienced data scientists to select the appropriate model.Extracts features from structured and unstructured data (internal and external).With guidance, conducts advanced analytics: predictive modeling, Machine Learning, and optimization. Works with Data Engineering/IT partners to develop architectures for new products, services and features.Explains complex models and outcomes to colleagues who are not data scientists.  Minimum Education Bachelor's degree in Computer Science, Applied Mathematics, Quantitative Economics, Statistics, or related field or 4 additional years of related experience beyond the minimum required may be substituted in lieu of a degree.  Minimum Experience 2 years of related experience and accountability for complex tasks and/or projects.Proficient knowledge of the function/discipline and demonstrated application of knowledge, skills and abilities towards work products.Proficient level of business acumen in the areas of the business operations, industry practices and emerging trends.Strong coding skills in the dominant scripting language (such as Python).Deep academic understanding of model assumptions. Solid grasp of statistics and mathematics.Proficient knowledge of Data Science principals and experience with data science methodologies.  *Qualifications may warrant placement in a different job level*  When you apply for this position, you will be required to answer some initial questions. This will take approximately 5 minutes. Once you begin the questions you will not be able to finish them at a later time and you will not able to change your responses.  Preferred Experience Proficient knowledge with applying modern advanced analytics methods (predictive modeling, Machine Learning, and optimization).Experience with Time Series/Forecasting Modeling.Solid grasp of mathematics, with a strong foundation in calculus, linear algebra, probability, and statistics.Strong Python coding skills to develop numerical models.Demonstrated ability to effectively communicate (written and oral) complex analytical and technical concepts to both technical and non-technical employees.  The above description reflects the details considered necessary to describe the principal functions of the job and should not be construed as a detailed description of all the work requirements that may be performed in the job.  At USAA our employees enjoy one of the best benefits package in the business, including a flexible business casual or casual dress environment, comprehensive medical, dental and vision plans, along with wellness and wealth building programs. Additionally, our career path planning and continuing education will assist you with your professional goals.  USAA also offers a variety of on-site services and conveniences to help you manage your work and personal life, including seven cafeterias, two company stores and three fitness centers .  Relocation assistance is not available for this position.  For Internal Candidates  Must complete 12 months in current position (from date of hire or date of placement), or must have manager's approval prior to posting.  Last day for internal candidates to apply to the opening is 11/03/20 by 11:59 pm CST time.",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Servicios y tecnologías de la información, Dotación y selección de personal, Consultoría de estrategia y operaciones",0,None,False,,1,None
895,2247373791,2020-10-27,Change Healthcare,Senior Data Scientist,"Roseville, MN, US","Transforming the future of healthcare isn’t something we take lightly. It takes teams of the best and the brightest, working together to make an impact.As one of the largest healthcare technology companies in the U.S., we are a catalyst to accelerate the journey toward improved lives and healthier communities.Here at Change Healthcare, we’re using our influence to drive positive changes across the industry, and we want motivated and passionate people like you to help us continue to bring new and innovative ideas to life.  If you’re ready to embrace your passion and do what you love with a company that’s committed to supporting your future, then you belong at Change Healthcare.Pursue purpose. Champion innovation. Earn trust. Be agile. Include all. Empower Your Future. Make a Difference. Title: Senior Data Scientist, Enterprise Imaging   Overview Of Position  We are seeking to grow our Artificial Intelligence (AI) Imaging team as a Senior Data Scientist with broad technical abilities. We are looking for a machine learning (ML) expert with medical imaging experience and an innovative and collaborative mindset that wants to be part of a dynamic team that develops end-to-end AI solutions for our Enterprise Imaging business unit at Change Healthcare (CHC).  This AI/ML Engineering opportunity is an exciting role that will expand your knowledge and will allow you to create commercial-grade AI solutions for various medical imaging products that have the potential to directly improve the radiologists and cardiologists work efficiency as well as improve patient’s clinical outcome. We have access to state-of-the-art tools in ML, comprehensive cloud support, and extensive data from our large customer installed base.  In this role as Sr. Data Scientist will consist of the design, development, and optimization of innovative AI solutions, from data ingestion and machine learning modeling to integration into an end product. The AI Enterprise Imaging team has product and development stakeholders throughout the business unit, and also works closely with academic and industrial partners. The AI Data Scientist is expected to work with all stakeholders to fulfill the Company’s business needs  What will be my duties and responsibilities in this position? Design, prototype, and implement innovative machine learning algorithms for medical imaging use casesCollaborate with academic and industrial partners to collect and optimize data collection and validate AI solutionsBuild and maintain large medical imaging databasesDevelop data cleaning and pre-processing methods to normalize data and detect outliersOptimize data transfer, data flows, and data operationsImplement and document API’s for machine learning algorithmsAssist with product integration of machine learning solutionsAssist in the development of machine learning web/UI applications What are the minimum requirements needed for this position? 5+ years of machine learning experience (conventional ML and Deep Learning)5+ years in software development1+ year of experience in medical imaging What are the critical skills required to have for this position?  5+ years of programming experience in Python, JS, and C/C++5+ years of development in data modeling and machine learning, including practical experience in deep learning methods (CNN, RNN) and/or natural language processing3+ years of experience in agile development2+ year of experience with machine learning toolkits (TensorFlow, scikit-learn, Keras)1+ years of experience with cloud-based storage and computing tools for machine learningExperience with at least one of the public cloud providers such as GCP, AWS, Azure, or IBM Cloud What are the additional skills and knowledge that would be beneficial for you to have in this role? Experience developing commercial Web/UI applicationsDevelopment experience with topological data analysisExperience in CI/CD toolsExperience in automated functional/load/integration test toolsExperience in declarative languages such as XML, JSON, and YAMLExperience in ‘Linux/Unix’ OS and shell scripting What are the soft skills you will need to possess for this role?  Strong written and verbal communication, and interpersonal skillsHighly self-motivated, directed and results-orientedCross-cultural and team player who enjoys working in a fast-paced environment  What is the minimum education you are required to have in order to be considered for this role?  Electrical Engineering, Computer Science, or related background (BS, MS, or Ph.D.)  Join our team today where we are creating a better coordinated, increasingly collaborative, and more efficient healthcare system!   Equal Opportunity/Affirmative Action Statement   Change Healthcare is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, age, sex, sexual orientation, gender identity, genetic information, national origin, disability, or veteran status. To read more about employment discrimination protections under federal law, read EEO is the Law at https://www.eeoc.gov/employers/eeo-law-poster and the supplemental information at https://www.dol.gov/ofccp/regs/compliance/posters/pdf/OFCCP_EEO_Supplement_Final_JRF_QA_508c.pdf .  If you need a reasonable accommodation to assist with your application for employment, please contact us by sending an email to applyaccommodations@changehealthcare.com with 'Applicant requesting reasonable accommodation' as the subject. Resumes or CVs submitted to this email box will not be accepted.  Click here https://www.dol.gov/ofccp/pdf/pay-transp_%20English_formattedESQA508c.pdf to view our pay transparency nondiscrimination policy.  Change Healthcare maintains a drug free workplace and conducts pre-employment drug-testing, where applicable, in accordance with federal, state and local laws.",No corresponde,Jornada completa,Otro,Servicios y tecnologías de la información,21,None,False,applyaccommodations@changehealthcare.com,152,ACTIVELY_HIRING_COMPANY
896,2268498978,2020-11-02,Intuitext,Senior User Experience Designer,"Bucharest, Romania","Linkedin: We are an educational company with experience in the Romanian market. We have multiple online products for children ranging from 6-14 years old as well as teachers. We are looking for a Senior UX designer.  You will be responsible for building a clean and effective user experience for our customers, the children, as well as teachers. By working cross-functionally, you will understand needs from the product management, engineering, and business stakeholders and will be able to build solutions that fit those needs.  You will work closely with the another senior UX designer, product manager, teachers, machine learning developers and mobile developers during the development of the app. Post launch you will work with data scientist to analyse user behavior and improve the solution. You will work remotely from your home, for the next 6 months. We are looking for someone to work 9 am - 18 pm.  Responsibilities: 20% of time be a Team Lead for UX Design team: Create learning paths for other 2-5 junior UX designers, help grow them, monitor them. Develop wireframes for the mobile app based on user interviewsDevelop user friendly screens that address the functionality of the app so farcreate UI for products15 % of time have user interviews for: UX Testing design15% of time have user interviews for discovery of user needs , and determine the value of feature or product to the userVery important: Make sure the business needs are met though the UX. You should have a business sense. Be interested in the usage of the app after launch via analytics, and determine what user behavior is adopted5% of time: watch user behavior on recordings for users using the appimplement usability best practices in the company, so that the product tests for usability correctly. 2 year Experience with doing UX for mobile apps Qualifications: Don’t expect us to give you tasks 30% of the time, you should have a very proactive attitude, to drive team forward.You should be very protective about a product, be very detail oriented.Be heavily oriented to UX research.Be heavily oriented to user research. You will collaborate with a user researcher. Portfolio of mobile apps designed that you can present (preferably addressed to children)",Algo de responsabilidad,Jornada completa,Tecnología de la información,Publicaciones,50,None,True,,215,ACTIVELY_HIRING_COMPANY
897,2283601681,2020-11-06,Unite Us,Data Engineer,"New York City, NY, US","Job Title: Data Engineer  Department: Engineering  Who We Are:  Unite Us is reinventing the delivery of health and human services. We connect service providers on a common platform, enabling scalable, accountable and measurable delivery of wraparound care. Our technology provides the collaborative infrastructure for these communities. We care deeply about the work we do and the communities our software benefits. We're looking for people to join our team who share that passion for our mission to reinvent Health & Human Services and aspire to make a lasting difference for future generations. No matter how large our team grows, we will always be family. Unite Us prides itself on offering a competitive salary, full benefits, and the opportunity to change the world. Come to Unite Us and together we can build healthier communities for everyone.  Description:  Unite Us has experienced rapid growth over the past couple of years. As we have grown, our clients' skills and requirements around data have grown more sophisticated. Data has long been a foundation of our system. Now, we need to start taking the data that exists within our platform and transform it into an actionable source of information for our clients in order to assist them in better understanding the impact that Social Determinants of Health are having on those they help. To do this, we need to build an experienced team of data technologists who want to have an impact on healthcare across the entire country.  The impact of SDoH data is revolutionizing the healthcare industry. As we continue our rapid pace of growth, we want to build a solid data platform that can serve the needs of our clients and shape the way the industry thinks about and relates to social determinants of health. We are looking for a strong technical individual contributor who has experience building data warehouses, lakes and pipelines to help us continue growing our impact on the healthcare industry and the lives of people around the country.  What You'll Do:   Execute a data architecture and infrastructure to meet business objectives Work closely with Solutions Architects and Product Managers to make sure that the technical infrastructure can support client requirements Develop ETL and data pipeline solutions to load data warehouse Test internal data pipelines for reliability and performance   What's Required:   Experience as a Data Engineer in which you set up data pipelines Experience using and building solutions to support various reporting and data user tools (Chartio, Tableau, Looker, etc) Experience with Spark using Scala and Python. Experience working with data warehouses, data lakes and ETL pipelines (Snowflake, Infomatica, Redshift, Postgres, SQL, etc) Experience setting up an maintaining databases within AWS Experience working on applications serving large enterprise clients Experience working on healthcare and/or social determinants of health data products A focus on building performant systems Ability to think forward and build a scalable solution that satisfies various needs of enterprise clients with dedicated data teams   Environmental Job Requirements and Working Conditions:   This position is remote  Unite Us is committed to building a diverse team and fostering an inclusive culture, and is proud to be an equal opportunity employer. We embrace and encourage our employees' differences in race, religion, color, national origin, gender, family status, sexual orientation, gender identity, gender expression, age, veteran status, disability, pregnancy, medical conditions, and other characteristics",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Atención sanitaria y hospitalaria",6,None,False,,52,ACTIVELY_HIRING_COMPANY
898,2282160937,2020-11-06,Dell,Data Engineer - Analytics and Automation,"Round Rock, TX, US","Data Engineer/Analytics & Automation  Data Science is all about breaking new ground to enable businesses to answer their most urgent questions. Pioneering massively parallel data-intensive analytic processing, our mission is to develop a whole new approach to generating meaning and value from petabyte-scale data sets and shape brand new methodologies, tools, statistical methods and models. What’s more, we are in collaboration with leading academics, industry experts and highly skilled engineers to equip our customers to generate sophisticated new insights from the biggest of big data.  Join us to do the best work of your career and make a profound social impact as a Data Engineer on our Data Enablement team.  What You’ll Achieve  As a Data Engineer, you will be responsible for supporting our digital supply chain infrastructure and tools. You will work with the Data Enablement team on our backend infrastructure and our frontend tools. You have the passion for innovation and the application of emerging data technologies to the delivery of cutting-edge business intelligence solutions.  You Will  Support our architecture build-outs, design and build data models.  Implement Business Intelligence tools and technology such as PowerBI and ThoughtSpot.  Take the first step towards your dream career  Essential Requirements  Every Dell Technologies team member brings something unique to the table. Here’s what we are looking for with this role:  2+ years of related experience in a professional role with a Bachelor’s degree: or an advanced degree or equivalent experience  Ability to quickly learn new tools/technologies Experienced in working both independently and in a collaborative, cross-functional team environment  Background and experience with RDBMS technology  Proficiency in standard programming languages such as SQL, C++, PERL etc.  Self-starter, comfortable dealing with ambiguity and competing priorities  Desirable Requirements  Post-Graduate degree in Computer Science or related discipline.  Self-starter, comfortable dealing with ambiguity and competing priorities General understanding of data sets, data relationships and KPI measures  Here’s our story: now tell us yours  Dell Technologies helps organizations and individuals build a brighter digital tomorrow. Our company is made up of more than 150,000 people, located in over 180 locations around the world. We’re proud to be a diverse and inclusive team and have an endless passion for our mission to drive human progress.  What’s most important to us is that you are respected, feel like you can be yourself and have the opportunity to do the best work of your life -- while still having a life. We offer excellent benefits, bonus programs, flexible work arrangements, a variety of career development opportunities, employee resource groups, and much more.  We started with computers, but we didn’t stop there. We are helping customers move into the future with multi-cloud, AI and machine learning through the most innovative technology and services portfolio for the data era. Join us and become a part of what’s next in technology, starting today.  You can also learn more about us by reading our latest Diversity and Inclusion Report and our plan to make the world a better place by 2030 here.  Application closing date: 30 Nov 2020  Dell is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at Dell are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV Status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. Dell will not tolerate discrimination or harassment based on any of these characteristics. Dell encourages applicants of all ages. Read the full Equal Employment Opportunity Policy here.  Job Id: R076051",No corresponde,Jornada completa,Tecnología de la información,"Equipos informáticos, Software, Servicios y tecnologías de la información",78,None,False,,343,COMPANY_RECRUIT
899,2268028357,2020-10-08,Skiltrek,Sr. Data Scientist - Claims - REMOTE,"Indianapolis, IN, US","Position Title: Sr. Data Scientist Location: Jacksonville FL or ( Open to 100 % Remote ) Job Type: Contract Work Auth: GC/USC/GCEAD Salary Method: W2 Client Type: Healthcare Insuance Job Duration: Long Term Contract - 12 months + Rate: $126,000-$170,000 /year  Job Description  This a niche skillset and not just any data scientist. Candidate must have worked in Claims and used Machine Learning models to gain for efficiencies in Prepay / Post Pay reviews ** Data Scientists produce innovative solutions driven by exploratory data analysis from complex and high-dimensional datasets. Apply knowledge of statistics, data modeling, and advanced mathematics to recognize patterns, identify opportunities, pose business questions, and make valuable discoveries. Use a flexible, analytical approach to design, develop, and evaluate predictive models. Generate and test hypotheses. The Data Scientist proactively seeks to develop their skillsets and provide value-added support within the Data Science team.  Essential Functions  Communication & Project Ownership  Support large projects, and manage smaller projects in their entirety Partner with senior team members to assess customer needs and define business questions. Emerging ability to influence customers to take action on analytical insights. Communicate results and insights, both verbally and written (including visual graphics), in a clear and concise manner to a non-technical audience. Identify and communicate roadblocks. Work on multiple concurrent projects and accommodate frequent interruptions and changing priorities Effectively participate in meetings with customers and emerging ability to guide discussion and decision making. Data Analysis  Acquire and bring structure to data so that it can be used in existing and new data systems. Build tools that help you and the other Data Scientists translate insights into action at scale. Identify, define and translate business needs/problems into analytical questions. Design and execute experiments, models, algorithms, and visualizations Understand data sources and limitations, warehousing system and the impact of the data on business decisions. Identify, retrieve, and manipulate data from internal and external datasets. Apply statistical and computational methodologies to provide actionable insights and identify opportunities that optimize quality, consumer experience, and healthcare costs. Develop scalable, efficient, and automated processes for large scale data analyses and model development, validation, and implementation. Reporting & Other  Contribute to technical reports, white papers, and publications. Stay current on new processes and technology in Data Science and communicate findings to team Perform all other tasks as assigned Job Requirements  Strong programming experience in R, or Python Requires expert proficiency in SQL Strong analytical and problem-solving skills Experience in supporting large projects, and manage smaller projects in their entirety Ability to partner with senior team members to assess customer needs and define business questions. Emerging ability to influence customers to take action on analytical insights. Ability to communicate results and insights, both verbally and written (including visual graphics), in a clear and concise manner to a non-technical audience. Must have applied experience with advanced analytics e.g. predictive analytics models Must have applied experience in Machine Learning Experience in Big Data - e.g. s3/presto is a plus Business Intelligence tool development Other programming experience - Java, Perl, UNIX/Linux scripting Healthcare, medical, or pharmaceutical work experience Experience with analysis around quality, consumer experience, and healthcare costs Experience in consumer analytics Experience in business analytics Required Experience  5-8 years related work experience in advanced analytics or equivalent combination of transferable experience and education  Minimum Five Years' Experience As a Data Scientist  PhD or Masters in a quantitative discipline: Computer Science, Statistics, Applied Mathematics, Operations Research, Engineering Working knowledge of health care systems and healthcare terminology Expert in various healthcare datasets. Expert in analyzing large complex, multi-dimensional data sets with a variety of tools Ability to thrive and demonstrate constant applied learning in highly complex, interdisciplinary, and dynamic work environment Design anomaly detection models to detect and eliminate FWA in claim payments. Experience in implementing Machine Learning Models to gain efficiencies in Claims Prepay / Post Pay reviews  Required Education  Related Bachelor’s degree in Data Science, Applied Mathematics, Computer science (e.g. specialization: Machine learning/Artificial Intelligence /Visualization, databases, and Big Data), Statistics, Epidemiology, Health Services Research, or closely related field with Data Science specialization or additional related equivalent work experience  This person can work 100% remotely even after Covid-19!",Sin experiencia,Jornada completa,Tecnología de la información,"Sanidad, bienestar y ejercicio",0,None,False,,8,None
900,2002424244,2020-10-26,Focus GTS,Senior Data Engineer,New York City Metropolitan Area,"Senior Data Engineer Location: Remote6 Month Contract To HireCompetitive Hourly Rate A top cyber security defense client is looking for an expert to defining, building, and improving data pipelines and warehouses for real-time data processing, and to make predictions on threat/breach detection. ﻿Responsibilities:Develop reliable data pipelines and translate raw data into actionable insights Identify areas of cyberattack analysis and be able to transparently communicate with the teamconjure magical Jupyter notebook workflows, design experiments, and conceive defensive analytics to detect cyberattacksBuild & design queries for Adhoc business projectsTake full ownership of extending the data pipelineBoost libraries, logging, and error reporting with Sentry, Docker, Zstrandard Compression, Concurent programming, and object serialization  Required Experience:5-9 years of a hands-on experienceExperience with C++ Julia & Jupyter NotebookSQL & Note JS (Preferred) Predictive modeling expertise (Bonus) A prior background in Software Development (Preferred)Exposure to Cadence (Preferred)Good verbal and written communication skills.",Intermedio,Contrato por obra,Ingeniería,"Departamento de defensa y del espacio exterior, Servicios y tecnologías de la información, Software",246,None,True,,745,ACTIVELY_HIRING_COMPANY
901,2254576096,2020-10-29,Facebook,"Data Scientist, Product Analytics - Epidemic Response","Menlo Park, CA, US","Facebook's mission is to give people the power to build community and bring the world closer together. Through our family of apps and services, we're building a different kind of company that connects billions of people around the world, gives them ways to share what matters most to them, and helps bring people closer together. Whether we're creating new products or helping a small business expand its reach, people at Facebook are builders at heart. Our global teams are constantly iterating, solving problems, and working together to empower people around the world to build community and connect in meaningful ways. Together, we can help people build stronger communities - we're just getting started. The Health team is focused on leveraging Facebook to improve global health outcomes, and the Epidemic Response team is crucial to our long-term success. In H2 2020, the Epidemic Response team is primarily focused around efforts related to COVID19. End-to-end success includes (1) building datasets/models for the pandemic (2) working with public health organizations to derive relevant insights from those datasets/models and (3) working with policy makers (such as government officials) to change relevant policies in response to those insights.   Ongoing work includes Symptom Surveys, which have been created in partnership with CMU and UMD, our Preventive Behavior Surveys, which have been created in partnership with MIT and JHU, and programmatic efforts to support Contact Tracing.  In addition to executing and building upon our COVID19 efforts, the DS will also be responsible for generalizing our strategy (e.g. surveys, visualizations, prediction models, datasets, partnerships) for (1) what datasets we create for future pandemics (2) what datasets we create for new areas where we can meaningfully benefit public health and (3) how external, non-FB data can help improve the strategy of our existing Health teams.Validate and analyze the data for the external datasets that we produce to shape our perspective on the accuracy and value of the dataWork closely with partnerships, Product Management and cross functional teams and third party organizations (academics, global health organizations) to maximize the value of the data that we produceIdentify public/private collaborations that can accelerate research/understanding around public health outcomes and the role Facebook can play hereGeneralize our Pandemic Response data strategy and ideate for additional metrics that can help us expand beyond our existing surveys and data for application for future global epidemics as well as for future public health causesIdentify existing external data that can help form Facebook’s strategy in the Health space broadly as well as improve our already existing investments in the Health spaceBS, MS or PhD Degree in Statistics, Computer Science, Econometrics, or similar domain5+ years of experience working in an analytics organization5+ years of experience working with Health data and Health organizationsExperience working independently and as a member of a cross-functional teamExperience working with academia and public health organizationsExperience taking highly ambiguous problems (including emergent problems in the world) and forming a structured opinion on what we should doExperience communicating effectively to stakeholders, including executives, external leaders in the Health space, and other DS on the Health teamProven machine learning sense in building robust modelsBackground in data privacy issuesExperience in querying and manipulating large datasets for analysis (with Python and SQL)Facebook is proud to be an Equal Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law.   Facebook is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.",Intermedio,Jornada completa,Tecnología de la información,Internet,59,None,False,accommodations-ext@fb.com.,649,JOB_SEEKER_QUALIFIED
902,2218885326,2020-10-28,IQVIA,Senior Data Scientist,"Warsaw, PL","Data Science & Advanced Analytics  Data Science & Advanced Analytics - with departments in Frankfurt, Philadelphia, Beijing and Warsaw as well as a network of over 150 team members worldwide - is the global competence centre for data science at IQVIA. Complex advanced analysis at the highest level are conceptualized and implemented to support international customers in the pharmaceutical industry - often within multinational projects. As a member of our team you can expect exciting international projects with interesting development perspectives.  Senior Data Scientist, Data Science & Advanced Analytics – the role Collaboration in projects of the European Data Science & Advanced Analytics TeamDevelopment and execution of complex statistical, econometric, and machine learning analysis (Advanced Analytics, Predictive Analytics), especially in the area of Commercial Effectiveness (e.g., Next Best Customer, Profiling, Segmentation and Targeting, Brand Performance drivers and optimisation, etc) and Real World Evidence (e.g., risk of disease progression, treatment compliance, etc) in collaboration with European local officesDevelopment of innovative methodologies to deliver custom solutions to our clients as well as execution and implementation of concept studies using advanced statistical methodsApplication of modern data mining and machine learning techniques in connection with Healthcare Big Data to identify complex relationships, to derive business-relevant findings, and develop new offerings Implementation of new statistical and machine learning technologiesWorking with technology teams to support machine-learning algorithms in big data platforms  Our Ideal Candidate Will Have Master degree in Mathematics/Statistics, Economics/Econometrics, Computer Science or related fieldAt least 3 years of professional experience in quantitative data analysis or PhD with at least 1 year of relevant professional experience with research in machine learning algorithmsVery good knowledge and in depth understanding of Machine Learning methodsExperience applying Machine Learning methods to business questionsVery good knowledge of the higher statistical and econometric methods in theory and practiceExperience with handling Big DataProficient in Python and/or RExcellent communication skills (written and oral) including technical aspects of a project, ability to develop usable documentation, results interpretation and business recommendationsLocal language skills to an advanced level (spoken and written), with complete fluency in English.Strong analytic mindset and logical thinking capability, strong QC mindsetDemonstrates consulting, creativity, critical thinking, project planning, and attention to detail capabilitiesKnowledge of pharmaceutical market and experience with pharmaceutical data (medical, hospital, pharmacy, claims data) would be a plus, but not a must  We know that meaningful results require not only the right approach but also the right people. Regardless of your role, we invite you to reimagine healthcare with us. You will have the opportunity to play an important part in helping our clients drive healthcare forward and  Whatever your career goals, we are here to ensure you get there!  We invite you to join IQVIA™.  At IQVIA, we believe in pushing the boundaries of human science and data science to make the biggest impact possible – to help our customers create a healthier world. The advanced analytics, technology solutions and contract research services we provide to the life sciences industry are made possible by our 67,000+ employees around the world who apply their insight, curiosity and intellectual courage every step of the way. Learn more at jobs.iqvia.com.",No corresponde,Jornada completa,Otro,Industria farmacéutica,38,None,True,,154,COMPANY_RECRUIT
903,2232597418,2020-10-23,ASTEK Polska,Senior Data Scientist,Kraków i okolice,"Position Responsibilities: • Work with business stakeholders and product owners to understand the business domain and related data • Prepare data for modelling, including data ingestion, cleansing  • Work with data engineers to store data and make it available as required • Build, validate and operationalize ML models  • Present and communicate solution to both technical and nontechnical stakeholders • Participate in demos and data analysis reviews  • Train, coach and mentor other team members demonstrating aptitude for and interest in data science.  • Proactively seek ways to incorporate new and creative ideas and methodologies into SaaS solution engineering.  The successful candidate will have/possess: • Passion for solving practical problems, a high level of entrepreneurial drive and high collaboration skills. • Tenacious attitude to grasp the core of the problem and convince the stakeholders of ML application value  • Proven record of applying machine learning techniques to solve business problems  • Effective verbal and written communication skills. • Organization, time management, and prioritization skills. • Proficiency in statistical packages and standard libraries in R (glmnet, ggplot, tidyverse etc.) and/or Python (numpy, pandas, etc.).   Preferred Qualifications: • Educational background in Applied Mathematics, Statistics or other quantitative disciplines • Hands-on experience with SQL and distributed Big Data Analytics using one of: Apache Spark, Hadoop, Azure Data Lake, Azure Databricks or CosmosDB.  • Hands-on experience in machine learning frameworks such as scikit-learn, TensorFlow or PyTorch.  • Domain understanding of downstream",Intermedio,Jornada completa,"Tecnología de la información, Ingeniería, Análisis",Servicios y tecnologías de la información,47,None,True,,252,JOB_SEEKER_QUALIFIED
904,2241869545,2020-10-26,Michael Page,Senior Data Engineer (Indonesia based),"Jakarta, ID","As a Senior Data Engineer you will work closely with CTO, given an enormous sense of ownership to build highly scalable pipeline for processing large volumes of complex data. You will work on cloud infrastructure alongside the experts.           Client Details  Our client is one of the first publicly listed FinTech company based in Indonesia, owned by a multinational company. Equipped with the latest data analytic and technological platform, they leverage big data to create unconventional data credit scoring. Aiming to focus on financial literacy, they have strong vision in technology and Data analytics to stay at the forefront of financial inclusion agenda year to year.  The role is based in Jakarta, Indonesia. Open for remote work with occasional travel requirements to Jakarta.  Description  Design and build highly scalable pipeline (end-to-end) for large volumes of complex data processing and analysisBuild and develop large data warehouses, high performance data processing pipelines, and ETL toolsEnsure high data integrity and quality from various data sourcesDesign and implement process improvements, build automated processes, optimize data delivery and re-designing infrastructure for larger scalabilityWork with machine learning systems in productionUnderstanding of software design principles and best practices (test driven development, source control management etc.)Able to clearly articulate pros and cons of different technologies, solutions and platformsAble to document use cases, solutions and recommendations   Profile     Solid experience and knowledge on Google Cloud Platform (or any of the major cloud solution providers such as AWS, Azure, AliCloud) for data management: Composer, Pubsub, Google Storage, Dataflow, Big Query and Data Fusion, or equivalentSavvy with Airflow, or a diverse set of data technologies: Redshift, Elastic Search, PostgreSQL, Spark, Hadoop, KubernetesFluency in Python, SQL, Java or equivalentUnderstanding of SQL & NoSQL databases and other manipulation toolsAbility to work with stream-processing systems: Storm, Spark-streaming, etc.Able to benchmark systems, analyse performance and bottlenecks and propose solutions to resolve themExcellent written and verbal communication, able to switch between technical and plain language when discussing workAble to work in teams, understand and empathize with all major stakeholders, take the lead on initiatives and direct and manage data engineersAble to work in a fast-paced agile development environment         Job Offer  Exposure to work with the latest technological platform and cloud infrastructureHighly competitive benefits           Desired Skills and Experience  Data Engineer, Data Analytics, Business Intelligence, Data Science, Google Cloud Platform, GCP, ETL, Datawarehouse, Python, Airflow, Database  To apply online please click the 'Apply' button below. For a confidential discussion about this role please contact Josephine Wiliputri on +62 21 2958 8871.",Intermedio,Jornada completa,Tecnología de la información,Servicios financieros,15,None,False,,231,COMPANY_RECRUIT
905,2206907443,2020-10-23,MBN Solutions,Chief Data Scientist,"London, England Metropolitan Area","MBNs client, a globally renowned media giant, is looking for a Chief Data Scientist to spearhead science, innovation, and exploration across their entire organisation. This is a leadership role reporting to the Chief Data and AI Officer in which you will be responsible for driving both value and profitability using Data, Machine Learning and AI. As the Chief Data Scientist, you will:﻿Refine and execute on pre-scoped projects in areas such as NLU, Computer Vision, Forecasting, Clustering and Personalisation whilst leading on the next generation of Data Science and AI products.Build, nurture and lead a team of Data Scientist, Machine Learning and Data engineers to deliver fully productionised products at scale in the cloud.Work in partnership with other technology and engineering teams to build robust data science workflows and frameworks that allow for rapid experimentation, prototyping and deployment.Evangelise Data Science, Machine Learning and AI across the business using thought leadership and other methods to do so. Experience required: Experience building, leading and nurturing a team of data scientists and engineers.Experience delivering quantifiable commercial value time and time again using Data.Experience productionizing several products at scale in the cloud.Contribution to the wider industry such as:  Meet up groups, thought leadership and academic collaborations.Technical expertise in Machine Learning, Data Science, Mathematics and Computer Science including experience with a range of tooling such as:  Python, PyTorch, TensorFlow, Spark, GCP/AWS, Git Apply or get in touch with me, David for more information.",Director,Jornada completa,"Ingeniería, Tecnología de la información, Ciencias","Software, Producción multimedia, Internet",114,None,True,,674,JOB_SEEKER_QUALIFIED
906,2261250051,2020-10-31,NBCR Rekrutacja IT Sp. z o.o.,Senior Data Engineer (Cloud Expert)- 100% remote,"Poznań, PL","NBCR Sp. z o.o. is a company with an established position in the market specializing in the recruitment of specialists in the IT industry (Certificate No. 14492). For over a dozen years, we have been helping our clients in providing highly qualified specialist staff, thanks to which they can work and grow and we accompany them as a reliable partner.  Responsibilities  We are currently looking for candidates for the position:  We focus on the finance, retail, and healthcare sectors with use cases like investment optimization, semi-automated data mapping, lead scoring. We conduct internal webinars to share knowledge in the fields of Machine Learning and Data Engineering. We’re building an ML-Ops culture within our department and we want to extend that to the Data Engineering area. We use AWS and GCP as our cloud providers. We encourage our team members to share their knowledge and experience at external conferences. We cooperate closely with the Machine Learning team. Requirements  3+ years of DE experience, Strong experience with S3 + Athena/Presto and Redshift/Redshift Spectrum, Hands-on experience with at least 2 of the following: AWS Glue/EMR or Kinesis/Kafka or ELK stack or Lambdas. Experience in designing data lakes - from structuring to managing and optimization, Knowledge of data storage formats (Parquet, ORC, AVRO, etc.), Experience with Python and Linux and shell scripting, Familiarity with relational databases like Oracle, PostgreSQL, MySQL, Advanced SQL writing skills. Nice-to-haves  Experience with: Airflow / Luigi MongoDB / ElasticSearch / Cassandra Kubernetes We Offer  attractive salary Generous private health insurance package with dental care. Optional life insurance for you and your family. A growth budget for your educational plan. Masterbenefit: discounts on car leasing. Discounts on Apple products. Various internal initiatives: webinars, knowledge sharing sessions, internal conferences.",Algo de responsabilidad,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Software, Internet",0,None,False,,20,None
907,2288832342,2020-11-08,None,Data Scientist - REMOTE,"London, GB","Medable's mission is to get effective therapies to patients faster. We provide an end-to-end, cloud-based platform with a flexible suite of tools that allows patients, healthcare providers, clinical research organizations and pharmaceutical sponsors to work together as a team in clinical trials. Our solutions enable more efficient clinical research, more effective healthcare delivery, and more accurate precision and predictive medicine. Our target audiences are patients, providers, principal investigators, and innovators who work in healthcare and life sciences.  Our vision is to accelerate the path to human discovery and medical cures. We are passionate about driving innovation and empowering consumers. We are proactive, collaborative, self-motivated learners, committed, bold and tenacious. We are dedicated to making this world a healthier place.  Job Description  Explore machine learning opportunities  Investigate and compile new sources of medical data  Provide clinical input to refine existing machine learning architecture  Develop and integrate machine learning algorithms for data processing and analysis  Building models to address business problems  Presenting information using data visualization techniques  Undertake preprocessing of structured and unstructured data  Analyze large amounts of information to discover trends and patterns  Build predictive models and machine-learning algorithms  Propose solutions and strategies to business challenges  Collaborate with engineering and product development teams  Other duties as assigned   Qualifications 0-3 years working in Computer Science or a combination of education and experience (3+ preferred) Bachelor’s degree in Computer Science, Artificial Intelligence, Engineering or relevant field  Experiece with R programming language, C++, Python, Java, Node.JS   Additional Information  Highly analytical with a knack for analysis, math and statistics  Critical thinking and problem-solving skills  Passion for machine-learning and research  Experience in data mining  Analytical mind and business acumen  Problem-solving aptitude  Excellent communication and presentation skills  Experience working in machine learning (preferred) All information will be kept confidential according to EEO guidelines.",Sin experiencia,Jornada completa,"Ingeniería, Tecnología de la información","Marketing y publicidad, Software, Industria farmacéutica",9,None,False,,51,None
908,2183073043,2020-10-14,UnitedHealth Group,Sr. Data Engineer (883100),"New York, United States","Optum is a company that's on the rise. We're expanding in multiple directions, across borders and, most of all, in the way we think. Here, innovation isn't about another gadget, it's about transforming the health care industry. Ready to make a difference? Make yourself at home with us and start doing your life's best work. (sm)  Genoa Telepsychiatry is an innovative and rapidly growing Telemedicine for Mental Health business owned by Optum. As a Lead Data Engineer, you will be part of the Genoa Telepsychiatry team. We are increasing access to behavioral healthcare in underserved communities across the U.S. by building telepsychiatry programs that connect patients with psychiatrists & APRNs remotely. We have programs in over 35 states providing 250,000+ appointments annually. Our fast-paced New York team is growing rapidly and offers ample career development opportunities in a mission-driven culture valuing empathy, collaboration, grit, and continuous learning.  Primary Responsibilities:Build scalable, fault-tolerant batch and real-time data pipelines to power internal applications, operational workflows, and business intelligence platforms Create and maintain data-driven APIs to support a wide range of integration with healthcare partners Recommend and implement best practices for data management and governanceHelp set technical direction and provide guidance to more junior data engineers. Work as a partner with our product team to represent engineering interests and inform product decisions Solve technical problems, simple and complex, in a lean and efficient manner Follow engineering best practices and cultivate a best-practices culture Resolve to put the customer first, by chasing ROI in all engineering efforts, recognizing that doing something the fastest way possible, lets us do more for patients Required Qualifications:Bachelor’s degree in computer science, engineering or a similar field of study, or equivalent experience3 + years of experience professional data engineering, building and using data infrastructure, APIs, and integrations in a cloud-hosted setting. Demonstrate a keen awareness of the importance of security, scalability, reliability, and feasibility in solution designFluent in at least one general-purpose programming language (Python, Java, Scala, Go, Ruby, C#, etc…)Expert knowledge of SQL   Preferred Qualifications:Experience with performance tuning tools and/or techniquesExperience with AWS technologies such as Redshift, S3, Lambda, EMR, Kinesis, RDSExperience with QuickSights, PowerBI, Qlikview, Tableau or other Reporting Tools  Technology Careers with Optum. Information and technology have amazing power to transform the health care industry and improve people's lives. This is where it's happening. This is where you'll help solve the problems that have never been solved. We're freeing information so it can be used safely and securely wherever it's needed. We're creating the very best ideas that can most easily be put into action to help our clients improve the quality of care and lower costs for millions. This is where the best and the brightest work together to make positive change a reality. This is the place to do your life's best work.(sm)",Intermedio,Jornada completa,"Ingeniería, Tecnología de la información, Atención médica",Atención sanitaria y hospitalaria,62,None,False,,366,ACTIVELY_HIRING_COMPANY
909,2252762382,2020-10-04,Jefferson Frank,AWS Data Engineer / Remote,"London, GB","Data Engineer / Remote (UK Based)  Up to £65,000  London  AWS Cloud Platform | Remote Interview / Working (2 days in the office every 3 - 4 weeks) | Progression Opportunities | Relaxed Working Environment | Fin-Tech Start-Up  A new fintech start-up is on the lookout for a new data engineer to join their in-house team.  You'll be joining as a key member of the engineering team and working on a new enterprise-grade platform. You'll be working on microservices architecture with analytics, AI and ML capabilities to leading SAAS platforms.  What you'll be working on?   Developing and designing solutions for new data pipelines and features Improvement of existing features Working on data architecture alongside Data Scientists Researching new tech to be at the forefront of modern development!  The techy part…  Have knowledge of   Strong Python Knowledge Working knowledge of AWS services e.g AWS Batch, Lambda, S3 Working with relational SQL and no-SQL databases Experience building and optimizing data pipelines, data sets and architectures Exposure to ETL pipeline building and tools  If you think this is the next exciting opportunity for you - apply today!  THIS ROLE DOES NOT PROVIDE SPONSORSHIP AND YOU MUST HAVE THE RIGHT TO WORK WITHIN THE UK  Jefferson Frank is the Amazon Web Services (AWS) & DevOps recruiter of choice. We work with organisations worldwide to find and deliver the best AWS & DevOps professionals on the planet. Backed by private equity firm TPG Growth, we have a proven track record servicing the AWS permanent and contract recruitment market and, to date, have worked with over 30,000 organisations globally from our offices in North America, Europe, and Asia-Pacific.",Sin experiencia,Jornada completa,Tecnología de la información,"Servicios y tecnologías de la información, Dotación y selección de personal, Recursos humanos",0,None,False,,5,JOB_SEEKER_QUALIFIED
910,2265041648,2020-10-17,Crowdskout,Behavioral Scientist,"Austin, TX, US","Crowdskout is a platform for advocates to create, power, and cultivate communities at local and national levels. We provide mobilization and data tools to non-profits, issue advocacy groups, electoral groups, and corporate social impact teams. We are building capabilities that live beyond a 4-year election cycle, and outside of a traditional 'Red/Blue' partisan paradigm.  We are looking for a Behavioral Scientist to join our growing Research Team. You will help Crowdskout to design, implement and analyze experiments and evidence-based interventions. As part of a cross-functional team, you will be involved in research collaborations within product, across client organizations and more broadly in society.  If you are highly motivated, super passionate about democracy, and want to join a close-knit team that is looking to build great things for regular people, Crowdskout may be for you. This is a full-time position in Durham, NC: Salt Lake City, UT: Austin TX: Washington, DC: New York City, NY, or fully remote.  Responsibilities:   Be an in-house expert in the principles and mechanisms of behavior change  Design, implement and analyze quantitative behavioral experiments (A/B tests, RCT, etc.) across Crowdskout. products and for client engagements. Work closely with User Researchers to understand user needs, goals, and experiences to create product features and content and Product Analysts to design and implement quantitative validation studies for new products and features.  Elucidate data-driven insights for product and content development for Crowdskout and clients and quickly learn from experiments to put forward new hypotheses, including identifying opportunities to improve the behavior change potential of products across the platform and organization. Conduct literature reviews and maintain up-to-date knowledge of academic research and market trends related to advocacy, civic engagement, voting, policy, campaigning, etc. Contribute to the development of quantitative survey instruments and user discussion guides  Develop behavioral and societal-level metrics and conduct appropriate statistical analysis of impact   Collaborate to develop and implement hands-on workshops, seminars, and other educational activities for Crowdskout focused on applied behavior analysis and design Improve data literacy across the organization and drive a culture of data-driven decision making   Must-haves   Deep experience in applied behavioral science: ideal candidate has a Master's Degree (or higher) in behavioral economics, experimental psychology, political science, applied behavior analysis, or closely related field 4+ years experience using evidence based behavior change interventions  Extensive training in statistical analysis and data management with demonstrated ability to use syntax-based statistical packages (e.g. R, SAS, Stata, MATLAB, etc.)  A love of experimentation and expertise with experimentation tools Excellent communication, collaboration, and interpersonal skills Strong project management skills  Nice-to-haves:    Understanding of political processes and campaign culture 2+ years proven experience working on product teams Exposure to the technical aspects of analytics, data science and data visualization software tools (Google Analytics, Mixpanel, SQL, Tableau etc.) Knowledge of technology and how to use technology and online tools in innovative ways    Crowdskout is an equal opportunity employer that encourages diversity across all spectrums in its hiring, without regard to race, gender, age, color, religion, national origin, marital status, disability, sexual orientation, or any other protected factor. With that being said, we wouldn't be able to accommodate candidates in need of work sponsorship at this time since we are a small company. If you find this role interesting and you hit on the elements above, please apply!",Algo de responsabilidad,Jornada completa,"Investigación, Análisis, Tecnología de la información","Servicios y tecnologías de la información, Software, Internet",6,None,False,,100,ACTIVELY_HIRING_COMPANY
911,2174481286,2020-10-12,Gazelle Global,Data Engineer,"Budapest, Hungary","Data Engineers are needed for a software development and software consultancy based in Poland. We're currently looking for Data Engineers at all levels to join this international team on a 6 to 12 months contract. These positions are all FULLY REMOTE, therefore you can be based anywhere as long as you are within or close to the CET time zone. The ideal Data Engineers will have the following skills and experience:4+ years of experience in Data EngineeringExperience with Python is a mustAWS and DWH experience is a must Nice to have skills:SQL Server database developmentExperience with ETL processesExta storage formats (like Parquet, ORC, etc.)Data pipelines (Luigi, Airflow, etc.)Data processing (Presto, Spark, etc.)Experience with Redshift, BigQuery, and/or SnowflakeExperience working with structured and unstructured dataExperience moving data from databases of different kinds and from external data sources What my client offers:Attractive hourly rateFlexible working hours and remote workPhone & laptop This is an amazing opportunity to work for a market leader. If interested, APPLY NOW for immediate consideration or contact me for more information at petra@gazellegc.com.",Intermedio,Jornada completa,Tecnología de la información,Servicios y tecnologías de la información,46,None,True,petra@gazellegc.com.,311,JOB_SEEKER_QUALIFIED
912,2203380344,2020-10-23,Canva,Machine Learning Engineer (Python),"Melbourne, Victoria, Australia","Designing with Canva involves making many choices, out of our incredibly large content pool of over 75M+ templates, photos, videos and elements. The Content Recommendations team is building machine learning-driven recommendations and a personalised content experience, helping to narrow down these choices, and make design easier, smarter, and more magical.  We're looking to grow the team to continue to scale the impact of recommendations across Canva. You'll be joining a fast moving team, rapidly building and shipping machine learning-driven recommendations to users, and making it effortless for users to discover the most relevant content for them. ResponsibilitiesHypothesis-driven development of recommendation features across Canva.Engineering implementation: developing and implementing ML models and features, as well as using third party APIs and pre-trained models when appropriate.Running offline and online recommendations experiments.Investigating and spiking applications of recommendations across the Canva product, considering tradeoffs between different approaches and rapidly shipping.Contributing to the full life cycle of ML/data models: data analysis, data preprocessing and pipeline, modelling, tuning and productization.Improving the scalability, speed and performance of existing models.Working alongside data specialists, software engineers and product owners to identify business and growth opportunities.Designing and creating new data workflows and deploying these workflows to users. Sharing and articulating statistical analysis, modelling, experiment and results to technical and non-technical audiences. RequirementsPrevious experience in the machine learning / data science domain.Experience building and deploying machine learning models, ideally recommendations models. Strong understanding of end-to-end machine learning pipelines and components.Coding proficiency in Python, interviews will be in Python. Experience in Scala is preferred. Strong understanding of Computer Science/Engineering fundamentals and first principles covering system design, data structures, architecture, and design patterns.Familiarity with big data tools: Apache Spark, Hadoop, MapReduce. SQL experience preferred.Strong research skills: the ability to dig through deep learning literature and translate this into product and value for users.Bachelor's degree in Computer Engineering / Science or Mathematics.Excellent collaboration and communication skills. Perks and BenefitsFlexible daily working hours, we value work-life balanceBreakfast and lunch prepared by our wonderful Vibe teamOnsite-Gym and Yoga MembershipEnd-of-Trip Facilities: Bicycle parking and showersGenerous parental (including secondary) leave policyPet-friendly officesSponsored social clubs, team events and celebrationsRelocation budget for interstate or overseas individuals (see below for visa information) Want to experience Canva for yourself?Check out what life is like at Canva on Instagram.Check out what our users are saying about us on Twitter.Learn how we work from Dave, our CTOGet to know our Chef, ChrisMeet our CEO, MelanieFinally, give Canva a go! If you're seeking professional growth and enjoy working on large, distributed, cloud-based applications that delight our millions of individual and business users alike - then apply now to be considered for the position! If you require visa sponsorship, you must ensure you have at least two (2) years of post-University commercial experience as a Software Engineer and meet the mandatory sponsorship requirements laid out by Department of Home Affairs. We will not accept or review any CVs from external recruitment agencies.",Intermedio,Jornada completa,"Tecnología de la información, Investigación","Servicios y tecnologías de la información, Software",285,None,True,,1289,COMPANY_RECRUIT
913,2231245286,2020-11-01,Branch International,Machine Learning Engineer,"San Diego, CA, US","Branch's Engineering Team builds products for customers in 4 markets and is distributed across 3 continents. Our team in the US works closely with teams in Africa and India on our existing products as well as new product initiatives. In the long term, we envision the US team as the team responsible for some of the most important foundational building blocks that enable us to rapidly build and improve products across multiple markets.  You will work closely with other Engineers, Product Managers, and Data Scientists to develop, improve, and deploy machine learning models and to solve other optimization problems. We make extensive use of machine learning in our credit product, where it is used (among other things) for underwriting and loan servicing decisions. We are also actively exploring other applications of Machine Learning in some of our newer products, with the ultimate goal of improving the user experience.  Machine Learning sits at the intersection of a number of different disciplines: Computer Science, Statistics, Operations Research, Data Science, and others. At Branch, we fundamentally believe that in order for Machine Learning to be impactful, it needs to be closely embedded into the rest of the product development and software engineering process, which is why we emphasize the importance of software engineering skills and experience for this role.  Qualifications  You excel at software engineering and programming in Python and SQL. You have 5+ years of experience working on Machine Learning systems in a production setting. You have a diverse range of data skills including experimentation, statistics, and machine learning, and have used these skills to inform business decisions. You have a keen eye for detail and a healthy skepticism for data before relying upon it. You are highly entrepreneurial. You teach yourself new skills. You take the initiative to solve problems before they arise. You know that startups are a team sport. You listen to others, speak your mind, and ask the right questions. You are a great collaborator and teacher. You are driven by making an impact on customers’ lives.  Project Examples  Credit Decisions - Core to our business is understanding and building signals from unstructured and structured data to identify good borrowers  Customer Service - Using machine learning, automate customer service interactions and provide context to our customer service team  Fraud Prevention - Identify patterns of fraudulent behavior and build models to detect and prevent these behaviors  Product Growth - Understand user experiences, test ideas, and improve conversion rates through experimentation  Paid Growth / Marketing - Use external and internal data sources to measure and optimize marketing spend  Benefits of Joining  Mission-driven and fast-paced, entrepreneurial environment  Competitive salary and equity package  99% coverage of insurance costs (health, dental, vision) Unlimited PTO Flexible working hours Discretionary trips to our offices around the globe (when it's safe to travel!) Pre-tax commuter and 401(k) programs Weekly team meals and quarterly team building events (virtual for now!) Generous child bonding leave policy  Location  We are primarily looking for candidates located (or willing to relocate to) the United States, ideally in the Pacific Time zone.  Branch International is an Equal Opportunity Employer. The company does not and will not discriminate in employment on any basis prohibited by applicable law. We’re looking for more than just qualifications -- so if you’re unsure that you meet the criteria, please do not hesitate to apply!  The salary range for this position is $190,000 - $250,000",Algo de responsabilidad,Jornada completa,Ingeniería,Software,56,None,False,,317,JOB_SEEKER_QUALIFIED
